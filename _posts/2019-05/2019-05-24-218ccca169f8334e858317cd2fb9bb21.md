---
layout:     post
catalog: true
title:      Analyzing Tweets with NLP in Minutes with Spark, Optimus and Twint
subtitle:      转载自：http://feedproxy.google.com/~r/kdnuggets-data-mining-analytics/~3/ZUx1aZMT-fs/analyzing-tweets-nlp-spark-optimus-twint.html
date:      2019-05-24
author:      Favio Vazquez
tags:
    - tweeted
    - usernames
    - bool
    - string
    - sentiment
---


  
 





---
![](https://i.ibb.co/Js5WWQb/1-Cv-Qjr-Mtg-Qh-Re-MMm-T2-ITSA.png)


 

### Introduction

 If you are here it’s likely that you are interested in analyzing tweets (or something similar) and you have a lot of them, or can get them. One of the most annoying things for that is getting a Twitter application, get the authentication and all of that. And then if you are using Pandas, there’s no way to scale that.

So what about a system that doesn’t have to authenticate with the Twitter API, that can get an unlimited (well almost) amount of tweets and the power to analyze them, with NLP and more. Well you’re in for a treat because that’s exactly what I’m going to show you right now.

 

### Getting the project and repo

 
![](https://i.ibb.co/j3BdQMb/0-An-YBOBh-V8f-KP1-S.png)




You can follow everything I’m going to show you very easily. Just forklift this MatrixDS project:

**MatrixDS | The Data Project Workbench***MatrixDS is a place to build, share and manage data projects at any scale.*community.platform.matrixds.com
![](https://i.ibb.co/vmnRj9h/1-s-Hng-X3dt1b6-T-Dc-Ec-Phc-Ew.png)


Also there’s a GitHub repo with everything:

**FavioVazquez/twitter_optimus_twint***Analyzing tweets with Twint, Optimus and Apache Spark. - FavioVazquez/twitter_optimus_twint*github.com

With MatrixDS you can actually run the notebooks, get the data and run the analysis for free, so if you want to learn more please do it.

 

### Getting Twint and Optimus

 
![](https://i.ibb.co/wCMdxz8/0-5-RGL-v-V0-Fb-WVt-S6.jpg)


Twint utilizes Twitter’s search operators to let you scrape Tweets from specific users, scrape Tweets relating to certain topics, hashtags & trends, or sort out *sensitive* information from Tweets like e-mail and phone numbers.

With Optimus, a library I co-created, you can clean your data, prepare it, analyze it, create profilers and plots, and perform machine learning and deep learning, all in a distributed fashion, because on the back-end we have Spark, TensorFlow, Sparkling Water and Keras.

So let’s first install everything you need, for that when you are in the Matrix project, go to the Analyze Tweets notebook and run (you can also do this from the JupyterLab terminal):



After that, we need to install Twint, for that run:



This will download a scr/ folder so we need to do some config:



Then to import Twint that we need to run:





and finally:



Optimus was installed in the first step, so let’s just start it (this will start a Spark cluster for you):



 

### Setup Twint for scrapping tweets

 
![](https://i.ibb.co/tLGxRSQ/0-9-LTS3-GDTtg-WTjgxa.png)






# Set up TWINT config
c = twint.Config()



If you are running this on notebooks you’ll need also to run:



 

### Search for data science tweets

 
![](https://i.ibb.co/gt4h4Vq/0-Brb-XH47ev9o-Vu-Kcr.jpg)


I’ll start our analysis scrapping tweets about data science, you can change this to whatever you want.

For doing that we just need to run this:





Let me explain this code to you. In the last section when we ran the code:



we started a new Twint configuration. After that we need to pass different options we want to scrape tweets. Here’s the full list of configuring options:



So in this code:



We are setting the search term, them formatting the response (just to check), getting only 20 tweets with the Limit =1 (they are in increments of 20) and finally making the result compatible with Pandas.Then when we run:



We are launching the search. The result is:



Doesn’t look that good but we got what we wanted. TWEETS!

 

### Saving results into Pandas

 
![](https://i.ibb.co/GsT8PvJ/0-p-VRFa-TCIPMLj-YZTy.jpg)


Sadly there’s no direct connection between Twint and Spark, but we can do it with Pandas and then pass the result to Optimus.

I created to simple functions that you can see in the actual project that helps you with Pandas and the weird Twint API for this part. So when we run this:



You’ll see:



These are the columns we have from the query we just did. There’s a lot of different things to do with this data, but for this article I’ll only use some of them. So to transform the result from Twint to Pandas we run:



and you’ll see this Pandas DF:
![](https://i.ibb.co/Nj6GQFY/1-b-Nfyvk-Kq-CQEx-CW7-O-n-Fs-Q.png)


Much better isn’t it?

 

### Sentiment Analysis (the simple way)

 
![](https://i.ibb.co/dr1TJzR/0-s-Pyjl7r-BPNXPxeo3.jpg)


We will run a sentiment analysis on some tweets, using Optimus and TextBlob a library for NLP. The first thing we need to do is clean this tweets, for that Optimus is the best choice.For saving the data as an Optimus (Spark) DF we need to run:



We’ll just remove accents and special characters with Optimus (for a real work scenario you need to do much more than this like removing links, images, and stopwords), for that:



Then we need to collect this tweets from Spark to get them in a Python list, for that:



Then to analyze the sentiment of these tweets we will use TextBlob *sentiment* function:





That will give us:



Neutral



Neutral



Positive



Neutral



Negative



Positive



Neutral



Positive



Negative



Positive



Neutral



Neutral.

And so on.

Well that was extremely easy, but it won’t scale, because in the end we are collecting the data from Spark so the driver’s RAM is the limit. Let’s do it a little better.





