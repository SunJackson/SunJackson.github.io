---
layout:     post
catalog: true
title:      Sentiment Analysis using DeepRNN Action Set
subtitle:      转载自：https://blogs.sas.com/content/subconsciousmusings/2019/05/21/sentiment-analysis-using-deeprnn-action-set/
date:      2019-05-21
author:      Patricia Neri
tags:
    - data
    - word
    - global
    - sas
    - models
---

In this blog, I use a Recurrent Neural Network (RNN) to predict whether opinions for a given review will be positive or negative. This prediction is treated as a text classification example. The Sentiment Classification Model is trained using deepRNN algorithms and the resulting model is used to predict if new reviews are positive or negative. I provide two versions of the code: one in CASL and the other one in Python but both will call the same deepRNN algorithms executed by CAS.

Machine learning is embedded in many SAS algorithms and offerings. In 2019, Gartner positioned SAS as a Leader for the sixth consecutive year for the Data Science & Machine Learning Platforms.

From Oliver Schabenberger’s post on *Advancing AI with deep learning and GPUs*:"At SAS, we have been building AI systems for decades, but a few things have changed to make today’s AI systems more powerful." … "Our advancements are not just aiming at neural networks and certain machine learning algorithms, for which GPU-specific implementations are being developed. They apply to the general mathematics that are underpinning many of our analytic tools and solutions."

**SAS Visual Text Analytics** (VTA) is the SAS offering designed to effectively extract insights from unstructured data at a large scale. It combines the power of Natural Language Processing (NLP), Machine Learning (ML) and Linguistic Rules. VTA is a web-based application built on SAS Viya™ platform and powered by CAS. Because CAS has an open architecture that supports 3rd-party programming interfaces, many Text Analytics Actions Sets can be executed from CASL, Lua, R and Python.

**Natural Language Processing** (NLP) is an exciting field with many applications. Briefly, NLP is a branch of artificial intelligence that helps computers understand, interpret and manipulate human language. NLP draws from many disciplines, including computer science and computational linguistics.

**Deep Learning** is a type of machine learning that trains a computer to perform human-like tasks, such as recognizing speech, identifying images or making predictions. **Deep Learning’s Recurrent Neural Networks** (RNNs) are specifically designed to handle sequence data, such as sentiment analysis and text categorization, automatic speech recognition, forecasting and time series, and so on. The network is recurrent because the network feedbacks into itself and makes decisions in several steps. The output for each element depends on the computations of its preceding elements. SAS Deep Learning actions support three model types: Recurrent Neural Network (RNN) the original and quite simple in architecture, Long Short-Term Memory (LSTM) and Gate Recurrent Unit (GRU). In this blog I use LSTM, because LSTM goes many steps back and uses that information to make good predictions on what will happen next.

Below there are few lines of the input dataset, we can see the title of the review and the initial part of the review itself:

![](https://blogs.sas.com/content/subconsciousmusings/files/2019/05/p0.png)


Humans use expressions such as “very good”, “excellent”, and similar expressions when we have a favorable opinion (or sentiment). These expressions “are related” to each other. Word embedding algorithms are used to automatically detect similar features for words and concepts that are related. **Word embeddings** are numeric vector representations of words trained based on large corpus. Words that are related end up getting mapped to a more similar feature vector. Popular word embeddings include Word2Vec, GloVe and FastText, and they are publicly available for download. In this blog, I use the 100-dimensions of pre-trained GloVe Word representation when training the model and when scoring the new reviews.

## Running DeepRNN in MPP

In this example, I ran DeepRNNs in a massively parallel processing (MPP) environment. Running code in an MPP environment versus a symmetric multi-processor (SMP) environment requires a bit of understanding. As Stephen Foerster mentions in his blog *Threads and CAS DATA Step*:

“CAS spreads its data and its processing over multiple machines. On each of those machines, the data is divided further into blocks, while the processing is divided further into threads. Each thread grabs a subset of the data blocks on its machine and performs the prescribed logic on that subset. The results from all of the threads are then gathered together and output.”

Now that I’ve reminded you how data is processed in an MPP environment, let’s consider RNNs where its algorithm feedbacks into itself and makes decisions in several steps. For the analyst who is accustomed to getting identical runs each and every time, consider the MPP environment:

- **Global data ordering**. Each time you load your data when you have multiple workers, there is no guarantee that the data will be distributed across workers in the same fashion.

- **Local data ordering**. When multiple threads are used, there is no guarantee that data will be read in a specified order by a particular worker.

- **Worker communication**. Part of this communication may involve a global summing operation. There is no guarantee that the sum will be performed in the same order each time. Since we are using floating point arithmetic, even tiny differences for initial computations can manifest as significant differences in later computations when we do training. This effect is compounded for RNN models because there are many more backpropagation steps for such models compared to either CNN or DNN models.

- **Order of computation matters**. Assume that your data consists of three mini-batches. You will get different final weights after one pass through your data if you process mini-batch 0, then 1, and then 2 versus mini-batch 2, then 0, and then 1.


Therefore, it is highly recommended that you load your data to a global caslib and run your RNNs from using that data. At least all of the analysts will be using the same global data ordering.

## Implementation

Both implementations shown below, one in CASL and the other in Python, use global tables that were loaded to the caslib “ANALYTIC” which is a global library in our GEL MPP collection. This MPP environment has 5 servers: one controller and 4 workers, 4 cores per server for a total of 20 cores.

First, I created global tables to be used in both the CASL and the Python programs. See both programs in the Code section below.

### CASL code main steps:
