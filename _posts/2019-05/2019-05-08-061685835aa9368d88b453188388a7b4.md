---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/05/08/distilled-news-1058/
date:      2019-05-08
author:      Michael Laux
tags:
    - machine learning
    - datasets
    - images
    - recognition
    - landmarks
---

**Linear programming and discrete optimization with Python using PuLP**

Linear and integer programming are key techniques for discrete optimization problems and they pop up pretty much everywhere in modern business and technology sectors. We will discuss how to tackle such problems using Python library PuLP and get a fast and robust solution.

**Moving AI from PoC Stage to Production**

After several AI projects, I realized that many PoCs fail to reach the production stage and only a few make it to the release stage. In 2019, many companies have begun applying AI solutions with impressive results but only a few have developed full-scale AI capabilities that bring a real added value to the company. Based on my experience, less than 20% of ML PoCs projects make it to production and if they succeed, an important number of them might fail during the ‘industrialization’ of your AI solution.

**Announcing Google-Landmarks-v2: An Improved Dataset for Landmark Recognition & Retrieval**

Last year we released Google-Landmarks, the largest world-wide landmark recognition dataset available at that time. In order to foster advancements in research on instance-level recognition (recognizing specific instances of objects, e.g. distinguishing Niagara Falls from just any waterfall) and image retrieval (matching a specific object in an input image to all other instances of that object in a catalog of reference images), we also hosted two Kaggle challenges, Landmark Recognition 2018 and Landmark Retrieval 2018, in which more than 500 teams of researchers and machine learning (ML) enthusiasts participated. However, both instance recognition and image retrieval methods require ever larger datasets in both the number of images and the variety of landmarks in order to train better and more robust systems. In support of this goal, this year we are releasing Google-Landmarks-v2, a completely new, even larger landmark recognition dataset that includes over 5 million images (2x that of the first release) of more than 200 thousand different landmarks (an increase of 7x). Due to the difference in scale, this dataset is much more diverse and creates even greater challenges for state-of-the-art instance recognition approaches. Based on this new dataset, we are also announcing two new Kaggle challenges – Landmark Recognition 2019 and Landmark Retrieval 2019 – and releasing the source code and model for Detect-to-Retrieve, a novel image representation suitable for retrieval of specific object instances.

**Bring your Jupyter Notebook to life with interactive widgets**

Traditionally, every time you need to modify the output of your notebook cells, you need to change the code and rerun the affected cells. This can be cumbersome, inefficient and error prone and in the case of a non-technical user it may even be impracticable. This is where the ipywidgets come into play: they can be embedded in the notebook and provide a user friendly interface to collect the user input and see the impact the changes have on the data/results, without having to interact with the code; your notebooks can be transformed from static documents to dynamic dashboards – ideal for showcasing your data story!

**Understanding when Simple and Multiple Linear Regression give Different Results**

Simple and multiple linear regression are often the first models used to investigate relationships in data. If you play around with them for long enough you’ll eventually realize they can give different results. Relationships that are significant when using simple linear regression may no longer be when using multiple linear regression and vice-versa, insignificant relationships in simple linear regression may become significant in multiple linear regression. Realizing why this may occur will go a long way towards improving your understanding of what’s going on under-the-hood of linear regression.

**Five Methods to Debug your Neural Network**

A lot of us trying to understand the Machine Learning Algorithms, but sometimes we have some time we faced bugging problem in our algorithm and that what we are going to find out how to debug your Neural Network. This article is short but well documented about the debugging process. So, I expect all of you know what Neural Network is and how it is work. But I’m still going to talk a little bit about the Neural Network, and you can skip this part if you are familiar with Neural Network Concepts.

**Towards Well Being, with Data Science (part 2)**

Now… where were we? L ast time, we left off at visualizing the data with matplotlib. We also covered some introductory material, explored the data on a surface level, and started a deeper analysis with the help of visualization. We noticed there were 6 different features that we could analyze but we decided to focus on ‘steps’ since it is more measurable and interesting. In part 2 of Towards Well-Being, with Data Science we are going to pick up where we left off and continue our journey to tackle C Analysis and Plotting (continued) ,D. Testing, and E. Conclusion.

**Towards Well-Being, with Data Science (part 1)**

I use my Apple Health data to measure my current state and set future fitness goals. O ver the last few weeks, I have been curious on how I could use data within my own life. On my day job, I use data to help make better decisions in a corporate setting so I figured, why not use data currently available to me to set metrics and targets for a healthier living? In these series, I will go through A. Introduction, B. Exploring the Data C. Analysis & Plotting, D. Testing, and E. Conclusion.

**How can artificial intelligence become curious?**

Many people get interested into Machine Learning (or Artificial Intelligence as a more general field of study) by some extraordinary plots presented in books, movies and tv series. It is indeed very fascinating to study and implement algorithms that can specialize and outperform humans in solving many tasks. However, when it comes to the majority of the problems we usually deal with, it feels we are far away from the intelligent entities present in Azimov stories and Terminator movies. In the reality there is no publicly available information about an artificial intelligence created with the necessary complexity to get conscious and able to willingly start doing things on its own. So, what is missing for us to reach that level of artificial intelligence? The answer is not simple, but I would say most of machine learning approaches are too dependent on the human supervision. For supervised learning big datasets with manual classified examples must be provided whereas in reinforcement learning the agent is highly dependent on the reward function. In that sense those algorithms are strongly tied to the tasks they were programmed to solve. But how to make a system able to learn without explicitly programming it? One alternative is to make this system curious about novel things.

**Extreme Rare Event Classification using Autoencoders in Keras**

In a rare-event problem, we have an unbalanced dataset. Meaning, we have fewer positively labeled samples than negative. In a typical rare-event problem, the positively labeled data are around 5-10% of the total. In an extreme rare event problem, we have less than 1% positively labeled data. For example, in the dataset used here it is around 0.6%. Such extreme rare event problems are quite common in the real-world, for example, sheet-breaks and machine failure in manufacturing, clicks or purchase in an online industry. Classifying these rare events is quite challenging. Recently, Deep Learning has been quite extensively used for classification. However, the small number of positively labeled samples prohibits Deep Learning application. No matter how large the data, the use of Deep Learning gets limited by the amount of positively labeled samples.

**Building Data Science Capabilities Means Playing the Long Game**

Are you frustrated with the challenge of finding and retaining data science hires who don’t require a lot of time and investment to develop? You’re not alone. Weariness from the ongoing data science talent shortage was recently expressed to me at a machine learning conference. An executive from a well-known data-driven corporation lamented that he just couldn’t find ‘good data science people who he wouldn’t have to spend a ton of time training’. His perspective was understandable. This company has been investing in data science capabilities for years, well ahead of its competitors, and is still struggling to find and develop seasoned data science talent.

**Sequence Embedding for Clustering and Classification**

Sequence modeling has been a challenge. This is because of the inherent un-structuredness of sequence data. Just like texts in Natural Language Processing (NLP), sequences are arbitrary strings. For a computer these strings have no meaning. As a result, building a data mining model is difficult. For texts, we have come up with embeddings, such as word2vec, that converts a word into a n-dimensional vector. Essentially, bringing it in a Euclidean space. In this post, we will learn to do the same for sequences. Here we will go over an approach to create embeddings for sequences that brings a sequence in a Euclidean space. With these embeddings, we can perform conventional Machine Learning and Deep Learning, e.g. kmeans, PCA, and Multi-Layer Perceptron on sequence datasets. We provide and work on two datasets – protein sequences and weblogs.

**Introduction to Transfer Learning**

Recipe – To get started begin by ploughing the land to prepare it for sowing the seeds. Sow the corn, wheat, apple and Cinnamon seeds. Wait for few years and watch them grow, keep watering and adding fertilizers to get a good quality produce. After the corn, wheat and apples are ripe harvest them and don’t forget to pick the bark of cinnamon trees. Get the corn and process it to make sugar meanwhile also mill and grind the wheat to make flour. Boil the saline water at medium heat until the whole water is evaporated and only salt remains. You can also start milking the cow to make the butter. Once your hen has laid eggs and you have made the butter from the cow’s milk you are all set to move to your kitchen to make the pie. Sounds like a crazy apple pie recipe isn’t it?

**Current Trends in Deep Learning**

In the last decade, the area of artificial intelligence (AI) has exploded with interesting and promising results. With major achievements in image recognition, speech recognition and highly complex games, AI continues to disrupt society. This blog post will discuss practical applications of AI, optimization and interpretability of deep learning models and reinforcement learning (RL), based on the 2018 REWORK Deep Learning Summit in Toronto. Four software engineers from Knowit had the pleasure of travelling to Canada to attend this conference, and with renowned speakers such as Geoff Hinton attending, it turned out be an insightful experience.

**Distributed training of Deep Learning models with PyTorch**

The motive of this article is to demonstrate the idea of Distributed Computing in the context of training large scale Deep Learning (DL) models. In particular, the article first presents the basic concepts of distributed computing and how it fits into the idea of Deep learning. Then it moves on to listing the standard requirements (hardware and software) for setting up an environment capable of handling distributed applications. Finally, to provide a hands-on experience, it demonstrates a specific distributed algorithm (namely Synchronous SGD) for training DL models from a theoretical as well as implementation perspective.





### Like this:

Like Loading...


*Related*

