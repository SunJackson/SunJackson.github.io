---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/05/17/distilled-news-1069/
date:      2019-05-16
author:      Michael Laux
tags:
    - data
    - machines
    - networks
    - classification
    - build deep learning models
---

**Simple Neural Network Model Using TensorFlow Eager Execution**

Eager Execution is a nifty approach in TensorFlow (TF) to build deep learning models from scratch. It allows you to build prototype models without the hassles that come with the graphical approach that TF uses conventionally. For example, with Eager Execution, there is no need to start a graph session in order to perform tensor computations. This means faster debugging, as you could check each line of computation on-the-fly without needing to wrap the computation in a graph session. As a disclaimer, however, using Eager Execution requires some knowledge on the matrix algebra concepts used in deep learning, particularly on how forward passes are done in a neural network. If you are looking for something more high-level and ready for use, I would advise using the Keras API in TF or PyTorch instead. This article will provide an example of how Eager Execution can be used, by describing the procedure to build, train and evaluate a simple Multilayer Perceptron.

**The Upcoming Revolution in Predictive Analytics (And Data Science)**

Quite literally, I am stunned. I have just completed my survey of data (from articles, blogs, white papers, university websites, curated tech websites, and research papers all available online) about predictive analytics. And I have a reason to believe that we are standing on the brink of a revolution that will transform everything we know about data science and predictive analytics.

**Logistic regression as a neural network**

As a teacher of Data Science (Data Science for Internet of Things course at the University of Oxford), I am always fascinated in cross connection between concepts. I noticed an interesting image on Tess Fernandez slideshare (which I very much recommend you follow) which talked of Logistic Regression as a neural network.

**Deep learning: the final frontier for signal processing and time series analysis?**

People use deep learning almost for everything today, and the ‘sexiest’ areas of applications are computer vision, natural language processing, speech and audio analysis, recommender systems and predictive analytics. But there is also one field that is unfairly forgotten in terms of machine learning – signal processing (and, of course, time series analysis). In this article, I want to show several areas where signals or time series are vital, after I will briefly review classical approaches and will move on to my experience with applying deep learning for biosignal analysis in Mawi Solutions and for algorithmic trading. I already gave a couple of talks on this topic in Barcelona and Lviv, but I would like to make the materials a bit more accessible.

**Make it explainable!**

Most people make the mistake of thinking design is what it looks like… People think it’s this veneer – that the designers are handed this box and told, ‘Make it look good!’ That’s not what we think design is. It’s not just what it looks like and feels like. Design is how it works.’ (Steve Jobs, The New York Times, 2003). Same goes with interpretable machine learning. Recently, I am talking a lot about interpretations and explainability. And sometimes I got impression that techniques like SHAP, Break Down, LIME, SAFE are treated like magical incantations that converts complex predictive models into ‘something interpretable’.

**Using Ant Colony and Genetic Evolution to Optimize Ride-Sharing Trip Duration**

Urban transportation is going through a rapid and significant evolution. Since the birth of the Internet and smartphones, we have become increasingly connected and are able to plan and optimize our daily commute. Along with that, large amounts of data are gathered and used to improve the efficiency of existing transportation systems. Real-time ride-sharing companies such as Uber and Lyft are using this data to revolutionize the taxi industry, laying the ground for a more connected and centrally controlled transportation structure, and building innovative systems like car-pooling. In this project, I tackled the travel time optimization problem for taxi vehicles. This can be framed as the Traveling Salesman Problem, a well-known computer science problem. The objective is to find the shortest route that visits a set of locations. For this problem, optimization techniques are required to intelligently search the solution space and find near-optimal solutions. More specifically, I first used machine learning to forecast travel times between every pair of pickup and dropoff locations. Then I used evolutionary algorithms, namely ant colony and genetic, to find the best travel itinerary for the vehicles in the dataset.

**GANs vs. Autoencoders: Comparison of Deep Generative Models**

Want to turn horses into zebras? Make DIY anime characters or celebrities? Generative adversarial networks (GANs) are your new best friend.

**Introduction to Machine Learning Model Interpretation**

Regardless of what problem you are solving an interpretable model will always be preferred because both the end-user and your boss/co-workers can understand what your model is really doing. Model Interpretability also helps you debug your model by giving you a chance to see what the model really thinks is important. Furthermore, you can use interpretable models to combat the common believe that Machine Learning algorithms are black boxes and that we humans aren’t capable of gaining any insights on how they work. This article is the first in my series of articles aimed to explain the different methods of how we can achieve explainable machine learning/artificial intelligence.

**The basics of Deep Neural Networks**

With the rise of libraries such as Tensorflow 2.0 and Fastai, implementing deep learning has become accessible to so many more people and it helps to understand the fundamentals behind deep neural networks. Hopefully this article will be of help people to people on the path of learning about deep neural networks. Back when I first learnt about neural nets and implemented my first, they were always represented as individual artificial neurons, essentially nodes with individually weighted inputs, a summed output and an activation function. When first returning into learning about deep neural networks, the concept of how this equated to matrix multiplication didn’t appear obvious. Also, linked to this is why Graphics Processing Units (GPUs) and their spin-offs have helped advance deep learning results so much.

**How To Create Simple Keyword-based Movie Recommender Models From Scratch**

Have you ever tried to use a movie recommender? In theory, it is something useful that can help figure out what to watch next instead of browsing through Netflix for a few hours, but their results tend to be hit-or-miss. This is a problem that most people can relate to, so I decided to create a homemade recommender system myself and share it in this blog post. I will show you how to create 3 simple recommender models from scratch that accept a movie as input and return the ‘n’ most similar movies as output, with ‘n’ being provided by the user. In general, recommender systems are either content-based or collaborative with the user’s history and interests. I chose to create content-based models since they make predictions based on the specific input item (movie) and not based on the user.

**Generating Text with TensorFlow 2.0**

At work, I spend most of my time working with tabular data, so branching out into adjacent machine learning areas helps broaden my horizons and identify potential applications… Last year, I had to delve into computer vision in order to complete Microsoft’s Professional Development Program in AI final project, and this year I decided to start with learning more about text generation. I chose Iliad as my training text, hence the picture of Acropolis above. While I also implemented the Recurrent Neural Network (RNN) text generation models in PyTorch, Keras (with TensorFlow back-end), and TensorFlow, I find the arrival of TensorFlow 2.0 very exciting and promising for the future of machine learning, so will focus on this framework in the article.

**Faster Way to Slice Dataframe by Row**

When we’d like to slice a dataframe by row, we can employ the split() function or the iter() function in the iterators package. By leveraging the power of parallelism, I wrote an utility function slice() to faster slice the dataframe. In the example shown below, the slice() is 3 times more efficient than the split() or the iter() to select 2 records out of 5,960 rows.

**The Myth of the Impartial Machine**

Wide-ranging applications of data science bring utopian proposals of a world free from bias, but in reality, machine learning models reproduce the inequalities that shape the data they’re fed. Can programmers free their models from prejudice?

**Data Mining Using Pseudo-Cellular Automata with Update Rules based on Local Gradients**

Classification is a type of supervised learning analyzing data based on features. Classification algorithms categorize data-points and often make decisions based on those categorizations. Among the popular data classification techniques are Neural Networks, K Nearest Neighbors, Naïve Bayes Algorithm, and Support Vector Machines. These methods are applicable to a wide array of problems in a variety of fields including analysis of text, multimedia, social networks, and biological data. Therefore, these methods are valuable data mining tools. One technique not commonly used for data classification is cellular automation. Cellular automation simulations could be used to ‘grow’ classification regions, which could prove helpful when data can only be separated into categories using complicated, nonlinear boundaries. A simple form of using cellular automation as a data mining tool was introduced in a paper by Fawcett in which local decisions are shown to viably define overall classification for specific two-dimensional datasets. However, the design of this cellular automation is kept simple, which can lead to inaccuracies when there is not a very clear separation between data-points that belong to different classes. Additionally, Multiple Attractor Cellular Automata (MACA) have gained attention as potential classifiers for bioinformatics problems. This method relies on genetic algorithms to create a system of states that can be used to categorize data. However, this process involves many components with an abundant amount of underlying theory. In this paper, a pseudo-cellular automation approach for classifying data is purposed which seeks to bridge the gap between classifier accuracy, practical implementation and complexity of theory.

**ExperTwin: An Alter Ego in Cyberspace for Knowledge Workers**

Even though the advent of the Web coupled with powerful search engines has empowered the knowledge workers to quickly find the needed information, it still is a time-consuming operation. Presently there are no readily available tools that can create and maintain an up-to-date personal knowledge base that can be readily consulted when needed. While organizing the entire Web as a semantic network is a long-term goal, creation of a semantic network of personal knowledge sources that are continuously updated by crawlers and other devices is an attainable task. We created an app titled ExperTwin, that collects personally relevant knowledge units (known as JANs) from the Web, Email correspondence, and locally stored files, organize them as a semantic network that can be easily queried and visualized in many formats – just in time – when performing a knowledge-based task. The architecture of ExperTwin is based on the model of a ‘Society of Intelligent Agents’, where each agent is responsible for a specific task. Collection of JANs from multiple sources, establishing the relevancy, and creation of the personal semantic network are some of the many tasks performed by the individual agents. Tensorflow and Natural Language Processing (NLP) tools have been implemented to let ExperTwin learn from users. Document the design and deployment of ExperTwin as a ‘Knowledge Advantage Machine’ able to search for relevant information while performing a knowledge-based task, is the main goal of the research presented in this post.





### Like this:

Like Loading...


*Related*

