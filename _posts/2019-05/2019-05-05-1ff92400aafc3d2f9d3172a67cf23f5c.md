---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/05/05/distilled-news-1055/
date:      2019-05-05
author:      Michael Laux
tags:
    - data
    - learning
    - learned
    - models
    - modeling
---

**Mitigating Risk of Machine Learning**

When something went wrong with your machine learning application, often the problems and risk created will trouble you more than the cause. According to Mckinsey, the following factors can contribute to the risk of your ML application• Data Difficulties• Technology Troubles• Security Snags• Models Misbehaving• Interaction IssuesWe commonly have validation frameworks in place to mitigate the risk associated with high profile applications. Deliberate modification of the existing validation frameworks can help to moderate the risk associated with complex machine learning, but frequently these are proved futile to tackle down the hurdles a machine learning application put forth.

**Five Machine Learning Paradoxes that will Change the Way You Think About Data**

• The Simpson’s Paradox• The Braess’s Paradox• The Moravec’s Paradox• The Accuracy Paradox• The Learnability-Godel Paradox

**Availability of Microsoft R Open 3.5.2 and 3.5.3**

It’s taken a little bit longer than usual, but Microsoft R Open 3.5.2 (MRO) is now available for download for Windows and Linux. This update is based on R 3.5.2, and accordingly fixes a few minor bugs compared to MRO 3.5.1. The main change you will note is that new CRAN packages released since R 3.5.1 can now be used with this version of MRO. Microsoft R Open 3.5.3, based on R 3.5.3, will be available next week, on May 10. Microsoft R Open 3.6.0, based on the recently-released R 3.6.0, is currently under development, and we’ll make an announcement here when it’s available too. One thing to note: as of version 3.5.2 Microsoft R Open is no longer distributed for MacOS systems. If you want to continue to take advantage of the Accelerate framework on MacOS for, it’s not too difficult to tweak the CRAN binary for MacOS to enable multi-threaded computing, and the additional open source bundled packages (like checkpoint and iterators) are available to install from CRAN or GitHub.

**Build your own Whatsapp Chat Analyzer**

Recently, after working on a number of projects from Udacity’s courses, I was on the look out for new, familiar data to analyze and what better place to start than one’s own phone. Whatsapp claims that nearly 55 billion messages are sent each day. The average user spends 195 minutes per week on Whatsapp, and is a member of plenty of groups.

**What to Tell Your Board About AI/ML**

Communicating with your Board of Directors about AI/ML is different from conversations with top operating executive. It’s increasingly likely your Board will want to know more and planning that communication in advance will make your presentation more successful.

**Parallel and Distributed Deep Learning: A Survey**

Deep learning is the hottest field in AI right now. From Google Duplex assistant to Tesla self- driving cars the applications are endless. The goal of this article is to explain briefly what deep learning is and to show that it has quickly evolved from a scientific curiosity to the solution to a broad and deep range of problems. And the complexity of these problems, the high availability of data and computer power has led deep learning to the high performance computing world at a point where both are now tightly coupled.

**Reinforcement Learning – A conceptual introduction**

As described in a previous post, Reinforcement Learning is the topic in Artificial Intelligence that interests me the most. Even not being a computer scientist, it matches really well with my background, and the concept itself is quite fascinating. In this post I will try to give a nice initial picture for those who want to know more about RL.

**Overview of the different approaches to putting Machine Learning (ML) models in production**

There are different approaches to putting models into productions, with benefits that can vary dependent on the specific use case. Take for example the use case of churn prediction, there is value in having a static value already that can easily be looked up when someone call a customer service, but there is some extra value that could be gained if for specific events, the model could be re-run with the newly acquired information. There is generally different ways to both train and server models into production: •Train: one off, batch and real-time/online training •Serve: Batch, Realtime (Database Trigger, Pub/Sub, web-service, inApp) Each approach having its own set of benefits and tradeoffs that need to be considered.

**Dynamic Modeling, Parameter Estimation, and Uncertainty Analysis in R**

In a wide variety of research fields, dynamic modeling is employed as an instrument to learn and understand complex systems. The differential equations involved in this process are usually non-linear and depend on many parameters whose values determine the characteristics of the emergent system. The inverse problem, i.e., the inference or estimation of parameter values from observed data, is of interest from two points of view. First, the existence point of view, dealing with the question whether the system is able to reproduce the observed dynamics for any parameter values. Second, the identifiability point of view, investigating invariance of the prediction under change of parameter values, as well as the quantification of parameter uncertainty. In this paper, we present the R package dMod providing a framework for dealing with the inverse problem in dynamic systems modeled by ordinary differential equations. The uniqueness of the approach taken by dMod is to provide and propagate accurate derivatives computed from symbolic expressions wherever possible. This derivative information highly supports the convergence of optimization routines and enhances their numerical stability, a requirement for the applicability of sophisticated uncertainty analysis methods. Computational efficiency is achieved by automatic generation and execution of C code. The framework is object-oriented (S3) and provides a variety of functions to set up ordinary differential equation models, observation functions and parameter transformations for multi-conditional parameter estimation. The key elements of the framework and the methodology implemented in dMod are highlighted by an application on a three-compartment transporter model.

**Relaunching the qualtRics package**

rOpenSci is one of the first organizations in the R community I ever interacted with, when I participated in the 2016 rOpenSci unconf. I have since reviewed several rOpenSci packages and been so happy to be connected to this community, but I have never submitted or maintained a package myself. All that changed when I heard the call for a new maintainer for the qualtRics package. ‘IT’S GO TIME,’ I thought. ?? Qualtrics is an online survey and data collection software platform. Qualtrics is used across many domains in both academia and industry for online surveys and research, including by me at my day job as a data scientist at Stack Overflow. While users can manually download survey responses from Qualtrics through a browser, importing this data into R is then cumbersome. The qualtRics R package implements the retrieval of survey data using the Qualtrics API and aims to reduce the pre-processing steps needed in analyzing such surveys. This package has been a huge help to me in my real day-to-day work, and I have been so grateful for the excellent work of the package’s original authors, including the previous maintainer Jasper Ginn. This package is currently the only package on CRAN that offers functionality like this for Qualtrics’ API, and is included in the official Qualtrics API documentation.

**Deep learning Data Sets for Every Data Scientist**

Machine Learning has seen a tremendous rise in the last decade, and one of its sub-fields which has contributed largely to its growth is Deep Learning. The large volumes of data and the huge computation power that modern system possess has given Data Scientist, Machine Learning Engineers, and others to achieve ground-breaking results in the Deep Learning and continue to bring in new developments in this field. In this blog post, we would cover the deep learning data sets that you could work with as a Data Scientist but before that, we would provide an intuition about the concept of Deep Learning.

**AI Series: A walk into the theory of learning.**

The statistical learning theory, one of the most beautifully developed branches of artificial intelligence, provides us with the theoretical basis for many of today’s machine learning algorithms. It also attempts a philosophical approach trying to identify the fundamental element which underpins the process of drawing valid conclusions from empirical data. In machine learning as a matter of fact, the target function which maps the data from an input domain to the corresponding data in the output domain, is unknown. If it was known, we would not need any learning at all and we would just need to implement it. The basic premise of learning is to use a set of observation to uncover an underlying process. In machine learning the objective is to find a function which approximate the target function learning it from finite sets of sample data. Looking at the problem from a supervised learning perspective, our challenge involves learning from a training set of labelled data. Every point in the training set is an input-output pair, where the input maps to a known output. The learning problem consists of finding the best algorithm able to capture the unknown governing rules that are implicitly described by the distribution of the sample data pairs and build a hypothetical function that, approximating the target function, can be used to predict output from future, unknown input. The performances of the learned model, or generalization performances, are measured in terms of percentage of accuracy of its prediction on independent test data.

**Everything You Need to Know About Autoencoders in TensorFlow**

Autoencoders are artificial neural networks that can learn from an unlabeled training set. This may be dubbed as unsupervised deep learning. They can be used for either dimensionality reduction or as a generative model, meaning that they can generate new data from input data. In this post, different types of autoencoders and their applications will be introduced and implemented with TensorFlow. All the code is available in a Github repo. Fire up your notebook, and let’s get to it!

**If it’s interpretable it’s pretty much useless.**

Some days ago I was interviewing a candidate for a data-related position: after a couple of technical questions I asked him what algorithm he would have used to have a reliable starting point for a random classification problem. I was just curious to understand how used he was in doing some data science and if he knew some state-of-the-art algorithms and techniques. He told me that he would have gone with a simple decision tree because it’s somehow easy to explain and interpret. That answer surprised me a little: I mean, why a decision tree in 2019 when you can get way better and, above all, more robust results using more advanced algorithms? As always happens, once you notice something you see it everywhere, and from that day I keep seeing and reading here and there blog posts about interpretability, explicability and how all of these concepts are connected to machine learning and trust. I disagree with pretty much all of them.

**Normalization vs Standardization – Quantitative analysis**

Every ML practitioner knows that feature scaling is an important issue. The two most discussed scaling methods are Normalization and Standardization. Normalization typically means rescales the values into a range of [0,1]. Standardization typically means rescales data to have a mean of 0 and a standard deviation of 1 (unit variance). In this blog, I conducted a few experiments and hope to answer questions like:1. Should we always scale our features?2. Is there a single best scaling technique?3. How different scaling techniques affect different classifiers?4. Should we consider scaling technique as an important hyperparameter of our model?I’ll analyze the empirical results of applying different scaling methods on features in multiple experiments settings.

**Principles and Techniques of Data Science**

Combining data, computation, and inferential thinking, data science is redefining how people and organizations solve challenging problems and understand their world. This intermediate level class bridges between Data8 and upper division computer science and statistics courses as well as methods courses in other fields. In this class, we explore key areas of data science including question formulation, data collection and cleaning, visualization, statistical inference, predictive modeling, and decision making.? Through a strong emphasizes on data centric computing, quantitative critical thinking, and exploratory data analysis this class covers key principles and techniques of data science. These include languages for transforming, querying and analyzing data; algorithms for machine learning methods including regression, classification and clustering; principles behind creating informative data visualizations; statistical concepts of measurement error and prediction; and techniques for scalable data processing.





### Like this:

Like Loading...


*Related*

