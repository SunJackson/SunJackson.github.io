---
layout:     post
catalog: true
title:      Python数据分析之pandas
subtitle:      转载自：https://www.jiqizhixin.com/articles/2018-07-18-3
date:      2018-07-18
author:      wengJJ
category:      Python
tags:
    - series
    - dataframe
    - python
    - 数据
    - data
---

---

前面一篇文章我们介绍了numpy，但numpy的特长并不是在于数据处理，而是在它能非常方便地实现科学计算，所以我们日常对数据进行处理时用的numpy情况并不是很多，我们需要处理的数据一般都是带有列标签和index索引的，而numpy并不支持这些，这时我们就需要pandas上场啦！ 
## WHAT?
---

**Pandas**是基于**Numpy**构建的库，在数据处理方面可以把它理解为numpy加强版，同时Pandas也是一项开源项目：Github 。不同于numpy的是，pandas拥有种数据结构：**Series**和**DataFrame**： 
**下面我们就来生成一个简单的series对象来方便理解：** 
Series是一种类似一维数组的数据结构，由一组数据和与之相关的index组成，这个结构一看似乎与dict字典差不多，我们知道字典是一种**无序**的数据结构，而pandas中的Series的数据结构不一样，它相当于**定长有序**的字典，并且它的**index和value**之间是**独立**的，两者的索引还是有区别的，Series的**index**是**可变**的，而**dict**字典的**key**值是不可变的。
**下面照例生成一个简单的DataFrame对象：**
DataFrame这种数据结构我们可以把它看作是一张二维表，DataFrame长得跟我们平时使用的Excel表格差不多，DataFrame的横行称为**columns**，竖列和Series一样称为**index**，DataFrame每一列可以是不同类型的值集合，所以DataFrame你也可以把它视为不同数据类型同一index的Series集合。
---

科学计算方面numpy是优势，但在数据处理方面DataFrame就更胜一筹了，事实上DataFrame已经覆盖了一部分的数据操作了，对于数据挖掘来说，工作可大概分为读取数据-数据清洗-分析建模-结果展示：
先说说**读取数据**，Pandas提供强大的IO读取工具，csv格式、Excel文件、数据库等都可以非常简便地读取，对于大数据，pandas也支持大文件的分块读取；
接下来就是**数据清洗**，面对数据集，我们遇到最多的情况就是存在缺失值，Pandas把各种类型数据类型的缺失值统一称为NaN（这里要多说几句，None==None这个结果是true，但np.nan==np.nan这个结果是false，NaN在官方文档中定义的是float类型，有关于NaN和None的区别以及使用，有位博主已经做好整理：None vs NaN
最重要的**分析建模**阶段，Pandas自动且明确的数据对齐特性，非常方便地使新的对象可以正确地与一组标签对齐，有了这个特性，Pandas就可以非常方便地将数据集进行拆分-重组操作。
最后就是**结果展示**阶段了，我们都知道Matplotlib是个数据视图化的好工具，Pandas与Matplotlib搭配，不用复杂的代码，就可以生成多种多样的数据视图。
---

## Series
**Series的两种生成方式：**
虽然我们在生成的时候没有设置index值，但Series还是会自动帮我们生成index，这种方式生成的Series结构跟list列表差不多，可以把这种形式的Series理解为竖起来的list列表。
这种形式的Series可以理解为numpy的array外面披了一件index的马甲，所以array的相关操作，Series同样也是支持的。结构非常相似的**dict字典同样也是可以转化为Series格式的**：
**查看Series的相关信息：**
**Series的NaN生成：**
从这里我们可以看出Series的生成依据的是**index值**，index‘a’在字典dic的key中并不存在，Series自然也找不到’a’的对应value值，这种情况下Pandas就会自动生成**NaN(not a number)**来填补缺失值，这里还有个有趣的现象，原本dtype是int类型，生成NaN后就变成了float类型了，因为NaN的官方定义就是**float类型**。
**NaN的相关查询：**
切记切记，查询NaN值切记不要使用np.nan==np.nan这种形式来作为判断条件，结果永远是False，==是用作**值判断**的，而NaN并没有值，如果你不想使用上方的判断方法，你可以使用is作为判断方法，**is**是**对象引用判断**，**np.nan is np.nan**，结果就是你要的True。
**Series自动对齐：**
从上面两个Series中不难看出各自的index所处位置并不完全相同，这时Series的**自动对齐**特性就发挥作用了，在算术运算中，Series会自动寻找匹配的**index值**进行运算，如果index不存在匹配则自动赋予NaN,值得注意的是，**任何数+NaN=NaN**,你可以把NaN理解为吸收一切的黑洞。
**Series的name属性：**
Series**对象本身**及其**索引index**都有一个**name属性**，name属性主要发挥作用是在**DataFrame**中，当我们把一个Series对象放进DataFrame中，新的列将根据我们的name属性对该列进行命名，如果我们没有给Series命名，DataFrame则会自动帮我们命名为**0**。

## DataFrame
**DataFrame的生成：**
DataFrame的生成与Series差不多，你可以自己指定index，也可不指定，DataFrame会自动帮你补上。
**查看DataFrame的相关信息：**
**DataFrame的索引：**
其实行索引，除了iloc，loc还有个**ix**，**ix**既可以进行**行标签索引**，也可以进行**行号索引**，但这也大大增加了它的不确定性，有时会出现一些奇怪的问题，所以pandas在0.20.0版本的时候就把ix给弃用了。
**DataFrame的常用操作：**
**简单地增加行、列：**
**删除行、列操作：**
这里需要注意的是，使用**drop（）方法**返回的是**Copy**而不是**视图**，要想真正在原数据里删除行，就要设置***inplace=True***：
**设置某一列为index：**
**处理缺失值：**
还是需要注意：**这些方法返回的是copy而不是视图，如果想在原数据上改变，别忘了*****inplace=True***。
**数据合并：**
平时进行数据合并操作，更多的会出一种情况，那就是出现**重复值**，DataFrame也为我们提供了简便的方法：
data.drop_duplicates(inplace=True)
**数据的简单保存与读取：**
为什么会出现这种情况呢，从头看到尾的同学可能就看出来了，增加第三行时，我用的是**loc[‘3’]行标签**来增加的，而**read_csv方法是默认index是从0开始增长的**，此时只需要我们设置下index参数就ok了：
其他的还有**header**参数，这些参数都是我们在保存数据时需要注意的。
---

pandas的操作和方法肯定远远不止于这些，查看这些方法最好的方法就是查看官方文档，pandas还有许多强大有用的方法，例如大数据读取，时间序列等等，这些就靠大家自己去pandas官方文档好好挖掘了。
 
**才学疏浅，欢迎评论指导**
参考资料：
Liu Lixiang的博客
YXiao’s Blog
极客学院-《从零开始学Python-第二版》
Pandas 0.23.0官方文档

