---
layout:     post
title:      Whats new on arXiv
subtitle:   转载自：https://advanceddataanalytics.net/2018/07/21/whats-new-on-arxiv-714/
date:       2018-07-21
author:     Michael Laux
header-img: img/background0.jpg
catalog: true
tags:
    - http
    - modeling
    - models
    - imaging
    - images
    - learning
    - learns
    - algorithms
    - approaches
    - networks
    - graphs
    - architectures
    - proposed based
    - word
    - informational
    - scale
    - scaling
    - optimization
    - optimize
    - optimal
    - semantically related
    - approximations
    - approximate
    - prediction
    - predictable
    - consumers
    - efficiently
    - latent
    - programming
    - representational efficiency
    - generate
    - generation
    - generating
    - generative
    - signals
    - signalling
    - predictive performance
    - multi
    - tests
    - testing
    - performed
    - performances
    - distributions
    - distributed
    - estimating
    - estimator
    - estimate
    - estimation
    - detecting
    - features
    - training
    - neural
    - regularization
    - regularizer
    - communications
    - improving
    - improves
    - improvement
    - objectives
    - novel regularized
    - classification
    - measure
    - points approximation methods
    - compressed representations
    - powerful
    - composite
    - systems
    - automate detection
    - random mutation
    - designer
    - intelligence
    - intelligent
    - mapping
    - maps
    - language
    - inputs
    - proposal
    - computes
    - computational
    - computing
    - generalization
    - generalizing
    - generalized
    - benchmarks
    - tasks
    - deep
    - stochastic
    - humans
    - objective function
    - vectors
    - relations
    - clustering
    - achieves
    - achievable
    - achievement
    - autoencoders
    - separately trained
    - strategies
    - strategy
    - constraints
    - adaptation
    - adaptive
    - result
    - technique designed
    - encoding
    - systematic compositionality
    - minimum
    - linear
    - convex combination
    - autoregressive flow
    - automated
    - cfpb
    - interpolated outputs
    - peak
    - integrating
    - integrated
    - integration
    - interpretation
    - interpretable
    - interpretability
    - interpreted
    - recovery
    - requiring
    - required
    - requires
    - preventing
    - guided
    - robust
    - convolutional
    - stability
    - stabilize
    - stabilization
    - spaces
    - enabling
    - enables
    - parameters
    - text
    - segmentation
    - interpolation
    - meaningful relative
    - compression
    - embeddings
    - embedded
    - datasets
    - wavenet
    - functional
    - functions
    - highly
    - transferred
    - reconstruction
    - reconstructing
    - labeling
    - visualization
    - controllable
    - recognition
    - camera
    - techniques
    - devices
    - domain
    - sources
    - geometric
    - degrees
    - food
    - lexical
    - concepts
    - claus
    - leverage
    - reputation
    - variables combining naturally
    - dynamics
    - critical errors
    - criticality
    - restricted
    - markets
    - tensor
    - combinations
    - combined
    - protections
    - attention
    - medical
    - financial
    - topics
    - indexing
    - levels
    - complexity
    - mimo
    - nlu
    - beamformer
    - beamforming
    - systematically
    - conditioned
    - conditional
    - brownian
    - motion
    - extracted
    - extraction
    - matrix
    - vae
    - settings
    - online
    - chest
    - extensively
    - findings
    - parallel
    - oriented
    - orientation
    - connects
    - connected
    - coverage
    - mixes
    - mixing
    - loading
    - complaints
    - possible threats
    - tracking
    - framework
    - delays
    - structures
    - semi
    - entanglement
    - transforms
    - analysis
    - poisoning
    - introduced
    - introduces
    - separation
    - gaussian
---

[**Latent Dirichlet Allocation (LDA) for Topic Modeling of the CFPB Consumer Complaints**](http://arxiv.org/abs/1807.07468v1)

A text mining approach is proposed based on latent Dirichlet allocation (LDA) to analyze the Consumer Financial Protection Bureau (CFPB) consumer complaints. The proposed approach aims to extract latent topics in the CFPB complaint narratives, and explores their associated trends over time. The time trends will then be used to evaluate the effectiveness of the CFPB regulations and expectations on financial institutions in creating a consumer oriented culture that treats consumers fairly and prioritizes consumer protection in their decision making processes. The proposed approach can be easily operationalized as a decision support system to automate detection of emerging topics in consumer complaints. Hence, the technology-human partnership between the proposed approach and the CFPB team could certainly improve consumer protections from unfair, deceptive or abusive practices in the financial markets by providing more efficient and effective investigations of consumer complaint narratives.

[**Anomaly Detection for Water Treatment System based on Neural Network with Automatic Architecture Optimization**](http://arxiv.org/abs/1807.07282v1)

We continue to develop our neural network (NN) based forecasting approach to anomaly detection (AD) using the Secure Water Treatment (SWaT) industrial control system (ICS) testbed dataset. We propose genetic algorithms (GA) to find the best NN architecture for a given dataset, using the NAB metric to assess the quality of different architectures. The drawbacks of the F1-metric are analyzed. Several techniques are proposed to improve the quality of AD: exponentially weighted smoothing, mean p-powered error measure, individual error weight for each variable, disjoint prediction windows. Based on the techniques used, an approach to anomaly interpretation is introduced.

[**Preventing Poisoning Attacks on AI based Threat Intelligence Systems**](http://arxiv.org/abs/1807.07418v1)

As AI systems become more ubiquitous, securing them becomes an emerging challenge. Over the years, with the surge in online social media use and the data available for analysis, AI systems have been built to extract, represent and use this information. The credibility of this information extracted from open sources, however, can often be questionable. Malicious or incorrect information can cause a loss of money, reputation, and resources; and in certain situations, pose a threat to human life. In this paper, we use an ensembled semi-supervised approach to determine the credibility of Reddit posts by estimating their reputation score to ensure the validity of information ingested by AI systems. We demonstrate our approach in the cybersecurity domain, where security analysts utilize these systems to determine possible threats by analyzing the data scattered on social media websites, forums, blogs, etc.

[**Statistical Model Compression for Small-Footprint Natural Language Understanding**](http://arxiv.org/abs/1807.07520v1)

In this paper we investigate statistical model compression applied to natural language understanding (NLU) models. Small-footprint NLU models are important for enabling offline systems on hardware restricted devices, and for decreasing on-demand model loading latency in cloud-based systems. To compress NLU models, we present two main techniques, parameter quantization and perfect feature hashing. These techniques are complementary to existing model pruning strategies such as L1 regularization. We performed experiments on a large scale NLU system. The results show that our approach achieves 14-fold reduction in memory usage compared to the original models with minimal predictive performance impact.

[**Analyzing Hypersensitive AI: Instability in Corporate-Scale Machine Learning**](http://arxiv.org/abs/1807.07404v1)

Predictive geometric models deliver excellent results for many Machine Learning use cases. Despite their undoubted performance, neural predictive algorithms can show unexpected degrees of instability and variance, particularly when applied to large datasets. We present an approach to measure changes in geometric models with respect to both output consistency and topological stability. Considering the example of a recommender system using word2vec, we analyze the influence of single data points, approximation methods and parameter settings. Our findings can help to stabilize models where needed and to detect differences in informational value of data points on a large scale.

[**Semantic Parsing: Syntactic assurance to target sentence using LSTM Encoder CFG-Decoder**](http://arxiv.org/abs/1807.07108v1)

Semantic parsing can be defined as the process of mapping natural language sentences into a machine interpretable, formal representation of its meaning. Semantic parsing using LSTM encoder-decoder neural networks have become promising approach. However, human automated translation of natural language does not provide grammaticality guarantees for the sentences generate such a guarantee is particularly important for practical cases where a data base query can cause critical errors if the sentence is ungrammatical. In this work, we propose an neural architecture called Encoder CFG-Decoder, whose output conforms to a given context-free grammar. Results are show for any implementation of such architecture display its correctness and providing benchmark accuracy levels better than the literature.

[**Linear Programming Approximations for Index Coding**](http://arxiv.org/abs/1807.07193v1)

[**A Projection Pursuit Forest Algorithm for Supervised Classification**](http://arxiv.org/abs/1807.07207v1)

[**Imparting Interpretability to Word Embeddings**](http://arxiv.org/abs/1807.07279v1)

As an ubiquitous method in natural language processing, word embeddings are extensively employed to map semantic properties of words into a dense vector representation. They capture semantic and syntactic relations among words but the vector corresponding to the words are only meaningful relative to each other. Neither the vector nor its dimensions have any absolute, interpretable meaning. We introduce an additive modification to the objective function of the embedding learning algorithm that encourages the embedding vectors of words that are semantically related a predefined concept to take larger values along a specified dimension, while leaving the original semantic learning mechanism mostly unaffected. In other words, we align words that are already determined to be related, along predefined concepts. Therefore, we impart interpretability to the word embedding by assigning meaning to its vector dimensions. The predefined concepts are derived from an external lexical resource, which in this paper is chosen as Roget’s Thesaurus. We observe that alignment along the chosen concepts is not limited to words in the Thesaurus and extends to other related words as well. We quantify the extent of interpretability and assignment of meaning from our experimental results. We also demonstrate the preservation of semantic coherence of the resulting vector space by using word-analogy and word-similarity tests. These tests show that the interpretability-imparted word embeddings that are obtained by the proposed framework do not sacrifice performances in common benchmark tests.

[**ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech**](http://arxiv.org/abs/1807.07281v1)

In this work, we propose an alternative solution for parallel wave generation by WaveNet. In contrast to parallel WaveNet (Oord et al., 2018), we distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet by minimizing a novel regularized KL divergence between their highly-peaked output distributions. Our method computes the KL divergence in closed-form, which simplifies the training algorithm and provides very efficient distillation. In addition, we propose the first text-to-wave neural architecture for speech synthesis, which is fully convolutional and enables fast end-to-end training from scratch. It significantly outperforms the previous pipeline that connects a text-to-spectrogram model to a separately trained WaveNet (Ping et al., 2017). We also successfully distill a parallel waveform synthesizer conditioned on the hidden representation in this end-to-end model.

[**Bounded Information Rate Variational Autoencoders**](http://arxiv.org/abs/1807.07306v1)

This paper introduces a new member of the family of Variational Autoencoders (VAE) that constrains the rate of information transferred by the latent layer. The latent layer is interpreted as a communication channel, the information rate of which is bound by imposing a pre-set signal-to-noise ratio. The new constraint subsumes the mutual information between the input and latent variables, combining naturally with the likelihood objective of the observed data as used in a conventional VAE. The resulting Bounded-Information-Rate Variational Autoencoder (BIR-VAE) provides a meaningful latent representation with an information resolution that can be specified directly in bits by the system designer. The rate constraint can be used to prevent overtraining, and the method naturally facilitates quantisation of the latent variables at the set rate. Our experiments confirm that the BIR-VAE has a meaningful latent representation and that its performance is at least as good as state-of-the-art competing algorithms, but with lower computational complexity.

[**Attend and Rectify: a Gated Attention Mechanism for Fine-Grained Recovery**](http://arxiv.org/abs/1807.07320v1)

We propose a novel attention mechanism to enhance Convolutional Neural Networks for fine-grained recognition. It learns to attend to lower-level feature activations without requiring part annotations and uses these activations to update and rectify the output likelihood distribution. In contrast to other approaches, the proposed mechanism is modular, architecture-independent and efficient both in terms of parameters and computation required. Experiments show that networks augmented with our approach systematically improve their classification accuracy and become more robust to clutter. As a result, Wide Residual Networks augmented with our proposal surpasses the state of the art classification accuracies in CIFAR-10, the Adience gender recognition task, Stanford dogs, and UEC Food-100.

[**FuzzerGym: A Competitive Framework for Fuzzing and Learning**](http://arxiv.org/abs/1807.07490v1)

Fuzzing is a commonly used technique designed to test software by automatically crafting program inputs. Currently, the most successful fuzzing algorithms emphasize simple, low-overhead strategies with the ability to efficiently monitor program state during execution. Through compile-time instrumentation, these approaches have access to numerous aspects of program state including coverage, data flow, and heterogeneous fault detection and classification. However, existing approaches utilize blind random mutation strategies when generating test inputs. We present a different approach that uses this state information to optimize mutation operators using reinforcement learning (RL). By integrating OpenAI Gym with libFuzzer we are able to simultaneously leverage advancements in reinforcement learning as well as fuzzing to achieve deeper coverage across several varied benchmarks. Our technique connects the rich, efficient program monitors provided by LLVM Santizers with a deep neural net to learn mutation selection strategies directly from the input data. The cross-language, asynchronous architecture we developed enables us to apply any OpenAI Gym compatible deep reinforcement learning algorithm to any fuzzing problem with minimal slowdown.

[**Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer**](http://arxiv.org/abs/1807.07543v1)

Autoencoders provide a powerful framework for learning compressed representations by encoding all of the information needed to reconstruct a data point in a latent code. In some cases, autoencoders can ‘interpolate’: By decoding the convex combination of the latent codes for two datapoints, the autoencoder can produce an output which semantically mixes characteristics from the datapoints. In this paper, we propose a regularization procedure which encourages interpolated outputs to appear more realistic by fooling a critic network which has been trained to recover the mixing coefficient from interpolated data. We then develop a simple benchmark task where we can quantitatively measure the extent to which various autoencoders can interpolate and show that our regularizer dramatically improves interpolation in this setting. We also demonstrate empirically that our regularizer produces latent codes which are more effective on downstream tasks, suggesting a possible link between interpolation abilities and learning useful representations.

[**Rearranging the Familiar: Testing Compositional Generalization in Recurrent Networks**](http://arxiv.org/abs/1807.07545v1)

Systematic compositionality is the ability to recombine meaningful units with regular and predictable outcomes, and it’s seen as key to humans’ capacity for generalization in language. Recent work has studied systematic compositionality in modern seq2seq models using generalization to novel navigation instructions in a grounded environment as a probing tool, requiring models to quickly bootstrap the meaning of new words. We extend this framework here to settings where the model needs only to recombine well-trained functional words (such as ‘around’ and ‘right’) in novel contexts. Our findings confirm and strengthen the earlier ones: seq2seq models can be impressively good at generalizing to novel combinations of previously-seen input, but only when they receive extensive training on the specific pattern to be generalized (e.g., generalizing from many examples of ‘X around right’ to ‘jump around right’), while failing when generalization requires novel application of compositional rules (e.g., inferring the meaning of ‘around right’ from those of ‘right’ and ‘around’).

• [A Hand-Held Multimedia Translation and Interpretation System with Application to Diet Management](http://arxiv.org/abs/1807.07149v1)• [Minimizing convex quadratic with variable precision Krylov methods](http://arxiv.org/abs/1807.07476v1)• [Guess who Multilingual approach for the automated generation of author-stylized poetry](http://arxiv.org/abs/1807.07147v1)• [Clinical Text Classification with Rule-based Features and Knowledge-guided Convolutional Neural Networks](http://arxiv.org/abs/1807.07425v1)• [Signal Alignment for Humanoid Skeletons via the Globally Optimal Reparameterization Algorithm](http://arxiv.org/abs/1807.07432v1)• [Real-Time Stereo Vision for Road Surface 3-D Reconstruction](http://arxiv.org/abs/1807.07433v1)• [Eigenspace-Based Minimum Variance Combined with Delay Multiply and Sum Beamformer: Application to Linear-Array Photoacoustic Imaging](http://arxiv.org/abs/1807.07405v1)• [High-Mobility Wideband Massive MIMO Communications: Doppler Compensation, Analysis and Scaling Law](http://arxiv.org/abs/1807.07438v1)• [A Fixed-Parameter Linear-Time Algorithm to Compute Principal Typings of Planar Flow Networks](http://arxiv.org/abs/1807.07067v1)• [Entanglement Transitions from Holographic Random Tensor Networks](http://arxiv.org/abs/1807.07082v1)• [Universal Scaling Theory of the Boundary Geometric Tensor in Disordered Metals](http://arxiv.org/abs/1807.07085v1)• [Ricci curvature for parametric statistics via optimal transport](http://arxiv.org/abs/1807.07095v1)• [Comparative study of Discrete Wavelet Transforms and Wavelet Tensor Train decomposition to feature extraction of FTIR data of medicinal plants](http://arxiv.org/abs/1807.07099v1)• [Weakly Monotone Fock Space and Monotone Convolution of the Wigner Law](http://arxiv.org/abs/1807.07101v1)• [NIP omega-categorical structures: the rank 1 case](http://arxiv.org/abs/1807.07102v1)• [Hierarchical Multi Task Learning With CTC](http://arxiv.org/abs/1807.07104v1)• [Real-time digital signal recovery for a low-pass transfer function system with multiple complex poles](http://arxiv.org/abs/1807.07105v1)• [The trinomial transform triangle](http://arxiv.org/abs/1807.07109v1)• [The classification of homogeneous finite-dimensional permutation structures](http://arxiv.org/abs/1807.07110v1)• [Continuous approximation of $(M_t,M_t, 1)$ distributions with application to production](http://arxiv.org/abs/1807.07115v1)• [A Holistic Approach to Forecasting Wholesale Energy Market Prices](http://arxiv.org/abs/1807.07120v1)• [Reconstructing Latent Orderings by Spectral Clustering](http://arxiv.org/abs/1807.07122v1)• [Datamining a medieval medical text reveals patterns in ingredient choice that reflect biological activity against the causative agents of specified infections](http://arxiv.org/abs/1807.07127v1)• [Distributed Second-order Convex Optimization](http://arxiv.org/abs/1807.07132v1)• [A Scalable MCEM Estimator for Spatio-Temporal Autoregressive Models](http://arxiv.org/abs/1807.07133v1)• [Representational efficiency outweighs action efficiency in human program induction](http://arxiv.org/abs/1807.07134v1)• [Fast and Deterministic Approximations for $k$-Cut](http://arxiv.org/abs/1807.07143v1)• [CT Image Enhancement Using Stacked Generative Adversarial Networks and Transfer Learning for Lesion Segmentation Improvement](http://arxiv.org/abs/1807.07144v1)• [Minimum distance computation of linear codes via genetic algorithms with permutation encoding](http://arxiv.org/abs/1807.07151v1)• [Take a Look Around: Using Street View and Satellite Images to Estimate House Prices](http://arxiv.org/abs/1807.07155v1)• [Approximation Schemes for Low-Rank Binary Matrix Approximation Problems](http://arxiv.org/abs/1807.07156v1)• [What kind of content are you prone to tweet Multi-topic Preference Model for Tweeters](http://arxiv.org/abs/1807.07162v1)• [Once reinforced random walk on $\mathbb{Z}\times Γ$](http://arxiv.org/abs/1807.07167v1)• [How Consumer Empathy Assist Power Grid in Demand Response](http://arxiv.org/abs/1807.07170v1)• [Automatic Identification of Ineffective Online Student Questions in Computing Education](http://arxiv.org/abs/1807.07173v1)• [A $φ$-Competitive Algorithm for Scheduling Packets with Deadlines](http://arxiv.org/abs/1807.07177v1)• [Efficient Power Flow Management and Peak Shaving in a Microgrid-PV System](http://arxiv.org/abs/1807.07180v1)• [A Novel Scheme for Support Identification and Iterative Sampling of Bandlimited Graph Signals](http://arxiv.org/abs/1807.07184v1)• [Tomlinson-Harashima Precoded Rate-Splitting for Multiuser MIMO Systems](http://arxiv.org/abs/1807.07185v1)• [Evaluating Word Embeddings in Multi-label Classification Using Fine-grained Name Typing](http://arxiv.org/abs/1807.07186v1)• [Efficient Training on Very Large Corpora via Gramian Estimation](http://arxiv.org/abs/1807.07187v1)• [A Tale of Santa Claus, Hypergraphs and Matroids](http://arxiv.org/abs/1807.07189v1)• [Tracking Sparse mmWave Channel: Performance Analysis under Intra-Cluster Angular Spread](http://arxiv.org/abs/1807.07190v1)• [Is the SIC Outcome There When Nobody Looks](http://arxiv.org/abs/1807.07194v1)• [Achievable Rate maximization by Passive Intelligent Mirrors](http://arxiv.org/abs/1807.07196v1)• [Asymptotically Optimal Estimation Algorithm for the Sparse Signal with Arbitrary Distributions](http://arxiv.org/abs/1807.07200v1)• [Performance, Power, and Area Design Trade-offs in Millimeter-Wave Transmitter Beamforming Architectures](http://arxiv.org/abs/1807.07201v1)• [Few-Shot Adaptation for Multimedia Semantic Indexing](http://arxiv.org/abs/1807.07203v1)• [Negative Imaginary State Feedback Control with a Prescribed Degree of Stability](http://arxiv.org/abs/1807.07212v1)• [Coexistence of scale invariant and rhythmic behavior in self-organized criticality](http://arxiv.org/abs/1807.07213v1)• [A Machine Learning Approach for Detecting Students at Risk of Low Academic Achievement](http://arxiv.org/abs/1807.07215v1)• [Isolating effects of age with fair representation learning when assessing dementia](http://arxiv.org/abs/1807.07217v1)• [Disorder-robust entanglement transport](http://arxiv.org/abs/1807.07218v1)• [Efficient Sampling of Bandlimited Graph Signals](http://arxiv.org/abs/1807.07222v1)• [Exponential Stabilization for Ito Stochastic Systems with Multiple Input Delays](http://arxiv.org/abs/1807.07223v1)• [Monocular Object Orientation Estimation using Riemannian Regression and Classification Networks](http://arxiv.org/abs/1807.07226v1)• [Convex Relaxations in Power System Optimization: A Brief Introduction](http://arxiv.org/abs/1807.07227v1)• [Stability of generalized Petersen graphs](http://arxiv.org/abs/1807.07228v1)• [UAV-Based in-band Integrated Access and Backhaul for 5G Communications](http://arxiv.org/abs/1807.07230v1)• [Cooperative Adaptive Cruise Control for Connected Autonomous Vehicles by Factoring Communication-Related Constraints](http://arxiv.org/abs/1807.07232v1)• [Optimal estimation of Gaussian mixtures via denoised method of moments](http://arxiv.org/abs/1807.07237v1)• [Limiting spectral distribution of the product of truncated Haar unitary matrices](http://arxiv.org/abs/1807.07240v1)• [ArticulatedFusion: Real-time Reconstruction of Motion, Geometry and Segmentation Using a Single Depth Camera](http://arxiv.org/abs/1807.07243v1)• [Chest X-rays Classification: A Multi-Label and Fine-Grained Problem](http://arxiv.org/abs/1807.07247v1)• [Normalization of ternary generalized pseudostandard words](http://arxiv.org/abs/1807.07248v1)• [Ricci-flat graphs with girth four](http://arxiv.org/abs/1807.07253v1)• [Towards Explainable and Controllable Open Domain Dialogue Generation with Dialogue Acts](http://arxiv.org/abs/1807.07255v1)• [Visual Domain Adaptation with Manifold Embedded Distribution Alignment](http://arxiv.org/abs/1807.07258v1)• [Machine Learning Based Featureless Signalling](http://arxiv.org/abs/1807.07260v1)• [A hybrid algorithm for the two-trust-region subproblem](http://arxiv.org/abs/1807.07264v1)• [On the modular Erdös-Burgess constant](http://arxiv.org/abs/1807.07266v1)• [Simple robust genomic prediction and outlier detection for a multi-environmental field trial](http://arxiv.org/abs/1807.07268v1)• [Searching for network modules](http://arxiv.org/abs/1807.07275v1)• [In pixels we trust: From Pixel Labeling to Object Localization and Scene Categorization](http://arxiv.org/abs/1807.07284v1)• [Label Aggregation via Finding Consensus Between Models](http://arxiv.org/abs/1807.07291v1)• [Deep Sequential Multi-camera Feature Fusion for Person Re-identification](http://arxiv.org/abs/1807.07295v1)• [Mr. DLib’s Living Lab for Scholarly Recommendations](http://arxiv.org/abs/1807.07298v1)• [SPDEs with Space-Mean Dynamics](http://arxiv.org/abs/1807.07303v1)• [Deep Adaptive Proposal Network for Object Detection in Optical Remote Sensing Images](http://arxiv.org/abs/1807.07327v1)• [Quantifying Volatility Reduction in German Day-ahead Spot Market in the Period 2006 through 2016](http://arxiv.org/abs/1807.07328v1)• [Sequence to Logic with Copy and Cache](http://arxiv.org/abs/1807.07333v1)• [On the Phase Tracking Reference Signal (PT-RS) Design for 5G New Radio (NR)](http://arxiv.org/abs/1807.07336v1)• [QoS and Coverage Aware Dynamic High Density Vehicle Platooning (HDVP)](http://arxiv.org/abs/1807.07337v1)• [Birkhoff-von Neumann Graphs that are PM-compact](http://arxiv.org/abs/1807.07339v1)• [Automated Phenotyping of Epicuticular Waxes of Grapevine Berries Using Light Separation and Convolutional Neural Networks](http://arxiv.org/abs/1807.07343v1)• [Indexing Execution Patterns in Workflow Provenance Graphs through Generalized Trie Structures](http://arxiv.org/abs/1807.07346v1)• [Generative Adversarial Networks for MR-CT Deformable Image Registration](http://arxiv.org/abs/1807.07349v1)• [Can We Assess Mental Health through Social Media and Smart Devices Addressing Bias in Methodology and Evaluation](http://arxiv.org/abs/1807.07351v1)• [MITK-ModelFit: generic open-source framework for model fits and their exploration in medical imaging – design, implementation and application on the example of DCE-MRI](http://arxiv.org/abs/1807.07353v1)• [Test-time augmentation with uncertainty estimation for deep learning-based medical image segmentation](http://arxiv.org/abs/1807.07356v1)• [Stochastic Quantization for the Edwards Measure of Fractional Brownian Motion with $Hd=1$](http://arxiv.org/abs/1807.07358v1)• [Green function of a random walk in a cone](http://arxiv.org/abs/1807.07360v1)• [Speeding up the Hyperparameter Optimization of Deep Convolutional Neural Networks](http://arxiv.org/abs/1807.07362v1)• [Revisiting Cross Modal Retrieval](http://arxiv.org/abs/1807.07364v1)• [On some special classes of contact $B_0$-VPG graphs](http://arxiv.org/abs/1807.07372v1)• [An entropy generation formula on $RCD(K,\infty)$ spaces](http://arxiv.org/abs/1807.07379v1)• [Fuzzy quantification for linguistic data analysis and data mining](http://arxiv.org/abs/1807.07389v1)• [ISIC 2018-A Method for Lesion Segmentation](http://arxiv.org/abs/1807.07391v1)• [Localization of disordered harmonic chain with long-range correlation](http://arxiv.org/abs/1807.07400v1)• [Image Reconstruction via Variational Network for Real-Time Hand-Held Sound-Speed Imaging](http://arxiv.org/abs/1807.07416v1)• [Delay and Communication Tradeoffs for Blockchain Systems with Lightweight IoT Clients](http://arxiv.org/abs/1807.07422v1)• [Modeling Visual Context is Key to Augmenting Object Detection Datasets](http://arxiv.org/abs/1807.07428v1)• [Semi-Dense 3D Reconstruction with a Stereo Event Camera](http://arxiv.org/abs/1807.07429v1)• [Selective Zero-Shot Classification with Augmented Attributes](http://arxiv.org/abs/1807.07437v1)• [On the almost-principal minors of a symmetric matrix](http://arxiv.org/abs/1807.07448v1)• [Can Artificial Intelligence Reliably Report Chest X-Rays : Radiologist Validation of an Algorithm trained on 1.2 Million X-Rays](http://arxiv.org/abs/1807.07455v1)• [On the Sweep Map for Fuss Rational Dyck Paths](http://arxiv.org/abs/1807.07458v1)• [Two algorithms for a fully coupled and consistently macroscopic PDE-ODE system modeling a moving bottleneck on a road](http://arxiv.org/abs/1807.07461v1)• [Conditional Random Fields as Recurrent Neural Networks for 3D Medical Imaging Segmentation](http://arxiv.org/abs/1807.07464v1)• [Stochastic Model Predictive Control with Discounted Probabilistic Constraints](http://arxiv.org/abs/1807.07465v1)• [Guided Upsampling Network for Real-Time Semantic Segmentation](http://arxiv.org/abs/1807.07466v1)• [Three for one and one for three: Flow, Segmentation, and Surface Normals](http://arxiv.org/abs/1807.07473v1)• [Prophet Secretary Through Blind Strategies](http://arxiv.org/abs/1807.07483v1)• [Robust Oil-spill Forensics and Petroleum Source Differentiation using Quantized Peak Topography Maps](http://arxiv.org/abs/1807.07484v1)• [A Microservice-enabled Architecture for Smart Surveillance using Blockchain Technology](http://arxiv.org/abs/1807.07487v1)• [Edge colourings and topological graph polynomials](http://arxiv.org/abs/1807.07500v1)• [Improving Simple Models with Confidence Profiles](http://arxiv.org/abs/1807.07506v1)• [Finding Minimum Volume Circumscribing Ellipsoids Using Copositive Programming](http://arxiv.org/abs/1807.07507v1)• [A Strategy of MR Brain Tissue Images’ Suggestive Annotation Based on Modified U-Net](http://arxiv.org/abs/1807.07510v1)• [Harmonic functions on mated-CRT maps](http://arxiv.org/abs/1807.07511v1)• [Hybrid scene Compression for Visual Localization](http://arxiv.org/abs/1807.07512v1)• [An invariance principle for ergodic scale-free random environments](http://arxiv.org/abs/1807.07515v1)• [Exact Algorithms for Finding Well-Connected 2-Clubs in Real-World Graphs: Theory and Experiments](http://arxiv.org/abs/1807.07516v1)• [Using Deep Neural Networks to Translate Multi-lingual Threat Intelligence](http://arxiv.org/abs/1807.07517v1)• [Exact asymptotics for Duarte and supercritical rooted kinetically constrained models](http://arxiv.org/abs/1807.07519v1)• [Bio-Measurements Estimation and Support in Knee Recovery through Machine Learning](http://arxiv.org/abs/1807.07521v1)• [Emulating malware authors for proactive protection using GANs over a distributed image visualization of the dynamic file behavior](http://arxiv.org/abs/1807.07525v1)• [Optimal Las Vegas Approximate Near Neighbors in $\ell_p$](http://arxiv.org/abs/1807.07527v1)• [Self-Organizing Maps as a Storage and Transfer Mechanism in Reinforcement Learning](http://arxiv.org/abs/1807.07530v1)• [Limited Memory Kelley’s Method Converges for Composite Convex and Submodular Objectives](http://arxiv.org/abs/1807.07531v1)• [Attention-Guided Curriculum Learning for Weakly Supervised Classification and Localization of Thoracic Diseases on Chest Radiographs](http://arxiv.org/abs/1807.07532v1)• [Positional Value in Soccer: Expected League Points Added above Replacement](http://arxiv.org/abs/1807.07536v1)• [An expansion formula for type A and Kronecker quantum cluster algebras](http://arxiv.org/abs/1807.07539v1)• [A unified theory of adaptive stochastic gradient descent as Bayesian filtering](http://arxiv.org/abs/1807.07540v1)• [Partial recovery bounds for clustering with the relaxed $K$means](http://arxiv.org/abs/1807.07547v1)• [Realization Spaces of Uniform Phased Matroids](http://arxiv.org/abs/1807.07552v1)• [A geometric integration approach to nonsmooth, nonconvex optimisation](http://arxiv.org/abs/1807.07554v1)• [Transfer Learning for Action Unit Recognition](http://arxiv.org/abs/1807.07556v1)• [Capsule Networks against Medical Imaging Data Challenges](http://arxiv.org/abs/1807.07559v1)• [Compositional GAN: Learning Conditional Image Composition](http://arxiv.org/abs/1807.07560v1)• [Nested Covariance Determinants and Restricted Trek Separation in Gaussian Graphical Models](http://arxiv.org/abs/1807.07561v1)• [A linear-time algorithm for generalized trust region problems](http://arxiv.org/abs/1807.07563v1)





### Like this:

Like Loading...


*Related*

