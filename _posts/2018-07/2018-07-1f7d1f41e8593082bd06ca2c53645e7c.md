---
layout:     post
title:      Whats new on arXiv
subtitle:   转载自：https://advanceddataanalytics.net/2018/07/19/whats-new-on-arxiv-713/
date:       2018-07-19
author:     Michael Laux
header-img: img/background2.jpg
catalog: true
tags:
    - http
    - based
    - learning
    - learns
    - learned
    - models
    - modelling
    - networks
    - network weights
    - modeling dynamic systems
    - optimization
    - optimized
    - optimizing
    - optimal
    - approaches
    - timed
    - methods
    - recommendations
    - recommender
    - recommending
    - training
    - trained
    - generated
    - generation
    - generative
    - generating
    - relative
    - processes
    - features
    - functions
    - computationally
    - computing
    - computed
    - efficiently train
    - complexity
    - complexes
    - datasets
    - images
    - distributions
    - distributed
    - estimators
    - estimating
    - estimated
    - improved
    - improving
    - improves
    - improvements
    - random
    - feature spaces
    - representations
    - structural estimation
    - generalizes
    - generalized
    - generalization
    - controller
    - locality
    - localization
    - structured
    - structures
    - neural
    - trusted
    - reviews
    - reviewers
    - algorithms
    - algorithmic
    - agents
    - efficiency
    - weighted
    - framework
    - deep
    - interpretability
    - interpretable
    - interpretations
    - dependency
    - dependences
    - attacks
    - attackers
    - locally observable
    - similarity
    - rates
    - complex collective
    - graphs
    - properties
    - property
    - adversarial
    - control synthesis
    - detection
    - detecting
    - natural language processing
    - analysis
    - state representation
    - adaptively
    - adapting
    - errors
    - requires trusting
    - predicting
    - predictive
    - predictions
    - trees
    - performance
    - performs
    - performed
    - machines
    - symmetry
    - products
    - morphologically
    - gaussian
    - agent states
    - samples
    - sampling
    - probabilistic estimates
    - correlations
    - correlated
    - information content required
    - communications
    - long depends
    - dynamics
    - search
    - decisions
    - applications
    - applicability
    - observed
    - observations
    - nature
    - humans
    - multi
    - driven
    - experiments
    - statistical
    - statistics
    - vulnerable
    - vulnerabilities
    - vulnerability
    - application domains
    - policy
    - policies
    - designed
    - designs
    - segmentation
    - noise
    - approximations
    - approximating
    - approximate
    - clustering
    - scales
    - game
    - interpolative
    - interpolations
    - architectures
    - architectural
    - settings
    - semantics
    - simple communication
    - clusters biases
    - techniques
    - maximum
    - evaluation
    - evaluate
    - evaluating
    - bounds
    - bounded
    - sparse
    - infection
    - paths
    - robustness
    - linearity
    - empirical
    - theoretical
    - powered
    - powerful
    - meaning
    - successful
    - collectives
    - separate
    - separating
    - separation
    - compression
    - deterministic
    - result
    - privacy
    - recognition
    - traditionally
    - visual
    - programming
    - edges
    - invariants
    - uses quantization
    - regularization
    - regularized
    - international
    - distrusting
    - census
    - positives
    - cross
    - tight
    - stochastic
    - tasks
    - diffusions
    - diffusive
    - regressions
    - levels
    - attention
    - sensitive
    - sensitivity
    - convolutional
    - degrees
    - mechanism
    - mechanics
    - mechanical
    - languages
    - quantizer
    - quantized
    - guaranteed
    - guarantees
    - supervised
    - meeting
    - meets
    - selection
    - science
    - maximize
    - maximizing
    - maximal
    - validate
    - validation
    - grids
    - proposed
    - recurrent
    - france
    - july
    - resp
    - strategies
    - cycle
    - parallel
    - free
    - convex
    - color
    - vector
    - filtering
    - weakly
    - vary
    - discrete
    - decomposition
    - annotation
    - embeddings
    - practice
    - practical
    - activation
    - active
    - existing
    - strong
    - initial
    - employed
    - employing
    - employment
    - rl
    - examples
    - typically
    - record
    - layers
    - layered
    - items
    - residual
    - basis
    - trade
    - trading
    - classification
    - disease
    - susceptible
    - autoencoding
    - autoencoders
---

[**Linear Model Regression on Time-series Data: Non-asymptotic Error Bounds and Applications**](http://arxiv.org/abs/1807.06611v1)

Data-driven methods for modeling dynamic systems have received considerable attention as they provide a mechanism for control synthesis directly from the observed time-series data. In the absence of prior assumptions on how the time-series had been generated, regression on the system model has been particularly popular. In the linear case, the resulting least squares setup for model regression, not only provides a computationally viable method to fit a model to the data, but also provides useful insights into the modal properties of the underlying dynamics. Although probabilistic estimates for this model regression have been reported, deterministic error bounds have not been examined in the literature, particularly as they pertain to the properties of the underlying system. In this paper, we provide deterministic non-asymptotic error bounds for fitting a linear model to the observed time-series data, with a particular attention to the role of symmetry and eigenvalue multiplicity in the underlying system matrix.

[**Efficient Deep Learning on Multi-Source Private Data**](http://arxiv.org/abs/1807.06689v1)

Machine learning models benefit from large and diverse datasets. Using such datasets, however, often requires trusting a centralized data aggregator. For sensitive applications like healthcare and finance this is undesirable as it could compromise patient privacy or divulge trade secrets. Recent advances in secure and privacy-preserving computation, including trusted hardware enclaves and differential privacy, offer a way for mutually distrusting parties to efficiently train a machine learning model without revealing the training data. In this work, we introduce Myelin, a deep learning framework which combines these privacy-preservation primitives, and use it to establish a baseline level of performance for fully private machine learning.

[**Defend Deep Neural Networks Against Adversarial Examples via Fixed andDynamic Quantized Activation Functions**](http://arxiv.org/abs/1807.06714v1)

Recent studies have shown that deep neural networks (DNNs) are vulnerable to adversarial attacks. To this end, many defense approaches that attempt to improve the robustness of DNNs have been proposed. In a separate and yet related area, recent works have explored to quantize neural network weights and activation functions into low bit-width to compress model size and reduce computational complexity. In this work,we find that these two different tracks, namely the pursuit of network compactness and robustness, can bemerged into one and give rise to networks of both advantages. To the best of our knowledge, this is the first work that uses quantization of activation functions to defend against adversarial examples. We also propose to train robust neural networks by using adaptive quantization techniques for the activation functions. Our proposed Dynamic Quantized Activation (DQA) is verified through a wide range of experiments with the MNIST and CIFAR-10 datasets under different white-box attack methods, including FGSM, PGD, andC attacks. Furthermore, Zeroth Order Optimization and substitute model based black-box attacks are also considered in this work. The experimental results clearly show that the robustness of DNNs could be greatly improved using the proposed DQA.

[**Machine Learning Interpretability: A Science rather than a tool**](http://arxiv.org/abs/1807.06722v1)

The term ‘interpretability’ is oftenly used by machine learning researchers each with their own intuitive understanding of it. There is no universal well agreed upon definition of interpretability in machine learning. As any type of science discipline is mainly driven by the set of formulated questions rather than by different tools in that discipline, e.g. astrophysics is the discipline that learns the composition of stars, not as the discipline that use the spectroscopes. Similarly, we propose that machine learning interpretability should be a discipline that answers specific questions related to interpretability. These questions can be of statistical, causal and counterfactual nature. Therefore, there is a need to look into the interpretability problem of machine learning in the context of questions that need to be addressed rather than different tools. We discuss about a hypothetical interpretability framework driven by a question based scientific approach rather than some specific machine learning model. Using a question based notion of interpretability, we can step towards understanding the science of machine learning rather than its engineering. This notion will also help us understanding any specific problem more in depth rather than relying solely on machine learning methods.

[**Improving Explainable Recommendations with Synthetic Reviews**](http://arxiv.org/abs/1807.06978v1)

An important task for a recommender system to provide interpretable explanations for the user. This is important for the credibility of the system. Current interpretable recommender systems tend to focus on certain features known to be important to the user and offer their explanations in a structured form. It is well known that user generated reviews and feedback from reviewers have strong leverage over the users’ decisions. On the other hand, recent text generation works have been shown to generate text of similar quality to human written text, and we aim to show that generated text can be successfully used to explain recommendations. In this paper, we propose a framework consisting of popular review-oriented generation models aiming to create personalised explanations for recommendations. The interpretations are generated at both character and word levels. We build a dataset containing reviewers’ feedback from the Amazon books review dataset. Our cross-domain experiments are designed to bridge from natural language processing to the recommender system domain. Besides language model evaluation methods, we employ DeepCoNN, a novel review-oriented recommender system using a deep neural network, to evaluate the recommendation performance of generated reviews by root mean square error (RMSE). We demonstrate that the synthetic personalised reviews have better recommendation performance than human written reviews. To our knowledge, this presents the first machine-generated natural language explanations for rating prediction.

[**Deep Reinforcement Learning for Swarm Systems**](http://arxiv.org/abs/1807.06613v1)

Recently, deep reinforcement learning (RL) methods have been applied successfully to multi-agent scenarios. Typically, these methods rely on a concatenation of agent states to represent the information content required for decentralized decision making. However, concatenation scales poorly to swarm systems with a large number of homogeneous agents as it does not exploit the fundamental properties inherent to these systems: (i) the agents in the swarm are interchangeable and (ii) the exact number of agents in the swarm is irrelevant. Therefore, we propose a new state representation for deep multi-agent RL based on mean embeddings of distributions. We treat the agents as samples of a distribution and use the empirical mean embedding as input for a decentralized policy. We define different feature spaces of the mean embedding using histograms, radial basis functions and a neural network learned end-to-end. We evaluate the representation on two well known problems from the swarm literature (rendezvous and pursuit evasion), in a globally and locally observable setup. For the local setup we furthermore introduce simple communication protocols. Of all approaches, the mean embedding representation using neural network features enables the richest information exchange between neighboring agents facilitating the development of more complex collective strategies.

[**Improving Named Entity Recognition by Jointly Learning to Disambiguate Morphological Tags**](http://arxiv.org/abs/1807.06683v1)

Previous studies have shown that linguistic features of a word such as possession, genitive or other grammatical cases can be employed in word representations of a named entity recognition (NER) tagger to improve the performance for morphologically rich languages. However, these taggers require external morphological disambiguation (MD) tools to function which are hard to obtain or non-existent for many languages. In this work, we propose a model which alleviates the need for such disambiguators by jointly learning NER and MD taggers in languages for which one can provide a list of candidate morphological analyses. We show that this can be done independent of the morphological annotation schemes, which differ among languages. Our experiments employing three different model architectures that join these two tasks show that joint learning improves NER performance. Furthermore, the morphological disambiguator’s performance is shown to be competitive.

[**Adaptive Neural Trees**](http://arxiv.org/abs/1807.06699v1)

Deep neural networks and decision trees operate on largely separate paradigms; typically, the former performs representation learning with pre-specified architectures, while the latter is characterised by learning hierarchies over pre-specified features with data-driven architectures. We unite the two via adaptive neural trees (ANTs), a model that incorporates representation learning into edges, routing functions and leaf nodes of a decision tree, along with a backpropagation-based training algorithm that adaptively grows the architecture from primitive modules (e.g., convolutional layers). We demonstrate that, whilst achieving over 99% and 90% accuracy on MNIST and CIFAR-10 datasets, ANTs benefit from (i) faster inference via conditional computation, (ii) increased interpretability via hierarchical clustering e.g. learning meaningful class associations, such as separating natural vs. man-made objects, and (iii) a mechanism to adapt the architecture to the size and complexity of the training dataset.

[**Receiver Operating Characteristic Curves and Confidence Bands for Support Vector Machines**](http://arxiv.org/abs/1807.06711v1)

Many problems that appear in biomedical decision making, such as diagnosing disease and predicting response to treatment, can be expressed as binary classification problems. The costs of false positives and false negatives vary across application domains and receiver operating characteristic (ROC) curves provide a visual representation of this trade-off. Nonparametric estimators for the ROC curve, such as a weighted support vector machine (SVM), are desirable because they are robust to model misspecification. While weighted SVMs have great potential for estimating ROC curves, their theoretical properties were heretofore underdeveloped. We propose a method for constructing confidence bands for the SVM ROC curve and provide the theoretical justification for the SVM ROC curve by showing that the risk function of the estimated decision rule is uniformly consistent across the weight parameter. We demonstrate the proposed confidence band method and the superior sensitivity and specificity of the weighted SVM compared to commonly used methods in diagnostic medicine using simulation studies. We present two illustrative examples: diagnosis of hepatitis C and a predictive model for treatment response in breast cancer.

[**Dependency Leakage: Analysis and Scalable Estimators**](http://arxiv.org/abs/1807.06713v1)

In this paper, we prove the first theoretical results on dependency leakage — a phenomenon in which learning on noisy clusters biases cross-validation and model selection results. This is a major concern for domains involving human record databases (e.g. medical, census, advertising), which are almost always noisy due to the effects of record linkage and which require special attention to machine learning bias. The proposed theoretical properties justify regularization choices in several existing statistical estimators and allow us to construct the first hypothesis test for cross-validation bias due to dependency leakage. Furthermore, we propose a novel matrix sketching technique which, along with standard function approximation techniques, enables dramatically improving the sample and computational scalability of existing estimators. Empirical results on several benchmark datasets validate our theoretical results and proposed methods.

[**SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities**](http://arxiv.org/abs/1807.06756v1)

The detection of software vulnerabilities (or vulnerabilities for short) is an important problem that has yet to be tackled, as manifested by many vulnerabilities reported on a daily basis. This calls for machine learning methods to automate vulnerability detection. Deep learning is attractive for this purpose because it does not require human experts to manually define features. Despite the tremendous success of deep learning in other domains, its applicability to vulnerability detection is not systematically understood. In order to fill this void, we propose the first systematic framework for using deep learning to detect vulnerabilities. The framework, dubbed Syntax-based, Semantics-based, and Vector Representations (SySeVR), focuses on obtaining program representations that can accommodate syntax and semantic information pertinent to vulnerabilities. Our experiments with 4 software products demonstrate the usefulness of the framework: we detect 15 vulnerabilities that are not reported in the National Vulnerability Database. Among these 15 vulnerabilities, 7 are unknown and have been reported to the vendors, and the other 8 have been ‘silently’ patched by the vendors when releasing newer versions of the products.

[**General Value Function Networks**](http://arxiv.org/abs/1807.06763v1)

In this paper we show that restricting the representation-layer of a Recurrent Neural Network (RNN) improves accuracy and reduces the depth of recursive training procedures in partially observable domains. Artificial Neural Networks have been shown to learn useful state representations for high-dimensional visual and continuous control domains. If the the tasks at hand exhibits long depends back in time, these instantaneous feed-forward approaches are augmented with recurrent connections and trained with Back-prop Through Time (BPTT). This unrolled training can become computationally prohibitive if the dependency structure is long, and while recent work on LSTMs and GRUs has improved upon naive training strategies, there is still room for improvements in computational efficiency and parameter sensitivity. In this paper we explore a simple modification to the classic RNN structure: restricting the state to be comprised of multi-step General Value Function predictions. We formulate an architecture called General Value Function Networks (GVFNs), and corresponding objective that generalizes beyond previous approaches. We show that our GVFNs are significantly more robust to train, and facilitate accurate prediction with no gradients needed back-in-time in domains with substantial long-term dependences.

[**Self-supervised Knowledge Distillation Using Singular Value Decomposition**](http://arxiv.org/abs/1807.06819v1)

[**Trust-Based Collaborative Filtering: Tackling the Cold Start Problem Using Regular Equivalence**](http://arxiv.org/abs/1807.06839v1)

User-based Collaborative Filtering (CF) is one of the most popular approaches to create recommender systems. This approach is based on finding the most relevant k users from whose rating history we can extract items to recommend. CF, however, suffers from data sparsity and the cold-start problem since users often rate only a small fraction of available items. One solution is to incorporate additional information into the recommendation process such as explicit trust scores that are assigned by users to others or implicit trust relationships that result from social connections between users. Such relationships typically form a very sparse trust network, which can be utilized to generate recommendations for users based on people they trust. In our work, we explore the use of a measure from network science, i.e. regular equivalence, applied to a trust network to generate a similarity matrix that is used to select the k-nearest neighbors for recommending items. We evaluate our approach on Epinions and we find that we can outperform related methods for tackling cold-start users in terms of recommendation accuracy.

[**Towards Automated Deep Learning: Efficient Joint Neural Architecture and Hyperparameter Search**](http://arxiv.org/abs/1807.06906v1)

While existing work on neural architecture search (NAS) tunes hyperparameters in a separate post-processing step, we demonstrate that architectural choices and other hyperparameter settings interact in a way that can render this separation suboptimal. Likewise, we demonstrate that the common practice of using very few epochs during the main NAS and much larger numbers of epochs during a post-processing step is inefficient due to little correlation in the relative rankings for these two training regimes. To combat both of these problems, we propose to use a recent combination of Bayesian optimization and Hyperband for efficient joint neural architecture and hyperparameter search.

[**Backplay: ‘Man muss immer umkehren’**](http://arxiv.org/abs/1807.06919v1)

A long-standing problem in model free reinforcement learning (RL) is that it requires a large number of trials to learn a good policy, especially in environments with sparse rewards. We explore a method to increase the sample efficiency of RL when we have access to demonstrations. Our approach, which we call Backplay, uses a single demonstration to construct a curriculum for a given task. Rather than starting each training episode in the environment’s fixed initial state, we start the agent near the end of the demonstration and move the starting point backwards during the course of training until we reach the initial state. We perform experiments in a competitive four player game (Pommerman) and a path-finding maze game. We find that this weak form of guidance provides significant gains in sample complexity with a stark advantage in sparse reward environments. In some cases, standard RL did not yield any improvement while Backplay reached success rates greater than 50% and generalized to unseen initial conditions in the same amount of training time. Additionally, we see that agents trained via Backplay can learn policies superior to those of the original demonstration.

[**A Probabilistic Theory of Supervised Similarity Learning for Pointwise ROC Curve Optimization**](http://arxiv.org/abs/1807.06981v1)

The performance of many machine learning techniques depends on the choice of an appropriate similarity or distance measure on the input space. Similarity learning (or metric learning) aims at building such a measure from training data so that observations with the same (resp. different) label are as close (resp. far) as possible. In this paper, similarity learning is investigated from the perspective of pairwise bipartite ranking, where the goal is to rank the elements of a database by decreasing order of the probability that they share the same label with some query data point, based on the similarity scores. A natural performance criterion in this setting is pointwise ROC optimization: maximize the true positive rate under a fixed false positive rate. We study this novel perspective on similarity learning through a rigorous probabilistic framework. The empirical version of the problem gives rise to a constrained optimization formulation involving U-statistics, for which we derive universal learning rates as well as faster rates under a noise assumption on the data distribution. We also address the large-scale setting by analyzing the effect of sampling-based approximations. Our theoretical results are supported by illustrative numerical experiments.

[**Cross Validation Based Model Selection via Generalized Method of Moments**](http://arxiv.org/abs/1807.06993v1)

Structural estimation is an important methodology in empirical economics, and a large class of structural models are estimated through the generalized method of moments (GMM). Traditionally, selection of structural models has been performed based on model fit upon estimation, which take the entire observed samples. In this paper, we propose a model selection procedure based on cross-validation (CV), which utilizes sample-splitting technique to avoid issues such as over-fitting. While CV is widely used in machine learning communities, we are the first to prove its consistency in model selection in GMM framework. Its empirical property is compared to existing methods by simulations of IV regressions and oligopoly market model. In addition, we propose the way to apply our method to Mathematical Programming of Equilibrium Constraint (MPEC) approach. Finally, we perform our method to online-retail sales data to compare dynamic market model to static model.

[**Time-Varying Optimization: Algorithms and Engineering Applications**](http://arxiv.org/abs/1807.07032v1)

This is the write-up of the talk I gave at the 23rd International Symposium on Mathematical Programming (ISMP) in Bordeaux, France, July 6th, 2018. The talk was a general overview of the state of the art of time-varying, mainly convex, optimization, with special emphasis on discrete-time algorithms and applications in energy and transportation. This write-up is mathematically correct, while its style is somewhat less formal than a standard paper.

• [Fast Model-Selection through Adapting Design of Experiments Maximizing Information Gain](http://arxiv.org/abs/1807.07024v1)• [Analysis of social media content and search behavior related to seasonal topics using the sociophysics approach](http://arxiv.org/abs/1807.05320v1)• [Backscatter-assisted Relaying in Wireless Powered Communications Network](http://arxiv.org/abs/1807.05372v1)• [Degree Correlations Amplify the Growth of Cascades in Networks](http://arxiv.org/abs/1807.05472v1)• [On SDEs with Lipschitz coefficients, driven by continuous, model-free price paths](http://arxiv.org/abs/1807.05692v1)• [Discrete linear-complexity reinforcement learning in continuous action spaces for Q-learning algorithms](http://arxiv.org/abs/1807.06957v1)• [Design and Analysis of Efficient Maximum/Minimum Circuits for Stochastic Computing](http://arxiv.org/abs/1807.06966v1)• [Bridging the Accuracy Gap for 2-bit Quantized Neural Networks (QNN)](http://arxiv.org/abs/1807.06964v1)• [Data-Efficient Weakly Supervised Learning for Low-Resource Audio Event Detection Using Deep Learning](http://arxiv.org/abs/1807.06972v1)• [Analysis of Optimized Threshold with SLM based Blanking Non-Linearity for Impulsive Noise Reduction in Power Line Communication Systems](http://arxiv.org/abs/1807.06458v1)• [On maximum $k$-edge-colorable subgraphs of bipartite graphs](http://arxiv.org/abs/1807.06556v1)• [A tight lower bound for the hardness of clutters](http://arxiv.org/abs/1807.06568v1)• [A Fast Segmentation-free Fully Automated Approach to White Matter Injury Detection in Preterm Infants](http://arxiv.org/abs/1807.06604v1)• [Monochromatic cycle partitions in random graphs](http://arxiv.org/abs/1807.06607v1)• [Learning Noise-Invariant Representations for Robust Speech Recognition](http://arxiv.org/abs/1807.06610v1)• [Influence Models on Layered Uncertain Networks: A Guaranteed-Cost Design Perspective](http://arxiv.org/abs/1807.06612v1)• [Rapid Bipedal Gait Design Using C-FROST with Illustration on a Cassie-series Robot](http://arxiv.org/abs/1807.06614v1)• [SRN: Side-output Residual Network for Object Reflection Symmetry Detection and Beyond](http://arxiv.org/abs/1807.06621v1)• [Emergent Meaning Structures: A Socio-Semantic Network Analysis of Artistic Collectives](http://arxiv.org/abs/1807.06623v1)• [Distributed Triangle Detection via Expander Decomposition](http://arxiv.org/abs/1807.06624v1)• [Parallel Restarted SGD for Non-Convex Optimization with Faster Convergence and Less Communication](http://arxiv.org/abs/1807.06629v1)• [Expressive power of outer product manifolds on feed-forward neural networks](http://arxiv.org/abs/1807.06630v1)• [Multimatricvariate distribution under elliptical models](http://arxiv.org/abs/1807.06635v1)• [Developing a Portable Natural Language Processing Based Phenotyping System](http://arxiv.org/abs/1807.06638v1)• [Discovering Job Preemptions in the Open Science Grid](http://arxiv.org/abs/1807.06639v1)• [A Framework for Moment Invariants](http://arxiv.org/abs/1807.06644v1)• [The Online $k$-Taxi Problem](http://arxiv.org/abs/1807.06645v1)• [Remote Sampling with Applications to General Entanglement Simulation](http://arxiv.org/abs/1807.06649v1)• [Generative adversarial interpolative autoencoding: adversarial training on latent space interpolations encourage convex latent distributions](http://arxiv.org/abs/1807.06650v1)• [Item Recommendation with Variational Autoencoders and Heterogenous Priors](http://arxiv.org/abs/1807.06651v1)• [From modelling of systems with constraints to generalized geometry and back to numerics](http://arxiv.org/abs/1807.06652v1)• [Invariant Information Distillation for Unsupervised Image Segmentation and Clustering](http://arxiv.org/abs/1807.06653v1)• [Devam vs. Tamam: 2018 Turkish Elections](http://arxiv.org/abs/1807.06655v1)• [Mixed-Stationary Gaussian Process for Flexible Non-Stationary Modeling of Spatial Outcomes](http://arxiv.org/abs/1807.06656v1)• [Airline Passenger Name Record Generation using Generative Adversarial Networks](http://arxiv.org/abs/1807.06657v1)• [Model selection for sequential designs in discrete finite systems using Bernstein kernels](http://arxiv.org/abs/1807.06661v1)• [Payoff Control in the Iterated Prisoner’s Dilemma](http://arxiv.org/abs/1807.06666v1)• [Accel: A Corrective Fusion Network for Efficient Semantic Segmentation on Video](http://arxiv.org/abs/1807.06667v1)• [Derandomizing the Lovasz Local Lemma via log-space statistical tests](http://arxiv.org/abs/1807.06672v1)• [Query-Conditioned Three-Player Adversarial Network for Video Summarization](http://arxiv.org/abs/1807.06677v1)• [Modular Semantics and Characteristics for Bipolar Weighted Argumentation Graphs](http://arxiv.org/abs/1807.06685v1)• [Supermodular Locality Sensitive Hashes](http://arxiv.org/abs/1807.06686v1)• [A transformation-based approach to Gaussian mixture density estimation for bounded data](http://arxiv.org/abs/1807.06690v1)• [Tensor Methods for Additive Index Models under Discordance and Heterogeneity](http://arxiv.org/abs/1807.06693v1)• [Regularized Zero-Forcing Precoding Aided Adaptive Coding and Modulation for Large-Scale Antenna Array Based Air-to-Air Communications](http://arxiv.org/abs/1807.06695v1)• [Integrating Algorithmic Planning and Deep Learning for Partially Observable Navigation](http://arxiv.org/abs/1807.06696v1)• [Pink Work: Same-Sex Marriage, Employment and Discrimination](http://arxiv.org/abs/1807.06698v1)• [Massively Parallel Symmetry Breaking on Sparse Graphs: MIS and Maximal Matching](http://arxiv.org/abs/1807.06701v1)• [Stochastic defense against complex grid attacks](http://arxiv.org/abs/1807.06707v1)• [A Modulation Module for Multi-task Learning with Applications in Image Retrieval](http://arxiv.org/abs/1807.06708v1)• [Digit sums and generating functions](http://arxiv.org/abs/1807.06710v1)• [Evaluating Gaussian Process Metamodels and Sequential Designs for Noisy Level Set Estimation](http://arxiv.org/abs/1807.06712v1)• [Multivariate approximation in total variation using local dependence](http://arxiv.org/abs/1807.06715v1)• [Pattern Synthesis via Complex-Coefficient Weight Vector Orthogonal Decomposition–Part I: Fundamentals](http://arxiv.org/abs/1807.06716v1)• [Encrypted Control System with Quantizer](http://arxiv.org/abs/1807.06717v1)• [Recurrent Capsule Network for Relations Extraction: A Practical Application to the Severity Classification of Coronary Artery Disease](http://arxiv.org/abs/1807.06718v1)• [Deterministic oblivious distribution (and tight compaction) in linear time](http://arxiv.org/abs/1807.06719v1)• [Synthesis of Successful Actuator Attackers on Supervisors](http://arxiv.org/abs/1807.06720v1)• [Pattern Synthesis via Complex-Coefficient Weight Vector Orthogonal Decomposition–Part II: Robust Sidelobe Synthesis](http://arxiv.org/abs/1807.06721v1)• [Timed Discrete-Event Systems are Synchronous Product Structures](http://arxiv.org/abs/1807.06725v1)• [The MOEADr Package – A Component-Based Framework for Multiobjective Evolutionary Algorithms Based on Decomposition](http://arxiv.org/abs/1807.06731v1)• [Motivating the Rules of the Game for Adversarial Example Research](http://arxiv.org/abs/1807.06732v1)• [Generating Levels That Teach Mechanics](http://arxiv.org/abs/1807.06734v1)• [Forward Attention in Sequence-to-sequence Acoustic Modelling for Speech Synthesis](http://arxiv.org/abs/1807.06736v1)• [3D Global Convolutional Adversarial Network\\ for Prostate MR Volume Segmentation](http://arxiv.org/abs/1807.06742v1)• [A generalisation of the relation between zeros of the complex Kac polynomial and eigenvalues of truncated unitary matrices](http://arxiv.org/abs/1807.06743v1)• [Gradient Band-based Adversarial Training for Generalized Attack Immunity of A3C Path Finding](http://arxiv.org/abs/1807.06752v1)• [A Learning-Based Coexistence Mechanism for LAA-LTE Based HetNets](http://arxiv.org/abs/1807.06754v1)• [On Evaluation of Embodied Navigation Agents](http://arxiv.org/abs/1807.06757v1)• [Convergence guarantees for RMSProp and ADAM in non-convex optimization and their comparison to Nesterov acceleration on autoencoders](http://arxiv.org/abs/1807.06766v1)• [Comparing Respiratory Monitoring Performance of Commercial Wireless Devices](http://arxiv.org/abs/1807.06767v1)• [A pliable lasso for the Cox model](http://arxiv.org/abs/1807.06770v1)• [Bag-of-Visual-Words for Signature-Based Multi-Script Document Retrieval](http://arxiv.org/abs/1807.06772v1)• [Visual Affordance and Function Understanding: A Survey](http://arxiv.org/abs/1807.06775v1)• [Detecting strong signals in gene perturbation experiments: An adaptive approach with power guarantee and FDR control](http://arxiv.org/abs/1807.06776v1)• [Planning and Synthesis Under Assumptions](http://arxiv.org/abs/1807.06777v1)• [Resilient Feedback Controller Design For Linear Model of Power Grids](http://arxiv.org/abs/1807.06778v1)• [An Attention-Based Approach for Single Image Super Resolution](http://arxiv.org/abs/1807.06779v1)• [Effect of Sensor Error on the Assessment of Seismic Building Damage](http://arxiv.org/abs/1807.06785v1)• [Deep Content-User Embedding Model for Music Recommendation](http://arxiv.org/abs/1807.06786v1)• [Lower bounds for embeddings into hypercubes]{Lower bounds for dilation, wirelength, and edge congestion of embedding graphs into hypercubes](http://arxiv.org/abs/1807.06787v1)• [DroNet: Efficient convolutional neural network detector for real-time UAV applications](http://arxiv.org/abs/1807.06789v1)• [Multi-Task Unsupervised Contextual Learning for Behavioral Annotation](http://arxiv.org/abs/1807.06792v1)• [A Central Limit Theorem for $L_p$ transportation cost with applications to Fairness Assessment in Machine Learning](http://arxiv.org/abs/1807.06796v1)• [Robust Distributed Compression of Symmetrically Correlated Gaussian Sources](http://arxiv.org/abs/1807.06799v1)• [Approximating Systems Fed by Poisson Processes with Rapidly Changing Arrival Rates](http://arxiv.org/abs/1807.06805v1)• [Delay Minimization for NOMA-MEC Offloading](http://arxiv.org/abs/1807.06810v1)• [Tri-Compress: A Cascaded Data Compression Framework for Smart Electricity Distribution Systems](http://arxiv.org/abs/1807.06811v1)• [Local symmetry theory of resonator structures for the real-space control of edge-states in binary aperiodic chains](http://arxiv.org/abs/1807.06812v1)• [Traditional Wisdom and Monte Carlo Tree Search Face-to-Face in the Card Game Scopone](http://arxiv.org/abs/1807.06813v1)• [Determining ellipses from low resolution images with a comprehensive image formation model](http://arxiv.org/abs/1807.06814v1)• [The Scheduler is Very Powerful in Competitive Analysis of Distributed List Accessing](http://arxiv.org/abs/1807.06820v1)• [Computed Tomography Image Enhancement using 3D Convolutional Neural Network](http://arxiv.org/abs/1807.06821v1)• [Customer Sharing in Economic Networks with Costs](http://arxiv.org/abs/1807.06822v1)• [News-based trading strategies](http://arxiv.org/abs/1807.06824v1)• [Semilinear evolution equations for the Anderson Hamiltonian in two and three dimensions](http://arxiv.org/abs/1807.06825v1)• [Spaceborne Staring Spotlight SAR Tomography – A First Demonstration with TerraSAR-X](http://arxiv.org/abs/1807.06826v1)• [Network Identification: A Passivity and Network Optimization Approach](http://arxiv.org/abs/1807.06841v1)• [What circle bundles can be triangulated over $\partial Δ^3$](http://arxiv.org/abs/1807.06842v1)• [Learning Interpretable Anatomical Features Through Deep Generative Models: Application to Cardiac Remodeling](http://arxiv.org/abs/1807.06843v1)• [Practical MIMO-NOMA: Low Complexity & Capacity-Approaching Solution](http://arxiv.org/abs/1807.06846v1)• [Reactive random walkers on complex networks](http://arxiv.org/abs/1807.06847v1)• [Random walks on graphs: new bounds on hitting, meeting, coalescing and returning](http://arxiv.org/abs/1807.06858v1)• [Mix $\star$-autonomous quantales and the continuous weak order](http://arxiv.org/abs/1807.06862v1)• [Vertex Turán problems for the oriented hypercube](http://arxiv.org/abs/1807.06866v1)• [Approximation algorithms on $k-$ cycle covering and $k-$ clique covering](http://arxiv.org/abs/1807.06867v1)• [An Information-theoretic Framework for the Lossy Compression of Link Streams](http://arxiv.org/abs/1807.06874v1)• [Distinct patterns of syntactic agreement errors in recurrent networks and humans](http://arxiv.org/abs/1807.06882v1)• [Guaranteed Error Bounds on Approximate Model Abstractions through Reachability Analysis](http://arxiv.org/abs/1807.06888v1)• [Large deviation principle for fractional Brownian motion with respect to capacity](http://arxiv.org/abs/1807.06891v1)• [An entropic interpolation proof of the HWI inequality](http://arxiv.org/abs/1807.06893v1)• [Interacting diffusions on random graphs with diverging degrees: hydrodynamics and large deviations](http://arxiv.org/abs/1807.06898v1)• [Melanoma Recognition with an Ensemble of Techniques for Segmentation and a Structural Analysis for Classification](http://arxiv.org/abs/1807.06905v1)• [Comment on ‘Nodal infection in Markovian susceptible-infected-susceptible and susceptible-infected-removed epidemics on networks are non-negatively correlated”](http://arxiv.org/abs/1807.06909v1)• [Quantum cluster algebras from unpunctured triangulated surfaces](http://arxiv.org/abs/1807.06910v1)• [Intriguing yet simple skewness – kurtosis relation in economic and demographic data distributions; pointing to preferential attachment processes](http://arxiv.org/abs/1807.06911v1)• [On graphs admitting two disjoint maximum independent sets](http://arxiv.org/abs/1807.06914v1)• [RARD II: The 2nd Related-Article Recommendation Dataset](http://arxiv.org/abs/1807.06918v1)• [Learning Hybrid Sparsity Prior for Image Restoration: Where Deep Learning Meets Sparse Coding](http://arxiv.org/abs/1807.06920v1)• [Time-Bounded Influence Diffusion with Incentives](http://arxiv.org/abs/1807.06921v1)• [Fake news as we feel it: perception and conceptualization of the term ‘fake news’ in the media](http://arxiv.org/abs/1807.06926v1)• [Stochastic Dominance Under Independent Noise](http://arxiv.org/abs/1807.06927v1)• [An ETH-Tight Exact Algorithm for Euclidean TSP](http://arxiv.org/abs/1807.06933v1)• [Identifying Position-Dependent Mechanical Systems: A Modal Approach with Applications to Wafer Stage Control](http://arxiv.org/abs/1807.06942v1)• [Linearity of Saturation for Berge Hypergraphs](http://arxiv.org/abs/1807.06947v1)• [On the Gardner-Zvavitch conjecture: symmetry in the inequalities of Brunn-Minkowski type](http://arxiv.org/abs/1807.06952v1)• [Method for motion artifact reduction using a convolutional neural network for dynamic contrast enhanced MRI of the liver](http://arxiv.org/abs/1807.06956v1)• [Quantifying Biases in Online Information Exposure](http://arxiv.org/abs/1807.06958v1)• [Active Learning for Segmentation by Optimizing Content Information for Maximal Entropy](http://arxiv.org/abs/1807.06962v1)• [The parameterised complexity of computing the maximum modularity of a graph](http://arxiv.org/abs/1807.06965v1)• [The Generalized Lasso for Sub-gaussian Measurements with Dithered Quantization](http://arxiv.org/abs/1807.06976v1)• [Quantile-Regression Inference With Adaptive Control of Size](http://arxiv.org/abs/1807.06977v1)• [Video Time: Properties, Encoders and Evaluation](http://arxiv.org/abs/1807.06980v1)• [A Quantitative Central Limit Theorem for the Excursion Area of Random Spherical Harmonics over Subdomains of $\mathbb{S}^2$](http://arxiv.org/abs/1807.06982v1)• [Intermediate spectral statistics in the many–body localization transition](http://arxiv.org/abs/1807.06983v1)• [An exploratory factor analysis model for slum severity index in Mexico City](http://arxiv.org/abs/1807.06994v1)• [Evolving Large-Scale Data Stream Analytics based on Scalable PANFIS](http://arxiv.org/abs/1807.06996v1)• [Is it worth it Budget-related evaluation metrics for model selection](http://arxiv.org/abs/1807.06998v1)• [Spectrum accessing optimization in congestion times in radio cognitive networks based on chaotic neural networks](http://arxiv.org/abs/1807.07000v1)• [Skin Lesion Segmentation and Classification for ISIC 2018 Using Traditional Classifiers with Hand-Crafted Features](http://arxiv.org/abs/1807.07001v1)• [Quantified boolean formula problem](http://arxiv.org/abs/1807.07005v1)• [Cruise Missile Target Trajectory Movement Prediction based on Optimal 3D Kalman Filter with Firefly Algorithm](http://arxiv.org/abs/1807.07006v1)• [Probability Density Function Estimation in OFDM Transmitter and Receiver in Radio Cognitive Networks based on Recurrent Neural Network](http://arxiv.org/abs/1807.07009v1)• [Learning Sums of Independent Random Variables with Sparse Collective Support](http://arxiv.org/abs/1807.07013v1)• [Cross-layer Optimization for High Speed Adders: A Pareto Driven Machine Learning Approach](http://arxiv.org/abs/1807.07023v1)• [Extrinsic Spin-Charge Coupling in Diffusive Superconducting Systems](http://arxiv.org/abs/1807.07029v1)• [Throttling for Zero Forcing and Variants](http://arxiv.org/abs/1807.07030v1)• [Sample Path Properties of the Average Generation of a Bellman-Harris Process](http://arxiv.org/abs/1807.07031v1)• [Skeletal Movement to Color Map: A Novel Representation for 3D Action Recognition with Inception Residual Networks](http://arxiv.org/abs/1807.07033v1)• [Heuristic Policies for Stochastic Knapsack Problem with Time-Varying Random Demand](http://arxiv.org/abs/1807.07034v1)• [Location Augmentation for CNN](http://arxiv.org/abs/1807.07044v1)• [Robot Learning in Homes: Improving Generalization and Reducing Dataset Bias](http://arxiv.org/abs/1807.07049v1)• [A New Index of Human Capital to Predict Economic Growth](http://arxiv.org/abs/1807.07051v1)• [Weighted Persistent Homology Sums of Random Cech Complexes](http://arxiv.org/abs/1807.07054v1)• [Hypergraphs not containing a tight tree with a bounded trunk ~II: 3-trees with a trunk of size 2](http://arxiv.org/abs/1807.07057v1)• [Semi-Markov processes, integro-differential equations and anomalous diffusion-aggregation](http://arxiv.org/abs/1807.07060v1)





### Like this:

Like Loading...


*Related*

