---
layout:     post
title:      AI and ML Futures 1： Background
subtitle:   转载自：http://inverseprobability.com/2016/01/17/machine-learning-futures-1
date:       2016-01-17
author:     未知
header-img: img/background3.jpg
catalog: true
tags:
    - short term
    - ai
    - elon
    - learning
    - debate
---

![](http://imgs.xkcd.com/comics/judgment_day.png)


With the purchase of DeepMind by Google for a rumoured 400 million pounds a chain of events was set off that began a debate in the glare of the media: just how far away was superintelligence, the AI singularity?

[Elon Musk was an investor in DeepMind](http://www.theguardian.com/technology/2014/jun/18/elon-musk-deepmind-ai-tesla-motors), and a reader of [Nick Boström’s](https://en.wikipedia.org/wiki/Nick_Bostrom) book “Superintelligence” and he became convinced that artificial intelligence was a threat to humanity [“We are summoning the demon” he said](https://www.washingtonpost.com/news/innovations/wp/2014/10/24/elon-musk-with-artificial-intelligence-we-are-summoning-the-demon).

To the researchers behind the most recent developments in AI, the idea that our faltering steps towards artificial *perceptual* systems were anywhere close to a demon seemed ridiculous (speech recognition, object recognition). But the public perception remained and yet others with little knowledge of the technologies underpinng the advances added their voices to the fray.

At the post conference banquet for NIPS 2014, a few of us were talking about the potential effect of these discussions on our research. There were various ideas about what the issues were and what our priorities should be, but the one aspect we all agreed on was that embracing the debate was the right thing to do. If the progenitors of the approaches which instigated these fears did not engage, someone else would on their behalf.

As it happened, in planning the 2015 edition of the conference one discussion was how to handle larger issues of the day (such as deep learning) which were in danger of dominating the conference. To appease the appetite for such issues to be comprehensively covered the 2015 committee resurrected the idea of “symposia”. Last run in Vancouver these were longer focussed events to develop topics of wider interest to NIPS attendees. When a symposium was proposed by Adrian Weller, Michael Osborne and Murray Shanahan: [“Algorithms Amoung Us”](http://www.doc.ic.ac.uk/~mpsha/NIPS_Symposium_2015.html), it was selected as one of three to be presented in 2015. It became apparent that with regard to the idea of xengagement, the view of those around the table in 2014 was shared by many, and the meeting, which covered many societal issues of AI: short term effects and long term fears, was warmly received.

However, at this point it was also apparent that more also needed to be done to bridge the arguments of the different fields and exchange points of view to found a more constructive debate. Fortunately in the meantime other initiatives had also been planned. At the 2015 DALI meeting Yann LeCun proposed a meeting to be held in January in New York on the “Future of AI”. Before reviewing that meeting though (held under Chatham House Rules) I want to pause and give some perspectives on the future of the field.

To stop any one post getting too long, I’m splitting these thoughts into several posts. This has given some of the background of how we came to be speaking about the societal impact of machine learning. Next I’ll try and give a short personal historical perspective of societal, which is mainly industrial, involvement in machine learning in the past.

This is post 1 in a series. [Next Post here](http://inverseprobability.com/2016/01/17/machine-learning-futures-2).
