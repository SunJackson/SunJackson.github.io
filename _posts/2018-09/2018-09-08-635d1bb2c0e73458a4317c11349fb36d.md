---
layout:     post
catalog: true
title:      Whats new on arXiv
subtitle:      转载自：https://advanceddataanalytics.net/2018/09/08/whats-new-on-arxiv-757/
date:      2018-09-08
author:      Michael Laux
tags:
    - networks
    - networked
    - models
    - modeling
    - based
---

**Eigenvalue analogy for confidence estimation in item-based recommender systems**

Item-item collaborative filtering (CF) models are a well known and studied family of recommender systems, however current literature does not provide any theoretical explanation of the conditions under which item-based recommendations will succeed or fail. We investigate the existence of an ideal item-based CF method able to make perfect recommendations. This CF model is formalized as an eigenvalue problem, where estimated ratings are equivalent to the true (unknown) ratings multiplied by a user-specific eigenvalue of the similarity matrix. Preliminary experiments show that the magnitude of the eigenvalue is proportional to the accuracy of recommendations for that user and therefore it can provide reliable measure of confidence.

**A change-point problem and inference for segment signals**

We address the problem of detection and estimation of one or two change-points in the mean of a series of random variables. We use the formalism of set estimation in regression: To each point of a design is attached a binary label that indicates whether that point belongs to an unknown segment and this label is contaminated with noise. The endpoints of the unknown segment are the change-points. We study the minimal size of the segment which allows statistical detection in different scenarios, including when the endpoints are separated from the boundary of the domain of the design, or when they are separated from one another. We compare this minimal size with the minimax rates of convergence for estimation of the segment under the same scenarios. The aim of this extensive study of a simple yet fundamental version of the change-point problem is twofold: Understanding the impact of the location and the separation of the change points on detection and estimation and bringing insights about the estimation and detection of convex bodies in higher dimensions.

**Hyperbolic Recommender Systems**

Many well-established recommender systems are based on representation learning in Euclidean space. In these models, matching functions such as the Euclidean distance or inner product are typically used for computing similarity scores between user and item embeddings. This paper investigates the notion of learning user and item representations in Hyperbolic space. In this paper, we argue that Hyperbolic space is more suitable for learning user-item embeddings in the recommendation domain. Unlike Euclidean spaces, Hyperbolic spaces are intrinsically equipped to handle hierarchical structure, encouraged by its property of exponentially increasing distances away from origin. We propose HyperBPR (Hyperbolic Bayesian Personalized Ranking), a conceptually simple but highly effective model for the task at hand. Our proposed HyperBPR not only outperforms their Euclidean counterparts, but also achieves state-of-the-art performance on multiple benchmark datasets, demonstrating the effectiveness of personalized recommendation in Hyperbolic space.

**An Analysis of Hierarchical Text Classification Using Word Embeddings**
![](https://s0.wp.com/latex.php?latex=%7B%7D_%7BLCA%7DF_1&bg=ffffff&fg=000&s=0)


**MDCN: Multi-Scale, Deep Inception Convolutional Neural Networks for Efficient Object Detection**

Object detection in challenging situations such as scale variation, occlusion, and truncation depends not only on feature details but also on contextual information. Most previous networks emphasize too much on detailed feature extraction through deeper and wider networks, which may enhance the accuracy of object detection to certain extent. However, the feature details are easily being changed or washed out after passing through complicated filtering structures. To better handle these challenges, the paper proposes a novel framework, multi-scale, deep inception convolutional neural network (MDCN), which focuses on wider and broader object regions by activating feature maps produced in the deep part of the network. Instead of incepting inner layers in the shallow part of the network, multi-scale inceptions are introduced in the deep layers. The proposed framework integrates the contextual information into the learning process through a single-shot network structure. It is computational efficient and avoids the hard training problem of previous macro feature extraction network designed for shallow layers. Extensive experiments demonstrate the effectiveness and superior performance of MDCN over the state-of-the-art models.

**Narrating a Knowledge Base**

We aim to automatically generate natural language narratives about an input structured knowledge base (KB). We build our generation framework based on a pointer network which can copy facts from the input KB, and add two attention mechanisms: (i) slot-aware attention to capture the association between a slot type and its corresponding slot value; and (ii) a new table position self-attention to capture the inter-dependencies among related slots. For evaluation, besides standard metrics including BLEU, METEOR, and ROUGE, we also propose a \textit{KB reconstruction} based metric by extracting a KB from the generation output and comparing it with the input KB. We also create a new data set which includes 106,216 pairs of structured KBs and their corresponding natural language descriptions for two distinct entity types. Experiments show that our approach significantly outperforms state-of-the-art methods. The reconstructed KB achieves 68.8% – 72.6% F-score.

**Interpretable Visual Question Answering by Reasoning on Dependency Trees**

Collaborative reasoning for understanding each image-question pair is very critical but underexplored for an interpretable visual question answering system. Although very recent works also attempted to use explicit compositional processes to assemble multiple subtasks embedded in the questions, their models heavily rely on annotations or handcrafted rules to obtain valid reasoning processes, leading to either heavy workloads or poor performance on composition reasoning. In this paper, to better align image and language domains in diverse and unrestricted cases, we propose a novel neural network model that performs global reasoning on a dependency tree parsed from the question, and we thus phrase our model as parse-tree-guided reasoning network (PTGRN). This network consists of three collaborative modules: i) an attention module to exploit the local visual evidence for each word parsed from the question, ii) a gated residual composition module to compose the previously mined evidence, and iii) a parse-tree-guided propagation module to pass the mined evidence along the parse tree. Our PTGRN is thus capable of building an interpretable VQA system that gradually derives the image cues following a question-driven parse-tree reasoning route. Experiments on relational datasets demonstrate the superiority of our PTGRN over current state-of-the-art VQA methods, and the visualization results highlight the explainable capability of our reasoning system.

**CASC: Context-Aware Segmentation and Clustering for Motif Discovery in Noisy Time Series Data**

Complex systems, such as airplanes, cars, or financial markets, produce multivariate time series data consisting of system observations over a period of time. Such data can be interpreted as a sequence of segments, where each segment is associated with a certain state of the system. An important problem in this domain is to identify repeated sequences of states, known as motifs. Such motifs correspond to complex behaviors that capture common sequences of state transitions. For example, a motif of ‘making a turn’ might manifest in sensor data as a sequence of states: slowing down, turning the wheel, and then speeding back up. However, discovering these motifs is challenging, because the individual states are unknown and need to be learned from the noisy time series. Simultaneously, the time series also needs to be precisely segmented and each segment needs to be associated with a state. Here we develop context-aware segmentation and clustering (CASC), a method for discovering common motifs in time series data. We formulate the problem of motif discovery as a large optimization problem, which we then solve using a greedy alternating minimization-based approach. CASC performs well in the presence of noise in the input data and is scalable to very large datasets. Furthermore, CASC leverages common motifs to more robustly segment the time series and assign segments to states. Experiments on synthetic data show that CASC outperforms state-of-the-art baselines by up to 38.2%, and two case studies demonstrate how our approach discovers insightful motifs in real-world time series data.

**Adversarial Reprogramming of Sequence Classification Neural Networks**

Adversarial Reprogramming has demonstrated success in utilizing pre-trained neural network classifiers for alternative classification tasks without modification to the original network. An adversary in such an attack scenario trains an additive contribution to the inputs to repurpose the neural network for the new classification task. While this reprogramming approach works for neural networks with a continuous input space such as that of images, it is not directly applicable to neural networks trained for tasks such as text classification, where the input space is discrete. Repurposing such classification networks would require the attacker to learn an adversarial program that maps inputs from one discrete space to the other. In this work, we introduce a context-based vocabulary remapping model to reprogram neural networks trained on a specific sequence classification task, for a new sequence classification task desired by the adversary. We propose training procedures for this adversarial program in both white-box and black-box settings. We demonstrate the application of our model by adversarially repurposing various text-classification models including LSTM, bi-directional LSTM and CNN for alternate classification tasks.

**How to Combine Tree-Search Methods in Reinforcement Learning**
![](https://s0.wp.com/latex.php?latex=h&bg=ffffff&fg=000&s=0)


**GAMENet: Graph Augmented MEmory Networks for Recommending Medication Combination**

Recent progress in deep learning is revolutionizing the healthcare domain including providing solutions to medication recommendations, especially recommending medication combination for patients with complex health conditions. Existing approaches either do not customize based on patient health history, or ignore existing knowledge on drug-drug interactions (DDI) that might lead to adverse outcomes. To fill this gap, we propose the Graph Augmented Memory Networks (GAMENet), which integrates the drug-drug interactions knowledge graph by a memory module implemented as a graph convolutional networks, and models longitudinal patient records as the query. It is trained end-to-end to provide safe and personalized recommendation of medication combination. We demonstrate the effectiveness and safety of GAMENet by comparing with several state-of-the-art methods on real EHR data. GAMENet outperformed all baselines in all effectiveness measures, and also achieved 3.60% DDI rate reduction from existing EHR data.

**Propheticus: Generalizable Machine Learning Framework**

Due to recent technological developments, Machine Learning (ML), a subfield of Artificial Intelligence (AI), has been successfully used to process and extract knowledge from a variety of complex problems. However, a thorough ML approach is complex and highly dependent on the problem at hand. Additionally, implementing the logic required to execute the experiments is no small nor trivial deed, consequentially increasing the probability of faulty code which can compromise the results. Propheticus is a data-driven framework which results of the need for a tool that abstracts some of the inherent complexity of ML, whilst being easy to understand and use, as well as to adapt and expand to assist the user’s specific needs. Propheticus systematizes and enforces various complex concepts of an ML experiment workflow, taking into account the nature of both the problem and the data. It contains functionalities to execute all the different tasks, from data preprocessing, to results analysis and comparison. Notwithstanding, it can be fairly easily adapted to different problems due to its flexible architecture, and customized as needed to address the user’s needs.

**Model-Based Stabilisation of Deep Reinforcement Learning**

Though successful in high-dimensional domains, deep reinforcement learning exhibits high sample complexity and suffers from stability issues as reported by researchers and practitioners in the field. These problems hinder the application of such algorithms in real-world and safety-critical scenarios. In this paper, we take steps towards stable and efficient reinforcement learning by following a model-based approach that is known to reduce agent-environment interactions. Namely, our method augments deep Q-networks (DQNs) with model predictions for transitions, rewards, and termination flags. Having the model at hand, we then conduct a rigorous theoretical study of our algorithm and show, for the first time, convergence to a stationary point. En route, we provide a counter-example showing that ‘vanilla’ DQNs can diverge confirming practitioners’ and researchers’ experiences. Our proof is novel in its own right and can be extended to other forms of deep reinforcement learning. In particular, we believe exploiting the relation between reinforcement (with deep function approximators) and online learning can serve as a recipe for future proofs in the domain. Finally, we validate our theoretical results in 20 games from the Atari benchmark. Our results show that following the proposed model-based learning approach not only ensures convergence but leads to a reduction in sample complexity and superior performance.

**Hands-on Experience with Gaussian Processes (GPs): Implementing GPs in Python – I**

This document serves to complement our website which was developed with the aim of exposing the students to Gaussian Processes (GPs). GPs are non-parametric Bayesian regression models that are largely used by statisticians and geospatial data scientists for modeling spatial data. Several open source libraries spanning from Matlab [1], Python [2], R [3] etc., are already available for simple plug-and-use. The objective of this handout and in turn the website was to allow the users to develop stand-alone GPs in Python by relying on minimal external dependencies. To this end, we only use the default python modules and assist the users in developing their own GPs from scratch giving them an in-depth knowledge of what goes on under the hood. The module covers GP inference using maximum likelihood estimation (MLE) and gives examples of 1D (dummy) spatial data.

**RDPD: Rich Data Helps Poor Data via Imitation**

In many situations, we have both rich- and poor- data environments: in a rich-data environment (e.g., intensive care units), we have high-quality multi-modality data. On the other hand, in a poor-data environment (e.g., at home), we often only have access to a single data modality with low quality. How can we learn an accurate and efficient model for the poor-data environment by leveraging multi-modality data from the rich-data environment? In this work, we propose a knowledge distillation model RDPD to enhance a small model trained on poor data with a complex model trained on rich data. In an end-to-end fashion, RDPD trains a student model built on a single modality data (poor data) to imitate the behavior and performance of a teacher model from multimodal data (rich data) via jointly optimizing the combined loss of attention imitation and target imitation. We evaluated RDPD on three real-world datasets. RDPD consistently outperformed all baselines across all three datasets, especially achieving the greatest performance improvement over a standard neural network model trained on the common features (Direct model) by 24.56% on PR-AUC and 12.21% on ROC-AUC, and over the standard knowledge distillation model by 5.91% on PR-AUC and 4.44% on ROC-AUC.

**A tutorial on Particle Swarm Optimization Clustering**

This paper proposes a tutorial on the Data Clustering technique using the Particle Swarm Optimization approach. Following the work proposed by Merwe et al. here we present an in-deep analysis of the algorithm together with a Matlab implementation and a short tutorial that explains how to modify the proposed implementation and the effect of the parameters of the original algorithm. Moreover, we provide a comparison against the results obtained using the well known K-Means approach. All the source code presented in this paper is publicly available under the GPL-v2 license.

**Training Millions of Personalized Dialogue Agents**

Current dialogue systems are not very engaging for users, especially when trained end-to-end without relying on proactive reengaging scripted strategies. Zhang et al. (2018) showed that the engagement level of end-to-end dialogue models increases when conditioning them on text personas providing some personalized back-story to the model. However, the dataset used in Zhang et al. (2018) is synthetic and of limited size as it contains around 1k different personas. In this paper we introduce a new dataset providing 5 million personas and 700 million persona-based dialogues. Our experiments show that, at this scale, training using personas still improves the performance of end-to-end systems. In addition, we show that other tasks benefit from the wide coverage of our dataset by fine-tuning our model on the data from Zhang et al. (2018) and achieving state-of-the-art results.

**Scalable Load Balancing Algorithms in Networked Systems**

A fundamental challenge in large-scale networked systems viz., data centers and cloud networks is to distribute tasks to a pool of servers, using minimal instantaneous state information, while providing excellent delay performance. In this thesis we design and analyze load balancing algorithms that aim to achieve a highly efficient distribution of tasks, optimize server utilization, and minimize communication overhead.

**Sample-Efficient Imitation Learning via Generative Adversarial Nets**

Recent work in imitation learning articulate their formulation around the GAIL architecture, relying on the adversarial training procedure introduced in GANs. Albeit successful at generating behaviours similar to those demonstrated to the agent, GAIL suffers from a high sample complexity in the number of interactions it has to carry out in the environment in order to achieve satisfactory performance. In this work, we dramatically shrink the amount of interactions with the environment by leveraging an off-policy actor-critic architecture. Additionally, employing deterministic policy gradients allows us to treat the learned reward as a differentiable node in the computational graph, while preserving the model-free nature of our approach. Our experiments span a variety of continuous control tasks.

**A Memory-Network Based Solution for Multivariate Time-Series Forecasting**

Multivariate time series forecasting is extensively studied throughout the years with ubiquitous applications in areas such as finance, traffic, environment, etc. Still, concerns have been raised on traditional methods for incapable of modeling complex patterns or dependencies lying in real word data. To address such concerns, various deep learning models, mainly Recurrent Neural Network (RNN) based methods, are proposed. Nevertheless, capturing extremely long-term patterns while effectively incorporating information from other variables remains a challenge for time-series forecasting. Furthermore, lack-of-explainability remains one serious drawback for deep neural network models. Inspired by Memory Network proposed for solving the question-answering task, we propose a deep learning based model named Memory Time-series network (MTNet) for time series forecasting. MTNet consists of a large memory component, three separate encoders, and an autoregressive component to train jointly. Additionally, the attention mechanism designed enable MTNet to be highly interpretable. We can easily tell which part of the historic data is referenced the most.

**ANS: Adaptive Network Scaling for Deep Rectifier Reinforcement Learning Models**

This work provides a thorough study on how reward scaling can affect performance of deep reinforcement learning agents. In particular, we would like to answer the question that how does reward scaling affect non-saturating ReLU networks in RL? This question matters because ReLU is one of the most effective activation functions for deep learning models. We also propose an Adaptive Network Scaling framework to find a suitable scale of the rewards during learning for better performance. We conducted empirical studies to justify the solution.

**Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning**

Learning how to act when there are many available actions in each state is a challenging task for Reinforcement Learning (RL) agents, especially when many of the actions are redundant or irrelevant. In such cases, it is sometimes easier to learn which actions not to take. In this work, we propose the Action-Elimination Deep Q-Network (AE-DQN) architecture that combines a Deep RL algorithm with an Action Elimination Network (AEN) that eliminates sub-optimal actions. The AEN is trained to predict invalid actions, supervised by an external elimination signal provided by the environment. Simulations demonstrate a considerable speedup and added robustness over vanilla DQN in text-based games with over a thousand discrete actions.

• Calibration for massive physiological signal collection in hospital — Sawtooth artifact in beat-to-beat pulse transit time measured from patient monitor data• A Limitation of V-Matrix based Methods• Named Entity Recognition on Noisy Data using Images and Text (1-page abstract)• Three-Stage Speaker Verification Architecture in Emotional Talking Environments• HASP: A High-Performance Adaptive Mobile Security Enhancement Against Malicious Speech Recognition• Deep Joint Source-Channel Coding for Wireless Image Transmission• Quantum algorithms and lower bounds for convex optimization• Optimal merging from an on-ramp into a high-speed lane dedicated to connected autonomous vehicles• Recurrent World Models Facilitate Policy Evolution• Inexact cuts in Stochastic Dual Dynamic Programming• Sample Design for Medicaid and Healthcare Audits• Hierarchical Distribution Matching for Probabilistically Shaped Coded Modulation• Parameter estimation for mixed sub-fractional Ornstein-Ulenbeck process• Latent Molecular Optimization for Targeted Therapeutic Design• A Differentially Private Wilcoxon Signed-Rank Test• Quantum Topological Boundary States in Quasi-crystal• Hierarchical Selective Recruitment in Linear-Threshold Brain Networks – Part I: Intra-Layer Dynamics and Selective Inhibition• Measures of Cluster Informativeness for Medical Evidence Aggregation and Dissemination• Deep Relevance Ranking Using Enhanced Document-Query Interactions• Breast Mass Segmentation and Shape Classification in Mammograms Using Deep Neural Networks• Accelerated Reinforcement Learning for Sentence Generation by Vocabulary Prediction• TVQA: Localized, Compositional Video Question Answering• Pack and Detect: Fast Object Detection in Videos Using Region-of-Interest Packing• Design and Realization of Intersection Traffic Control Simulation System Using Connected Vehicle Technology• Real-time Optimal Resource Allocation for Embedded UAV Communication Systems• Optimal On-Off Control for a Class of Discrete Event Systems with Real-Time Constraints• Controlled Random Search Improves Sample Mining and Hyper-Parameter Optimization• Bridging machine learning and cryptography in defence against adversarial attacks• The Multilinear Minimax Relaxation of Bimatrix Games and Comparison with Nash Equilibria via Lemke-Howson• Q-zero range has random walking shocks• Neural Comic Style Transfer: Case Study• Attention-based Audio-Visual Fusion for Robust Automatic Speech Recognition• Recovering a Single Community with Side Information• Join-the-Shortest Queue Diffusion Limit in Halfin-Whitt Regime: Sensitivity on the Heavy-traffic Parameter• Predicting Smoking Events with a Time-Varying Semi-Parametric Hawkes Process Model• On the wellposedness of some McKean models with moderated or singular diffusion coefficient• A deep learning approach for Magnetic Resonance Fingerprinting• Token Curated Registries – A Game Theoretic Approach• Multi-finger binary search trees• Zero-diffusion Limit for Aggregation Equations over Bounded Domains• Sample Efficient Stochastic Gradient Iterative Hard Thresholding Method for Stochastic Sparse Linear Regression with Limited Attribute Observation• Special Configurations in Anchored Rectangle Packings• Multi-view Factorization AutoEncoder with Network Constraints for Multi-omic Integrative Analysis• Tight MIP formulations for bounded length cyclic sequences• Deep Recurrent Electricity Theft Detection in AMI Networks with Random Tuning of Hyper-parameters• Factorization and estimates of Dirichlet heat kernels for non-local operators with critical killings• Controlling FDR while highlighting distinct discoveries• One-Shot Variable-Length Secret Key Agreement Approaching Mutual Information• Information-Theoretic Privacy in Distributed Average Consensus• Optimal Sparse Singular Value Decomposition for High-dimensional High-order Data• A Bridge between Liquid and Social Welfare in Combinatorial Auctions with Submodular Bidders• Discovering Influential Factors in Variational Autoencoder• Strong list-chromatic index of subcubic graphs• Improbotics: Exploring the Imitation Game using Machine Intelligence in Improvised Theatre• Security Metrics of Networked Control Systems under Sensor Attacks (extended preprint)• Noise Contrastive Estimation and Negative Sampling for Conditional Models: Consistency and Statistical Efficiency• Visual Coreference Resolution in Visual Dialog using Neural Module Networks• Online Adaptive Image Reconstruction (OnAIR) Using Dictionary Models• Improving Explorability in Variational Inference with Annealed Variational Objectives• Driving Experience Transfer Method for End-to-End Control of Self-Driving Cars• Smooth entrywise positivity preservers, a Horn-Loewner master theorem, and Schur polynomials• Connecting Image Denoising and High-Level Vision Tasks via Deep Learning• Eigendecomposition-Free Sampling Set Selection for Graph Signals• The Block Bootstrap Method for Longitudinal Microbiome Data• Wasserstein Soft Label Propagation on Hypergraphs: Algorithm and Generalization Error Bounds• Unsupervised Learning of View-invariant Action Representations• Yes, IoU loss is submodular – as a function of the mispredictions• Determination of Stationary Points and Their Bindings in Dataset using RBF Methods• Top-down Tree Structured Decoding with Syntactic Connections for Neural Machine Translation and Parsing• Deep Learning-Based Decoding for Constrained Sequence Codes• Cluster algebras with Grassmann variables• Automated Quality Assessment of Space-Continuous Models for Pedestrian Dynamics• LMMSE Receivers in Uplink Massive MIMO Systems with Correlated Rician Fading• The Minrank of Random Graphs over Arbitrary Fields• Existence and uniqueness of the solutions of forward-backward doubly stochastic differential equations with Poisson jumps• A Stochastic Maximum Principle for Markov chains of mean-field type• Travel Speed Prediction with a Hierarchical Convolutional Neural Network and Long Short-Term Memory Model Framework• On the order of regular graphs with fixed second largest eigenvalue• Full-body High-resolution Anime Generation with Progressive Structure-conditional Generative Adversarial Networks• Open-Loop and Closed-Loop Solvabilities for Stochastic Linear Quadratic Optimal Control Problems of Markov Regime-Switching System• Extremal graphs for vertex-degree-based invariants with given degree sequences• Reversible Markov chains: variational representations and ordering• The sharp threshold for jigsaw percolation in random graphs• Malliavin-Stein Method: a Survey of Recent Developments• Dynamic Block Matching to assess the longitudinal component of the dense motion field of the carotid artery wall in B-mode ultrasound sequences – Association with coronary artery disease• One-shot Learning for iEEG Seizure Detection Using End-to-end Binary Operations: Local Binary Patterns with Hyperdimensional Computing• Multi-User Visible Light Communications: State-of-the-Art and Future Directions• An unexpected connection between Bayes $A-$optimal designs and the Group Lasso• Towards online triggering for the radio detection of air showers using deep neural networks• The size of the primes obstructing the existence of rational points• Disentangled Variational Representation for Heterogeneous Face Recognition• Strong convergence for explicit space-time discrete numerical approximation for 2D stochastic Navier-Stokes equations• Why are Sequence-to-Sequence Models So Dull? Understanding the Low-Diversity Problem of Chatbots• Cascaded Mutual Modulation for Visual Reasoning• Analyzing and improving maximal attainable accuracy in the communication hiding pipelined BiCGStab method• A solution of the minimum-time velocity planning problem based on lattice theory• A Generalized Central Sets Theorem In Partial Semigroups• Code-switched Language Models Using Dual RNNs and Same-Source Pretraining• Time-optimality by distance-optimality for parabolic control systems• Graph-based algorithms for the efficient solution of a class of optimization problems• Pore detection in high-resolution fingerprint images using Deep Residual Network• Multi-Expert Gender Classifications on Age Groups by Integrating Deep Neural Networks• Evaluation Measures for Quantification: An Axiomatic Approach• Dense Pose Transfer• Dual Ask-Answer Network for Machine Reading Comprehension• Min (A)cyclic Feedback Vertex Sets and Min Ones Monotone 3-SAT• 3D Surface Reconstruction by Pointillism• Robust H-infinity Adaptive Fuzzy Approach for Unknown Nonlinear Networked Systems• Rigidity for sticky disks• On some new hook-content identities• Gaussian Process Regression for Binned Data• Exponential decay for the exit probability from slabs of ballistic RWRE• The peeling process on random planar maps coupled to an O(n) loop model (with an appendix by Linxiao Chen)• Dynamic Bayesian Games for Adversarial and Defensive Cyber Deception• Logarithmic regret in the dynamic and stochastic knapsack problem• Robust Signaling for Bursty Interference• Harmonizing discovery thresholds and reporting two-sided confidence intervals: a modified Feldman & Cousins method• Variable order Mittag-Leffler fractional operators on isolated time scales and application to the calculus of variations• Planning with Arithmetic and Geometric Attributes• Evaluating Syntactic Properties of Seq2seq Output with a Broad Coverage HPSG: A Case Study on Machine Translation• Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks• On-Orbit Smart Camera System to Observe Illuminated and Unilluminated Space Objects• Oblique Stripe Removal in Remote Sensing Images via Oriented Variation• On Stein’s Method for Multivariate Self-Decomposable Laws With Finite First Moment• Surface Light Field Fusion• Memory Replay GANs: learning to generate images from new categories without forgetting• Around the entropic Talagrand inequality• Extracting distribution parameters from multiple uncertain observations with selection biases• Two Dimensional Stochastic Configuration Networks for Image Data Analytics• Deep learning for in vitro prediction of pharmaceutical formulations• ARCHER: Aggressive Rewards to Counter bias in Hindsight Experience Replay• Multiple Object Tracking in Urban Traffic Scenes with a Multiclass Object Detector• Spectral gap critical exponent for Glauber dynamics of hierarchical spin models• IDSGAN: Generative Adversarial Networks for Attack Generation against Intrusion Detection• Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models• On $\mathbb{R}^d$-valued multi-self-similar Markov processes• A Mathematical Model for Vineyard Replacement with Nonlinear Binary Control Optimization• Bayesian, classical and hybrid methods of inference when one parameter value is special• The Tutte embedding of the Poisson-Voronoi tessellation of the Brownian disk converges to $\sqrt{8/3}$-Liouville quantum gravity• Uniqueness of the welding problem for SLE and Liouville quantum gravity• Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation• The Zumbach effect under rough Heston• Homogenization of an advection equation with locally stationary random coefficients• Triple systems with no three triples spanning at most five points• Stable Lévy motion with values in the Skorokhod space: construction and approximation• Are adversarial examples inevitable?• Deep Audio-Visual Speech Recognition• Panoptic Segmentation with a Joint Semantic and Instance Segmentation Network• A Low Complexity Detection Algorithm Based on Alternating Minimization• Labeling Panoramas with Spherical Hourglass Networks• On the dynamics of Simulated Quantum Annealing in random Ising chains• Structural Consistency and Controllability for Diverse Colorization





### Like this:

Like Loading...


*Related*

