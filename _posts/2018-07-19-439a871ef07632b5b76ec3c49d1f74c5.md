---
layout:     post
title:      Conversion rates &ndash; you are (most likely) computing them wrong
subtitle:   转载自：https://erikbern.com/2017/05/23/conversion-rates-you-are-most-likely-computing-them-wrong.html
date:       2018-07-19
author:     未知
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - https
    - rates
    - cohorts
    - data
    - conversion
    - cohort plots
    - companies
    - people
    - itâ
    - survival
    - kaplan
    - looked
    - converted
    - converting
    - estimator
    - estimate
    - observed
    - observations
    - exited
    - exiting
    - exits
    - lag
    - instance look
    - correct
    - code
    - diff
    - confidence
    - feedback
    - growing
    - free
    - ts ys
    - charts
    - highly
    - letâ
---

How hard can it be to compute conversion rate? Take the total number of users that converted and divide them with the total number of users. *Done.* Exceptâ€¦ itâ€™s a lot more complicated when you have any sort of significant time lag.

## Prelude â€“ a story

Fresh out of school I joined Spotify as the first data analyst. One of my first projects was to understand conversion rates. Conversion rate from the free service to Premium is tricky because thereâ€™s a huge time lag. At that time, labels were highly skeptical that we would be able to convert many users, and this was a contentious source of disagreement. We had converted a really small fraction of our users, and we kept growing our free users like crazy. The conversion rates was standing still, if not going down.

The â€œinsightâ€� I had was when I started breaking it up into cohorts. For instance, look at all users that joined on May 1 and track their conversion rate over time. The beautiful thing that happened was that *the conversion rate keeps growing and growing over time*. People converted at an almost uniform rate over the first few years. It was amazing to see. Some of the old cohorts that had used the service for 2+ years had some crazy high conversion rates, like 40-50%. This insight it implied that conversion rates wasnâ€™t a big problem, and it was only becuase *we were growing exponentially* that the *current conversion rate* looked â€œartificiallyâ€� low.

![](https://erikbern.com/assets/spotify_conversion_rate.png)


My lesson here is that conversion rates are sometimes pointless to try to quantify as a single number. Sometimes itâ€™s a useful metric, but in many cases itâ€™s not. Spotifyâ€™s conversion rate is not that useful to know in itself, since the user base is not in equilibrium. As long as the user base keeps growing, and as long as thereâ€™s a substantial lag until conversion, you really canâ€™t say anything by trying to quantify it into a single number.

## An example â€“ exit rate for startups 2008-2015

Letâ€™s go through an example of all the bad ways to look at conversion and then arrive at what I think of as the â€œbest wayâ€� (in my ~~humble~~ correct opinion). Just for fun, I scraped a bunch of startup data from a well-known database of startups. Not going to get into all the gory details of the scraping, except that scraping is fun and if you do it too much your scraper gets bannedâ€¦ I probably could have used some lame boring data set, but data analysis is 38.1% more fun if you can relate to the data.

I have about 1,836 companies in the data set that were invested at some point, and 243 (13%) that exited at some point (either IPO or acquisition). So letâ€™s for instance ask ourselves, how is the conversion rate going? Are newer companies exiting at a higher rate than older companies? Or is it getting harder over time to exit? The naÃ¯ve way is to break it up by year founded and compute the conversion rates:

![](https://erikbern.com/assets/conversion_by_year.png)


Except for 2008, it looks like the conversion rate is *going down*. Why? Is it harder and harder for companies to exit? Letâ€™s look at the *time to exit as well*.

![](https://erikbern.com/assets/time_to_conversion_by_year.png)


Here we see the opposite trend of what we saw in the previous chart â€“ it seems like itâ€™s getting easier and easier for companies to exit!

So whatâ€™s going on? If you think about it for a bit itâ€™s pretty clear â€“ we are mixing data from 2008 (where the companies have had 9 years to convert) with data from 2016 (where companies have had a year or less). We donâ€™t know what companies from the 2016 group that will convert *in the future*.

Both of these charts underlines that thereâ€™s often no such thing as a single â€œconversion rateâ€� and no such thing as a â€œtime to conversionâ€�. In the case where conversion has some clear upper time limit, you might get away talking about those metrics. For instance, itâ€™s probably fine to measure landing page conversion rate by looking at how many people clicked a link within an hour. But in many cases, including the case of startup exits, as well as Spotify free to Premium, â€œconversion rateâ€� and â€œtime to conversionâ€� is nonsensical and cannot be defined.

## The right way to look at conversion rates â€“ cohort plots

To compare conversion rates, it makes a lot more sense to compare the *at time T*, where T is some time lag such as 7 days or 30 days or 1 year or whatever. For instance in order to compare the conversion rates for the companies in the 2012 and 2014 cohort, compare what percentage of them has converted within 24 months.

We extend this to *all* times *T*, and plot it as a function of T. Does it take longer to exit for startups that started in 2014 compared to 2008? Letâ€™s take a look:

![](https://erikbern.com/assets/cohort_plot_all_years.png)


Iâ€™m not sure whatâ€™s the â€œofficial nameâ€� of a plot like this, but generally people refer to it as a *cohort plot*. For every cohort, we look at the conversion rate *at time T*. Note that since we donâ€™t know anything about the future, we canâ€™t say much about the 2016 cohort beyond ~5 months â€“ it includes some companies started in Dec 2016 so we simply donâ€™t have full data after 5 months. This is all great and checks a lot of boxes:

- We can compare conversion rates for different cohorts and understand if itâ€™s getting better or worse âœ…

- We can see if certain cohorts convert faster âœ…


I generally think of this approach as â€œas good as it getsâ€� in most situations. Except my only issue with it is that the idea of measuring â€œconversion at time Tâ€� means we canâ€™t use too much recent data. For instance, it would be much better if we could look at 2017 data and see how well itâ€™s converting? I like metrics to have fast feedback loops so surely we can do better? Turns out we can.

## The ğŸ˜� way to look at conversion rates â€“ Kaplan-Meier

[Kaplan-Meier](https://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator estimator) is a *non-parametric* estimator originally used to estimate the survival function. Turns out the survival function is 1 minus the conversion rate, so itâ€™s the exact same thing essentially. Non-parameteric is good if you have no idea what the underlying distribution you are modeling is.

The best part of the Kaplan-Meier is that it lets us include data for which we simply havenâ€™t observed anything past a certain point. This is best illustrated if we broaden each cohort a bit so that they contain a larger span. Letâ€™s say weâ€™re trying to understand the conversion rate of the 2008-2011 cohort vs the conversion rate of the 2012-2015 cohort. The hypothesis would be that we want to understand how the exit rate has changed over time:

![](https://erikbern.com/assets/cohort_plot_grouped.png)


This is a super simple plot to draw except for the confidence interval. Just literally divide the number of exited companies by the total number of companies to get a rate.

The problem here is that we canâ€™t say anything about the second cohort beyond ~1.5 years because *that would require saying something about future data*. This cohort contains companies up to and including Dec 31, 2015, which have had slightly less than 18 months of history to convert. On the other hand, the oldest companies in this cohort are from Jan 2012, so they have had a lot of time to convert. Surely we should be able to plot something more for this cohort. The Kaplan-Meier estimator lets us work with this issue by being smart with how it treats â€œfutureâ€� data for different observations (â€œcensoredâ€� observations, as itâ€™s called in survival analysis lingo):

![](https://erikbern.com/assets/kaplan_meier_grouped.png)


The implementation is absolutely trivial, although I used the [lifelines](https://github.com/CamDavidsonPilon/lifelines) packages in Python to get this and we also get a snazzy confidence interval for free (this is a bit harder to do). So the conclusion here is that yes â€“ it seems like newer companies donâ€™t convert at the same rate as older.

If you want to implement Kaplan-Meier yourself, the idea is basically to compute a conversion â€œsurvival rateâ€�. If we start out with 100 items and one of them convert at time 1, the survival rate is 99%. We keep computing those rates and multiply them together. When data is â€œcensoredâ€�, we just remove from the denominator:

```
n, k = len(te), 0
ts, ys = [], []
p = 1.0
for t, e in te:
 if e:
 # whether the event was "observed" (converted)
# not observed means they may still convert in the future
 p *= (n-1) / n
 n -= 1
 ts.append(t)
 ys.append(100. * (1-p))
pyplot.plot(ts, ys, 'b')

```

Kaplan-Meier lets us get a bit more out of each cohort. Look at what happens if we plot one cohort for each year:

![](https://erikbern.com/assets/cohort_vs_kaplan_meier.gif)


## Epilogue

In [a previous post](https://erikbern.com/2016/12/05/the-half-life-of-code.html), I built a tool to analyze the survival of code. Given that itâ€™s obviously survival analysis, I went back and [updated the tool](https://github.com/erikbern/git-of-theseus/pull/32) tool to plot survival rates (of code) using Kaplan-Meier since it was such a tiny diff. Hereâ€™s the survival curve of individual lines of code of [Git](https://github.com/git/git) itself:

![](https://erikbern.com/assets/kaplan_meier_git.png)


Cool to see that a few lines of code are still present after 12 years!

## Conclusion

When people talk about conversion, and if thereâ€™s time lag involved, remember: *itâ€™s complicated!*

## Notes
