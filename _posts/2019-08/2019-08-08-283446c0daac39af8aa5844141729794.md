---
layout:     post
catalog: true
title:      B3 is NOT shutting down its ftp site, for now..
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/d0u1r3T6E8k/
date:      2019-08-08
author:      R on msperlin
tags:
    - trades
    - df
    - type
    - ftp
    - tickers
---



[This article was first published on ** R on msperlin**, and kindly contributed to R-bloggers]. (You can report issue about the content on this page here)
Want to share your content on R-bloggers? click here if you have a blog, or here if you don't.



**Surprise, surprise. B3’s ftp site is still up and running.**

Following previous post regarding the shutdown of B3’s ftp site and its impact over GetHFData, I’m happy to report that the site is up and running.

We can check it with code:

```
library(GetHFData)
library(tidyverse)

df.ftp <- ghfd_get_ftp_contents(type.market = 'equity')
```

```
## 
## Reading ftp contents for equity(trades) (attempt = 1|10)
```

```
# check time difference
max(df.ftp$dates) - min(df.ftp$dates)
```

```
## Time difference of 158 days
```

Let’s download some trade data:

```
df.trades <- ghfd_get_HF_data(my.assets = 'PETR3', 
 type.market = 'equity', 
 first.date = Sys.Date()-6, 
 last.date = Sys.Date(),type.data = 'trades', type.output = 'agg', 
 first.time = '11:00:00', last.time = '18:00:00', dl.dir = tempdir()
 )
```

```
## 
## Running ghfd_get_HF_Data for:
## type.market = equity
## type.data = trades
## my.assets = PETR3
## type.output = agg
## agg.diff = 15 min
## Reading ftp contents for equity(trades) (attempt = 1|10)
## Found 107 files in ftp
## First available date in ftp: 2019-02-28
## Last available date in ftp: 2019-08-05
## First date to download: 2019-08-02
## Last date to download: 2019-08-05
## Downloading /tmp/RtmpJjZnMZ/NEG_20190802.gz (1|2) Attempt 1
## -> Reading files - Imported 1662368 lines, 547 unique tickers
## -> Processing file - Found 24794 lines for 1 selected tickers
## -> Aggregation resulted in dataframe with 27 rows
## Downloading /tmp/RtmpJjZnMZ/NEG_20190805.gz (2|2) Attempt 1
## -> Reading files - Imported 1962293 lines, 583 unique tickers
## -> Processing file - Found 20874 lines for 1 selected tickers
## -> Aggregation resulted in dataframe with 27 rows
```

And check it out:

```
glimpse(df.trades)
```

```
## Observations: 54
## Variables: 13
## $ InstrumentSymbol "PETR3", "PETR3", "PETR3", "PETR3", "PETR3", "P…
## $ SessionDate 2019-08-02, 2019-08-02, 2019-08-02, 2019-08-02…
## $ TradeDateTime 2019-08-02 11:00:00, 2019-08-02 11:15:00, 2019…
## $ n.trades 1123, 1522, 1884, 1109, 675, 803, 568, 653, 541…
## $ last.price 29.24, 29.02, 29.02, 28.96, 29.11, 29.06, 29.12…
## $ weighted.price 29.39957, 29.06305, 28.97820, 28.96853, 28.9880…
## $ period.ret -0.0098205215, -0.0071843996, 0.0000000000, -0.…
## $ period.ret.volat 0.0002035764, 0.0002197109, 0.0001967620, 0.000…
## $ sum.qtd 656500, 1140000, 1090700, 506000, 277200, 37400…
## $ sum.vol 19300683, 33131637, 31606455, 14658055, 8035460…
## $ n.buys 616, 731, 859, 552, 409, 265, 273, 337, 250, 28…
## $ n.sells 507, 791, 1025, 557, 266, 538, 295, 316, 291, 2…
## $ Tradetime "11:00:00", "11:15:00", "11:30:00", "11:45:00",…
```

Its working fine. The ammount of data available at the ftp is more than necessary for research and class material.

I’m not really sure what happened. It could be a simple delay to the shutdown. Lets keep our fingers crossed.


*Related*






---
