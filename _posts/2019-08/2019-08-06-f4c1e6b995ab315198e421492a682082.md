---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/08/06/distilled-news-1154/
date:      2019-08-06
author:      Michael Laux
tags:
    - liking
    - models
    - modelling
    - humans
    - learning
---

**Why Machine Learning Models Degrade In Production**

After several failed ML projects due to unexpected ML degradation, I wanted to share my experience in ML models degradation. Indeed, there is a lot of hype around model creation and development phase, as opposed to model maintenance. Assuming that a Machine Learning solution will work perfectly without maintenance once in production is a faulty assumption and represents the most common mistake of companies taking their first artificial intelligence (AI) products to market.

**Universal Language Model Fine-tuning for Text Classification – ULMFiT**

Natural Language Processing (NLP) needs no introduction in today’s world. It’s one of the most important fields of study and research, and has seen a phenomenal rise in interest in the last decade. The basics of NLP are widely known and easy to grasp. But things start to get tricky when the text data becomes huge and unstructured. That’s where deep learning becomes so pivotal. DL has proven its usefulness in computer vision tasks like image detection, classification and segmentation, but NLP applications like text generation and classification have long been considered fit for traditional ML techniques. And deep learning has certainly made a very positive impact in NLP. We will focus on the concept of transfer learning and how we can leverage it in NLP to build incredibly accurate models using the popular fastai library. I will introduce you to the ULMFiT framework as well in the process.

**Open-source Xenophobic Tweet Classifier**

When building new applications in today’s quickly changing world, machine learning is often necessary to provide users with power insights. Unfortunately, for many of the people developing these applications, AI can be difficult to implement, and expensive to outsource. Several of our tech friends have said that while working on personal projects or at hackathons, they would have liked to include machine learning. Typically, even if they knew how to implement the model, there wasn’t an existing dataset they could use for their application and creating a dataset from scratch would have been a very laborious process. To help address this gap in the developer and AI community, we have decided to create and release a series of publicly available classifiers that anyone can use. We will periodically release an open-source AI model on an interesting and relevant topic, and users can either download the model/data for local use, or simply use our API. For our first model, we created a model to detect xenophobic tweets.

**Algebra, Topology, Differential Calculus, and Optimization Theory For Computer Science and Machine Learning**

[Book]

**ERNIE – A Continual Pre-training Framework for Language Understanding**

ERNIE 2.0 is a continual pre-training framework for language understanding in which pre-training tasks can be incrementally built and learned through multi-task learning. In this framework, different customized tasks can be incrementally introduced at any time. For example, the tasks including named entity prediction, discourse relation recognition, sentence order prediction are leveraged in order to enable the models to learn language representations.

**The Evolutionary Roots of Human Decision Making**

Humans exhibit a suite of biases when making economic decisions. We review recent research on the origins of human decision making by examining whether similar choice biases are seen in nonhuman primates, our closest phylogenetic relatives. We propose that comparative studies can provide insight into four major questions about the nature of human choice biases that cannot be addressed by studies of our species alone. First, research with other primates can address the evolution of human choice biases and identify shared versus human-unique tendencies in decision making. Second, primate studies can constrain hypotheses about the psychological mechanisms underlying such biases. Third, comparisons of closely related species can identify when distinct mechanisms underlie related biases by examining evolutionary dissociations in choice strategies. Finally, comparative work can provide insight into the biological rationality of economically irrational preferences.

**Neural Networks Intuitions: 4. Connectionist Temporal Classification**

Today I am going to talk about a topic which took me a long time(reaallyy long time) to understand, both the motivation of usage as well as its working-Connectionist Temporal Classification(CTC). Before talking about CTC, let us first understand what Sequence-to-Sequence models are ðŸ™‚

**Artificial General Intelligence (AGI) Vs. Narrow AI**

Vendors and theorists can promise the world, but it’s essential to differentiate between Artificial General Intelligence (AGI) and narrow AI in order to make informed decisions. In simplest terms, all of the contemporary AI is narrow or weak AI. Even the smartest systems are not able to execute common sense comparable to human intelligence. While computers can outperform humans at specific tasks such as chess, Jeopardy, or predicting the weather, they are still not able to think abstractly, interpret recollections, or solve creative problems with complex solutions.

**NLP with Pipeline & GridSearch**

Natural Language Processing or NLP for short, is all the rage with artificial intelligence assistants such as Alexa, Siri, and Google Assistant. It seems like only yesterday when I saw J.A.R.V.I.S for the first time in the Iron Man movie. Seeing this sparked my interest even more in how we interact with computers. A computer that is able to hear and respond like a human? How does it work? It seems like magic, but in reality the computer is breaking words down into more simple forms, and in some cases creating lists of those forms to sort through. The computer looks for patterns or relationships between certain words and then can make predictions based on those relationships. We are going to use Pipeline and GridSearch to run several models and confirm which one will be best at predicting the location of a post given any blog topic. For instance, would a model be able to tell with a certain effectiveness if my post would be found in NHL or Fantasy Hockey? I will be using a dataset of my own for this, however the code is reproducible in most situations.

**Deploying Natural Language Processing for Product Reviews**

We have data all around us and there are of two forms of data namely; tabular and text. If you have good statistical tools tabular data has a lot to convey. But it is really hard to get something out of the text, especially the natural language spoken text. So what is natural language? We, humans, have very complex language and natural language is the true form of human language which is spoken/written with sincerity also surpassing grammatical rules. To consider the best example where you can find this language is in ‘Reviews’. You write review mainly for two reasons, either you are very happy with the product or very disappointed with it and, with your reviews and a Machine Learning Algorithm, entities like Amazon can figure out whether the product they are selling is good or bad. Depending upon the results on the analysis of the reviews they can make further decisions on that product for their betterment. Consider an example wherein we have thousands of comments in a review of a product sold by Amazon. It is very time consuming and hard for an individual to sit back and read all the thousands of comments and make a decision about whether people are liking the product or not. We can simply make machines do this work by implementing a Machine Learning Algorithm from which Machines can learn the Natural Human Language and make decisions. An approach to this is Machine ‘bags’ words basically of two types viz; positive and negative words. After bagging these words machines apply majority rules to identify: are there more of positive or negative words thus helping us identifying the acceptance of the product sold. The technique described above is called as ‘Bagging of Words (BoW)’ Natural Language Processing (NLP) Machine Learning Algorithm which is what we are going to learn today and also could have been this complex name of this blog but phew, I managed with a better one. So, there are other techniques too called as Word Embedding NLP and might be more but as far as I know, they are these two. Today we are only focusing on ‘BoW’ type of NLP in this article.

**Multilevel Models in R**

Regression analysis is one of the most requested machine learning methods in 2019. One group of regression analysis for measuring hierarchical effects is Multilevel Models. This method is well suited for spatial differences between groups in the dataset. In this article, you learn how to do Multilevel Modelling in R.

**AI Often Adds To Bias In Recruiting – But There’s A New Approach That Could Change The Game**

Most people aren’t trying to be biased, but bias is inherent – it influences how we view any situation, often unconsciously. When you think of bias, characteristics like race, gender, and religion likely come to mind. But there’s a much broader context of what bias can actually be. Bias comes in many forms. For example, the halo effect occurs when we assume that our initial impression of someone means something about his or her character. The halo effect can lead us to believe, without evidence, that someone who is warm and likable when you meet them is also intelligent and capable. Similarity bias is our implicit affinity toward those similar to us. In our flawed minds, relatable traits are positive traits – even when they really aren’t. Is someone who grew up 15 minutes from you, or someone who is also a soccer fan, really more likely to be a better team member? These types of biases present a big problem in recruiting and hiring. And not just in human recruiters. When you consider that recruiting software – both AI and traditional – mirrors human tendencies, you realize that bias affects every part of the recruiting process, from in-person interviews to resume-scanning software.

**Pruning Deep Neural Networks**

Deep Learning models these days require a significant amount of computing, memory, and power which becomes a bottleneck in the conditions where we need real-time inference or to run models on edge devices and browsers with limited computational resources. Energy efficiency is a major concern for current deep learning models. One of the methods for tackling this efficiency is enabling inference efficiency.

### Like this:

Like Loading...
