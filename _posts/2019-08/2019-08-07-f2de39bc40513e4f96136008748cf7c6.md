---
layout:     post
catalog: true
title:      Finding out why
subtitle:      转载自：https://analytixon.com/2019/08/07/finding-out-why-28/
date:      2019-08-07
author:      Michael Laux
tags:
    - data
    - estimation
    - estimates
    - estimating
    - estimated
---

***R Library***: ***Causal Inference and Prediction in Cohort-Based Analyses*** (RISCA)

We propose numerous functions for cohort-based analyses, either for prediction or causal inference. For causal inference, it includes Inverse Probability Weighting and G-computation for marginal estimation of an exposure effect when confounders are expected. We deal with binary outcomes, times-to-events (Le Borgne, 2016, ), competing events (Trebern-Launay, 2018, ), and multi-state data (Gillaizeau, 2018, ). For multistate data, semi-Markov model with interval censoring (Foucher, 2008, ) may be considered and we propose the possibility to consider the excess of mortality related to the disease compared to reference lifetime tables (Gillaizeau, 2017, ). For predictive studies, we propose a set of functions to estimate time-dependent receiver operating characteristic (ROC) curves with the possible consideration of right-censoring times-to-events or the presence of confounders (Le Borgne, 2018, ). Finally, several functions are available to assess time-dependant ROC curves (Combescure, 2017, ) or survival curves (Combescure, 2014, ) from aggregated data.

***Paper***: ***A local direct method for module identification in dynamic networks with correlated noise***

The identification of local modules in dynamic networks with known topology has recently been addressed by formulating conditions for arriving at consistent estimates of the module dynamics, under the assumption of having disturbances that are uncorrelated over the different nodes. The conditions typically reflect the selection of a set of node signals that are taken as predictor inputs in a MISO identification setup. In this paper an extension is made to arrive at an identification setup for the situation that process noises on the different node signals can be correlated with each other. In this situation the local module may need to be embedded in a MIMO identification setup for arriving at a consistent estimate with maximum likelihood properties. This requires the proper treatment of confounding variables. The result is a set of algorithms that, based on the given network topology and disturbance correlation structure, selects an appropriate set of node signals as predictor inputs and outputs in a MISO or MIMO identification setup. Three algorithms are presented that differ in their approach of selecting measured node signals. Either a maximum or a minimum number of measured node signals can be considered, as well as a preselected set of measured nodes.

***Paper***: ***Sensitivity Analysis of Treatment Effect to Unmeasured Confounding in Observational Studies with Survival and Competing Risks Outcomes***

No unmeasured confounding is often assumed in estimating treatment effects in observational data when using approaches such as propensity scores and inverse probability weighting. However, in many such studies due to the limitation of the databases, collected confounders are not exhaustive, and it is crucial to examine the extent to which the resulting estimate is sensitive to the unmeasured confounders. We consider this problem for survival and competing risks data. Due to the complexity of models for such data, we adapt the simulated potential confounders approach of Carnegie et al. (2016), which provides a general tool for sensitivity analysis due to unmeasured confounding. More specifically, we specify one sensitivity parameter to quantify the association between an unmeasured confounder and the treatment assignment, and another set of parameters to quantify the association between the confounder and the time-to-event outcomes. By varying the magnitudes of the sensitivity parameters, we estimate the treatment effect of interest using the stochastic EM and the EM algorithms. We demonstrate the performance of our methods on simulated data, and apply them to a comparative effectiveness study in inflammatory bowel disease (IBD).

***Paper***: ***Leveraging Random Assignment in Multiple Imputation of Missing Covariates in Causal Studies***

Baseline covariates in randomized experiments are often used in the estimation of treatment effects, for example, when estimating treatment effects within covariate-defined subgroups. In practice, however, covariate values may be missing for some data subjects. To handle missing values, analysts can use multiple imputation to create completed datasets, from which they can estimate the treatment effects. We investigate the performance of multiple imputation routines that utilize randomized treatment assignment, that is, make use of the fact that the true covariate distributions are the same across treatment arms. We do so for both ignorable and non-ignorable missing data, using simulation studies to compare the quality of inferences when we respect or disregard randomization. We consider this question for imputation routines estimated with covariates only, and imputation routines estimated conditional on the outcome variable. In either case, accounting for randomization does not noticeably improve inferences when sample sizes are in hundreds of units.

### Like this:

Like Loading...
