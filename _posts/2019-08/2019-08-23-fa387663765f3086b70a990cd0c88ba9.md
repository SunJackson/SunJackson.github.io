---
layout:     post
catalog: true
title:      Finding out why
subtitle:      转载自：https://analytixon.com/2019/08/23/finding-out-why-35/
date:      2019-08-23
author:      Michael Laux
tags:
    - causality
    - networks
    - paper
    - modelling
    - models
---

***Paper***: ***A Multi-level Neural Network for Implicit Causality Detection in Web Texts***

Mining causality from text is a complex and crucial natural language understanding task. Most of the early attempts at its solution can group into two categories: 1) utilizing co-occurrence frequency and world knowledge for causality detection; 2) extracting cause-effect pairs by using connectives and syntax patterns directly. However, because causality has various linguistic expressions, the noisy data and ignoring implicit expressions problems induced by these methods cannot be avoided. In this paper, we present a neural causality detection model, namely Multi-level Causality Detection Network (MCDN), to address this problem. Specifically, we adopt multi-head self-attention to acquire semantic feature at word level and integrate a novel Relation Network to infer causality at segment level. To the best of our knowledge, in touch with the causality tasks, this is the first time that the Relation Network is applied. The experimental results on the AltLex dataset, demonstrate that: a) MCDN is highly effective for the ambiguous and implicit causality inference; b) comparing with the regular text classification task, causality detection requires stronger inference capability; c) the proposed approach achieved state-of-the-art performance.

***Paper***: ***Data Management for Causal Algorithmic Fairness***

Fairness is increasingly recognized as a critical component of machine learning systems. However, it is the underlying data on which these systems are trained that often reflects discrimination, suggesting a data management problem. In this paper, we first make a distinction between associational and causal definitions of fairness in the literature and argue that the concept of fairness requires causal reasoning. We then review existing works and identify future opportunities for applying data management techniques to causal algorithmic fairness.

***Paper***: ***Finding the right scale of a network: Efficient identification of causal emergence through spectral clustering***

All networks can be analyzed at multiple scales. A higher scale of a network is made up of macro-nodes: subgraphs that have been grouped into individual nodes. Recasting a network at higher scales can have useful effects, such as decreasing the uncertainty in the movement of random walkers across the network while also decreasing the size of the network. However, the task of finding such a macroscale representation is computationally difficult, as the set of all possible scales of a network grows exponentially with the number of nodes. Here we compare various methods for finding the most informative scale of a network, discovering that an approach based on spectral analysis outperforms greedy and gradient descent-based methods. We then use this procedure to show how several structural properties of preferential attachment networks vary across scales. We describe how meso- and macroscale representations of networks can have significant benefits over their underlying microscale, which include properties such as increase in determinism, a decrease in degeneracy, a lower entropy rate of random walkers on the network, an increase in global network efficiency, and higher values for a variety of centrality measures than the microscale.

***Paper***: ***Reinforcement Learning is not a Causal problem***

We use an analogy between non-isomorphic mathematical structures defined over the same set and the algebras induced by associative and causal levels of information in order to argue that Reinforcement Learning, in its current formulation, is not a causal problem, independently if the motivation behind it has to do with an agent taking actions.

***Paper***: ***Latent group structure and regularized regression***

Regression modelling typically assumes homogeneity of the conditional distribution of responses Y given features X. For inhomogeneous data, with latent groups having potentially different underlying distributions, the hidden group structure can be crucial for estimation and prediction, and standard regression models may be severely confounded. Worse, in the multivariate setting, the presence of such inhomogeneity can easily pass undetected. To allow for robust and interpretable regression modelling in the heterogeneous data setting we put forward a class of mixture models that couples together both the multivariate marginal on X and the conditional Y | X to capture the latent group structure. This joint modelling approach allows for group-specific regression parameters, automatically controlling for the latent confounding that may otherwise pose difficulties, and offers a novel way to deal with suspected distributional shifts in the data. We show how the latent variable model can be regularized to provide scalable solutions with explicit sparsity. Estimation is handled via an expectation-maximization algorithm. We illustrate the key ideas via empirical examples.

***Paper***: ***QCNN: Quantile Convolutional Neural Network***

A dilated causal one-dimensional convolutional neural network architecture is proposed for quantile regression. The model can forecast any arbitrary quantile, and it can be trained jointly on multiple similar time series. An application to Value at Risk forecasting shows that QCNN outperforms linear quantile regression and constant quantile estimates.

### Like this:

Like Loading...
