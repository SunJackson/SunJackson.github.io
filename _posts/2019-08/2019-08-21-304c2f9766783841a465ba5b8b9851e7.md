---
layout:     post
catalog: true
title:      Let’s get it right
subtitle:      转载自：https://analytixon.com/2019/08/21/lets-get-it-right-58/
date:      2019-08-21
author:      Michael Laux
tags:
    - systems
    - graphs
    - data
    - ethics
    - ethical
---

***Article***: ***Machinery And Ethics***

No one can escape the fact that trying to legislate on the existing connection between man and machine will lead us to the serious problem of shifting our customs and morality into the field of ethics. In fact, it would be foolish to think that any social pact marked between humans and humanoids would not be reflected through human rights, especially when humanoids themselves were exclusively artificial. The starting point is to analyze which are the inherent human rights acquired by the machines so as to be able to consider which aspect is concerned with morality. So one way to simplify the essay is to postulate that the 1948 Charter of Human Rights could form part of the ethical principles that define not only human beings, but also the very concept of humanity.

***Article***: ***Robots and AI Threaten to Mediate Disputes Better Than Lawyers***

Algorithms and big data are entering the often shrouded world of alternative dispute resolution. Robots and artificial intelligence seem worlds away from the sensitive and nuanced area of international mediation. Here, battles are largely settled behind closed doors and skilled mediators pick their way through sticky negotiations. Algorithms and big data, however, are fast entering the often mystery-shrouded world of alternative dispute resolution. This is much the result of the rapidly increasing demand for the kind of data analytics being harnessed in US litigation to predict trial outcomes. The incursion of robots into mediation hit a new milestone in February, when Canadian electronic negotiation specialists iCan Systems reputedly became the first company to resolve a dispute in a public court in England and Wales using a ‘robot mediator’.

***Paper***: ***Connected Fair Allocation of Indivisible Goods***

We study the fair allocation of indivisible goods under the assumption that the goods form an undirected graph and each agent must receive a connected subgraph. Our focus is on well-studied fairness notions including envy-freeness and maximin share fairness. We establish graph-specific maximin share guarantees, which are tight for large classes of graphs in the case of two agents and for paths and stars in the general case. Unlike in previous work, our guarantees are with respect to the complete-graph maximin share, which allows us to compare possible guarantees for different graphs. For instance, we show that for biconnected graphs it is possible to obtain at least $3/4$ of the maximin share, while for the remaining graphs the guarantee is at most $1/2$. In addition, we determine the optimal relaxation of envy-freeness that can be obtained with each graph for two agents, and characterize the set of trees and complete bipartite graphs that always admit an allocation satisfying envy-freeness up to one good (EF1) for three agents. Our work demonstrates several applications of graph-theoretical tools and concepts to fair division problems.

***Paper***: ***Tackling Online Abuse: A Survey of Automated Abuse Detection Methods***

Abuse on the Internet represents an important societal problem of our time. Millions of Internet users face harassment, racism, personal attacks, and other types of abuse on online platforms. The psychological effects of such abuse on individuals can be profound and lasting. Consequently, over the past few years, there has been a substantial research effort towards automated abuse detection in the field of natural language processing (NLP). In this paper, we present a comprehensive survey of the methods that have been proposed to date, thus providing a platform for further development of this area. We describe the existing datasets and review the computational approaches to abuse detection, analyzing their strengths and limitations. We discuss the main trends that emerge, highlight the challenges that remain, outline possible solutions, and propose guidelines for ethics and explainability

***Paper***: ***A Survey on Computational Politics***

Computational Politics is the study of computational methods to analyze and moderate users\textquotesingle behaviors related to political activities such as election campaign persuasion, political affiliation, and opinion mining. With the rapid development and ease of access to the Internet, Information Communication Technologies (ICT) have given rise to a massive number of users joining the online communities and to the digitization of analogous data such as political debates. These communities and digitized data contain both explicit and latent information about users and their behaviors related to politics. For researchers, it is essential to utilize data from these sources to develop and design systems that not only provide solutions to computational politics but also help other businesses, such as marketers, to increase the users\textquotesingle participation and interaction. In this survey, we attempt to categorize main areas in computational politics and summarize the prominent studies at one place to better understand computational politics across different and multidimensional platforms. e.g., online social networks, online forums, and political debates. We then conclude this study by highlighting future research directions, opportunities, and challenges.

***Article***: ***Discriminating Systems – Gender, Race, and Power in AI***

Research Findings:• There is a diversity crisis in the AI sector across gender and race.• The AI sector needs a profound shift in how it addresses the current diversity crisis.• The overwhelming focus on ‘women in tech’ is too narrow and likely to privilege white women over others.• Fixing the ‘pipeline’ won’t fix AI’s diversity problems.• The use of AI systems for the classification, detection, and prediction of race and gender is in urgent need of re-evaluation.

***Paper***: ***Oxford Handbook on AI Ethics Book Chapter on Race and Gender***

From massive face-recognition-based surveillance and machine-learning-based decision systems predicting crime recidivism rates, to the move towards automated health diagnostic systems, artificial intelligence (AI) is being used in scenarios that have serious consequences in people’s lives. However, this rapid permeation of AI into society has not been accompanied by a thorough investigation of the sociopolitical issues that cause certain groups of people to be harmed rather than advantaged by it. For instance, recent studies have shown that commercial face recognition systems have much higher error rates for dark skinned women while having minimal errors on light skinned men. A 2016 ProPublica investigation uncovered that machine learning based tools that assess crime recidivism rates in the US are biased against African Americans. Other studies show that natural language processing tools trained on newspapers exhibit societal biases (e.g. finishing the analogy ‘Man is to computer programmer as woman is to X’ by homemaker). At the same time, books such as Weapons of Math Destruction and Automated Inequality detail how people in lower socioeconomic classes in the US are subjected to more automated decision making tools than those who are in the upper class. Thus, these tools are most often used on people towards whom they exhibit the most bias. While many technical solutions have been proposed to alleviate bias in machine learning systems, we have to take a holistic and multifaceted approach. This includes standardization bodies determining what types of systems can be used in which scenarios, making sure that automated decision tools are created by people from diverse backgrounds, and understanding the historical and political factors that disadvantage certain groups who are subjected to these tools.

***Paper***: ***A Mulching Proposal***

The ethical implications of algorithmic systems have been much discussed in both HCI and the broader community of those interested in technology design, development and policy. In this paper, we explore the application of one prominent ethical framework – Fairness, Accountability, and Transparency – to a proposed algorithm that resolves various societal issues around food security and population ageing. Using various standardised forms of algorithmic audit and evaluation, we drastically increase the algorithm’s adherence to the FAT framework, resulting in a more ethical and beneficent system. We discuss how this might serve as a guide to other researchers or practitioners looking to ensure better ethical outcomes from algorithmic systems in their line of work.

### Like this:

Like Loading...
