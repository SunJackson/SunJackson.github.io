---
layout:     post
catalog: true
title:      Lesser known dplyr functions
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/U2z3fGpe1C8/
date:      2019-08-30
author:      kjytay
tags:
    - functions
    - values
    - flights
    - top_n
    - month
---





The `dplyr` package is an essential tool for manipulating data in R. The “Introduction to dplyr” vignette gives a good overview of the common dplyr functions (list taken from the vignette itself):

- `filter()` to select cases based on their values.

- `arrange()` to reorder the cases.

- `select()` and `rename()` to select variables based on their names.

- `mutate()` and `transmute()` to add new variables that are functions of existing variables.

- `summarise()` to condense multiple values to a single value.

- `sample_n()` and `sample_frac()` to take random samples.


The “Two-table verbs” vignette gives a good introduction to using `dplyr` function for joining two tables together. The “Window functions” vignette talks about, well, window functions, which are defined as functions which take n values and return n values (as opposed to aggregation functions, which take n values but return one value). The window functions mentioned there are (list taken from the vignette itself):

- Ranking and ordering functions: `row_number()`, `min_rank()`, `dense_rank()`, `cume_dist()`, `percent_rank()`, and `ntile()`. These functions all take a vector to order by, and return various types of ranks.

- Offsets: `lead()` and `lag()` allow you to access the previous and next values in a vector, making it easy to compute differences and trends.

- Cumulative aggregates: `cumsum()`, `cummin()`, `cummax()` (from base R), and `cumall()`, `cumany()`, and `cummean()` (from dplyr).


However, `dplyr` comes with several other functions that are not mentioned in the vignettes (or at least, not at length). In this post I’ll talk about some of them. (For the full list of `dplyr` functions, see the reference manual.)

- Counting functions: `n()` and `n_distinct()`

- If-else functions: `if_else()` and `case_when()`

- Comparison functions: `between()` and `near()`

- Selecting specific elements based on position: `nth()`, `first()` and `last()`

- Selecting specific rows based on position/value: `slice()` and `top_n()`

- Utilities: `coalesce()` and `pull()`


To illustrate these functions, I will use the flights dataset in the `nycflights13` package.

**Counting functions: `n()` and `n_distinct()`**

Ok, these aren’t exactly lesser known functions but they’re certainly useful. `n()` counts the number of rows in each group. For example, to count the number of flights in each month:

`n_distinct()` counts the number of unique values in each group. To count the number of distinct values of `day` in the dataset:

as we expect, since the longest month only has 31 days. We can also count the number of unique sets of values across columns. To count the number of distinct `(month, day)` values:

as expected (number of days in a year).

**If-else functions: `if_else()` and `case_when()`**

`if_else()` returns a value which depends on whether a given condition is true or not. It works like the base `ifelse()` function, except that it is stricter in that the returned value must be of the same type, whether the given condition is true or not. `if_else()` is commonly used to create new columns. For example, we could create a new column that is “United” if a flight was from United Airlines, “Other” otherwise:

`case_when()` is like `if_else()` except that we have more than 2 possible values for the output. It is “the R equivalent of the SQL CASE WHEN statement”. If none of the cases match, an NA is returned. As with `if_else()`, the returned values for all the cases must be of the same type.

Here is some code to return “United” if carrier is UA, “JetBlue” if it is B6, and “Other” for all other carriers (notice that the syntax within `case_when()` is a little different from the usual, and how we use `TRUE` to catch all the cases that don’t meet the first two conditions):

**Comparison functions: `between()` and `near()`**

`between(x, left, right)` is a shortcut for `x >= left & x <= right` that has an efficient implementation. It makes for more concise code too, at the expense of being unable to tell if the endpoints are included or not unless one is familiar with the function.

`near()` is a safer way than using `==` to compare if two vectors of floating point numbers are equal element-wise. This is because it uses tolerance which is based on the machine’s double precision. Here is the example provided in `near()`‘s documentation:

**Selecting specific elements based on position: `nth()`, `first()` and `last()`**

`nth(x, n)` returns the nth element in the vector `x`. An optional vector to determine the order can be passed to the function as well. If `n` is negative, we count from the end of `x` (e.g. -2 will return the second last value in `x`). `first()` and `last()` are obvious special cases of `nth()`.

What’s interesting is that these functions are actually wrappers around `[[`. This means that they can be used to pull out the nth element in a list as well!

**Selecting specific rows based on position/value: `slice()` and `top_n()`**

`slice()` allows us to select certain rows based on their ordinal position (i.e. row number). This works especially well with grouped dataframes. For example, if we want the first row for each date:

A simple modification gives us the first two rows for each date:

In contrast to `slice()` which picks out rows by their position (within the group), `top_n()` picks out rows by their value in a pre-specified column (within the group). For example, if we wanted to see the carriers for the top 3 longest departure delays for each day, we could use this code:

Notice that while we get the top 3 rows in `dep_delay` for each day, the rows are not sorted according to the `dep_delay` column. To get the bottom three rows instead, use a negative number:

Notice how Jan 2nd has 4 entries, not 3? That’s because there was a tie for 3rd place. `top_n()` either takes all rows with a value or none of them. Another gotcha: if the column that you are sorting against is not specified, it defaults to the last variable in the data frame, NOT to ordinal position/row number.

**Utilities: `coalesce()` and `pull()`**

From the documnetation: “Given a set of vectors, `coalesce()` finds the first non-missing value at each position. This is inspired by the SQL COALESCE function which does the same thing for NULLs.”

I haven’t had to use this function myself so far, but I imagine it could be useful when you have a number of different data sources reporting the same thing but with different missing values in each source. Here is a contrived example:

Notice that the third value in `y` showing a 4 is ignored.

`pull()` works like `[[`: it allows you to pull out a particular column (as a vector). The variable you pass to the function can be a variable name, a positive integer (giving the column position when counting from the left) or a negative integer (giving the column position when counting from the right).


*Related*






---
