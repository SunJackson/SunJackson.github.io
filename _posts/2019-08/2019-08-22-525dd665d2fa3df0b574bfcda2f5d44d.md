---
layout:     post
catalog: true
title:      Whats new on arXiv
subtitle:      转载自：https://analytixon.com/2019/08/22/whats-new-on-arxiv-1082/
date:      2019-08-22
author:      Michael Laux
tags:
    - models
    - modeling
    - modeled
    - modelling
    - graphs
---

**TDAM: a Topic-Dependent Attention Model for Sentiment Analysis**

We propose a topic-dependent attention model for sentiment classification and topic extraction. Our model assumes that a global topic embedding is shared across documents and employs an attention mechanism to derive local topic embedding for words and sentences. These are subsequently incorporated in a modified Gated Recurrent Unit (GRU) for sentiment classification and extraction of topics bearing different sentiment polarities. Those topics emerge from the words’ local topic embeddings learned by the internal attention of the GRU cells in the context of a multi-task learning framework. In this paper, we present the hierarchical architecture, the new GRU unit and the experiments conducted on users’ reviews which demonstrate classification performance on a par with the state-of-the-art methodologies for sentiment classification and topic coherence outperforming the current approaches for supervised topic extraction. In addition, our model is able to extract coherent aspect-sentiment clusters despite using no aspect-level annotations for training.

**A New k-Shortest Path Search Approach based on Graph Reduction**

We present a new approach called GR (Graph Reduction) algorithm for searching loop-less k-shortest paths (1st to k-th shortest paths) in a graph based on graph reduction. Let a source vertex and a target vertex of k-shortest paths be v_s and v_t respectively. First our approach computes shortest paths to every vertex from v_s and v_t respectively, and reduce a graph to a subgraph that contains all vertices and edges of loop-less k-shortest paths using the already computed shortest paths, and apply an existing k-shortest path search algorithm to the reduced graph. A graph can be reduced quickly after computing the shortest paths using them, therefore a very efficient search can be achieved. In an experiment using a hypercube graph which has 16384 vertices where k=128, the number of vertices is reduced to about 1/22, and a variant of Dijkstra algorithm for k-shortest path search were speeded up by about 365 times. We implemented a fast k-shortest path variant of bidirectional Dijkstra algorithm (k-biDij) which is the state-of-the-art algorithm and the fastest as long as we know, GR outperforms k-biDij in dense scale-free graphs. However, k-biDij outperforms GR in hypercube-shaped and sparse scale-free graphs, but even then GR can also speed up it by 12.3 and 2.0 times respectively by precomputing all-pairs shortest paths. We also show the graph reduction can be done in time complexity O(m + n log n). We also introduce our improvements to k-biDij simply.

**Training Deep Learning Models via Synthetic Data: Application in Unmanned Aerial Vehicles**

This paper describes preliminary work in the recent promising approach of generating synthetic training data for facilitating the learning procedure of deep learning (DL) models, with a focus on aerial photos produced by unmanned aerial vehicles (UAV). The general concept and methodology are described, and preliminary results are presented, based on a classification problem of fire identification in forests as well as a counting problem of estimating number of houses in urban areas. The proposed technique constitutes a new possibility for the DL community, especially related to UAV-based imagery analysis, with much potential, promising results, and unexplored ground for further research.

**SPOCC: Scalable POssibilistic Classifier Combination — toward robust aggregation of classifiers**

We investigate a problem in which each member of a group of learners is trained separately to solve the same classification task. Each learner has access to a training dataset (possibly with overlap across learners) but each trained classifier can be evaluated on a validation dataset. We propose a new approach to aggregate the learner predictions in the possibility theory framework. For each classifier prediction, we build a possibility distribution assessing how likely the classifier prediction is correct using frequentist probabilities estimated on the validation set. The possibility distributions are aggregated using an adaptive t-norm that can accommodate dependency and poor accuracy of the classifier predictions. We prove that the proposed approach possesses a number of desirable classifier combination robustness properties.

**A Consistent Independence Test for Multivariate Time-Series**

A fundamental problem in statistical data analysis is testing whether two phenomena are related. When the phenomena in question are time series, many challenges emerge. The first is defining a dependence measure between time series at the population level, as well as a sample level test statistic. The second is computing or estimating the distribution of this test statistic under the null, as the permutation test procedure is invalid for most time series structures. This work aims to address these challenges by combining distance correlation and multiscale graph correlation (MGC) from independence testing literature and block permutation testing from time series analysis. Two hypothesis tests for testing the independence of time series are proposed. These procedures also characterize whether the dependence relationship between the series is linear or nonlinear, and the time lag at which this dependence is maximized. For strictly stationary auto-regressive moving average (ARMA) processes, the proposed independence tests are proven valid and consistent. Finally, neural connectivity in the brain is analyzed using fMRI data, revealing linear dependence of signals within the visual network and default mode network, and nonlinear relationships in other regions. This work opens up new theoretical and practical directions for many modern time series analysis problems.

**Neural Dynamics on Complex Networks**

We introduce a deep learning model to learn continuous-time dynamics on complex networks and infer the semantic labels of nodes in the network at terminal time. We formulate the problem as an optimal control problem by minimizing a loss function consisting of a running loss of network dynamics, a terminal loss of nodes’ labels, and a neural-differential-equation-system constraint. We solve the problem by a differential deep learning framework: as for the forward process of the system, rather than forwarding through a discrete number of hidden layers, we integrate the ordinary differential equation systems on graphs over continuous time; as for the backward learning process, we learn the optimal control parameters by back-propagation during solving initial value problem. We validate our model by learning complex dynamics on various real-world complex networks, and then apply our model to graph semi-supervised classification tasks. The promising experimental results demonstrate our model’s capability of jointly capturing the structure, dynamics and semantics of complex systems.

**Benchmarks for Graph Embedding Evaluation**

**Transfer in Deep Reinforcement Learning using Knowledge Graphs**

Text adventure games, in which players must make sense of the world through text descriptions and declare actions through text descriptions, provide a stepping stone toward grounding action in language. Prior work has demonstrated that using a knowledge graph as a state representation and question-answering to pre-train a deep Q-network facilitates faster control policy transfer. In this paper, we explore the use of knowledge graphs as a representation for domain knowledge transfer for training text-adventure playing reinforcement learning agents. Our methods are tested across multiple computer generated and human authored games, varying in domain and complexity, and demonstrate that our transfer learning methods let us learn a higher-quality control policy faster.

**A Co-analysis Framework for Exploring Multivariate Scientific Data**

In complex multivariate data sets, different features usually include diverse associations with different variables, and different variables are associated within different regions. Therefore, exploring the associations between variables and voxels locally becomes necessary to better understand the underlying phenomena. In this paper, we propose a co-analysis framework based on biclusters, which are two subsets of variables and voxels with close scalar-value relationships, to guide the process of visually exploring multivariate data. We first automatically extract all meaningful biclusters, each of which only contains voxels with a similar scalar-value pattern over a subset of variables. These biclusters are organized according to their variable sets, and biclusters in each variable set are further grouped by a similarity metric to reduce redundancy and support diversity during visual exploration. Biclusters are visually represented in coordinated views to facilitate interactive exploration of multivariate data based on the similarity between biclusters and the correlation of scalar values with different variables. Experiments on several representative multivariate scientific data sets demonstrate the effectiveness of our framework in exploring local relationships among variables, biclusters and scalar values in the data.

**Latent User Linking for Collaborative Cross Domain Recommendation**

With the widespread adoption of information systems, recommender systems are widely used for better user experience. Collaborative filtering is a popular approach in implementing recommender systems. Yet, collaborative filtering methods are highly dependent on user feedback, which is often highly sparse and hard to obtain. However, such issues could be alleviated if knowledge from a much denser and a related secondary domain could be used to enhance the recommendation accuracy in the sparse target domain. In this publication, we propose a deep learning method for cross-domain recommender systems through the linking of cross-domain user latent representations as a form of knowledge transfer across domains. We assume that cross-domain similarities of user tastes and behaviors are clearly observable in the low dimensional user latent representations. These user similarities are used to link the domains. As a result, we propose a Variational Autoencoder based network model for cross-domain linking with added contextualization to handle sparse data and for better transfer of cross-domain knowledge. We further extend the model to be more suitable in cold start scenarios and to utilize auxiliary user information for additional gains in recommendation accuracy. The effectiveness of the proposed model was empirically evaluated using multiple datasets. The experiments proved that the proposed model outperforms the state of the art techniques.

**High dimensional statistical inference: theoretical development to data analytics**

This article is due to appear in the Handbook of Statistics, Vol. 43, Elsevier/North-Holland, Amsterdam, edited by Arni S. R. Srinivasa Rao and C. R. Rao. In modern day analytics, there is ever growing need to develop statistical models to study high dimensional data. Between dimension reduction, asymptotics-driven methods and random projection based methods, there are several approaches developed so far. For high dimensional parametric models, estimation and hypothesis testing for mean and covariance matrices have been extensively studied. However, practical implementation of these methods are fairly limited and are primarily restricted to researchers involved in high dimensional inference. With several applied fields such as genomics, metagenomics and social networking, high dimensional inference is a key component of big data analytics. In this chapter, a comprehensive overview of high dimensional inference and its applications in data analytics is provided. Key theoretical developments and computational tools are presented, giving readers an in-depth understanding of challenges in big data analysis.

**AdaptSPEC-X: Covariate Dependent Spectral Modeling of Multiple Nonstationary Time Series**

We present a method for the joint analysis of a panel of possibly nonstationary time series. The approach is Bayesian and uses a covariate-dependent infinite mixture model to incorporate multiple time series, with mixture components parameterized by a time varying mean and log spectrum. The mixture components are based on AdaptSPEC, a nonparametric model which adaptively divides the time series into an unknown but finite number of segments and estimates the local log spectra by smoothing splines. We extend AdaptSPEC to handle multiple time series with time varying mean and missing values. Covariates, assumed to be time-independent, are incorporated via the mixture weights using the logistic stick breaking process. The resulting model can estimate time varying means and spectra at both observed and unobserved covariate values, allowing for predictive inference. Estimation is performed by Markov chain Monte Carlo (MCMC) methods, combining data augmentation, reversible jump, and Riemann manifold Hamiltonian Monte Carlo techniques. We evaluate the methodology using simulated data, and describe applications to Australian rainfall data and measles incidence in the US. Efficient software implementing the method proposed in this paper is available in the R package BayesSpec.

**Cluster-based Distributed Augmented Lagrangian Algorithm for a Class of Constrained Convex Optimization Problems**

We propose a distributed solution for a constrained convex optimization problem over a network of clustered agents each consisted of a set of subagents. The communication range of the clustered agents is such that they can form a connected undirected graph topology. The total cost in this optimization problem is the sum of the local convex cost of the subagents of each cluster. We seek a minimizer of this cost subject to a set of affine equality constraints, and a set of affine inequality constrains specifying the bounds on the decision variables if such bounds exist. Our proposed distributed algorithm is a novel continuous-time algorithm that is linked to the augmented Lagrangian approach. It converges asymptotically when the local cost functions are convex and exponentially when they are strongly convex and have Lipschitz gradients. For efficient communication and computation resource management, we only require the agents that are coupled through an equality constraint to form a communication topology to address that coupling in a distributed manner. We use an {\epsilon}-exact penalty function to address the inequality constraints, and drive an explicit lower bound on the penalty function weight to guarantee convergence to {\epsilon}-neighborhood of the global minimum value of the cost. We demonstrate our results via an optimal resource allocation problem for power generators, and an optimal multi-sensor deployment problem.

**A Computational Model for Tensor Core Units**

To respond to the need of efficient training and inference of deep neural networks, a pletora of domain-specific hardware architectures have been introduced, such as Google Tensor Processing Units and NVIDIA Tensor Cores. A common feature of these architectures is a hardware circuit for efficiently computing a dense matrix multiplication of a given small size. In order to broad the class of algorithms that exploit these systems, we propose a computational model, named TCU model, that captures the ability to natively multiply small matrices. We then use the TCU model for designing fast algorithms for linear algebra problems, including dense and sparse matrix multiplication, FFT, integer multiplication, and polynomial evaluation. We finally highlight a relation between the TCU model and the external memory model.

**Quantum Expectation-Maximization Algorithm**

Clustering algorithms are a cornerstone of machine learning applications. Recently, a quantum algorithm for clustering based on the k-means algorithm has been proposed by Kerenidis, Landman, Luongo and Prakash. Based on their work, we propose a quantum expectation-maximization (EM) algorithm for Gaussian mixture models (GMMs). The robustness and quantum speedup of the algorithm is demonstrated. We also show numerically the advantage of GMM over k-means for non-trivial cluster data.

**Bayesian models for survival data of clinical trials: Comparison of implementations using R software**

Objective: To provide guidance for the use of the main functions available in R for performing \emph{post hoc} Bayesian analysis of a randomized clinical trial with a survival endpoint using proportional hazard models. Study Design and Setting: Data derived from the ALLOZITHRO trial, conducted with 465 patients after allograft to prevent pulmonary complications and allocated between azithromycin and placebo; airflow decline–free survival at 2 years after randomization was the main endpoint. Results: Despite heterogeneity in modeling assumptions, in particular for the baseline hazard (parametric or nonparametric), and in estimation methods, Bayesian posterior mean hazard ratio (HR) estimates of azithromycin effect were close to those obtained by the maximum likelihood approach. Conclusion: Bayesian models can be implemented using various R packages, providing results in close agreement with the maximum likelihood estimates. These models provide probabilistic statements that could not be obtained otherwise.

**Recommender Systems Fairness Evaluation via Generalized Cross Entropy**

Fairness in recommender systems has been considered with respect to sensitive attributes of users (e.g., gender, race) or items (e.g., revenue in a multistakeholder setting). Regardless, the concept has been commonly interpreted as some form of equality — i.e., the degree to which the system is meeting the information needs of all its users in an equal sense. In this paper, we argue that fairness in recommender systems does not necessarily imply equality, but instead it should consider a distribution of resources based on merits and needs. We present a probabilistic framework based on generalized cross entropy to evaluate fairness of recommender systems under this perspective, where we show that the proposed framework is flexible and explanatory by allowing to incorporate domain knowledge (through an ideal fair distribution) that can help to understand which item or user aspects a recommendation algorithm is over- or under-representing. Results on two real-world datasets show the merits of the proposed evaluation framework both in terms of user and item fairness.

**AFrame: Extending DataFrames for Large-Scale Modern Data Analysis (Extended Version)**

Analyzing the increasingly large volumes of data that are available today, possibly including the application of custom machine learning models, requires the utilization of distributed frameworks. This can result in serious productivity issues for ‘normal’ data scientists. This paper introduces AFrame, a new scalable data analysis package powered by a Big Data management system that extends the data scientists’ familiar DataFrame operations to efficiently operate on managed data at scale. AFrame is implemented as a layer on top of Apache AsterixDB, transparently scaling out the execution of DataFrame operations and machine learning model invocation through a parallel, shared-nothing big data management system. AFrame incrementally constructs SQL++ queries and leverages AsterixDB’s semistructured data management facilities, user-defined function support, and live data ingestion support. In order to evaluate the proposed approach, this paper also introduces an extensible micro-benchmark for use in evaluating DataFrame performance in both single-node and distributed settings via a collection of representative analytic operations. This paper presents the architecture of AFrame, describes the underlying capabilities of AsterixDB that efficiently support modern data analytic operations, and utilizes the proposed benchmark to evaluate and compare the performance and support for large-scale data analyses provided by alternative DataFrame libraries.

**Quantum algorithms for Second-Order Cone Programming and Support Vector Machines**
![](//s0.wp.com/latex.php?latex=%5Cepsilon&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Cepsilon&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D+%5Cleft%28+n%5Csqrt%7Br%7D+%5Cfrac%7B%5Czeta+%5Ckappa%7D%7B%5Cdelta%5E2%7D+%5Clog+%5Cleft%281%2F%5Cepsilon%5Cright%29+%5Cright%29&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D+%5Cleft%28+n%5Csqrt%7Br%7D+%5Cfrac%7B%5Czeta+%5Ckappa%7D%7B%5Cdelta%5E2%7D+%5Clog+%5Cleft%281%2F%5Cepsilon%5Cright%29+%5Cright%29&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=r&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=r&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=n&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=n&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%5Cdelta&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Cdelta&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%5Czeta&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Czeta&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%5Ckappa&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Ckappa&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28n%5E%7B2.557%7D%29&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Cwidetilde%7BO%7D%28n%5E%7B2.557%7D%29&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%5COmega+%28n%5E%7B3%7D%29&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5COmega+%28n%5E%7B3%7D%29&bg=ffffff&fg=000&s=0)


**Computing Spectral Measures and Spectral Types: New Algorithms and Classifications**

Despite new results on computing the spectrum, there has been no general method able to compute spectral measures (as given by the classical spectral theorem) of infinite-dimensional normal operators. Given a matrix representation, we show that if each matrix column decays at infinity at a known asymptotic rate, then it is possible to compute spectral measures of self-adjoint and unitary linear operators on separable Hilbert spaces. The central ingredient of the new algorithm is the computation of the resolvent operator with error control. Computational spectral problems in infinite dimensions have led to the SCI hierarchy, which classifies the difficulty of a problem through the number of limits needed to numerically compute the solution. We classify the computation of measures, measure decompositions, types of spectra (pure point, absolutely continuous, singular continuous), functional calculus and Radon–Nikodym derivatives in the SCI hierarchy for such operators. The new algorithms are demonstrated to be efficient and practical on examples taken from orthogonal polynomials on the real line and the unit circle, and are also applied to evolution equations on a two-dimensional quasicrystal model.

**Align, Mask and Select: A Simple Method for Incorporating Commonsense Knowledge into Language Representation Models**

Neural language representation models such as Bidirectional Encoder Representations from Transformers (BERT) pre-trained on large-scale corpora can well capture rich semantics from plain text, and can be fine-tuned to consistently improve the performance on various natural language processing (NLP) tasks. However, the existing pre-trained language representation models rarely consider explicitly incorporating commonsense knowledge or other knowledge. In this paper, we develop a pre-training approach for incorporating commonsense knowledge into language representation models. We construct a commonsense-related multi-choice question answering dataset for pre-training a neural language representation model. The dataset is created automatically by our proposed ‘align, mask, and select’ (AMS) method. We also investigate different pre-training tasks. Experimental results demonstrate that pre-training models using the proposed approach followed by fine-tuning achieves significant improvements on various commonsense-related tasks, such as CommonsenseQA and Winograd Schema Challenge, while maintaining comparable performance on other NLP tasks, such as sentence classification and natural language inference (NLI) tasks, compared to the original BERT models.

**Fast End-to-End Wikification**

Wikification of large corpora is beneficial for various NLP applications. Existing methods focus on quality performance rather than run-time, and are therefore non-feasible for large data. Here, we introduce RedW, a run-time oriented Wikification solution, based on Wikipedia redirects, that can Wikify massive corpora with competitive performance. We further propose an efficient method for estimating RedW confidence, opening the door for applying more demanding methods only on top of RedW lower-confidence results. Our experimental results support the validity of the proposed approach.

**SIRUS: making random forests interpretable**

State-of-the-art learning algorithms, such as random forests or neural networks, are often qualified as ‘black-boxes’ because of the high number and complexity of operations involved in their prediction mechanism. This lack of interpretability is a strong limitation for applications involving critical decisions, typically the analysis of production processes in the manufacturing industry. In such critical contexts, models have to be interpretable, i.e., simple, stable, and predictive. To address this issue, we design SIRUS (Stable and In-terpretable RUle Set), a new classification algorithm based on random forests, which takes the form of a short list of rules. While simple models are usually unstable with respect to data perturbation, SIRUS achieves a remarkable stability improvement over cutting-edge methods. Furthermore, SIRUS inherits a predictive accuracy close to random forests, combined with the simplicity of decision trees. These properties are assessed both from a theoretical and empirical point of view, through extensive numerical experiments based on our R/C++ software implementation sirus.

**Comparing linear structure-based and data-driven latent spatial representations for sequence prediction**

Predicting the future of Graph-supported Time Series (GTS) is a key challenge in many domains, such as climate monitoring, finance or neuroimaging. Yet it is a highly difficult problem as it requires to account jointly for time and graph (spatial) dependencies. To simplify this process, it is common to use a two-step procedure in which spatial and time dependencies are dealt with separately. In this paper, we are interested in comparing various linear spatial representations, namely structure-based ones and data-driven ones, in terms of how they help predict the future of GTS. To that end, we perform experiments with various datasets including spontaneous brain activity and raw videos.

**Across-Stack Profiling and Characterization of Machine Learning Models on GPUs**

The world sees a proliferation of machine learning/deep learning (ML) models and their wide adoption in different application domains recently. This has made the profiling and characterization of ML models an increasingly pressing task for both hardware designers and system providers, as they would like to offer the best possible computing system to serve ML models with the desired latency, throughput, and energy requirements while maximizing resource utilization. Such an endeavor is challenging as the characteristics of an ML model depend on the interplay between the model, framework, system libraries, and the hardware (or the HW/SW stack). A thorough characterization requires understanding the behavior of the model execution across the HW/SW stack levels. Existing profiling tools are disjoint, however, and only focus on profiling within a particular level of the stack. This paper proposes a leveled profiling design that leverages existing profiling tools to perform across-stack profiling. The design does so in spite of the profiling overheads incurred from the profiling providers. We coupled the profiling capability with an automatic analysis pipeline to systematically characterize 65 state-of-the-art ML models. Through this characterization, we show that our across-stack profiling solution provides insights (which are difficult to discern otherwise) on the characteristics of ML models, ML frameworks, and GPU hardware.

**Computational Flight Control: A Domain-Knowledge-Aided Deep Reinforcement Learning Approach**

This papers aims to examine the potential of using the emerging deep reinforcement learning techniques in flight control. Instead of learning from scratch, the autopilot structure is fixed as typical three-loop autopilot and deep reinforcement learning is utilised to learn the autopilot gains. This domain-knowledge-aided approach is proved to significantly improve the learning efficiency. To solve the flight control problem, we then formulate a Markovian decision process with a proper reward function that enable the application of reinforcement learning theory. The state-of-the-art deep deterministic policy gradient algorithm is utilised to learn an action policy that maps the observed states to the autopilot gains. Extensive empirical numerical simulations are performed to validate the proposed computational control algorithm.

**Architecture Search by Estimation of Network Structure Distributions**

The influence of deep learning is continuously expanding across different domains, and its new applications are ubiquitous. The question of neural network design thus increases in importance, as traditional empirical approaches are reaching their limits. Manual design of network architectures from scratch relies heavily on trial and error, while using existing pretrained models can introduce redundancies or vulnerabilities. Automated neural architecture design is able to overcome these problems, but the most successful algorithms operate on significantly constrained design spaces, assuming the target network to consist of identical repeating blocks. We propose a probabilistic representation of a neural network structure under the assumption of independence between layer types. The probability matrix (prototype) can describe general feedforward architectures and is equivalent to the population of models, while being simple to interpret and analyze. We construct an architecture search algorithm, inspired by the estimation of distribution algorithms, to take advantage of this representation. The probability matrix is tuned towards generating high-performance models by repeatedly sampling the architectures and evaluating the corresponding networks. Our algorithm is shown to discover models which are competitive with those produced by existing architecture search methods, both in accuracy and computational costs, despite the conceptual simplicity and the comparatively limited scope of achievable designs.

**Neural Architectures for Nested NER through Linearization**

We propose two neural network architectures for nested named entity recognition (NER), a setting in which named entities may overlap and also be labeled with more than one label. We encode the nested labels using a linearized scheme. In our first proposed approach, the nested labels are modeled as multilabels corresponding to the Cartesian product of the nested labels in a standard LSTM-CRF architecture. In the second one, the nested NER is viewed as a sequence-to-sequence problem, in which the input sequence consists of the tokens and output sequence of the labels, using hard attention on the word whose label is being predicted. The proposed methods outperform the nested NER state of the art on four corpora: ACE-2004, ACE-2005, GENIA and Czech CNEC. We also enrich our architectures with the recently published contextual embeddings: ELMo, BERT and Flair, reaching further improvements for the four nested entity corpora. In addition, we report flat NER state-of-the-art results for CoNLL-2002 Dutch and Spanish and for CoNLL-2003 English.

**Consistent Community Detection in Continuous-Time Networks of Relational Events**

In many application settings involving networks, such as messages between users of an on-line social network or transactions between traders in financial markets, the observed data are in the form of relational events with timestamps, which form a continuous-time network. We propose the Community Hawkes Independent Pairs (CHIP) model for community detection on such timestamped relational event data. We demonstrate that applying spectral clustering to adjacency matrices constructed from relational events generated by the CHIP model provides consistent community detection for a growing number of nodes. In particular, we obtain explicit non-asymptotic upper bounds on the misclustering rates based on the separation conditions required on the parameters of the model for consistent community detection. We also develop consistent and computationally efficient estimators for the parameters of the model. We demonstrate that our proposed CHIP model and estimation procedure scales to large networks with tens of thousands of nodes and provides superior fits compared to existing continuous-time network models on several real networks.

**Gradient Boosting Machine: A Survey**

In this survey, we discuss several different types of gradient boosting algorithms and illustrate their mathematical frameworks in detail: 1. introduction of gradient boosting leads to 2. objective function optimization, 3. loss function estimations, and 4. model constructions. 5. application of boosting in ranking.

**Dynamic Graph Message Passing Networks**

Modelling long-range dependencies is critical for complex scene understanding tasks such as semantic segmentation and object detection. Although CNNs have excelled in many computer vision tasks, they are still limited in capturing long-range structured relationships as they typically consist of layers of local kernels. A fully-connected graph is beneficial for such modelling, however, its computational overhead is prohibitive. We propose a dynamic graph message passing network, based on the message passing neural network framework, that significantly reduces the computational complexity compared to related works modelling a fully-connected graph. This is achieved by adaptively sampling nodes in the graph, conditioned on the input, for message passing. Based on the sampled nodes, we then dynamically predict node-dependent filter weights and the affinity matrix for propagating information between them. Using this model, we show significant improvements with respect to strong, state-of-the-art baselines on three different tasks and backbone architectures. Our approach also outperforms fully-connected graphs while using substantially fewer floating point operations and parameters.

### Like this:

Like Loading...
