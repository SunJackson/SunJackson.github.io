---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/08/25/distilled-news-1175/
date:      2019-08-25
author:      Michael Laux
tags:
    - learning
    - learns
    - computational
    - computers
    - tasks
---

**Cracking the Box: Interpreting Black Box Machine Learning Models**

To kick off this article, I’d like to explain the interpretability of a machine learning (ML) model. According to Merriam-Webster, interpretability describes the process of making something plain or understandable. In the context of ML, interpretability provides us with an understandable explanation of how a model behaves. Basically, it helps us figure out what’s behind model predictions and how these models work. Miller and Tim’s ‘Explanation in Artificial Intelligence: Insights from the Social Sciences’ states that ‘Interpretability is the degree to which a human can understand the cause of a decision.’ By utilizing ML interpretability methods, we increase this degree and allow humans to consistently predict the model’s behavior. Moreover, fairness and unbiasedness have recently become important auxiliary criteria for model optimization. ML interpretability is an essential tool to check these properties for ML systems. In this work, I’ll let you in on major methods of tackling the interpretability of ML models using Python and explain how to build a resilient machine learning infrastructure that serves as a foundation for artificial intelligence, accelerating the time to market for AI-powered projects.

**Making Apache Spark Effortless for All of Uber**

Apache Spark is a foundational piece of Uber’s Big Data infrastructure that powers many critical aspects of our business. We currently run more than one hundred thousand Spark applications per day, across multiple different compute environments. Spark’s versatility, which allows us to build applications and run them everywhere that we need, makes this scale possible. However, our ever-growing infrastructure means that these environments are constantly changing, making it increasingly difficult for both new and existing users to give their applications reliable access to data sources, compute resources, and supporting tools. Also, as the number of users grow, it becomes more challenging for the data team to communicate these environmental changes to users, and for us to understand exactly how Spark is being used. We built the Uber Spark Compute Service (uSCS) to help manage the complexities of running Spark at this scale. This Spark-as-a-service solution leverages Apache Livy, currently undergoing Incubation at the Apache Software Foundation, to provide applications with necessary configurations, then schedule them across our Spark infrastructure using a rules-based approach. uSCS now handles the Spark applications that power business tasks such as rider and driver pricing computation, demand prediction, and restaurant recommendations, as well as important behind-the-scenes tasks like ETL operations and data exploration. uSCS introduced other useful features into our Spark infrastructure, including observability, performance tuning, and migration automation.

**Building and managing training datasets for ML with Snorkel**

Alex Ratner outlines work on Snorkel, an open source framework for building and managing training datasets, and details three key operators for letting users build and manipulate training datasets: labeling functions for labeling unlabeled data, transformation functions for expressing data augmentation strategies, and slicing functions for partitioning and structuring training datasets. These operators allow domain expert users to specify ML models via noisy operators over training data, leading to applications that can be built in hours or days rather than months or years. Alex explores recent work on modeling the noise and imprecision inherent in these operators and using these approaches to train ML models that solve real-world problems, including a recent state-of-the-art result on the SuperGLUE natural language processing benchmark task.

**Announcing Cisco Data Intelligence Platform**

Data scientists are constantly searching for newer techniques and methodologies that can unlock the value of big data and distill this data further to identify additional insights which could transform productivity and provide business differentiation. One such area is Artificial Intelligence/Machine Learning (AI/ML), which has seen tremendous development with bringing in new frameworks and new forms of compute (CPU, GPU and FPGA) to work on data to provide key insights. While data lakes have historically been data intensive workloads, these advancements in technologies have led to a new growing demand of compute intensive workloads to operate on the same data.

**The 5 Sampling Algorithms every Data Scientist need to know**

I grapple through with many algorithms on a day to day basis so I thought of listing some of the most common and most used algorithms one will end up using in this new DS Algorithm series. This post is about some of the most common sampling techniques one can use while working with data.â€¢ Simple Random Samplingâ€¢ Stratified Samplingâ€¢ Reservoir Samplingâ€¢ Random Undersampling and Oversamplingâ€¢ Undersampling and Oversampling using imbalanced-learn

**Ten simple rules for writing and sharing computational analyses in Jupyter Notebooks**

As studies grow in scale and complexity, it has become increasingly difficult to provide clear descriptions and open access to the methods and data needed to understand and reproduce computational research. Numerous papers , including several in the Ten Simple Rules collection , have highlighted the need for robust and reproducible analyses in computational research, described the difficulty of achieving these standards, and enumerated best practices. We aim to augment this existing wellspring of advice by addressing the unique challenges and opportunities that arise when using computational notebooks, especially Jupyter Notebooks, for research .Rule 1: Tell a story for an audienceRule 2: Document the process, not just the resultsRule 3: Use cell divisions to make steps clearRule 4: Modularize codeRule 5: Record dependenciesRule 6: Use version controlRule 7: Build a pipelineRule 8: Share and explain your dataRule 9: Design your notebooks to be read, run, and exploredRule 10: Advocate for open research

**Getting Your Data Ready for AI**

Despite the enthusiasm for AI, a recent survey reveals that few organizations have adopted this technology in any meaningful way. One reason is the tedious process of accessing, labeling, and transforming data – known as data wrangling – that consumes 80% of a data scientist’s time. There’s a better way to model data. This practical ebook explores a new crop of self-service data preparation tools and services, including IBM Watson Studio, for automating data wrangling.Featuring interviews with data analytics experts, including Alex Castrounis (InnoArchiTech), Jay Limburn (IBM), and Katharine Jarmul (Data Wrangling with Python) among others, this ebook examines key barriers to capturing value from AI processes, including problems with data access and preparation. Author Kate Shoup shows data scientists and analysts how Watson Studio and other self-service tools enable domain experts, developers, and business analysts to practice data science.â€¢ Get an overview of data science and learn how it differs from data analysisâ€¢ Examine a typical AI workflow, including challenges that surface at each step of the data wrangling processâ€¢ Learn solutions to AI workflow challenges, including the use of data catalogs to help you access and prep dataâ€¢ Dive into Watson Studio and learn how the platform combines data catalogs with support for data science tools in one environmentâ€¢ Evaluate a Watson Studio example and explore real-world use cases

**On Nonscalability – The Living World Is Not Amenable to Precision-Nested Scales**

There is something disturbingly beautiful about precision, even when we know it fails us. A century ago, people stood awestruck at the terrible precision of the factory; today it is the precision of the computer. Precision has mesmerized not just engineers but all kinds of designers, scholars, and observers. One arena where precision has gained a malevolent hegemony is the use of scale. As in digital media, with its power to make the great tiny and the tiny great in an effortless zoom, scale has become a verb that requires precision; to scale well is to develop the quality called scalability, that is, the ability to expand – and expand, and expand – without rethinking basic elements. Scalability is, indeed, a triumph of precision design, not just in computers but in business, development, the ‘conquest’ of nature, and, more generally, world making. It is a form of design that has a long history of dividing winners and losers. Yet it disguises such divisions by blocking our ability to notice the heterogeneity of the world; by its design, scalability allows us to see only uniform blocks, ready for further expansion. This essay recalls attention to the wild diversity of life on earth through the argument that it is time for a theory of nonscalability.

**Less than Half of Google Searches Now Result in a Click**

We’ve passed a milestone in Google’s evolution from search engine to walled-garden. In June of 2019, for the first time, a majority of all browser-based searches on Google.com resulted in zero-clicks.

**The Rise of Data Downtime**

Introducing ‘data downtime’ and its importance to data-driven organizations. Has it ever happened to you that your CEO looked at a report you showed and said the numbers look way off? Has a customer ever called out incorrect data in your product’s dashboards? I’m sure it hasn’t happened to you specifically, but perhaps you have a friend who had this problem? ðŸ™‚ In 2016, while I was leading a team at Gainsight, fondly called Gainsight on Gainsight (GonG), I became all too familiar with these issues. We were responsible for our customer data and analytics, including key reports reviewed weekly by our CEO and quarterly by our board of directors. Seemingly every Monday morning, I would wake up to a series of emails about errors in the data. It felt like every time we fixed a problem, we found three other things that went wrong. What’s worse, we weren’t catching the issues on our own. Instead, other people, including our very patient CEO, were alerting us about these issues. Recently, I talked to a CEO of another company who told me he used to go around the office and put sticky notes saying ‘this is wrong’ on monitors displaying analytics with erroneous data.

**Data Imputation to improve model performance**

Ultimately it is small steps which make huge impact. Data imputation is an important part of data preparation stage while executing any machine learning project. In pure statistical term, it is a process of replacing missing data with some meaningful substitute.

**Lean + Data Science**

1. data science practice is full of waste2. explicit hypothesis testing helps to finetune ideas3. communication is the key for integrating data scientists into the software development lifecycle

**Meta-transfer Learning for Few-shot Learning**

Meta-learning has been proposed as a framework to address the challenging few-shot learning setting. The key idea is to leverage a large number of similar few-shot tasks in order to learn how to adapt a base-learner to a new task for which only a few labeled samples are available. As deep neural networks (DNNs) tend to overfit using a few samples only, meta-learning typically uses shallow neural networks (SNNs), thus limiting its effectiveness. In this paper we propose a novel few-shot learning method called meta-transfer learning (MTL) which learns to adapt a deep NN for few shot learning tasks. Specifically, meta refers to training multiple tasks, and transfer is achieved by learning scaling and shifting functions of DNN weights for each task. In addition, we introduce the hard task (HT) meta-batch scheme as an effective learning curriculum for MTL. We conduct experiments using (5-class, 1-shot) and (5-class, 5-shot) recognition tasks on two challenging few-shot learning benchmarks: miniImageNet and Fewshot-CIFAR100. Extensive comparisons to related works validate that our meta-transfer learning approach trained with the proposed HT meta-batch scheme achieves top performance. An ablation study also shows that both components contribute to fast convergence and high accuracy.

**Correspondence Analysis visualization using ggplot**

Recently, I used a correspondence analysis from the ca package in a paper. All of the figures in the paper were done with ggplot. So, I wanted the visualization for the correspondence analysis to match the style of the other figures. The standard plot method plot.ca() however, produces base graphics plots. So, I had to create the ggplot visualization myself. Actually, I don’t know if there are any packages that take a ca object (created by the ca package) and produce ggplots from it. I found this website but it uses the FactoMineR/factoextra package to do and visualize the correspondence analysis. So, off we go… let’s build our own ggplot-based visualization for ca objects.

**Detecting outliers with PyOD**

As the name suggests, outliers are datapoint which differs significantly from the rest of your observations. In other words, they are far away from the average path of your data. In statistics and Machine Learning, detecting outliers is a pivotal step, since they might affect the performance of your model. Namely, imagine you want to predict the return of your company based on the amount of sold units.

**Data Preprocessing in Data Mining & Machine Learning**

In this discussion we are going to talk about the following approaches of Data Preprocessing:â€¢ Aggregationâ€¢ Samplingâ€¢ Dimensionality Reductionâ€¢ Feature Subset Selectionâ€¢ Feature Creationâ€¢ Discretization and Binarizationâ€¢ Variable Transformation

### Like this:

Like Loading...
