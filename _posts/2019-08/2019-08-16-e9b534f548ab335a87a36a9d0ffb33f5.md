---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/08/16/distilled-news-1165/
date:      2019-08-16
author:      Michael Laux
tags:
    - learning
    - learned
    - modeling
    - previous data
    - features
---

**Address Limitation of RNN in NLP Problems by Using Transformer-XL**

Recurrent Neural Network (RNN) offers a way to learn a sequence of inputs. The drawback is that it is difficult to optimize due to vanishing gradient problem. Transformer (Al-Rfou et al., 2018) is introduced to overcome the limitation of RNN. By design, a fixed-length segment is defined to reduce resource consumption. However, there is another problem that calls context fragmentation. If the input sequence is larger than pre-defined segment length, the input sequence needs to be separated and information cannot be captured across segments. Transformer-XL is introduced to overcome this limitation by Dai et al. (2019)

**Machine Learning: Create Expert Systems**

achine Learning is nothing but creating the machines or software which can take its own decisions on the basis of previous data collected. Technically speaking, machine learning involves ‘explicit’ programming rather than an ‘implicit’ one:Machine learning is divided into three categories viz.• Supervised Learning• Unsupervised Learning• Reinforcement Learning.

**Processing a Slowly Changing Dimension Type 2 Using PySpark in AWS**

With the emergence of new technologies that make data processing lightening fast, and cloud ecosystems which allow for flexibility, cost savings, security, and convenience, there appear to be some data modeling philosophies that are being used less frequently. One of these approaches is the star schema data architecture.

**Create predictive models in R with Caret**

Caret is the short for Classification And REgression Training. It is a complete package that covers all the stages of a pipeline for creating a machine learning predictive model. In this tutorial, I will explain the following topics:• How to install caret• How to create a simple model• How to use cross-validation to avoid overfitting• How to add simple preprocessing to your data• How to find the best parameters for your chosen model• How to see the most important features/variables for your model• How to use your model to predict

**From Research to Production: Containerized Training Jobs**

This article demonstrates how to containerize training code using Docker and deploy the fitted model as a web app. Although it partly builds on my previous post Transformer Fine-Tuning for Sentiment Analysis, bear in mind that the method described here is generic; it can be adopted as a standard solution for Machine Learning practitioners to encapsulate their research code and facilitate reproducibility.

**A New Way to Share & Collaborate on Jupyter Notebooks**

Sharing and reproducing data science is still not easy – most work just sits on Github, undiscovered, as very technical documents. Most companies still do not have a central hub for knowledge. Data teams typically use tools like Github for project management, but this means their work is not shared with the non-technical people in the company. This also holds true for individual projects. Kyso solves this problem with an elegant blogging platform, making accessible to everyone information that was previously only possessed by a select few. Kyso lets you blog and share your analyses. Think of it like Medium, but for data science – you can publish Jupyter notebooks, charts, code, datasets and even write articles. Any code is hidden by default and can be toggled so that your post is readable for both technical and non-technical audiences. This guide is about sharing the results of your Jupyter notebooks with people who aren’t comfortable with code. You will learn how to integrate your Github repositories with Kyso to create an effortless computation-to-dissemination workflow.

**Introducing mlrPlayground**

The idea behind this project was to offer a platform in the form of a Shiny web application, in which a user can try out different kinds of learners provided by the mlr package. On a small set of distinct and tunable regression and classification tasks, it is possible to observe the prediction/performance behavior based on changes on the task, the learner or the learner’s hyperparameters. The user is able to gain new insights and a deeper understanding of how a learner performs, where it’s advantages are and in which cases the learner might fail. There are a lot of different settings we want to offer in the user interface, and so – to not remove the fun of our playground – a huge effort went into creating an aesthetically pleasing and user-friendly UI. To achieve this, a website template was downloaded from Templated and used as the baseline design. After extending the template with missing CSS classes, most of the used shiny widgets have been overwritten – or even completely replaced -, offering refreshingly new visuals for the well-known shiny framework. For the smooth feel of the app, an object-oriented R6 class system with reactive attributes was engineered for the backend to give a well-defined framework of which elements should trigger what evaluation; an otherwise extremely tiresome and error-prone task for dozens of different UI elements. After all ‘mlrPlayground’ may not be as fun as a real playground, but you are also not as likely to hurt yourself and it is definitely more entertaining than looking at boring pictures of learners in a book.

**Fraud detection using Benford’s Law (Python Code)**

Have you ever noticed what chance has a given number to start with the digit 1?Does the digit 1 has the same propability to be a leading digit as 9? To let you know that the leading numbers of a number represents its non zero left most digits. For example 29 and 0.037 are 2 and 3.Well the unswer in the previous question is no…According to Benford’s law, a.k.a. the first digit law, the frequency of occurrence of the leading digits in naturally occurring numerical distributions is predictable and nonuniform but more close to a power law distribution. In fact, a given number is six times more likely to start with a 1 than a 9! This is very illogical, as most people would expect a uniform distribution U(1,9) where all the digits have the same likelihood to show up in first slot so they expext a propability 1/9 percent ~ 11,1%. Let us consider that Pr(D1=d) is the propability of a given number has first digit d and and the Pr(D2=d) the first two digits, the following table provide all the decemical digits probs that emerged by Newcomb’s observation in 1881.

**A 2019 Guide to Semantic Segmentation**

Semantic segmentation refers to the process of linking each pixel in an image to a class label. These labels could include a person, car, flower, piece of furniture, etc., just to mention a few. We can think of semantic segmentation as image classification at a pixel level. For example, in an image that has many cars, segmentation will label all the objects as car objects. However, a separate class of models known as instance segmentation is able to label the separate instances where an object appears in an image. This kind of segmentation can be very useful in applications that are used to count the number of objects, such as counting the amount of foot traffic in a mall. Some of its primary applications are in autonomous vehicles, human-computer interaction, robotics, and photo editing/creativity tools. For example, semantic segmentation is very crucial in self-driving cars and robotics because it is important for the models to understand the context in the environment in which they’re operating.

**Proximal Policy Optimization Tutorial (Part 1: Actor-Critic Method)**

Welcome to the first part of a math and code turorial series. I’ll be showing how to implement a Reinforcement Learning algorithm known as Proximal Policy Optimization (PPO) for teaching an AI agent how to play football/soccer. By the end of this tutorial, you’ll get an idea on how to apply an on-policy learning method in an actor-critic framework in order to learn navigating any game environment. We shall see what these terms mean in context of the PPO algorithm and also implement them in Python with the help of Keras. So, let’s first start with the installation of our game environment.

**The ultimate guide to A/B testing. Part 2: Data distributions**

A/B testing is a very popular technique for checking granular changes in a product without mistakenly taking into account changes that were caused by outside factors. In this series of articles, I will try to give an easy hands-on manual on how to design, run and estimate results of a/b tests, so you are ready to go and get these amazing statistically significant results!

**What I have Learned After Building A Successful AI PoC**

I recently completed an AI PoC that has reached production and I wanted to share what I have learned on how to improve the chances of any AI PoC. Only a few companies have started their AI journey. Indeed AI-based solutions are still in the early stages. As a result, decision-makers are often tempted to first rely on a PoC. The cold truth is that a majority of them don’t reach production. To put it simply, the goal of a Proof of Concept is to test whether it’s worth investing time and more money into a technological solution. Needless to say that building an AI PoC is hard because it requires a large set of skills.

**4 Tips for Advanced Feature Engineering and Preprocessing**

Techniques for creating new features, detecting outliers, handling imbalanced data, and impute missing values. Arguably, two of the most important steps in developing a machine learning model is feature engineering and preprocessing. Feature engineering consists of the creation of features whereas preprocessing involves cleaning the data. Torture the data, and it will confess to anything. – Ronald Coase We often spend a significant amount of time refining the data into something useful for modeling purposes. In order to make this work more efficient, I would like to share 4 Tips and Tricks that could help you with engineering and preprocessing those features. I should note that, how cliche it might be, domain knowledge might be one of the most important things to have when engineering features. It might help you in preventing under- and overfitting by having a better understanding of the features that you use.

**Python Risk Management: Kelly Criterion**

From the recent events in the financial market correction, I thought it would be a fun time to talk about risk management. Specifically, we’ll go over the Kelly Criterion with a concrete example in Python. First, we’ll discuss a brief overview of the Kelly Criterion. Next, we’ll go over a simple coin flip example. Lastly, we’ll take that simple example and apply it to a financial index.

### Like this:

Like Loading...
