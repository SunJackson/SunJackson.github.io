---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/08/30/distilled-news-1180/
date:      2019-08-29
author:      Michael Laux
tags:
    - data
    - machine learning models
    - machines
    - posts
    - training
---

**TensorFlow Model Optimization Toolkit – Post-Training Integer Quantization**

Since we introduced the Model Optimization Toolkit – a suite of techniques that both novice and advanced developers can use to optimize machine learning models for deployment and execution – we have been working hard to reduce the complexity of quantizing machine learning models. Initially, we supported post-training quantization via ‘hybrid operations’, which is quantizing the parameters of the model (i.e. weights), but allowing certain parts of the computation to take place in floating point. Today, we are happy to announce the next addition to our tooling: post-training integer quantization. Integer quantization is a general technique that reduces the numerical precision of the weights and activations of models to reduce memory and improve latency.

**Top Deep Learning Frameworks of 2019 and How Do They Compare**

In this post, we present the top Deep Learning frameworks preferred by data scientists and Deep Learning experts across the globe. We have also included the major pros and cons of each framework, enabling you to choose the right one for your upcoming project.1. TensorFlow2. Keras3. PyTorch4. CNTK5. Apache MXNet

**Introducing the Snail Chart**

The bar chart – the mother of data graphs. Since its introduction in the 18th century by William Playfair, it underwent several alterations, mainly regarding• its orientation (vertical and horizontal bar charts)• and its arrangement (e.g. grouped and stacked bar charts)The reason behind the success of bar charts is a simple and intuitive design that makes it easy to interpret the presented data. It is also a widely used graph type which is already deeply integrated into our daily life (through news, articles, dashboards, etc.). Whenever we think about a representation of discrete data we think of bar charts. Even me, a data viz enthusiast, uses bar charts extensively, mostly to provide me with a quick first insight into the data.

**FastEmbed: How to compute efficient high dimensional PCA embeddings?**

This is a summary of the paper FastEmbed [python] [pyspark] SVD / PCA is a commonly used embedding technique for low dimensional datasets. The question we answer here is ‘How do you scale SVD / PCA to high dimensional datasets like social networks?’

**A deep dive into the world of gated Recurrent Neural Networks: LSTM and GRU**

In the world of deep learning, the RNN is considered as the go-to model whenever the problem requires sequence-based learning and this has propelled the research community to come up with interesting improvements over the vanilla RNN. One such prominent improvement is the introduction of gated RNNs: the LSTM and GRU.

**Unsupervised Machine Learning Approaches for Outlier Detection in Time Series, using Python**

In this post, I cover some of my favorite methods for detecting outliers in time series data. There are many different approaches for detecting anomalous data points; for the sake of brevity, I only focus on unsupervised machine learning methods in this post.The anomaly/outlier detection algorithms covered in this article include:• Low-pass filters: taking the centered rolling average of a time series, and removing anomalies based on Z-score• Isolation forests• Seasonal-extreme studentized deviate (S-ESD) algorithm• One class support vector machines (SVM’s)

**Kernel Functions in Non-linear Classification**

Learn how kernel functions map features into higher dimensions.

**Take a deeper look at your Pytorch model with the new Tensorboard built-in**

Deep learning models are often complex, hard to understand and used as a ‘black box’. Making your model more accessible and visualizing its progress can help you understand better what is happening during the training process. It is a nice and educating ability in a well performing model but it is a force to be reckoned with when you encounter problems. It can help you catch them early, debug more effectively and eliminate any biases in the dataset. Tensorboard allows you to log events from your model training, including various scalars (e.g. accuracy, loss), images, histograms etc… Until recently, Tensorboard was officially supported only by Tensorflow, but with the latest release of Pytorch 1.2.0, Tensorboard is now a native Pytorch built-in.

**Data Visualization with Python HoloViz: Plotting**

The goal of these posts is to demonstrate various functionality using examples likely to be encountered by a data scientist. This post covers basic plotting with HoloViews to create a readout for a trained regression model. Subsequent posts will explore basic interactivity.

**Decoding the Black Box: An Important Introduction to Interpretable Machine Learning Models in Python**

Can you interpret a deep neural network? How about a random forest with 500 trees? Building a complex and dense machine learning model has the potential of reaching our desired accuracy, but does it make sense? Can you open up the black-box model and explain how it arrived at the final result? These are critical questions we need to answer as data scientists. A wide variety of businesses are relying on machine learning to drive their strategy and spruce up their bottomline. Building a model that we can explain to our clients and stakeholders is key.

**A guide to Ensemble Learning**

Nobody can know everything but with help, we can overcome every obstacle. That’s exactly the idea behind ensemble learning. Eventhough, individual models might produce weak results combined they might be unbeatable. And ensemble models are exactly that – models consisting of a combination of base models. The only difference being the way they combine the models which can range from simple methods like averaging or max voting to more complex like Boosting or stacking.

**Machine Learning Algorithms are Not Black Boxes**

Data science is a very new field with few standards set in stone. This makes it an exciting field to work in because it is up to current data scientists to create and set these standards. However, because data science is such a new field, there is a lot of misinformation out there. The #1 piece of misinformation I frequently hear is that machine learning algorithms are black boxes. I strongly disagree with this statement. I believe almost any machine learning is highly interpretable. Individuals saying that machine learning algorithms are black boxes also say they typically use linear models because they are more interpretable. I also strongly disagree with this statement and believe that many machine learning algorithms (e.g., neural networks, random forests) are more interpretable than linear models. The goal of this blog post is to discuss machine learning algorithm interpretability and present methods that can be used to interpret these algorithms.

**Apache Kafka: platform architecture and streaming analysis**

Kafka is a distributed streaming platform which allows its users to send and receive live messages containing a bunch of data.This article will dwell on the architecture of Kafka, which is pivotal to understand how to properly set your streaming analysis environment. Later on, I will provide an example of real-time data analysis by creating an instant messaging environment with Kafka. By the end of this article, you will be able to understand the principal features which make Kafka so useful, that are:• distribution• commit log• horizontal scalability• fault toleranceFor now, let’s keep them in mind without explaining their meaning, which will be far clearer after introducing some further notions.

**Outlier detection 101: Median and Interquartile range.**

Median and Interquartile range provides a powerful tool for detecting outliers that can be used instead of mean and standard deviation due to its invulnerability against outlier contamination.

### Like this:

Like Loading...
