---
layout:     post
catalog: true
title:      Let’s get it right
subtitle:      转载自：https://analytixon.com/2019/08/24/lets-get-it-right-59/
date:      2019-08-24
author:      Michael Laux
tags:
    - ai development
    - trials
    - article
    - machines
    - data
---

***Article***: ***Europe will be left behind if it focuses on ethics and not keeping pace in AI development***

President-elect of the European Commission, Ursula von der Leyen made clear in her recently unveiled policy agenda, that not only will artificial intelligence (AI) be a key component of European digital strategy, but the cornerstone of the European AI plan will be to develop ‘AI made in Europe’ that is more ethical than AI made anywhere else in the world. What this means is not always clear, since there is no universal consensus on ethics. However, most European policymakers are less concerned about the ‘what’ and more about the ‘why.’ As explained by former Vice-President for the Digital Single Market, Andrus Ansip, ‘Ethical AI is a win-win proposition that can become a competitive advantage for Europe.’ This idea that Europe can become the global leader in AI simply by creating the most ethical AI systems, rather than by competing to build the best-performing ones, has become the conventional wisdom in Brussels, repeated ad nauseum by those tasked with charting a course for Europe’s AI future. But it is a delusion built on three fallacies: that there is a market for AI that is ethical-by-design, that other countries are not interested in AI ethics, and that Europeans have a competitive advantage in producing AI systems that are more ethical than those produced elsewhere.

***Article***: ***How Much Can We Afford to Forget, If We Train Machines to Remember?***

Civilizations evolve through strategic forgetting of once-vital life skills. But can machines do all our remembering? When I was a student, in the distant past when most computers were still huge mainframes, I had a friend whose PhD advisor insisted that he carry out a long and difficult atomic theory calculation by hand. This led to page after page of pencil scratches, full of mistakes, so my friend finally gave in to his frustration. He snuck into the computer lab one night and wrote a short code to perform the calculation. Then he laboriously copied the output by hand, and gave it to his professor. Perfect, his advisor said – this shows you are a real physicist. The professor was never any the wiser about what had happened. While I’ve lost touch with my friend, I know many others who’ve gone on to forge successful careers in science without mastering the pencil-and-paper heroics of past generations.

***Article***: ***AI and Collective Action***

Towards a more responsible development of artificial intelligence with a research paper from OpenAI. The 10th of July team members of OpenAI released a paper on arXiv called The Role of Cooperation in Responsible AI Development by Amanda Askell, Miles Brundage and Gillian Hadfield. One of the main statements in the article goes as follows: ‘Competition between AI companies could decrease the incentives of each company to develop responsibly by increasing their incentives to develop faster. As a result, if AI companies would prefer to develop AI systems with risk levels that are closer to what is socially optimal – as we believe many do – responsible AI development can be seen as a collective action problem’ Therefore how is it proposed we approach this problem?

***Article***: ***AI is transforming politics – for both good and bad***

Big Data powering Big Money, the return of direct democracy, and the tyranny of the minority. Nowadays, artificial intelligence (AI) is one of the most widely discussed phenomena. AI is poised to fundamentally alter almost every dimension of human life – from healthcare and social interactions to military and international relations. However, it is worth considering the effects of the advent of AI in politics – since politics are one of the fundamental pillars of today’s societal system, and understanding the dangers that AI poses for politics is crucial to combat AI’s negative implications, while at the same time maximizing the benefits stemming from the new opportunities in order to strengthen democracy.

***Paper***: ***Fairness Issues in AI Systems that Augment Sensory Abilities***

Systems that augment sensory abilities are increasingly employing AI and machine learning (ML) approaches, with applications ranging from object recognition and scene description tools for blind users to sound awareness tools for d/Deaf users. However, unlike many other AI-enabled technologies, these systems provide information that is already available to non-disabled people. In this paper, we discuss unique AI fairness challenges that arise in this context, including accessibility issues with data and models, ethical implications in deciding what sensory information to convey to the user, and privacy concerns both for the primary user and for others.

***Paper***: ***Bayesian leveraging of historical control data for a clinical trial with time-to-event endpoint***

The recent 21st Century Cures Act propagates innovations to accelerate the discovery, development, and delivery of 21st century cures. It includes the broader application of Bayesian statistics and the use of evidence from clinical expertise. An example of the latter is the use of trial-external (or historical) data, which promises more efficient or ethical trial designs. We propose a Bayesian meta-analytic approach to leveraging historical data for time-to-event endpoints, which are common in oncology and cardiovascular diseases. The approach is based on a robust hierarchical model for piecewise exponential data. It allows for various degrees of between trial-heterogeneity and for leveraging individual as well as aggregate data. An ovarian carcinoma trial and a non-small-cell cancer trial illustrate methodological and practical aspects of leveraging historical data for the analysis and design of time-to-event trials.

***Article***: ***How New A.I. Is Making the Law’s Definition of Hacking Obsolete***

Using adversarial machine learning, researchers can trick machines – potentially with fatal consequences. But the legal system hasn’t caught up. Imagine you’re cruising in your new Tesla, autopilot engaged. Suddenly you feel yourself veer into the other lane, and you grab the wheel just in time to avoid an oncoming car. When you pull over, pulse still racing, and look over the scene, it all seems normal. But upon closer inspection, you notice a series of translucent stickers leading away from the dotted lane divider. And to your Tesla, these stickers represent a non-existent bend in the road that could have killed you. In April this year, a research team at the Chinese tech giant Tencent showed that a Tesla Model S in autopilot mode could be tricked into following a bend in the road that didn’t exist simply by adding stickers to the road in a particular pattern. Earlier research in the U.S. had shown that small changes to a stop sign could cause a driverless car to mistakenly perceive it as a speed limit sign. Another study found that by playing tones indecipherable to a person, a malicious attacker could cause an Amazon Echo to order unwanted items.

***Article***: ***A.I. Is the Cause Of – And Solution To – the End of the World***

The development of artificial general intelligence offers tremendous benefits and terrible risks. There is no easy definition for artificial intelligence, or A.I. Scientists can’t agree on what constitutes ‘true A.I.’ versus what might simply be a very effective and fast computer program. But here’s a shot: intelligence is the ability to perceive one’s environment accurately and take actions that maximize the probability of achieving given objectives. It doesn’t mean being smart, in a sense of having a great store of knowledge, or the ability to do complex mathematics.

### Like this:

Like Loading...
