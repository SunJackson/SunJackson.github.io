---
layout:     post
catalog: true
title:      Frankfurt Data Science Meetup： Opening the Black Box
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/sV3OdnDcwaU/
date:      2019-04-26
author:      Lea Waniek
tags:
    - science
    - models
    - data
    - statworx love
    - historical
---





The place to be: Frankfurt Data Science Meetup
We at STATWORX love meetups: mingle with other data scientists, gain insights into their newest projects and approaches while having a beer… what’s not to like?

That’s why STATWORX supports the Frankfurt Data Science Meetup. However, while STATWORX chips in some beer money, the real work is done by the organizers of the meetup, who are doing a terrific job. A big thanks to everyone!

Yesterday’s meetup was extra special for us since our Head of Data Science Fabian Müller gave a talk on explainable machine learning. With data science growing more and more important in almost all fields of business, “cracking open the black box” is a matter of growing relevance. So, do yourself a favor and take a look at Fabian’s slides and code on github. (Even if you’re not that interested in the content, the memes and cute animal pictures are definitely worth it, believe me!) 

![](https://i2.wp.com/www.statworx.com/wp-content/uploads/frankfurt-data-science-meetup-april-2019-1024x576.png?resize=456%2C257&ssl=1)


## The takeaways: How and why to open the black box

As an appetizer, here are three of my most important takeaways: 

1. It’s not only cool to understand your model but it’s also the responsible thing to do. Because our models are trained on historical data, they mirror historical circumstances. Thus, model-based decisions might perpetuate discriminatory (social) structures. On top, understanding our models helps us to make them more performant. 

1. If we use model agnostic methods, which only use the model’s predictions, we can separate learning from explaining. Such model independent methods even enable comparisons across different classes of models. Also, there are many possible angles: We can focus on a single prediction and, e.g. explore what-if scenarios, decompose predictions or identify key features. Alternatively, we can focus on the model as a whole and analyze its structure or performance. 

1. Many methods to open the black box even apply to extremely complex models, e.g. CNN’s. The best thing: no matter how complex the model, most methods are intuitively understandable. You might need the help of a neat plot or two, but even data science non-specialists will get the gist.


I hope to have motivated you to check out more talks on the FFM Data Science Youtube channel. or, even better, come to the next Meetup in May. We’d love to see you! 

###### About the author

![](https://i0.wp.com/www.statworx.com/wp-content/uploads/statworx-avatar-female-300x300.png?resize=180%2C180&ssl=1)
![](https://i0.wp.com/www.statworx.com/wp-content/uploads/statworx-avatar-female-300x300.png?resize=180%2C180&ssl=1)


#### Lea Waniek

I am data scientist at STATWORX, apart from machine learning, I love to play around with RMarkdown and ggplot2, making data science beautiful inside and out.

---

STATWORXis a consulting company for data science, statistics, machine learning and artificial intelligence located in Frankfurt, Zurich and Vienna. Sign up for our NEWSLETTER and receive reads and treats from the world of data science and AI. 



 



**
