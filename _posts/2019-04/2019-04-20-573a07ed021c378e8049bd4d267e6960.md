---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/04/20/distilled-news-1043/
date:      2019-04-20
author:      Michael Laux
tags:
    - data
    - word
    - statistical
    - statistics
    - jasp
---

**Turning Data into Sound**

Inspired by Simon Rogers’s post introducing TwoTone, a tool to represent data as sound, I created my first data ‘sonification’ (aka musical representation of data). This was particularly interesting to me as I had only dreamt about creating jaw-dropping visualizations but never imagined that I could ever turn data into another format, especially sound. This post covers basics about TwoTone and how to use it.

**Embedding Graphs with Deep Learning**

Sparse representations are the natural killer of classifiers. Current graph data structures such as adjacency matrices and lists are plagued with this sparsity. This article will discuss techniques such as Matrix decomposition, DeepWalk, and Node2Vec which convert sparse graph data into low-dimensional continuous vector spaces.

**Scalable Jaccard similarity using MinHash and Spark**

It occurred to me a little while ago that the Jaccard similarity coefficient has probably cropped up in my work more than any other statistic except for the arithmetic mean. If you have two sets of things (words, parts of words, attributes, categories, or whatever), you can take the number of things in the intersection of the sets and divide by the number of things in the union of the sets. The resulting metric is a meaningful measure of similarity that has the added virtue of being pretty easily explainable to non-technical folks. Jaccard similarity gets a little difficult to calculate directly at scale. If you have a really large list of entity-attribute pairs, and you want an entity-by-entity similarity matrix, you basically have to do an inner join, group by entity and count, then do an outer join, group by entity and count, and then join the results of the two joins together. If your workflow uses Spark, as mine does, that’s a whole lot of shuffling. It’s expensive.

**X-AI, Black Boxes and Crystal Balls**

On our road to trusted AI, I discussed in my previous blog the question of bias, how it travels from humans to machines, how it is amplified by AI applications, the impacts in the real world, for individuals and for businesses, and the importance to proactively tackle this problem. Today, I’ll address the issue of explainability and transparency of the so-called ‘black box’ models.

**Data-Driven Scenario Stories**

So how do we tell meaningful, persuasive stories with data? How do we send messages that are relevant and relatable so that decision-makers can receive them in stride and accelerate down the field? Perhaps data scientists can borrow a page from scenario planning, which relies on informed narratives, to effectively bridge the gap between the digital world and the physical world.

**Why are you still doing batch processing? ‘ETL is dead’**

It was about year ago that a few colleagues suggested that I research Apache Kafka for an application that I was designing. I watched the rerun video from QCon 2016 titled ‘ETL is Dead; Long Live Streams’, in that video, Neha Narkhede (CTO of Confluent), describes the concept of replacing ETL batch data processing with messaging and microservices. It took some time for the paradigm to really sink in but after designing and writing a data streaming system, I can say that I am a believer. I will describe the difference between ETL batch processing and a data streaming process. Every company is still doing batch processing, it’s just a fact of life. A file of data is received, it must be processed: it needs to be parsed, validated, cleansed, calculated, organized, aggregated, then eventually delivered to some downstream system. Most companies are using some sort of workflow tool such as SSIS or Informatica, that can intuitively wrap these tasks into a ridged ‘package’ contained on a single server and execute on schedule.

**Please, explain.’ Interpretability of black-box machine learning models**

In February 2019 Polish government added an amendment to a banking law that gives a customer a right to receive an explanation in case of a negative credit decision. It’s one of the direct consequences of implementing GDPR in EU. This means that a bank needs to be able to explain why the loan wasn’t granted if the decision process was automatic. In October 2018 world headlines reported about Amazon AI recruiting tool that favored men. Amazon’s model was trained on biased data that were skewed towards male candidates. It has built rules that penalized résumés that included the word ‘women’s’.

**A Detailed Guide to Plotting Line Graphs in R using ggplot geom_line**

When it comes to data visualization, it can be fun to think of all the flashy and exciting ways to display a dataset. But if you’re trying to convey information, flashy isn’t always the way to go. In fact, one of the most powerful ways to communicate the relationship between two variables is the simple line graph. A line graph is a type of graph that displays information as a series of data points connected by straight line segments.

**Bling Fire**

Hi, we are a team at Microsoft called Bling (Beyond Language Understanding), we help Bing be smarter. Here we wanted to share with all of you our FInite State machine and REgular expression manipulation library (FIRE). We use Fire for many linguistic operations inside Bing such as Tokenization, Multi-word expression matching, Unknown word-guessing, Stemming / Lemmatization just to mention a few.

**A Comparative Review of the JASP Statistical Software**

JASP is a free and open source statistics package that targets beginners looking to point-and-click their way through analyses. This article is one of a series of reviews which aim to help non-programmers choose the Graphical User Interface (GUI) for R, which best meets their needs. Most of these reviews also include cursory descriptions of the programming support that each GUI offers. JASP stands for Jeffreys’ Amazing Statistics Program, a nod to the Bayesian statistician, Sir Harold Jeffreys. It is available for Windows, Mac, Linux, and there is even a cloud version. One of JASP’s key features is its emphasis on Bayesian analysis. Most statistics software emphasizes a more traditional frequentist approach; JASP offers both. However, while JASP uses R to do some of its calculations, it does not currently show you the R code it uses, nor does it allow you to execute your own. The developers hope to add that to a future version. Some of JASP’s calculations are done in C++, so getting that converted to R will be a necessary first step on that path.





### Like this:

Like Loading...


*Related*

