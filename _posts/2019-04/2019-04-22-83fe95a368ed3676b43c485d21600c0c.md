---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/04/22/distilled-news-1044/
date:      2019-04-22
author:      Michael Laux
tags:
    - learns
    - ai
    - gans
    - data
    - networks
---

**Neural Network Quantization Introduction**

I had been planing to write a series articles on neural network quantization. This Neural Network Quantization Introduction draws the skeleton. Regarding the rapid evolution of deep learning in recent years, there has been plenty of metarils on quantiaztion. However, for most of these documents, authors rush into their work details so fast that new comers can hardly understand even the baseline. This is of course not a good status in such a fast growing field.

**Generative Adversarial Networks Demystified**

Since Ian Goodfellow and co-authors published their first paper about GANs in 2014, GANs have been continuously improved and applied in many ways to generate new data. For example, GANs have been successfully used for generating realistic faces, characters or filling images. GANs represent a relatively new idea with wide applications, and this concept differs from common deep learning frameworks as it is a form of unsupervised learning. The inputs are unlabeled and the adversarial network learns what the data looks like (i.e., density estimation), which enables it to generate new examples.

**News Feature: What are the limits of deep learning?**

There’s no mistaking the image: It’s a banana – a big, ripe, bright-yellow banana. Yet the artificial intelligence (AI) identifies it as a toaster, even though it was trained with the same powerful and oft-publicized deep-learning techniques that have produced a white-hot revolution in driverless cars, speech understanding, and a multitude of other AI applications. That means the AI was shown several thousand photos of bananas, slugs, snails, and similar-looking objects, like so many flash cards, and then drilled on the answers until it had the classification down cold. And yet this advanced system was quite easily confused – all it took was a little day-glow sticker, digitally pasted in one corner of the image.

**What Microsoft and Google Are Not Telling You About Their A.I.**

It’s natural for companies to portray their A.I. technology as much more sophisticated than it really is. Doing so attracts new investors and raises consumer confidence. But as A.I. becomes more prevalent, tech companies run into trouble when the humans that support it behind the scenes decide to go public about their work – or when a human translator at a conference notices that things aren’t quite what they seem. Most A.I. companies reveal very little about their algorithms in the name of intellectual property protection. As investors flood into this new field, it’s worth examining any tech company’s claims critically. More than ever, we must use all available information to verify just how artificial and intelligent A.I. truly is.

**A graphical introduction to dynamic programming**

I’ve been helping a friend understand dynamic programming (DP for short), so I’ve been on the lookout for good resources. The topic is covered all across the web, but I found many of them focused on the code, and not enough on the beautiful visualizations that shed light into how DP works. In this post, I present a highly visual introduction to dynamic programming, then walk through three separate problems utilizing dynamic programming.

**The Rise of Generative Adversarial Networks**

**Principled GraphQL**

GraphQL, despite the name, isn’t simply a query language. It’s a comprehensive solution to the problem of connecting modern apps to services in the cloud. As such, it forms the basis for a new and important layer in the modern application development stack: the data graph. This new layer brings all of a company’s app data and services together in one place, with one consistent, secure, and easy-to-use interface, so that anyone can draw upon it with minimal friction.

**How to Debug a Neural Network With Gradient Checking**

When implementing a neural network from scratch, backpropagation is arguably where it is more prone to mistakes. Therefore, a method to debug this step could potentially save a lot of time and headaches when debugging a neural network. Here, the method of gradient checking will be introduced. Briefly, this methods consists in approximating the gradient using a numerical approach. If it is close to the calculated gradients, then backpropagation was implemented correctly! Let’s dive into more details and let’s see how it can be implemented in a project.

**Symbolic vs Connectionist A.I.**

It seems that wherever there are two categories of some sort, people are very quick to take one side or the other, to then pit both against each other. Artificial Intelligence techniques have traditionally been divided into two categories; Symbolic A.I. and Connectionist A.I. The latter kind have gained significant popularity with recent success stories and media hype, and no one could be blamed for thinking that they are what A.I. is all about. There have even been cases of people spreading false information to diverge attention and funding from more classic A.I. research and development. The truth of the matter is that each set of techniques has its place. There is no silver bullet A.I. algorithm yet, and trying to use the same algorithm for all problems is just plain stupid. Each has its own strengths and weaknesses, and choosing the right tools for the job is key.

**Reinforcement Learning 101**

Reinforcement Learning(RL) is one of the hottest research topics in the field of modern Artificial Intelligence and its popularity is only growing. Let’s look at 5 useful things one needs to know to get started with RL.

**Some Popular Metrics in Machine Learning**

In this article I provide a brief overview of several metrics used to evaluate the performance of models that simulate some behavior. These metrics compare the simulated output to some ground truth.

**Tidy correlation tests in R**

When we try to estimate the correlation coefficient between multiple variables, the task is more complicated in order to obtain a simple and tidy result. A simple solution is to use the tidy() function from the {broom} package. In this post we are going to estimate the correlation coefficients between the annual precipitation of several Spanish cities and climate teleconnections indices: download. The data of the teleconnections are preprocessed, but can be downloaded directly from crudata.uea.ac.uk. The daily precipitation data comes from ECA&D.

**The Complete Guide to Decision Trees**

In the beginning, learning Machine Learning (ML) can be intimidating. Terms like ‘Gradient Descent’, ‘Latent Dirichlet Allocation’ or ‘Convolutional Layer’ can scare lots of people. But there are friendly ways of getting into the discipline, and I think starting with Decision Trees is a wise decision. Decision Trees (DTs) are probably one of the most useful supervised learning algorithms out there. As opposed to unsupervised learning (where there is no output variable to guide the learning process and data is explored by algorithms to find patterns), in supervised learning your existing data is already labelled and you know which behaviour you want to predict in the new data you obtain. This is the type of algorithms that autonomous cars use to recognize pedestrians and objects, or organizations exploit to estimate customers lifetime value and their churn rates.

**34 Great Articles and Tutorials on Clustering**

This resource is part of a series on specific topics related to data science: regression, clustering, neural networks, deep learning, decision trees, ensembles, correlation, Python, R, Tensorflow, SVM, data reduction, feature selection, experimental design, cross-validation, model fitting, and many more.

**How do Graph Neural Networks Work?**

Graph neural networks (GNNs) have emerged as an interesting application to a variety of problems. The most pronounced is in the field of chemistry and molecular biology. An example of the impact in this field is DeepChem, a pythonic library that makes use of GNNs. But how exactly do they work?





### Like this:

Like Loading...


*Related*

