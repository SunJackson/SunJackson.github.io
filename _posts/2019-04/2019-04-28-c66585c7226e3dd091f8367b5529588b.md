---
layout:     post
catalog: true
title:      If you did not already know
subtitle:      转载自：https://analytixon.com/2019/04/28/if-you-did-not-already-know-714/
date:      2019-04-28
author:      Michael Laux
tags:
    - conditionally
    - models
    - modeled
    - computational
    - computers
---

**Barnard’s Test** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
In statistics, Barnard’s test is an exact test used in the analysis of contingency tables. The test was first published by George Alfred Barnard (1945, 1947) who claimed this test is a more powerful alternative than Fisher’s exact test for 2×2 contingency tables. A previous barrier to the widespread use of Barnard’s test was likely the computational difficulty of calculating the p-value; nowadays, computers can implement Barnard’s test. … 

**Conditional Information Gain Network** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
Deep neural network models owe their representational power to the high number of learnable parameters. It is often infeasible to run these largely parametrized deep models in limited resource environments, like mobile phones. Network models employing conditional computing are able to reduce computational requirements while achieving high representational power, with their ability to model hierarchies. We propose Conditional Information Gain Networks, which allow the feed forward deep neural networks to execute conditionally, skipping parts of the model based on the sample and the decision mechanisms inserted in the architecture. These decision mechanisms are trained using cost functions based on differentiable Information Gain, inspired by the training procedures of decision trees. These information gain based decision mechanisms are differentiable and can be trained end-to-end using a unified framework with a general cost function, covering both classification and decision losses. We test the effectiveness of the proposed method on MNIST and recently introduced Fashion MNIST datasets and show that our information gain based conditional execution approach can achieve better or comparable classification results using significantly fewer parameters, compared to standard convolutional neural network baselines. … 

**Whale Optimization Algorithm (WOA)** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
Whale Optimization Algorithm (WOA) is a recently proposed (2016) optimization algorithm mimicking the hunting mechanism of humpback whales in nature. It is worth mentioning here that bubble-net feeding is a unique behavior that can only be observed in humpback whales. In WOA the spiral bubble-net feeding maneuver is mathematically modeled in order to perform optimization.![](https://aboutdataanalytics.files.wordpress.com/2015/04/link.png?w=529)
 A Systematic and Meta-analysis Survey of Whale Optimization Algorithm … 





### Like this:

Like Loading...


*Related*

