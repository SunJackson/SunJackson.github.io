---
layout:     post
catalog: true
title:      Import AI 141： AIs play doom at thousands of frames per second; NeurIPS wants reproducible research; and Google creates&scraps AI ethics council.
subtitle:      转载自：https://jack-clark.net/2019/04/08/import-ai-141-ais-play-doom-at-thousands-of-frames-per-second-neurips-wants-reproducible-research-and-google-createsscraps-ai-ethics-council/
date:      2019-04-08
author:      Jack Clark
tags:
    - researchers trained
    - apple
    - chatty
    - chattiness
    - training
---

**75 seconds: How long it takes to train a network against ImageNet:***…Fujitsu Research claims state-of-the-art ImageNet training scheme…*Researchers with Fujitsu Laboratories in Japan have further reduced the time it takes to train large-scale, supervised learning AI models; their approach lets them train a residual network to around 75% accuracy on the ImageNet dataset after 74.7 seconds of training time. This is a big leap from where we were in 2017 (an hour), and is impressive relative to late-2018 performance (around 4 minutes: see issue #121).

**How they did it: **The researchers trained their system across **2,048 Tesla V100 GPUs** via the Amazon-developed MXNet deep learning framework. They used a large mini-batch size of 81,920, and also implemented layer-wise adaptive scaling (LARS) and a ‘warming up’ period to increase learning efficiency.

**Why it matters:** Training large models on distributed infrastructure is a key component of modern AI research, and the reduction in time we’ve seen on ImageNet training is striking – I think this is emblematic of the industrialization of AI, as people seek to create systematic approaches to efficiently training models across large amounts of computers. This trend ultimately leads to a speedup in the rate of research reliant on large-scale experimentation, and can unlock new paths of research.**   Read more:** Yet Another Accelerated SGD: ResNet-50 Training on ImageNet in 74.7 seconds (Arxiv).

#####################################################

**Ian ‘GANfather’ Goodfellow heads to Apple:***…Machine learning researcher swaps Google for Apple…*Ian Goodfellow, a machine learning researcher who developed an AI approach called generative adversarial networks (GANs), is leaving Google for Apple.

**Apple’s deep learning training period:** For the past few years, Apple has been trying to fill its ranks with more prominent people working on its AI projects. In 2016 it hired Russ Salakhutdinov, a researcher from CMU who had formerly studied under Geoffrey Hinton in Toronto, to direct its AI research efforts. Russ helped build up more of a traditional academic ML group at Apple, and Apple lifted its customary veil of secrecy a bit with the Apple Machine Learning Journal, a blog that details some of the research done by the secretive organization. Most recently, Apple hired John Giannandrea from Google to help lead its AI strategy. I hope Ian can push Apple towards being more discursive and open about aspects of its research, and I’m curious to see what happens next.

**Why this matters: Two of Ian’s research interests – GANs and adversarial examples (**manipulations made to data structures that cause neural networks to misclassify things) – have significant roles in AI policy, and I’m wondering if Apple might explore this more through proactive work (making things safer and better) along with policy advocacy.**  Read more:** One of Google’s top A.I. people has joined Apple (CNBC).

#####################################################

**World’s most significant AI conference wants more reproducible research:***…NeurIPS 2019 policy will have knock-on effect across wider AI ecosystem…*The organizing committee for the Neural Information Processing Systems Conference (NeurIPS, formerly NIPS), has made two changes to submissions for the AI conference: A “mandatory Reproducibility Checklist”, along with “a formal statement of expectations regarding the submission of code through a new Code Submission Policy”.

**Reproducibility checklist: **Those submitting papers to NeurIPS will fill out a reproducibility checklist, originally developed by researcher Joelle Pineau. “The answers will be available to reviewers and area chairs, who may use this information to help them assess the clarity and potential impact of submissions”.

**Code submissions:** People will be expected (though not *forced* – yet) to submit code along with their papers, if they involve experiments that relate to a new algorithm or a modification of an existing one. “It has become clear that this topic requires we move at a careful pace, as we learn where our “comfort zone” is as a community,” the organizers write.

**   Non-executable: **Code submitted to NeurIPS won’t need to be executable – this helps researchers whose work depends either on proprietary code (for instance, it plugs into a large-scale, proprietary training system, like those used by large technology companies), or who depend on proprietary datasets.

**Why this matters:** Reproducibility touches on many of the anxieties of current AI research relating to the difference in resources between academic researchers and those at corporate labs. Having more initiatives around reproducibility may help to close this divide, especially done in a (seemingly quite thoughtful) way that lets corporate researchers do things like publishing code without needing to worry about leaking information about internal proprietary infrastructure.**   Read more: **Call for Papers (NeurIPS Medium page).**   Check out the ****code submission policy here (**Google Doc).

#####################################################

**Making RL research cheaper by using more efficient environments:***…Want to train agents on a budget? Comfortable with your agents learning within a retro hell? Then ViZDoom might be the right choice for you…*A team of researchers from INRIA in France have developed a set of tasks that demand “complex reasoning and exploration”, which can be run within the ViZDoom simulator at around 10,000 environment interactions per second; the goal of the project is to make it easier for people to do reinforcement learning research without spending massive amounts of compute.

**Extending ViZDoom: **ViZDoom is an implementation of the ancient first-person shooter game, Doom. However, one drawback is that it ships with only eight different scenarios to train agents in. To extend this, the researchers have developed four new scenarios designed to “test navigation, reasoning, and memorization”, variants of which can be procedurally generated.

**Scenarios for creating thinking machines: **These four scenarios include a navigation task called *Labyrinth*; *Find and return, *where the agents needs to find an object in the maze then return to its starting point; *Ordered k-item*, where the agent needs to collect a few different items in a predefined order; and *Two color correlation*, where an agent needs to explore a maze to find a column at its center, then pick up objects which are the same color as the column.

**Spatial reasoning is… reassuringly difficult: **“The experiments on our proposed suite of benchmarks indicate that current state-of-the-art models and algorithms still struggle to learn complex tasks, involving several different objects in different places, and whose appearance and relationships to the task itself need to be learned from reward”.**  Read more: **Deep Reinforcement Learning on a Budget: 3D Control and Reasoning Without a Supercomputer (Arxiv)**.**

######################################################**Facebook wants to make smart robots, so it built them a habitat:*******…New open source research platform can conduct large-scale experiments, running 3D world simulators at thousands of frames per second…*****A team from Facebook, Georgia Institute of Technology, Simon Fraser University, Intel Labs, and Berkeley, have released Habitat, “a platform for embodied AI research”. The open source software is designed to help train agents for navigation and interaction tasks in a variety of domains, ranging from 3D environment simulators like Stanford’s ‘Gibson’ system or Matterport 3D to fully synthetic datasets like SUNCG.   “Our goal is to unify existing community efforts and to accelerate research into embodied AI,” the researchers write. “This is a longterm effort that will succeed only by full engagement of the broader research community. To this end, we have opensourced the entire Habitat platform stack.”   Major engineering: **The Habitat simulator can support “thousands of frames per second per simulator thread and is orders of magnitude faster than previous simulators for realistic indoor environments (which typically operate at tens or hundreds of frames per second)”. Speed matters here, because the faster you can run your simulator, the more experience you can collect at each computational timestep. Faster simulators = its cheaper and quicker to train agents. **   Using habitat to test how well an agent can navigate: **The researchers ran very large-scale tests on Habitat with a simple task: “an agent is initialized at a random starting position and orientation in an environment and asked to navigate to target coordinates that are provided relative to the agent’s position; no ground-truth map is available and the agent must use only its sensory input to navigate”. This is akin to waking up in a mansion with no memory and needing to get to a specific room…except in this world you do this for thousands of subjective years, since Facebook trains its agents for a little over **70 million timesteps** in the simulator.**   PPO outperforms hand-coded SLAM approach**: They find in tests that they can develop an AI agent based on a proximal policy optimization (PPO) policy trained via reinforcement learning which outperforms hand-coded ‘SLAM’ systems which implement “a classical robotics navigation pipeline including components for localization, mapping, and planning”.**Why this matters: **Environments frequently contribute to the advancement of AI research, and the need for high-performance environments has been accentuated by the recent trend for using significant computational resources to train large, simple models. Habitat seems like a solid platform for large-scale research, and Facebook plans to add new features to it, like physics-based interactions within the simulator and supporting multiple agents concurrently. It’ll be interesting to see how this develops, and what things they learn along the way. **   Read more:** Habitat: A Platform for Embodied AI Research (Arxiv).######################################################

**People want their AI assistants to be chatty, says Apple:***…User research suggests people prefer a chattier, more discursive virtual assistant…*Apple researchers want to build personal assistants that people actually *want *to use, so as part of that they’ve conducted research into how users respond to chatty or terse/non-chatty personal assistants, and how they respond to systems that try to ‘mirror’ the human they are interacting with.

***Wizard-of-Oz****: *Apple composes this as a Wizard-of-Oz study, which means there is basically no AI involved: Apple instead had 20 people (three men and seventeen women – the lack of gender balance is not explained in the paper) take turns sitting in a room, where they would utter verbal commands for a simulated virtual assistant, which was in fact an Apple employee sitting in another room. The purpose of this type of study is to simulate the interactions that may occur between human and AI systems to help researchers figure out what they should build next, and how users might react to what they build.

**Study methodology: **They tested people against three systems: a chatty system, a non-chatty system, and one which tried to mirror the chattiness of the user.

   When testing the chatty vs non-chatty systems, Apple asked some human users to make a variety of verbal requests relating to alarms, calendars, navigation, weather, factual information, and searching the web. For example, a user make say “next meeting time”, and the simulated agent could respond with (chatty) “It looks like you have your next meeting after lunch at 2 P.M.”, or (non-chatty) “2 P.M.” Participants then classified the qualities of the responses into categories, like: *good, off topic, wrong information, too impolite *or *too casual*.

**Talk chatty to me: **The study finds that people tend to prefer chatty assistants to non-chatty ones, and have a significant preference for agents whose chattiness mirrors the chattiness of the human user. “”Mirroring user chattiness increases feelings of likability and trustworthiness in digital assistants. Given the positive impact of mirroring chattiness on interaction, we proceeded to build classifiers to determine whether features extracted from user speech could be used to estimate their level of chattiness, and thus the appropriate chattiness level of a response”, they explain.

**Why this matters: **Today’s virtual assistants contain lots and lots of hand-written material and/or specific reasoning modules (see: Siri, Cortana, Alexa, the Google Assistant). Many companies are trying to move to systems where a larger and larger chunk of the capabilities come from behaviors that are learned from interaction with users. To be able to build such systems, we need users that want to talk to their systems, which will generate the sorts of lengthy conversational interactions needed to train more advanced learning-based approaches.
