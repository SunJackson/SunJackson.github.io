---
layout:     post
catalog: true
title:      visualising bias and unbiasedness
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/fav68S9ZSWI/
date:      2019-04-28
author:      xi'an
tags:
    - x validated led
    - estimated
    - estimator
    - estimations
    - estimate completely
---





![](https://xianblog.files.wordpress.com/2019/03/temp.png?w=450#038;h=233)
![](https://xianblog.files.wordpress.com/2019/03/temp.png?w=450&h=233&fit=538%2C233)


**A** question on X validated led me to wonder at the point made by Christopher Bishop in his Pattern Recognition and Machine Learning book about the MLE of the Normal variance being biased. As it is illustrated by the above graph that opposes the true and green distribution of the data (made of two points) against the estimated and red distribution. While it is true that the MLE under-estimates the variance on average, the pictures are cartoonist caricatures in their deviance permanence across three replicas. When looking at 10⁵ replicas, rather than three, and at samples of size 10, rather than 2, the distinction between using the MLE (left) and the unbiased estimator of σ² (right).

![](https://i1.wp.com/i.stack.imgur.com/OA7m6.jpg?w=450&ssl=1)
![](https://i1.wp.com/i.stack.imgur.com/OA7m6.jpg?w=450&ssl=1)
When looking more specifically at the case n=2, the humongous variability of the density estimate completely dwarfs the bias issue:

![](https://xianblog.files.wordpress.com/2019/03/temp-1.jpg?w=456)
![](https://xianblog.files.wordpress.com/2019/03/temp-1.jpg?w=456)
Even when averaging over all 10⁵ replications, the difference is hard to spot (and both estimations are more dispersed than the truth!):

![](https://xianblog.files.wordpress.com/2019/03/temp-3.jpg?w=456)
![](https://xianblog.files.wordpress.com/2019/03/temp-3.jpg?w=456)



*Related*








---
