---
layout:     post
catalog: true
title:      Two interesting facts about high-dimensional random projections
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/qKMJUxAbuQI/
date:      2019-04-16
author:      kjytay
tags:
    - simulations p
    - functions
    - angles
    - random vectors
    - cook
---





John Cook recently wrote an interesting blog post on random vectors and random projections. In the post, he states two surprising facts of high-dimensional geometry and gives some intuition for the second fact. In this post, I will provide R code to demonstrate both of them.

**Fact 1: Two randomly chosen vectors in a high-dimensional space are very likely to be nearly orthogonal.**

Cook does not discuss this fact as it is “well known”. Let me demonstrate it empirically. Below, the first function generates a ![](https://s0.wp.com/latex.php?latex=p&bg=ffffff&%23038;fg=333333&%23038;s=0)
-dimensional unit vector uniformly at random. The second function takes in two ![](https://s0.wp.com/latex.php?latex=p&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=p&bg=ffffff&%23038;fg=333333&%23038;s=0)
-dimensional vectors, `x1` and `x2`, and computes the angle between them. (For details, see Cook’s blog post.)

Next, we use the `replicate` function to generate 100,000 pairs of 10,000-dimensional vectors and plot a histogram of the angles they make:

![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig1-1.png?w=456)
![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig1-1.png?w=456)


Note the scale of the x-axis: the angles are very closely bunched up around 90 degrees, as claimed.

This phenomenon only happens for “high” dimensions. If we change the value of `p` above to 2, we obtain a very different histogram:

![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig2-1.png?w=456)
![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig2-1.png?w=456)


***How “high” does the dimension have to be before we see this phenomenon kick in?*** Well, it depends on how tightly bunched up we want the angles to be around 90 degrees. The histogram below is the same simulation but for `p = 20` (notice the wider x-axis scale):

![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig3-1.png?w=456)
![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig3-1.png?w=456)


It seems like the bell-shaped curve already starts to appear with `p = 3`!

![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig4-1.png?w=456)
![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig4-1.png?w=456)


**Fact 2: Generate 10,000 random vectors in 20,000 dimensional space. Now, generate another random vector in that space. Then the angle between this vector and its projection on the span of the first 10,000 vectors is very likely to be very near 45 degrees.**

Cook presents a very cool intuitive explanation of this fact which I highly recommend. Here, I present simulation evidence of the fact.

The difficulty in this simulation is computing the projection of a vector onto the span of many vectors. It can be shown that the projection of a vector ![](https://s0.wp.com/latex.php?latex=v&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=v&bg=ffffff&%23038;fg=333333&%23038;s=0)
 onto the column span of a (full-rank) matrix ![](https://s0.wp.com/latex.php?latex=A&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=A&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is given by ![](https://s0.wp.com/latex.php?latex=%5Ctext%7Bproj%7D_A+%28v%29+%3D+A%28A%5ET+A%29%5E%7B-1%7DA%5ET+v&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=%5Ctext%7Bproj%7D_A+%28v%29+%3D+A%28A%5ET+A%29%5E%7B-1%7DA%5ET+v&bg=ffffff&%23038;fg=333333&%23038;s=0)
 (see this post and this post for details). For our fact, ![](https://s0.wp.com/latex.php?latex=A&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=A&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is a ![](https://s0.wp.com/latex.php?latex=20%2C000+%5Ctimes+10%2C000&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=20%2C000+%5Ctimes+10%2C000&bg=ffffff&%23038;fg=333333&%23038;s=0)
 matrix, so computing ![](https://s0.wp.com/latex.php?latex=%28A%5ET+A%29%5E%7B-1%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=%28A%5ET+A%29%5E%7B-1%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is going to take prohibitively long.

I don’t know another way to compute the projection of a vector onto the span of other vectors. (Does anyone know of better ways?) Fortunately, based on my simulations in Fact 1, this phenomenon will probably kick in for much smaller dimensions too!

First, let’s write up two functions: one that takes a vector `v` and matrix `A` and returns the projection of `v` onto the column span of `A`:

and a function that does one run of the simulation. Here, `p` is the dimensionality of each of the vectors, and I assume that we are looking at the span of `p/2` vectors:

The code below runs 10,000 simulations for p = 20`, taking about 2 seconds on my laptop:`

We can already see the bunching around 45 degrees:

![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig5.png?w=456)
![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig5.png?w=456)


The simulation for `p = 200` takes just under 2 minutes on my laptop, and we see tighter bunching around 45 degrees (note the x-axis scale).

![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig6.png?w=456)
![](https://statisticaloddsandends.files.wordpress.com/2019/04/fig6.png?w=456)



*Related*








---
