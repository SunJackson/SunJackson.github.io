---
layout:     post
catalog: true
title:      Separating the Signal from the Noise： Robust Statistics for Pedestrians
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/EO78Q8a_E9o/
date:      2019-04-10
author:      Learning Machines
tags:
    - data points
    - ransac
    - fitting model
    - iteratively
    - iterations
---










![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/auto-1020150_1280-e1551126392569-300x171.jpg?resize=300%2C171)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/auto-1020150_1280-e1551126392569-300x171.jpg?resize=300%2C171)
One of the problems of navigating an autonomous car through a city is to extract *robust signals* in the face of all the *noise* that is present in the different sensors. Just taking something like an arithmetic mean of all the data points could possibly end in a catastrophe: if a part of a wall looks similar to the street and the algorithm calculates an average trajectory of the two this would end in leaving the road and possibly crashing into pedestrians. So we need some robust algorithm to get rid of the noise. The area of statistics that especially deals with such problems is called *robust statistics* and the methods used therein *robust estimation*.

Now, one of the problems is that one doesnâ€™t know what is signal and what is noise. The big idea behind *RANSAC* (short for *RAndom SAmple Consensus*) is to get rid of *outliers* by basically taking as many points as possible which form a well-defined region and leaving out the others. It does that iteratively, similar to the famous *k-means algorithm* (the topic of one of the upcoming posts, so stay tunedâ€¦).

To really understand how RANSAC works we will now build it with R. We will take a simple linear regression as an example and make it robust against outliers.

For educational purposes we will do this step by step:

1. Understanding the general outline of the algorithm.

1. Looking at the steps in more detail.

1. Expressing the steps in pseudocode.

1. Translating this into R!


Conveniently enough Wikipedia gives a good outline of the algorithm and even provides us with the very clear pseudocode which will serve as the basis for our own R implementation (the given Matlab code is not very good in my opinion and has nothing to do with the pseudocode):

> 
The RANSAC algorithm is essentially composed of two steps that are iteratively repeated:

- In the first step, a sample subset containing minimal data items is randomly selected from the input dataset. A fitting model and the corresponding model parameters are computed using only the elements of this sample subset. The cardinality of the sample subset is the smallest sufficient to determine the model parameters.
- In the second step, the algorithm checks which elements of the entire dataset are consistent with the model instantiated by the estimated model parameters obtained from the first step. A data element will be considered as an outlier if it does not fit the fitting model instantiated by the set of estimated model parameters within some error threshold that defines the maximum deviation attributable to the effect of noise. The set of inliers obtained for the fitting model is called consensus set. The RANSAC algorithm will iteratively repeat the above two steps until the obtained consensus set in certain iteration has enough inliers.



In more detail:

> 
RANSAC achieves its goal by repeating the following steps:

- Select a random subset of the original data. Call this subset the hypothetical inliers.
- A model is fitted to the set of hypothetical inliers.
- All other data are then tested against the fitted model. Those points that fit the estimated model well, according to some model-specific loss function, are considered as part of the consensus set.
- The estimated model is reasonably good if sufficiently many points have been classified as part of the consensus set.
- Afterwards, the model may be improved by reestimating it using all members of the consensus set.

This procedure is repeated a fixed number of times, each time producing either a model which is rejected because too few points are part of the consensus set, or a refined model together with a corresponding consensus set size. In the latter case, we keep the refined model if its consensus set is larger than the previously saved model.


Now, this can be expressed in pseudocode:

It is quite easy to convert this into valid R code (as a learner of R you should try it yourself before looking at my solution!):

We now test this with some sample data:

![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/ransac-840x600.png?w=450)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/ransac-840x600.png?w=450)


The black line is a plain vanilla linear regression, the blue line is the RANSAC-enhanced version. As you can see: no more crashing into innocent pedestrians. ![](https://i2.wp.com/s.w.org/images/core/emoji/11.2.0/72x72/1f642.png?w=456&ssl=1)
![](https://i2.wp.com/s.w.org/images/core/emoji/11.2.0/72x72/1f642.png?w=456&ssl=1)



*Related*








---
