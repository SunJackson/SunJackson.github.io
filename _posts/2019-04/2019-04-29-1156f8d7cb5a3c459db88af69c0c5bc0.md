---
layout:     post
catalog: true
title:      If you did not already know
subtitle:      转载自：https://analytixon.com/2019/04/30/if-you-did-not-already-know-716/
date:      2019-04-29
author:      Michael Laux
tags:
    - models
    - distributed
    - distributions
    - measures
    - measurements
---

**Saturating Adaptive Field Estimator (SAFE)** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
We study resilient distributed field estimation under measurement attacks. A network of agents or devices measures a large, spatially distributed physical field parameter. An adversary arbitrarily manipulates the measurements of some of the agents. Each agent’s goal is to process its measurements and information received from its neighbors to estimate only a few specific components of the field. We present $\mathbf{SAFE}$, the Saturating Adaptive Field Estimator, a consensus+innovations distributed field estimator that is resilient to measurement attacks. Under sufficient conditions on the compromised measurement streams, the physical coupling between the field and the agents’ measurements, and the connectivity of the cyber communication network, $\mathbf{SAFE}$ guarantees that each agent’s estimate converges almost surely to the true value of the components of the parameter in which the agent is interested. Finally, we illustrate the performance of $\mathbf{SAFE}$ through numerical examples. … 

**Variational Predictive Natural Gradient** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
Variational inference transforms posterior inference into parametric optimization thereby enabling the use of latent variable models where otherwise impractical. However, variational inference can be finicky when different variational parameters control variables that are strongly correlated under the model. Traditional natural gradients based on the variational approximation fail to correct for correlations when the approximation is not the true posterior. To address this, we construct a new natural gradient called the variational predictive natural gradient. It is constructed as an average of the Fisher information of the reparameterized predictive model distribution. Unlike traditional natural gradients for variational inference, this natural gradient accounts for the relationship between model parameters and variational parameters. We also show the variational predictive natural gradient relates to the negative Hessian of the expected log-likelihood. A simple example shows the insight. We demonstrate the empirical value of our method on a classification task, a deep generative model of images, and probabilistic matrix factorization for recommendation. … 

**Hidden Factor Graph Models (HFM)** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
Hidden Factor graph models generalise Hidden Markov Models to tree structured data. The distinctive feature of ‘treeHFM’ is that it learns a transition matrix for first order (sequential) and for second order (splitting) events. It can be applied to all discrete and continuous data that is structured as a binary tree. In the case of continuous observations, ‘treeHFM’ has Gaussian distributions as emissions. … 





### Like this:

Like Loading...


*Related*

