---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/04/25/distilled-news-1047/
date:      2019-04-25
author:      Michael Laux
tags:
    - data
    - learning
    - models
    - augmentation
    - augmented
---

**Causality – The Next Most Important Thing in AI/ML**

Just when I thought we’d figured it all out, something comes along to make me realize I was wrong. And that something in AI/ML is as simple as realizing that everything we’ve done so far is just curve-fitting. Whether it’s a scoring model or a CNN to recognize cats, it’s all about association; reducing the error between the distribution of two data sets. What we should have had our eye on is CAUSATION. How many times have you repeated ‘correlation is not causation’. Well it seems we didn’t stop to ask how AI/ML can actually determine causality. And now it turns out it can. But to achieve an understanding of causality requires us to cast loose of many of the common tools and techniques we’ve been trained to apply and to understand the data from a wholly new perspective. Fortunately the constant advance of research and ever increasing compute capability now makes it possible for us to use new relatively friendly tools to measure causality. However, make no mistake, you’ll need to master the concepts of causal data analysis or you will most likely misunderstand what these tools can do.

**SpecAugment: A New Data Augmentation Method for Automatic Speech Recognition**

Automatic Speech Recognition (ASR), the process of taking an audio input and transcribing it to text, has benefited greatly from the ongoing development of deep neural networks. As a result, ASR has become ubiquitous in many modern devices and products, such as Google Assistant, Google Home and YouTube. Nevertheless, there remain many important challenges in developing deep learning-based ASR systems. One such challenge is that ASR models, which have many parameters, tend to overfit the training data and have a hard time generalizing to unseen data when the training set is not extensive enough. In the absence of an adequate volume of training data, it is possible to increase the effective size of existing data through the process of data augmentation, which has contributed to significantly improving the performance of deep networks in the domain of image classification. In the case of speech recognition, augmentation traditionally involves deforming the audio waveform used for training in some fashion (e.g., by speeding it up or slowing it down), or adding background noise. This has the effect of making the dataset effectively larger, as multiple augmented versions of a single input is fed into the network over the course of training, and also helps the network become robust by forcing it to learn relevant features. However, existing conventional methods of augmenting audio input introduces additional computational cost and sometimes requires additional data. In our recent paper, ‘SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition’, we take a new approach to augmenting audio data, treating it as a visual problem rather than an audio one. Instead of augmenting the input audio waveform as is traditionally done, SpecAugment applies an augmentation policy directly to the audio spectrogram (i.e., an image representation of the waveform). This method is simple, computationally cheap to apply, and does not require additional data. It is also surprisingly effective in improving the performance of ASR networks, demonstrating state-of-the-art performance on the ASR tasks LibriSpeech 960h and Switchboard 300h.

**Reproducible Environments**

Great data science work should be reproducible. The ability to repeat experiments is part of the foundation for all science, and reproducible work is also critical for business applications. Team collaboration, project validation, and sustainable products presuppose the ability to reproduce work over time. In my opinion, mastering just a handful of important tools will make reproducible work in R much easier for data scientists. R users should be familiar with version control, RStudio projects, and literate programming through R Markdown. Once these tools are mastered, the major remaining challenge is creating a reproducible environment.

**Ensemble methods: bagging, boosting and stacking**

Unity is strength’. This old saying expresses pretty well the underlying idea that rules the very powerful ‘ensemble methods’ in machine learning. Roughly, ensemble learning methods, that often trust the top rankings of many machine learning competitions (including Kaggle’s competitions), are based on the hypothesis that combining multiple models together can often produce a much more powerful model. The purpose of this post is to introduce various notions of ensemble learning. We will give the reader some necessary keys to well understand and use related methods and be able to design adapted solutions when needed. We will discuss some well known notions such as boostrapping, bagging, random forest, boosting, stacking and many others that are the basis of ensemble learning. In order to make the link between all these methods as clear as possible, we will try to present them in a much broader and logical framework that, we hope, will be easier to understand and remember.

**No, Machine Learning Does Not Make Understanding Obsolete**

Handing off decision-making to predictive AI would be catastrophic.

**AI Fairness – Explanation of Disparate Impact Remover**

AI Fairness is an important topic for machine learning practitioners. We must be aware that there can be both positive and negative implications for users when they interact with our models. Although our metric of success tends to be a performance metric (e.g. accuracy), those that interact with our models may consider other values as well. Tools using AI are being built to: approve or deny loans; decide if a person should be considered for an interview, and; determine if someone’s a good candidate for treatment. These outcomes all have high impact repercussions for the individual. This is why fairness is such an important value to consider. In order to ensure fairness, we must analyze and address any bias that may be present in our training data. Machine learning discovers and generalizes patterns in the data and could, therefore, replicate bias. When implementing these models at scale, it can result in a large number of biased decisions, harming a large number of users.

**Machine Learning vs Traditional Programming**

While some call AI and ML overhyped themes that are nothing more than if statements, or just programming stuff, I offer you to come face to face with all pieces of evidence to check this out. In this post, I will contrast these terms and also showcase the difference between the specialists who are involved in these two spheres: who are they? Software engineer, software developer, machine learning expert, data scientist…some people even use a programmer or coder, and some even go as far as a ninja, guru, or rock star! But, are they really the same? And if so, is there a line between Machine Learning and Traditional Programming?

**With MorphNet, Google Helps You Build Faster and Smaller Neural Networks**

Designing deep neural networks these days is more art than science. In the deep learning space, any given problem can be addressed with a fairly large number of neural network architectures. In that sense, designing a deep neural network from the ground up for a given problem can result incredibly expensive in terms of time and computational resources. Additionally, given the lack of guidance in the space, we often end up producing neural network architectures that are suboptimal for the task at hand. Recently, artificial intelligence(AI) researchers from Google published a paper proposing a method called MorphNet to optimize the design of deep neural networks.

**Introduction to Natural Language Processing (NLP) and Bias in AI**

Natural language processing (NLP) is a field that is being revolutionized by deep learning. From voice assistants to Gmail’s Smart Compose, deep learning has made it possible for machines to understand us in a more intuitive way. Of course, working with natural data is very different than working with tabular data, because we now need to represent words and sentences in a way that machines can understand. In this post, I will introduce key concepts of NLP such as word embeddings, and we will see how an algorithm can become biased, and how we can remove that bias. Let’s get started!

**TensorFlow Control Flow: tf.cond()**

Tensorflow is one of the most popular deep learning frameworks and has played a key role in advancing deep learning. I am using Tensorflow for more than two years, but I have seen lots of bizarre and unpredictable behavior during using control flow. Recently (19 April 2019), I watched a video of TensorFlow team’s own internal training sessions, which was very helpful and make it more clear how control flow ops work. I definitely recommend watching this video. The video covers tf.cond() and tf.while_loop in details. So, I decided to write this post to elaborate more on how tf.cond() works, and provide some examples for illustration. Hopefully, I will cover tf.while_loop in the subsequent post.

**Fundamentals of Augmented Reality (AR)**

Augmented reality is our reality augmented with digital data. The digital data can be in the form of text, pictures, videos, 3d assets, or a combination of all of the above. The AR system will need to understand reality and reconstruct it to create its digital twin. It also needs to enable the user to be able to interact with both the digital twin and the digital data.

**Transforming Categorical Data for Usability in Machine Learning Predictions**

**Data Ownership – Not Waiting for the Lawyers**

I spotted a fascinating article in today’s US print edition of the Financial Times. It was titled, ‘Patients take control of their medical data’. Here is the quote that almost took my breath away: ‘It [a new data platform collecting medical data] now has 1,200 users on its platform and has entered into research partnerships with pharma and health companies including Johnson & Johnson and Medtronic, as well as the Food and Drug Administration, the US medicines regulator.’ And the next paragraph: ‘For Richie Etwaru, the solution is to offer people legal title over their data.’ That last part is awesome. While privacy companies and regulators in the US waffle on about how to cope with GDPR and other privacy issues, private firms are quietly building up treasure troves of data that have strings attached. Those strings provide an ‘out’ clause for the consumer (that’s you and me) that creates the raw data. On their (our) behalf the platform owner licenses the use of consumer data for a fee, partly reimbursed to the consumer.

**Approach pre-trained deep learning models with caution**

Pre-trained models are easy to use, but are you glossing over details that could impact your model performance?

**Machine learning for anomaly detection and condition monitoring**

My previous article on anomaly detection and condition monitoring has received a lot of feedback. Many of the questions I receive, concern the technical aspects and how to set up the models etc. Due to this, I decided to write a follow-up article covering all the necessary steps in detail, from pre-processing data to building models and visualizing results. For an introduction to anomaly detection and condition monitoring, I recommend first reading my original article on the topic. This provides the neccesary background information on how machine learning and data driven analytics can be utilized to extract valuable information from sensor data. The current article focuses mostly on the technical aspects, and includes all the code needed to set up anomaly detection models based on multivariate statistical analysis and autoencoder neural networks.

**Deploy your Data Science Model**

Part 1: Get it off the notebook with Pickle or Joblib





### Like this:

Like Loading...


*Related*

