---
layout:     post
title:      Locally linear embedding and sparse eigensolvers
subtitle:   转载自：http://fa.bianp.net/blog/2011/locally-linear-embedding-and-sparse-eigensolvers/
date:       2011-04-21
author:     Fabian Pedregosa
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - work reasonably
    - linear embedding algorithm
    - dense routines
    - swiss roll existing
    - solvers
---

I've been working for some time on implementing a locally linear
embedding algorithm for the upcoming manifold module in scikit-learn.
While several implementations of this algorithm exist in Python, as far
as I know none of them is able to use a sparse eigensolver in the last
step of the algorithm, falling back to dense routines causing a huge
overhead in this step. To overcome this, my first implementation used
scipy.sparse.linalg.eigsh, which is a sparse eigensolver shipped by
scipy and based on ARPACK. However, this approach converged extremely
slowly, with timings that exceeded largely those of dense solvers.
Recently I found a way that seems to work reasonably well, with timings
that win by a factor of 5 on the swiss roll existing routines. This code
is able to solve the problem making use of a preconditioner computed by
[PyAMG](http://code.google.com/p/pyamg).

Full code for this algorithm applied to the
swiss roll can be found here [here](https://gist.github.com/934363), and I hope it will soon be part of
[scikit-learn](http://scikit-learn.sourceforge.net/).

![](http://fseoane.net/blog/static/uploads/2011/04/lle1-690x1024.png)

