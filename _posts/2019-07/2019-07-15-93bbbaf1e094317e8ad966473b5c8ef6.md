---
layout:     post
catalog: true
title:      Let’s get it right
subtitle:      转载自：https://analytixon.com/2019/07/15/lets-get-it-right-49/
date:      2019-07-15
author:      Michael Laux
tags:
    - data
    - article
    - ethics
    - ethical
    - financially
---

***Article***: ***Regulation of Artificial Intelligence in Selected Jurisdictions***

This report examines the emerging regulatory and policy landscape surrounding artificial intelligence (AI) in jurisdictions around the world and in the European Union (EU). In addition, a survey of international organizations describes the approach that United Nations (UN) agencies and regional organizations have taken towards AI. As the regulation of AI is still in its infancy, guidelines, ethics codes, and actions by and statements from governments and their agencies on AI are also addressed. While the country surveys look at various legal issues, including data protection and privacy, transparency, human oversight, surveillance, public administration and services, autonomous vehicles, and lethal autonomous weapons systems, the most advanced regulations were found in the area of autonomous vehicles, in particular for the testing of such vehicles.

***Paper***: ***Making AI Forget You: Data Deletion in Machine Learning***

Intense recent discussions have focused on how to provide individuals with control over when their data can and cannot be used — the EU’s Right To Be Forgotten regulation is an example of this effort. In this paper we initiate a framework studying what to do when it is no longer permissible to deploy models derivative from specific user data. In particular, we formulate the problem of how to efficiently delete individual data points from trained machine learning models. For many standard ML models, the only way to completely remove an individual’s data is to retrain the whole model from scratch on the remaining data, which is often not computationally practical. We investigate algorithmic principles that enable efficient data deletion in ML. For the specific setting of k-means clustering, we propose two provably deletion efficient algorithms which achieve an average of over 100X improvement in deletion efficiency across 6 datasets, while producing clusters of comparable statistical quality to a canonical k-means++ baseline.

***Article***: ***Making Egalitarian AI Algorithms***

Here is a small riddle – A father and son are in a horrible car crash that kills the dad. The son is rushed to the hospital for an emergency surgery; just as he’s about to go under the knife, the surgeon says, ‘I can’t operate – that boy is my son!’. What do you think is going on? If you guessed that the surgeon is the boy’s gay, second father, you get a point for enlightenment, at least outside the Bible Belt. But did you also guess the surgeon could be the boy’s mother? If not, you’re part of a surprising majority. Gender biases are deeply embedded in our psyche and are reflected in our thoughts and conversations. Language is one of the most powerful means through which sexism and gender discrimination are perpetrated. Lexical choices and everyday communication constantly reflects these long-standing biases. Our writings, our movies, tweets and all the content we generate reflect these biases. Incidentally with the recent advancements in NLP, machine learning and AI these disturbing biases in our content are being unearthed by our learning algorithms.

***Article***: ***Facing the Future***

Can a New Zealand-based lab take virtual assistants from the realm of marketing gimmicks and endow them with real intelligence?

***Article***: ***A New Study Suggests Employers Track Your Every Move to ‘Improve Productivity’***

How would you feel if your boss told you that, if you wanted that raise, you’d need to wear a tracking device 24/7? It’s not an implausible future. Workplace wellness programs, which sometimes use fitness trackers and other devices to assess employee health – data that in many cases impact insurance rates – blossomed under the Obama administration, and now cover upwards of 50 million American workers. A new study, funded in part by the Office of the Director of National Intelligence with lead researchers from Dartmouth College, suggests a potential next step into this brave new world: day and night data surveillance that connects seemingly irrelevant data points – like how often you check your phone or leave your home on the weekend – to your work performance.

***Article***: ***Applying artificial intelligence for social good***

AI is not a silver bullet, but it could help tackle some of the world’s most challenging social problems.

***Article***: ***The Moral Compass in the age of AI***

We can probably do that’ was the immediate response from one of our data scientists when I asked him a few years ago if we could segment our data (which by design is just anonymous IDs) by purchase power and some form of credit worthiness. The prospective customer wanted to find financially distressed people who ‘overspend based on their means’ to create new financial products (likely high interest credit cards). They wanted to understand how to build media plans to reach those already strapped customers. It was an awakening (not the first one but a strong one) to the power and responsibility dealing with large data and AI. Mind you, we have no PII, no direct data on people’s HHI or purchase history nor do we have credit scores as part of the data set. There was no privileged date involved. He was pretty certain it could be done. All it would take is combining public data sources we already have gobs of (online, social and public government sources), adding some AI and let the system do its work. The results could not have been applied to individuals. Still it would ultimately affect cohorts of people that were vulnerable. We never pursued this opportunity. Had the prospect been a company promoting financial education, should we have acted differently?

***Paper***: ***Grounding Value Alignment with Ethical Principles***

An important step in the development of value alignment (VA) systems in AI is understanding how values can interrelate with facts. Designers of future VA systems will need to utilize a hybrid approach in which ethical reasoning and empirical observation interrelate successfully in machine behavior. In this article we identify two problems about this interrelation that have been overlooked by AI discussants and designers. The first problem is that many AI designers commit inadvertently a version of what has been called by moral philosophers the ‘naturalistic fallacy,’ that is, they attempt to derive an ‘ought’ from an ‘is.’ We illustrate when and why this occurs. The second problem is that AI designers adopt training routines that fail fully to simulate human ethical reasoning in the integration of ethical principles and facts. Using concepts of quantified modal logic, we proceed to offer an approach that promises to simulate ethical reasoning in humans by connecting ethical principles on the one hand and propositions about states of affairs on the other.

### Like this:

Like Loading...
