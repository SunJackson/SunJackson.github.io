---
layout:     post
catalog: true
title:      Looking at flood insurance claims with choroplethr
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/xl0cwMIdvPY/
date:      2019-07-15
author:      kjytay
tags:
    - top_states
    - claimed
    - top_regions
    - values
    - state_no_claims_df
---





I recently learned how to use the `choroplethr` package through a short tutorial by the package author Ari Lamstein (youtube link here). To cement what I learned, I thought I would use this package to visualize flood insurance claims.

I am using the FIMA NFIP redacted claims dataset from FEMA, and it contains more than 2 million claims transactions going all the way back to 1970. (The dataset can be accessed from this URL.) From what I can tell, this dataset is updated somewhat regularly. For this post, the version of the dataset used was published on 26 Jun 2019, and I downloaded it on 10 Jul 2019. (Credit: I learned of this dataset from Jeremy Singer-Vine’s Data Is Plural newsletter, 2019.07.10 edition.)

To access all the code in this post in a single script, click here.

First, let’s load libraries and the dataset:

I get some parsing failures, indicating that there might be some issues with the dataset, but I will ignore them for now since it’s not a relevant point for this post. I end up with around 2.4 million observations of 39 variables. We are only going to be interested in a handful of variables. Here they are along with the description given in the accompanying data dictionary:



- `yearofloss`: Year in which the flood loss occurred (YYYY).

- `state`: The two-character alpha abbreviation of the state in which the insured property is located.

- `countycode`: The Federal Information Processing Standard(FIPS) defined unique 5-digit code for the identification of counties and equivalent entities of the united States, its possessions, and insular areas. The NFIP relies on our geocoding service to assign county.

- `amountpaidonbuildingclaim`: Dollar amount paid on the building claim. In some instances, a negative amount may appear which occurs when a check issued to a policy holder isn’t cashed and has to be re-issued.

- `amountpaidoncontentsclaim`: Dollar amount paid on the contents claim. In some instances, a negative amount may appear, which occurs when a check issued to a policy holder isn’t cashed and has to be re-issued.

- `amountpaidonincreasedcostofcomplianceclaim`: Dollar amount paid on the Increased Cost of Compliance (ICC) claim. Increased Cost of Compliance (ICC) coverage is one of several flood insurances resources for policyholders who need additional help rebuilding after a flood. It provides up to $30,000 to help cover the cost of mitigation measures that will reduce the flood risk. As we are not explicitly defining the building and contents components of the claim, I don’t think it is necessary to define ICC.


I didn’t understand the explanation for negative amounts for the claim fields. Since there were less than 20 records which such fields, I decided to remove them. I also removed all rows without any state information (12 records).

The code below makes a histogram of the number of claims per year:

![](https://statisticaloddsandends.files.wordpress.com/2019/07/hist_year.png?w=456&is-pending-load=1)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/hist_year.png?w=456)


While there are supposed to be records from 1970, the records before 1978 seem to be pretty sparse. We also don’t have a full year of records for 2019 yet. As such, I filtered for just records between 1978 and 2018 (inclusive). I also assumed that the total claim amount was the sum of the 3 claim columns: this is the only claim amount I work with in this post.

**Number of claims by state**

For my first map, I wanted to show the number of claims made by state. To do that, I have to give to the `state_choropleth()` function a very specific dataframe: it must have a `region` column with state names (e.g. “new york”, not “NY” or “New York”), and a `value` column with the number of the claims. The dataset has states in two-letter abbreviations, so we have to do a mapping from those abbreviations to the state names. Thankfully it is easy to do that with the `mapvalues()` function in the `plyr` package and the `state.regions` dataframe in the `choroplethMaps` package:

Note that we get a warning because our dataframe has regions that are not mappable (AS, GU, PR, VI: presumably places like Guam and Puerto Rico). Nevertheless we get a colored map:

![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_1.png?w=450&is-pending-load=1#038;h=375&fit=584%2C375)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_1.png?w=450&h=375&fit=584%2C375)


Not bad for a really short command! By default, the value column is split into 7 buckets (according to quantiles). To see which states are above/below the median number of claims, we can set the `num_colors` option to 2:

![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_2.png?w=450&is-pending-load=1#038;h=375&fit=584%2C375)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_2.png?w=450&h=375&fit=584%2C375)


For a continuous scale, set `num_colors` to 1 (if you have negative values, you can set `num_colors` 0 for a diverging scale):

![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_3.png?w=450&is-pending-load=1#038;h=375&fit=584%2C375)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_3.png?w=450&h=375&fit=584%2C375)


From the map above, it is clear that Louisiana had the most number of claims, followed by Texas and Florida.

It is easy to add a title and legend label to the map:

![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_4.png?w=450&is-pending-load=1#038;h=375&fit=584%2C375)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_4.png?w=450&h=375&fit=584%2C375)


The output of `state_choropleth` is a `ggplot` object, so we can modify the output as we would with ggplot graphics. One bug I noticed was that in adding the color scale below, the legend name reverted to “value” (instead of “No. of claims”); I have not figured out how to amend this yet.

![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_5.png?w=450&is-pending-load=1#038;h=375&fit=584%2C375)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_5.png?w=450&h=375&fit=584%2C375)


`state_choropleth()` allows us to plot just the states we want by passing a vector of states to the `zoom` option. In the code below, we just plot the states which border the Gulf of Mexico:

![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_6.png?w=456&is-pending-load=1)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_no_claims_6.png?w=456)


This last barplot shows the no. of claims by state (in descending order). 6 states have over 100,000 claims, with North Carolina barely hitting that number.

![](https://statisticaloddsandends.files.wordpress.com/2019/07/states_no_claims_bar.png?w=456&is-pending-load=1)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/states_no_claims_bar.png?w=456)


**Total claim amount by state**

This section doesn’t contain any new `choroplethr` syntax, but is for the completeness of the data story. Instead of looking at the number of claims by state, I look at the total claim amounts by state. My initial guess is that we shouldn’t see that much variation from the plots above.

The code below extracts the summary information from the claims level dataset and makes the choropleth map and the barplot (the red line indicates the $1 billion mark):

![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_claim_amt_1.png?w=450&is-pending-load=1#038;h=375&fit=584%2C375)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_claim_amt_1.png?w=450&h=375&fit=584%2C375)


![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_claim_amt_bar.png?w=456&is-pending-load=1)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/state_claim_amt_bar.png?w=456)


Perhaps not surprisingly the top 5 states with the most number of claims are also the top 5 states with the largest claim amounts. What might be more surprising is how much more money was claimed in LA and TX compared to the other states.

**Number of claims by county**

`choroplethr` makes plotting by county really easy, as long as you have the 5-digit FIPS code for the counties. Instead of using the `state_choropleth()` function, use the `county_choropleth()` function. As before, this function must have a “region” column with the FIPS codes (as numbers, not strings), and a “value” column for the values to be plotted. The `county.regions` dataset in the `choroplethrMaps` package can help the conversion of region values if necessary.

![](https://statisticaloddsandends.files.wordpress.com/2019/07/county_no_claims1.png?w=450&is-pending-load=1#038;h=375&fit=584%2C375)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/county_no_claims1.png?w=450&h=375&fit=584%2C375)


As with `state_choropleth()`, the default is to split the values into 7 bins according to quantiles. We get a bunch of warnings because several counties have NA values. By default, these counties are filled black. In this particular case I think they affect how we read the map, I use the code below to change the NAs to white. In this context it makes sense too, since counties have NA values because they have no claims.

![](https://statisticaloddsandends.files.wordpress.com/2019/07/county_no_claims_2.png?w=450&is-pending-load=1#038;h=375&fit=584%2C375)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/county_no_claims_2.png?w=450&h=375&fit=584%2C375)


We can draw county maps for specific states as well. The code below makes two plots: the first zooms in on just Florida, the second zooms in on all the Gulf states.

![](https://statisticaloddsandends.files.wordpress.com/2019/07/county_no_claims_3.png?w=456&is-pending-load=1)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/county_no_claims_3.png?w=456)


![](https://statisticaloddsandends.files.wordpress.com/2019/07/county_no_claims_4.png?w=456&is-pending-load=1)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/county_no_claims_4.png?w=456)


**Top 5 states: a (slightly) deeper look**

In this section we take a temporal look at the top 5 states. The code below filters for them and summarizes the data:

The first chunk of code plots the number of claims for each state for each year, while the second chunk does the same for total claim amount:

![](https://statisticaloddsandends.files.wordpress.com/2019/07/top_5_no_timeline.png?w=450&is-pending-load=1#038;h=389&fit=584%2C389)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/top_5_no_timeline.png?w=450&h=389&fit=584%2C389)


![](https://statisticaloddsandends.files.wordpress.com/2019/07/top_5_amt_timeline.png?w=450&is-pending-load=1#038;h=389&fit=584%2C389)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/top_5_amt_timeline.png?w=450&h=389&fit=584%2C389)


It looks like for these states, most of the claims and most of the damage comes in just one or two particular incidents. From the state and the year, you can probably guess the disaster that caused the spike.


*Related*







---
