---
layout:     post
catalog: true
title:      Whats new on arXiv
subtitle:      转载自：https://analytixon.com/2019/07/06/whats-new-on-arxiv-1038/
date:      2019-07-06
author:      Michael Laux
tags:
    - learning
    - learned
    - networks
    - based
    - modeling
---

**DIEL: Transparent Scaling for Interactive Visualization**

We live in an era of big data and rich data visualization. As data sets increase in size, browser-based interactive visualizations eventually hit limits in storage and processing capacity. In order to provide interactivity over large datasets, visualization applications typically need to be extensively rewritten to make use of powerful back-end services. It would be far preferable if front-end developers could write visualizations once in a natural way, and have a framework take responsibility for transparently scaling up the visualization to use back-end services as needed. Achieving this goal requires rethinking how communication and state are managed by the framework: the mapping of interaction logic to server APIs or database queries, handling of results arriving asynchronously over the network, as well as basic cross-layer performance optimizations like caching. In this paper, we present DIEL, a framework that achieves this cross-layer autoscaling transparently under a simple, declarative interface. DIEL treats UI events as a stream of data that is captured in an event history for reuse. Developers declare what the state of the interface should be after the arrival of events. DIEL compiles these declarative specifications into relational queries over both event history and the data to be visualized. In doing so, DIEL makes it easier to develop visualizations that are robust against changes to the size and location of data. To evaluate the DIEL framework, we developed a prototype implementation and confirmed that DIEL supports a range of visualization and interaction designs. Visualizations written using DIEL can transparently and seamlessly scale to use back-end services with little intervention from the developer.

**Programming with Timespans in Interactive Visualizations**

Modern interactive visualizations are akin to distributed systems, where user interactions, background data processing, remote requests, and streaming data read and modify the interface at the same time. This concurrency is crucial to provide an interactive user experience—forbidding it can cripple responsiveness. However, it is notoriously challenging to program distributed systems, and concurrency can easily lead to ambiguous or confusing interface behaviors. In this paper, we present DIEL, a declarative programming model to help developers reason about and reconcile concurrency-related issues. Using DIEL, developers no longer need to procedurally describe how the interface should update based on different input events, but rather declaratively specify what the state of the interface should be as queries over event history. We show that resolving conflicts from concurrent processes in real-world interactive visualizations can be done in a few lines of DIEL code.

**Extracting Novel Facts from Tables for Knowledge Graph Completion (Extended version)**

We propose a new end-to-end method for extending a Knowledge Graph (KG) from tables. Existing techniques tend to interpret tables by focusing on information that is already in the KG, and therefore tend to extract many redundant facts. Our method aims to find more novel facts. We introduce a new technique for table interpretation based on a scalable graphical model using entity similarities. Our method further disambiguates cell values using KG embeddings as additional ranking method. Other distinctive features are the lack of assumptions about the underlying KG and the enabling of a fine-grained tuning of the precision/recall trade-off of extracted facts. Our experiments show that our approach has a higher recall during the interpretation process than the state-of-the-art, and is more resistant against the bias observed in extracting mostly redundant facts since it produces more novel extractions.

**Large-scale inference with block structure**
![](//s0.wp.com/latex.php?latex=%5Csqrt%7B%5Clog+n%7D&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Csqrt%7B%5Clog+n%7D&bg=ffffff&fg=000&s=0)


**SetGANs: Enforcing Distributional Accuracy in Generative Adversarial Networks**

This paper addresses the ability of generative adversarial networks (GANs) to model complex distributions of data in high-dimensional spaces. Our proposition is that the more effective the adversary is in discriminating the output of the generator, the more effective the generator will be at modeling (or generating) the distribution represented by the training data. The most extreme failure of GANs in this context is mode collapse, and there are several proposed methods to address that problem. However, mode collapse is merely a symptom of a more general problem of GANs, where the generator fools the adversary while failing to faithfully model the distribution of the training data. Here, we address the challenge of constructing and evaluating GANs that more effectively represent the input distribution. We introduce an adversarial architecture that processes sets of generated and real samples, and discriminates between the origins of these sets (i.e., training versus generated data) in a flexible, permutation invariant manner. We present quantitative and qualitative results that demonstrate the effectiveness of this approach relative to state-of-the-art methods for avoiding mode collapse.

**Planting Trees for scalable and efficient Canonical Hub Labeling**

Point-to-Point Shortest Distance (PPSD) query is a crucial primitive in graph database applications. Hub labeling algorithms compute a labeling that converts a PPSD query into a list intersection problem (over a pre-computed indexing) enabling swift query response. However, constructing hub labeling is computationally challenging. Even state-of-the-art parallel algorithms based on Pruned Landmark Labeling (PLL) [3], are plagued by large label size, violation of given network hierarchy, poor scalability and inability to process large graphs. In this paper, we develop novel parallel shared-memory and distributed-memory algorithms for constructing the Canonical Hub Labeling (CHL) that is minimal in size for a given network hierarchy. To the best of our knowledge, none of the existing parallel algorithms guarantee canonical labeling. Our key contribution, the PLaNT algorithm, scales well beyond the limits of current practice by completely avoiding inter-node communication. PLaNT also enables the design of a collaborative label partitioning scheme across multiple nodes for completely in-memory processing of massive graphs whose labels cannot fit on a single machine. Compared to the sequential PLL, we empirically demonstrate upto 47.4x speedup on a 72 thread shared-memory platform. On a 64-node cluster, PLaNT achieves an average 42x speedup over single node execution. Finally, we show how our approach demonstrates superior scalability – we can process 14x larger graphs (in terms of label size) and construct hub labeling orders of magnitude faster compared to state-of-the-art distributed paraPLL algorithm.

**DataPop: Knowledge Base Population using Distributed Voice Enabled Devices**

Data scientists are constantly creating methods to efficiently and accurately populate big data sets for use in large-scale applications. Many recent efforts utilize crowd-sourcing and textual interfaces. In this paper, we propose a new method of curating data; namely, creating a multi-device Amazon Alexa Skill in the form of a research trivia game. Users experience a synchronized gaming experience with other Amazon Echo users, competing against one another while filling in gaps of a connected knowledge base. This allows for full exploitation of the speed improvement offered by voice interface technology in a game-based format.

**Privacy Risks of Explaining Machine Learning Models**

Can we trust black-box machine learning with its decisions? Can we trust algorithms to train machine learning models on sensitive data? Transparency and privacy are two fundamental elements of trust for adopting machine learning. In this paper, we investigate the relation between interpretability and privacy. In particular we analyze if an adversary can exploit transparent machine learning to infer sensitive information about its training set. To this end, we perform membership inference as well as reconstruction attacks on two popular classes of algorithms for explaining machine learning models: feature-based and record-based influence measures. We empirically show that an attacker, that only observes the feature-based explanations, has the same power as the state of the art membership inference attacks on model predictions. We also demonstrate that record-based explanations can be effectively exploited to reconstruct significant parts of the training set. Finally, our results indicate that minorities and special cases are more vulnerable to these type of attacks than majority groups.

**Continual Learning for Robotics**

Continual learning (CL) is a particular machine learning paradigm where the data distribution and learning objective changes through time, or where all the training data and objective criteria are never available at once. The evolution of the learning process is modeled by a sequence of learning experiences where the goal is to be able to learn new skills all along the sequence without forgetting what has been previously learned. Continual learning also aims at the same time at optimizing the memory, the computation power and the speed during the learning process. An important challenge for machine learning is not necessarily finding solutions that work in the real world but rather finding stable algorithms that can learn in real world. Hence, the ideal approach would be tackling the real world in a embodied platform: an autonomous agent. Continual learning would then be effective in an autonomous agent or robot, which would learn autonomously through time about the external world, and incrementally develop a set of complex skills and knowledge. Robotic agents have to learn to adapt and interact with their environment using a continuous stream of observations. Some recent approaches aim at tackling continual learning for robotics, but most recent papers on continual learning only experiment approaches in simulation or with static datasets. Unfortunately, the evaluation of those algorithms does not provide insights on whether their solutions may help continual learning in the context of robotics. This paper aims at reviewing the existing state of the art of continual learning, summarizing existing benchmarks and metrics, and proposing a framework for presenting and evaluating both robotics and non robotics approaches in a way that makes transfer between both fields easier.

**Deep Gamblers: Learning to Abstain with Portfolio Theory**
![](//s0.wp.com/latex.php?latex=m&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=m&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%28m%2B1%29&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%28m%2B1%29&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%28m%2B1%29&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%28m%2B1%29&bg=ffffff&fg=000&s=0)


**Adaptive Deep Learning of Cross-Domain Loss in Collaborative Filtering**

Nowadays, users open multiple accounts on social media platforms and e-commerce sites, expressing their personal preferences on different domains. However, users’ behaviors change across domains, depending on the content that users interact with, such as movies, music, clothing and retail products. In this paper, we propose an adaptive deep learning strategy for cross-domain recommendation, referred to as ADC. We design a neural architecture and formulate a cross-domain loss function, to compute the non-linearity in user preferences across domains and transfer the knowledge of users’ multiple behaviors, accordingly. In addition, we introduce an efficient algorithm for cross-domain loss balancing which directly tunes gradient magnitudes and adapts the learning rates based on the domains’ complexities/scales when training the model via backpropagation. In doing so, ADC controls and adjusts the contribution of each domain when optimizing the model parameters. Our experiments on six publicly available cross-domain recommendation tasks demonstrate the effectiveness of the proposed ADC model over other state-of-the-art methods. Furthermore, we study the effect of the proposed adaptive deep learning strategy and show that ADC can well balance the impact of the domains with different complexities.

**Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting**
![](//s0.wp.com/latex.php?latex=L&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=L&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=O%28L%28%5Clog+L%29%5E%7B2%7D%29&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=O%28L%28%5Clog+L%29%5E%7B2%7D%29&bg=ffffff&fg=000&s=0)


**Multidimensional Scaling on Metric Measure Spaces**
![](//s0.wp.com/latex.php?latex=S%5E1&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=S%5E1&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Em&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Em&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=m&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=m&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=n&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=n&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=S%5En&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=S%5En&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Em&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Em&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=X&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=X&bg=ffffff&fg=000&s=0)

![](//s0.wp.com/latex.php?latex=X&is-pending-load=1#038;bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=X&bg=ffffff&fg=000&s=0)


**Infrastructure-Agnostic Hypertext**

This paper presents a novel and formal interpretation of the original vision of hypertext: infrastructure-agnostic hypertext is independent from specific standards such as data formats and network protocols. Its model is illustrated with examples and references to existing technologies that allow for implementation and integration in current information infrastructures such as the Internet.

**NetTailor: Tuning the Architecture, Not Just the Weights**

Real-world applications of object recognition often require the solution of multiple tasks in a single platform. Under the standard paradigm of network fine-tuning, an entirely new CNN is learned per task, and the final network size is independent of task complexity. This is wasteful, since simple tasks require smaller networks than more complex tasks, and limits the number of tasks that can be solved simultaneously. To address these problems, we propose a transfer learning procedure, denoted NetTailor, in which layers of a pre-trained CNN are used as universal blocks that can be combined with small task-specific layers to generate new networks. Besides minimizing classification error, the new network is trained to mimic the internal activations of a strong unconstrained CNN, and minimize its complexity by the combination of 1) a soft-attention mechanism over blocks and 2) complexity regularization constraints. In this way, NetTailor can adapt the network architecture, not just its weights, to the target task. Experiments show that networks adapted to simple tasks, such as character or traffic sign recognition, become significantly smaller than those adapted to hard tasks, such as fine-grained recognition. More importantly, due to the modular nature of the procedure, this reduction in network complexity is achieved without compromise of either parameter sharing across tasks, or classification accuracy.

**Machine Reading Comprehension: a Literature Review**

Machine reading comprehension aims to teach machines to understand a text like a human and is a new challenging direction in Artificial Intelligence. This article summarizes recent advances in MRC, mainly focusing on two aspects (i.e., corpus and techniques). The specific characteristics of various MRC corpus are listed and compared. The main ideas of some typical MRC techniques are also described.

**Development of a novel matrix-based methodology for system engineering: A case study**

Developing a structured method for analyzing various aspects of a system requires a novel methodology. This study is aimed at developing such as methodology through combining two major matrix methods, namely, Design Structure Matrix (DSM) and Interface Structure Matrix (ISM). Through this paper, a business process modeling method is applied to turn a real work project to a process model. Then that process model is written in two various matrix forms of DSM and ISM. These two matrices are analyzed by two types of algorithm for extracting activity levels and sub-processes. In the end, a Mixed Matrix Model (MMM) is built upon these activity levels and sub-processes, which can be used as a framework for the engineering of real-world systems.

**Random Vector Functional Link Neural Network based Ensemble Deep Learning**

In this paper, we propose a deep learning framework based on randomized neural network. In particular, inspired by the principles of Random Vector Functional Link (RVFL) network, we present a deep RVFL network (dRVFL) with stacked layers. The parameters of the hidden layers of the dRVFL are randomly generated within a suitable range and kept fixed while the output weights are computed using the closed form solution as in a standard RVFL network. We also propose an ensemble deep network (edRVFL) that can be regarded as a marriage of ensemble learning with deep learning. Unlike traditional ensembling approaches that require training several models independently from scratch, edRVFL is obtained by training a single dRVFL network once. Both dRVFL and edRVFL frameworks are generic and can be used with any RVFL variant. To illustrate this, we integrate the deep learning networks with a recently proposed sparse-pretrained RVFL (SP-RVFL). Extensive experiments on benchmark datasets from diverse domains show the superior performance of our proposed deep RVFL networks.

### Like this:

Like Loading...
