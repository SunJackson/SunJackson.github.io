---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/07/30/distilled-news-1147/
date:      2019-07-30
author:      Michael Laux
tags:
    - computation models
    - colors
    - gpu
    - languages
    - recently researchers
---

**Could a Chatbot Make Working in Government Easier?**

Over the course of three weeks, I was part of a research project for the District of Columbia Government. The first two weeks were applied to user research and synthesis, and the final week was centered around designing a solution to a problem found in our research. I have a brief summary of the research that led to my design below. If you are interested in more detail about the research portion of this project, you can read my case study for that here.

**Easy, One-Click Jupyter Notebooks**

Data Science can be a fun thing to do! Really most of what we’re doing is poking at data while trying to extract its hidden information. It’s like we’re exploring through an unknown jungle looking for treasure! But it’s not always fun and games.

**UDPipe**

**This New Google Technique Help Us Understand How Neural Networks are Thinking**

Interpretability remains one of the biggest challenges of modern deep learning applications. The recent advancements in computation models and deep learning research have enabled the creation of highly sophisticated models that can include thousands of hidden layers and tens of millions of neurons. While its relatively simple to create incredibly advanced deep neural network models, its understanding how those models create and use knowledge remains a challenge. Recently, researchers from the Google Brain team published a paper proposing a new method called Concept Activation Vectors(CAVs) that takes a new angle to the interpretability of deep learning models.

**Save Yourself (And Your Boss) Some Hair: Automating Company Information Search with Web Scraping**

You’re wondering how in the world you got to this point. You thought it would be so simple. You thought it wouldn’t take long. Now your eyes are dying, your energy is rock bottom, and you’ve already downed 5 cups of coffee.

**You should fear Super Stupidity, not Super Intelligence**

I have been invited to participate in a quite large event in which some experts and I (allow me to not consider myself one) will discuss about Artificial Intelligence, and, in particular, about the concept of Super Intelligence. It turns out I recently found out this really interesting TED talk by Grady Booch, just in perfect timing to prepare my talk.

**What is RAPIDS AI?**

RAPIDS is a ‘suite of open source software libraries and APIs’ grouped together for the purpose of providing users the ability to ‘execute end-to-end data science and analytics pipelines entirely on GPUs.’ RAPIDS utilizes NVIDIA CUDA primitives for low-level compute optimization, and exposes GPU parallelism and high-bandwidth memory speed through user-friendly Python interfaces. The suite also focuses on common data preparation tasks for data science including a Pandas-esque dataframe API which integrates with a variety of machine learning algorithms to hedge ‘typical serialization costs.’ RAPIDS also includes support for multi-node, multi-GPU deployments, enabling vastly accelerated processing and training on much larger dataset sizes.

**Learning an image’s leading colors using k-means**

Color preferences, like many things in life, is a very intrinsic, and unique quality of a person. You have a favorite color, but more than that, I’m willing to say that you have a preferred tone for many of the things that you own. For example, you favor a particular color for your shoes, another one for your phone case, and in my case, I lean towards some colors while working a photograph. Besides being a data practitioner, I’m also an amateur photographer, and a few days ago, while editing an image, I realized I have a favored list of colors that I typically use on different objects or parts of the photograph. For example, I like my skies either gray, or strongly blue, my greens, a bit yellowish, and my darks, more ‘shadow-ish.’

**Mixing Topology and Deep Learning with PersLay**

In a former post, I presented Topological Data Analysis and its main descriptor, the so-called persistence diagram. In this post, I would like to show how these descriptors can be combined with neural networks, opening the way to applications based upon both deep learning and topology!

**Neuromorphic Hardware: Trying to Put Brain Into Chips**

Up until now, chip-makers have been piggybacking on the renowned Moore’s Law for delivering successive generations of chips that have more compute capabilities and are less power hungry. Now, these advancements are slowly coming to a halt. Researchers around the world are proposing alternative architectures to continue producing systems which are faster and more energy efficient. This article discusses those alternatives and reasons why one of them might have an edge over others in averting the chip design industry from getting stymied.

**All about Categorical Variable Encoding**

Most of the Machine learning algorithms can not handle categorical variables unless they are converted to numerical values and many algorithm’s performance varies based on how Categorical variables are encoded. Categorical variables can be divided in two categories. Nominal (No particular order) and Ordinal (some kind of ordered).

**Estimating the success of re-identifications in incomplete datasets using generative models**

While rich medical, behavioral, and socio-demographic data are key to modern data-driven research, their collection and use raise legitimate privacy concerns. Anonymizing datasets through de-identification and sampling before sharing them has been the main tool used to address those concerns. We here propose a generative copula-based method that can accurately estimate the likelihood of a specific person to be correctly re-identified, even in a heavily incomplete dataset. On 210 populations, our method obtains AUC scores for predicting individual uniqueness ranging from 0.84 to 0.97, with low false-discovery rate. Using our model, we find that 99.98% of Americans would be correctly re-identified in any dataset using 15 demographic attributes. Our results suggest that even heavily sampled anonymized datasets are unlikely to satisfy the modern standards for anonymization set forth by GDPR and seriously challenge the technical and legal adequacy of the de-identification release-and-forget model.

### Like this:

Like Loading...
