---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/07/16/distilled-news-1133/
date:      2019-07-15
author:      Michael Laux
tags:
    - learning
    - learned
    - functioning
    - articles
    - target
---

**Classical Time-Series vs Machine Learning Methods**

In an earlier article, I discussed the use of supervised machine learning to predict a poverty metric using 1000+ World Development Indicators (WDIs). In this article, I will use the same dataset to compare the lasso with a classical time-series method (exponential smoothing) and some other machine learning methods such as random forest and XGBoost). In the end, XGBoost was, by far, the best performer. XGBoost can handle sparse input data and interestingly, the best score by a large margin was obtained when no attempt to impute missing values in the input data was made. More on all of this later in the article.

**Simple Guide to Hyperparameter Tuning in Neural Networks**

This is the fourth article in my series on fully connected (vanilla) neural networks. In this article, we will be optimizing a neural network and performing hyperparameter tuning in order to obtain a high-performing model on the Beale function – one of many test functions commonly used for studying the effectiveness of various optimization techniques. This analysis can be reused for any function, but I recommend trying this out yourself on another common test function to test your skills. Personally, I find that optimizing a neural network can be incredibly frustrating (although not as bad as a GAN, if you’re familiar with those..) unless you have a clear and well-defined procedure to follow. I hope you enjoy this article and find it insightful. You can access the previous articles below. The first provides a simple introduction to the topic of neural networks, to those who are unfamiliar. The second article covers more intermediary topics such as activation functions, neural architecture, and loss functions.

**AI as a Service?**

Digital Infrastructure and Everything as a Service. AaaS – is of course not the most fortunate acronym. It would at this time be fitting to say when you ASSUME means that you make an ass out of you and me. What else is an algorithm if not an assumption? A mathematical assumption, no doubt, it can be right and wrong as human assumptions. There are now a large variety of ‘as a service’ abbreviations, some have even proposed AI as a Service or AIaaS. AaaS stands for algorithm as a service and is one of many acronyms I came across within the ‘as a service’ cloud of words.

**Getting Deeper into Categorical Encodings for Machine Learning**

In my experience with supervised learning, improving the model performance from decent to human-like requires creative feature engineering. Jumping from simple algorithms to complex ones does not always boost performance if the feature engineering is not done right. The goal of supervised learning is to extract all the juice from the relevant features and to do that, we generally have to enrich and transform features in order to make it easier for the algorithm to see how the target variable depends on given data. One type of features that do not easily give away the information they contain are categorical features. They keep on hiding the information until we transform them smartly. In this particular post, I am focussing on one particular categorical encoding technique called target encoding which works really well most of the times, but it has a risk of target leakage if not done correctly. Target leakage means using some information from target to predict the target itself (you see the issue here?). This leakage consequently increases the risk of overfitting on the training data, especially when the data is small. Similar target leakage also exists in standard gradient boosting algorithms. Catboost has implemented a technique called ordering principle which solves the problem of target leakage in both cases. Based on this technique plus numerous other small improvements, Catboost outperforms other publicly available gradient boosting libraries on a set of popular publicly available datasets. The comparison experiments done by Catboost are summarized in this paper – CatBoost: unbiased boosting with categorical features.

**The A-Z of AI and Machine Learning: Comprehensive Glossary**

Ultimate Terminology You Need to Know

**Why is it So Hard to Integrate Machine Learning into Real Business Applications?**

You’ve played around with machine learning, learned about the mysteries of neural networks, almost won a Kaggle competition and now you feel ready to bring all this to real world impact. It’s time to build some real AI-based applications. But time and again you face setbacks and you’re not alone. It takes time and effort to move from a decent machine learning model to the next level of incorporating it into a live business application. Why? Having a trained machine learning model is just the starting point. There are many other considerations and components that needs to be built, tested and deployed for a functioning application. In the following post I will present a real AI-based application (based on a real customer use case), explain the challenges and suggest ways to simplify development and deployment.

**Collaborative Evolutionary Reinforcement Learning**

Intel Researchers created a new approach to RL via Collaborative Evolutionary Reinforcement Learning (CERL) that combines policy gradient and evolution methods to optimize, exploit, and explore challenges.

**Deploying Python application using Docker and AWS**

The use of Docker in conjunction with AWS can be highly effective when it comes to building a data pipeline. Let me ask you if you have ever had this situation before. You are building a model in Python which you need to send over to a third-party, e.g. a client, colleague, etc. However, the person on the other end cannot run the code! Maybe they don’t have the right libraries installed, or their system is not configured correctly. Whatever the reason, Docker alleviates this situation by storing the necessary components in an image, which can then be used by a third-party to deploy an application effectively. In this example, we will see how a simple Python script can be incorporated into a Docker image, and this image will then be pushed to ECR (Elastic Container Registry) in AWS.

### Like this:

Like Loading...
