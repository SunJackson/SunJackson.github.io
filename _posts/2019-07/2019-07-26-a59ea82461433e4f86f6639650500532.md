---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/07/26/distilled-news-1143/
date:      2019-07-26
author:      Michael Laux
tags:
    - data
    - models
    - modelling
    - language
    - learning
---

**Cross-lingual Language Model**

A pre-trained model is proven to improve the downstream problem. Lample and Conneau propose two new training objectives to train cross-lingual language models (XLM). This approach leads to achieving state-of-the-art results on Cross-lingual Natural Language Inference (XNLI). On the other hand, Wada and Iwata proposed another way to learn cross-lingual text representation without parallel data. They named it Multilingual Neural Language Models.This story will discuss Cross-lingual Language Model Pretraining (Lample and Conneau, 2019) and Unsupervised Cross-lingual Word Embedding by Multilingual Neural Language Models (Wada and Iwata, 2018)The following are will be covered:• Data• Cross-lingual Language Model Architecture• Multilingual Neural Language Models Architecture• Experiment

**System Design Thinking: Distinguishing AI from ML**

How are Artificial Intelligence and Machine Learning different?

**Thinking about Moving Up to Automated Machine Learning (AML)**

Are you wondering about moving up to Automated Machine Learning (AML)? Or perhaps you’ve already made the decision but are wondering about the capabilities of individual platforms, their strengths and limitations and how to choose. Here are some considerations to help guide you.

**Multi GPU, multi process with Tensorflow**

Tensorflow is a tremendous tool to experiment deep learning algorithms. But to exploit the power of deep learning, you need to leverage it with computing power, and good engineering. You will eventually need to use multiple GPU, and maybe even multiple processes to reach your goals. I recommend you to read the official tutorial about GPUs by TensorFlow first.

**Winner Interview with Shivam Bansal | Data Science for Good Challenge: City of Los Angeles**

Let’s start with the problem you solved. Can you summarize the competition for readers who are unfamiliar? The business problem presented in this challenge was unique. More than one-third of the city’s 50,000 workers are eligible to retire in the coming year. In this situation, the organization wanted to learn from different datasets and core data science practices to ensure an efficient recruitment pipeline. They wanted to bring a structure in their job boards and optimize the content, tone, language, and format. All these factors can directly or indirectly influence the quality and diversity of the applicant pool. LA’s Mayor wanted to reimagine the city’s job boards by using text analysis to identify needed improvements. The primary goal was to develop techniques to convert plain-text job postings into a single structured file, then to use it to identify language that can negatively bias the pool of applicants; further, improve the diversity and quality of the applicant pool; and make it easier to determine which promotions are available to employees in each job class. As an overall solution, they wanted a framework to address these challenges and suggest actionable recommendations with meaningful impact.

**A Deeper Dive into Residual Learning**

In the field of computer vision, deep learning has helped make great strides with the introduction of DCNNs or Deep Convolutional Neural Networks. With the advent of powerful GPUs, deep networks are becoming the norm. However, these networks suffer from the problem of vanishing gradient. In order to overcome this, Kaiming He et al., in 2015 introduced the concept of residual learning, wherein the authors use residual units as the building blocks of the network. In this article, we take a closer look at the aforementioned residual units and the modifications it has gone through till date.

**Beginner’s Guide to LDA Topic Modelling with R**

What is topic modelling? In layman terms, topic modelling is trying to find similar topics across different documents, and trying to group different words together, such that each topic will consist of words with similar meanings. An analogy that I often like to give is – when you have a story book that is torn into different pages. After you try to run a topic modelling algorithm, you should be able to come up with various topics such that each topic would consist of words from each chapter. Otherwise, you may simply just use sentiment analysis – positive or negative review.

**Bayesian Machine Learning**

In this post we will see the methodology of building Bayesian models. In my previous post I used a Bayesian model for linear regression.

**Reproducible Data Processing: Make + Docker**

When performing experiments in data science and machine learning, two main blockers of initial progress are delays building/using ‘base code’ and lack of reproducibility. Thanks to some great open source tools, you don’t have to be a software guru to circumvent these obstacles and get meaning from your data in a much smoother process. ‘Hey there, I got this error when I ran your code…can you help me??’

**Data Science: An Artificial Ecosystem**

1. Data Science is not just machine learning or just statistics.2. Data Science is not all about prediction.3. Data Science is not only about data analysis.4. Data Science is not a discipline that sits merely within STEM (Science, Technology, Engineering, and Mathematics) fields.5. and most critically, Data Science is not even a single discipline by itself.

### Like this:

Like Loading...
