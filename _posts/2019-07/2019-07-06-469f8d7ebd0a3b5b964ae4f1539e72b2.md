---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/07/06/distilled-news-1124/
date:      2019-07-06
author:      Michael Laux
tags:
    - models
    - learning
    - clustering
    - datasets
    - algorithms
---

**Unit Testing in R**

You will ask: ‘Why unit tests? My code is working!’. Unit testing helps to create robust code. After a short motivation what robust code is, I give a survey of the basic unit testing idea. Finally, I show how to use them quickly in R, even for simple scripts (no burden to create R packages).

**Decision Trees: Which feature to split on?**

Decision Tree classification is perhaps one of the most intuitive and easy-to-interpret classification algorithms we have today. It can easily model non-linear relationships and results in predictive models that are quite accurate and stable.

**Python3 for Text Processing**

Python is more about ‘Programming like Hacker’ while writing your code if you keep things in mind like reference counting, type-checking, data manipulation, using stacks, managing variables, eliminating usage of lists, using less and less ‘for’ loops could really warm up your code for great looking code as well as less usage of CPU-resources with great Speed.

**Transfer Learning in PyTorch**

Transfer Learning is a technique where a model trained for a certain task is used for another similar task. In deep learning, there are two major transfer learning approaches.• Fine-tuning• Feature Extraction

**How you can change the world by learning Data Structures and Algorithms**

As a developer, you have the power to change the world! You can write programs that enable new technologies. For instance, develop software to find an earlier diagnosis of diseases. But, that’s not the only way, you might do it indirectly by creating projects that make people more productive and help them free up time to do other amazing things. Whatever you do, it has the potential to impact the community who use it. However, these accomplishments are only possible if we write software that is fast and can scale. Learning how to measure your code performance is the goal of this post. We are going to explore how you can measure your code performance using analysis of algorithms: time complexity and big O notation. First, let’s see a real story to learn why this is important.

**When Your Boss Is an Algorithm**

For Uber drivers, the workplace can feel like a world of constant surveillance, automated manipulation and threats of ‘deactivation’

**Importance of Exhaust Data in Data Science**

I was fascinated when I first heard the term Exhaust Data. There are a lot of definitions floating around on the same topic, and I wanted to dig an inch deeper. In simple words exhaust data is the data which is generated without a specific purpose in mind and immediately might not reveal to be important for organizations to spend money on curating, storing and using it. Hmm mm. Let us try again with a few examples, and simultaneously we will try to connect the examples with Data Science.

**Microsoft Azure ML Studio – A Tutorial on How to Create a Churn Model in No Time**

In this article, we will see how we can implement a simple customer churn model that is built by using Azure Machine Learning studio. This article will give us a starting point to understand how Azure ML based models are created and deployed in the most easy to understand manner. The experiment (Azure ML Model terminology) that I will refer to is based on a dummy customer data and is readily available on Azure ML Studio AI Gallery.

**Machine Learning: BIRCH Clustering Algorithm Clearly Explained**

Existing data clustering methods do not adequately address the problem of processing large datasets with a limited amount of resources (i.e. memory and cpu cycles). In consequence, as the dataset size increases, they scale poorly in terms of running time, and result quality. At a high level, Balanced Iterative Reducing and Clustering using Hierarchies, or BIRCH for short, deals with large datasets by first generating a more compact summary that retains as much distribution information as possible, and then clustering the data summary instead of the original dataset. BIRCH actually complements other clustering algorithms by virtue if the fact that different clustering algorithms can be applied to the summary produced by BIRCH. BIRCH can only deal with metric attributes (similar to the kind of features KMEANS can handle). A metric attribute is one whose values can be represented by explicit coordinates in an Euclidean space (no categorical variables).

**AI Differential Privacy and Federated Learning**

Use of Artificial Intelligence on users sensitive data has recently raised numerous concerns. Differential Privacy and Federated Learning is the solution now proposed to this problem by companies such as Google and Apple.

**Fine grained analysis of K- mean clustering and where we are using it**

K-means is a centroid based algorithm that means points are grouped in a cluster according to the distance(mostly Euclidean) from centroid.

**Language Detection Benchmark using Production Data**

This is a benchmark on real-life social media data for multilingual language detection algorithms.

**How to analyze the quality of training a chatbot?**

Currently, chatbots are in evidence. We can say that most companies, which have websites, have some bot and even without knowing (as there are exceptionally well-trained and implemented bots), most people have already interacted with one. Along with the bots, come a infinity of concepts, such as: entities, intents, dialog node, workspace, skill and a lot of them. There is also a need to evaluate the training and performance of the service provided by the bots. And there, dear reader, is that we have entered … the Super Data Scientists.

**Deploying Models to Flask**

You’ve built a model using Pandas, Sci-kit Learn, and Jupyter Notebooks. The results look great in your notebooks, but how do you share what you’ve made with others? To share models, we need to deploy them, ideally to some website, or at minimum using Python files. Today I will walk you through the process of deploying a model to a website using Python and Flask using my chatroom toxicity classifier models as an example. This article assumes you know how to write Python code, know the basics of HTML, and have Flask installed (pip install flask or conda install flask). We’ll start by going into the file structure!

**How to do hyperparameter tuning of a BigQuery ML model**

When carrying out machine learning, there are many parameters that we choose rather arbitrarily. These include factors such as the learning rate, the level of L2 regularization, the number of layers and nodes in a neural network, the maximum depth of a boosted tree, the number of factors of a matrix factorization model, etc. It is often the case that choosing a different value for these could result in a better model (as measured by the error on a withheld evaluation dataset). Choosing a good value for these parameters is called hyperparameter tuning.

**Colab synergy with MLflow: how to monitor progress and store models.**

An increasing number of models in deep learning rely on the usage of GPU. As a deep learning practitioner, I even thought of buying one to accelerate development of my side projects. But new models of GPU released every year make an old GPU somewhat ancient, slow, and not cool. Cool things are the new cloud technologies that allow to rent a virtual machine (VM) with GPU of the last generation and train your model (high) in the cloud. However, it might be still pricey, both in terms of money and time to set-up your cloud VM. What if I tell (or remind?) you about the cloud solution that solves all these issues? Colab Notebook from Google provides a free GPU for up to 12 hours. However, after 12 hours everything turns into pumpkin: all stored data is gone.

### Like this:

Like Loading...
