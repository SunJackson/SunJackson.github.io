---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/07/27/distilled-news-1144/
date:      2019-07-27
author:      Michael Laux
tags:
    - models
    - modelling
    - modeled
    - modeling
    - learning
---

**Artificial Intelligence versus Intelligence Engineering**

In conclusion, there are many exciting and important endeavors in the broad spectrum of activities that we call AI. I subscribe to the importance of human-centric AI, intelligent infrastructure and engineering. I agree that we need a broad palette of disciplines to work together to develop complex AI systems that are safe, useful, private, fair, transparent and so on. And as anyone who has developed a real system will tell you, the engineering efforts behind the scenes often represent the bulk of the hard work. Thus, a new field of ‘Intelligence Engineering’ may indeed be necessary and may in fact already be under construction behind the scenes.

**Dimension Reduction Techniques with Python**

A high-dimensional dataset is a dataset that has a great number of columns (or variables). Such a dataset presents many mathematical or computational challenges. The good news is that variables (or called features) are often correlated. We can find a subset of the variables to represent the same level of information in the data, or transform the variables to a new set of variables without losing much information. Although high-power computing can somehow handle high-dimensional data, in many applications it is still necessary to reduce the dimensionality of the original data.• Principal Component Analysis (PCA)• Kernel PCA (KPCA)• Linear Discriminant Analysis (LDA)• Singular Value Decomposition (SVD)• t-distributed Stochastic Neighbor Embedding (t-SNE)

**TF IDF | TFIDF Python Example**

Natural Language Processing (NLP) is a sub-field of artificial intelligence that deals understanding and processing human language. In light of new advancements in machine learning, many organizations have begun applying natural language processing for translation, chatbots and candidate filtering. Without further delay let’s dive into some code. To start, we’ll import the necessary libraries.

**Scalable Interpretable Multi-Response Regression via SEED**

Sparse reduced-rank regression is an important tool for uncovering meaningful dependence structure between large numbers of predictors and responses in many big data applications such as genome-wide association studies and social media analysis. Despite the recent theoretical and algorithmic advances, scalable estimation of sparse reduced-rank regression remains largely unexplored. In this paper, we suggest a scalable procedure called sequential estimation with eigen-decomposition (SEED) which needs only a single top-r sparse singular value decomposition from a generalized eigenvalue problem to find the optimal low-rank and sparse matrix estimate. Our suggested method is not only scalable but also performs simultaneous dimensionality reduction and variable selection. Under some mild regularity conditions, we show that SEED enjoys nice sampling properties including consistency in estimation, rank selection, prediction, and model selection. Moreover, SEED employs only basic matrix operations that can be efficiently parallelized in high performance computing devices. Numerical studies on synthetic and real data sets show that SEED outperforms the state-of-the-art approaches for large-scale matrix estimation problem.

**A Representer Theorem for Deep Neural Networks**

We propose to optimize the activation functions of a deep neural network by adding a corresponding functional regularization to the cost function. We justify the use of a second-order total-variation criterion. This allows us to derive a general representer theorem for deep neural networks that makes a direct connection with splines and sparsity. Specifically, we show that the optimal network configuration can be achieved with activation functions that are nonuniform linear splines with adaptive knots. The bottom line is that the action of each neuron is encoded by a spline whose parameters (including the number of knots) are optimized during the training procedure. The scheme results in a computational structure that is compatible with existing deep-ReLU, parametric ReLU, APL (adaptive piecewise-linear) and MaxOut architectures. It also suggests novel optimization challenges and makes an explicit link with l1 minimization and sparsity-promoting techniques.

**Measuring the Effects of Data Parallelism on Neural Network Training**

Recent hardware developments have dramatically increased the scale of data parallelism available for neural network training. Among the simplest ways to harness next-generation hardware is to increase the batch size in standard mini-batch neural network training algorithms. In this work, we aim to experimentally characterize the effects of increasing the batch size on training time, as measured by the number of steps necessary to reach a goal out-of-sample error. We study how this relationship varies with the training algorithm, model, and data set, and find extremely large variation between workloads. Along the way, we show that disagreements in the literature on how batch size affects model quality can largely be explained by differences in metaparameter tuning and compute budgets at different batch sizes. We find no evidence that larger batch sizes degrade out-of-sample performance. Finally, we discuss the implications of our results on efforts to train neural networks much faster in the future. Our experimental data is publicly available as a database of 71,638,836 loss measurements taken over the course of training for 168,160 individual models across 35 workloads.

**Complete Search for Feature Selection in Decision Trees**

The search space for the feature selection problem in decision tree learning is the lattice of subsets of the available features. We design an exact enumeration procedure of the subsets of features that lead to all and only the distinct decision trees built by a greedy top-down decision tree induction algorithm. The procedure stores, in the worst case, a number of trees linear in the number of features. By exploiting a further pruning of the search space, we design a complete procedure for finding d-acceptable feature subsets, which depart by at most d from the best estimated error over any feature subset. Feature subsets with the best estimated error are called best feature subsets. Our results apply to any error estimator function, but experiments are mainly conducted under the wrapper model, in which the misclassification error over a search set is used as an estimator. The approach is also adapted to the design of a computational optimization of the sequential backward elimination heuristic, extending its applicability to large dimensional datasets. The procedures of this paper are implemented in a multi-core data parallel C++ system. We investigate experimentally the properties and limitations of the procedures on a collection of 20 benchmark datasets, showing that oversearching increases both overfitting and instability.

**European Public Procurement Knowledge Graph**

This is the repository where all the work towards the creation of the TheyBuyForYou knowledge graph (KG) will be done. This repository is mostly related to activities that are being done in the context of Work Packages 1 and 2. In this repository we will keep:• Ontology model file that defines the schema for the TBFY knowledge graph.• Python scripts and RML mappings for the data ingestion pipeline developed for onboarding data to the knowledge graph: Python scripts; RML mappings.• Modules with references to related ontologies in the public procurement domain.• Documentation of the knowledge graph schema (ontology) and related services that is being developed.

**AI for Earthquake Damage Modelling**

In April 2015 Nepal was hit by a massive earthquake with a magnitude of 7.8Mw or 8.1Ms and a maximum Mercalli Intensity of VIII (Severe).According to the Nepal open data portal it affected 3,677,173 individuals and 762,106 properties.Post disaster it took years for Nepal to collect and asses the damage which in terms results in one of the world’s largest damage assessment data.After a large scale disaster like earthquake the recovery is generally modeled over two phases• Collection of demographic,architectural and legal data• Damage assessment by domain experts using this large scale and noisy dataBased on aspects of building location and construction, our goal is to predict the level of damage to buildings caused by the 2015 Gorkha earthquake in Nepal.

**Machine Learning for Content Moderation – Introduction**

As the internet’s social platforms, such as Facebook and Twitter, grow in popularity and access, so does the amount of content submitted to them. While the growth of these platforms brings many benefits and allows people to remain connected with each other and collectively organize across the world, it also brings problems such as the propagation of fake news, and online abuse such as cyberbullying. As the legal and social environments surrounding these interaction spaces mature, there is an increasing burden on these companies to police their platforms. They are becoming increasingly responsible for the maintenance and quality of their platforms. However, with billions of users, and millions of messages and photos posted on these platforms, it is impossible for these companies to manually inspect each one. Instead, they typically leverage machine learning systems to automatically parse the content uploaded to their websites. The submissions that are flagged as breaking a rule are then submitted to manual reviewers who provide a final judgment on whether or not that piece of content should be allowed on the site.

**Understanding RNNs by Example**

One of the toughest tasks of becoming a machine learning practitioner is understanding intuitively the magic behind a model. It’s common to believe you need to be a math savant to fully grasp the underlying mechanics, but all you really need is to walk through a few basic examples. Mastering simple models will give you the foundations needed to fall back on as complexity grows. There are a lot of great articles that talk at a high level about how an RNN functions, so I have geared this lesson towards those that are interested in actually implementing a concrete example for themselves. Many of the ideas and illustrations in this article are derived from fast.ai and their course in NLP.

**Training Your Models on Cloud TPUs in 4 Easy Steps on Google Colab**

You have a plain old TensorFlow model that’s too computationally expensive to train on your standard-issue work laptop. I get it. I’ve been there too, and if I’m being honest, seeing my laptop crash twice in a row after trying to train a model on it is painful to watch. In this article, I’ll be breaking down the steps on how to train any model on a TPU in the cloud using Google Colab. After this, you’ll never want to touch your clunky CPU ever again, believe me.

**How to deal with Uncertainty in the era of Deep Learning**

TensorFlow introduces Probabilistic Modeling in the Deep Learning Community. Recently no day goes by without a publication of a new outstanding machine learning application, most likely powered by some deep learning model. Beneath the surface hundreds of thousands of companies applying the same technology to all kinds of different processes. At the latest when it supports critical decision-making, you should think about the degree of certainty that comes with every prediction. We will go through why that is, how to define uncertainty and eventually look at some code examples so that you will be able to apply our findings in your next project.

**Introducing the Plato Research Dialogue System: Building Conversational Applications at Uber’s Scale**

Natural language understanding(NLU) is one of the areas of artificial intelligence(A) that has seen the greatest adoption into mainstream applications. From basic chatbot to sophisticated digital assistants, conversational applications are becoming a common trend in the software industry. Consequently, the market has seen an explosion on the number of tools and platforms that enable the implementation of conversational applications. While the process of building simple, domain-specific chatbots has gotten way easier, building large scale, multi-agent conversational applications remains a massive challenge. Recently, the Uber engineering team open sourced the Plato Research Dialogue System, which is the framework powering conversational agents across Uber’s different applications.

### Like this:

Like Loading...
