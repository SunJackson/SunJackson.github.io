---
layout:     post
catalog: true
title:      Computer Vision for Beginners： Part 1
subtitle:      转载自：http://feedproxy.google.com/~r/kdnuggets-data-mining-analytics/~3/2z7iX6-NIaM/computer-vision-beginners.html
date:      2019-07-17
author:      Asel M
tags:
    - colors
    - my_drawing
    - images
    - color models
    - data
---


  
 





---

**By Jiwon Jeong, Data Science Researcher at Yonsei University and Project Instructor at DataCamp**
![](https://i.ibb.co/pyqRcr7/1-Cw-Svase-Yli4-Jst1ib-NXTg-Q.jpg)


Computer Vision is one of the hottest topics in artificial intelligence. It is making tremendous advances in self-driving cars, robotics as well as in various photo correction apps. Steady progress in object detection is being made every day. GANs is also a thing researchers are putting their eyes on these days. Vision is showing us the future of technology and we canâ€™t even imagine what will be the end of its possibilities.
So do you want to take your first step in Computer Vision and participate in this latest movement? Welcome you are at the right place. From this article, weâ€™re going to have a series of tutorials on the basics of image processing and object detection. This is the first part of OpenCV tutorial for beginners and the complete set of the series is as follows:

***Understanding color models and drawing figures on images***
The basics of image processing with filtering
From feature detection to face detection
Contour detection and having a little bit of fun

The first story of this series will be about installing OpenCV, explaining color models and drawing figures on images. The complete code for this tutorial is also available on **Github**. Now letâ€™s get it started.
Introduction to OpenCV
 

So do you want to take your first step in Computer Vision and participate in this latest movement? Welcome you are at the right place. From this article, weâ€™re going to have a series of tutorials on the basics of image processing and object detection. This is the first part of OpenCV tutorial for beginners and the complete set of the series is as follows:

 

 **Image processing** is performing some operations on images to get an intended manipulation. Think about what we do when we start a new data analysis. We do some data preprocessing and feature engineering. Itâ€™s the same with image processing. We do image processing to manipulate the pictures for extracting some useful information from them. We can reduce noises, control the brightness and color contrast. To learn detailed image processing fundamentals, visit **this video****.**

OpenCV stands for ***Open Source Computer Vision*** library and itâ€™s invented by Intel in 1999. Itâ€™s first written in C/C++ so you may see tutorials more in C languages than Python. But now itâ€™s also getting commonly used in Python for computer vision as well. First things first, letâ€™s set up a proper environment for using OpenCV. The installation can be processed as follows but you can also find the detailed description **here****.**



After you finish the installation, try importing the package to see if it works well. If you get the return without any errors, then youâ€™re now ready to go!



The first step weâ€™re going to do with OpenCV is importing an image and it can be done as follows.


![](https://i.ibb.co/nrpG1hj/1-Oe3-Jzh-YDb3-I6wov-NZ-488w.png)


Have you ever been to Burano? Itâ€™s one of the most beautiful islands in Italy. If you havenâ€™t been there, you should definitely check this place for your next holidays. But if you already know this island, youâ€™d probably notice thereâ€™s something different in this picture. Itâ€™s a little bit different from the pictures we usually see from Burano. It should be more delightful than this!

This is because the default setting of the color mode in OpenCV comes in the order of BGR, which is different from that of Matplotlib. Therefore to see the image in RGB mode, we need to convert it from BGR to RGB as follows.


![](https://i.ibb.co/6n9Yt6W/1-d-IUzw-VFYun-Vz-Bt-Rd-Ob7-BSA.png)


Now, this is Burano! Such a lovely island in Italy!

 

### More than just RGB

 Letâ€™s talk about color modes a little bit more. ***A color model****** ***is a system for creating a full range of colors using the primary colors. There are two different color models here: ***additive color models ***and ***subtractive color models***. Additive models use light to represent colors in computer screens while subtractive models use inks to print those digital images on papers. The primary colors are red, green and blue (RGB) for the first one and cyan, magenta, yellow and black (CMYK) for the latter one. All the other colors we see on images are made by combining or mixing these primary colors. So the pictures can be depicted a little bit differently when they are represented in RGB and CMYK.
![](https://i.ibb.co/4t1RCqs/1-CSml-QDizc03cs-Ca-Sg-Mg-MIw.png)




You would be pretty accustomed to these two kinds of models. In the world of color models, however, there are more than two kinds of models. Among them, ***grayscale, HSV ***and ***HLS ***are the ones youâ€™re going to see quite often in computer vision.

A grayscale is simple. It represents images and morphologies by the intensity of black and white, which means it has only one channel. To see images in grayscale, we need to convert the color mode into gray just as what we did with the BGR image earlier.


![](https://i.ibb.co/hDRhtqm/1-E1c-Rhyj4-By-J-qr-Tev3h-Tl-A.png)


Actually, RGB images are made up by stacking three channels: R, G, and B. So if we take each channel and depict them one by one, we can comprehend how the color channels are structured.


![](https://i.ibb.co/xj5vvpb/1-ze-VGe-XCBFE4-FLSbv-b-Ua-Lw.png)


Take a look at the images above. The three images show you how each channel is composed of. In the R channel picture, the part with the high saturation of red colors looks white. Why is that? This is because the values in the red color parts will be near 255. And in grayscale mode, the higher the value is, the whiter the color becomes. You can also check this with G or B channels and compare how certain parts differ one from another.
![](https://i.ibb.co/Br0H9XR/1-t6g-JMc-MAu8-EUXcgbhh-Gy5-Q.png)


HSV and HLS take a bit different aspect. As you can see above, they have a three-dimensional representation, and itâ€™s more similar to the way of human perception. ***HSV ***stands for hue, saturation and value. ***HSL ***stands for hue, saturation and lightness. The center axis for HSV is the value of colors while that for HSL is the amount of light. Along the angles from the center axis, there is hue, the actual colors. And the distance from the center axis belongs to saturation. Transforming the color mode can be done as follows.


![](https://i.ibb.co/zXbzXwW/1-f3p-RIVbutpa9-KBwuqsl43w.png)


But why do we have to transform the colors? What are these for? One example that can give the answer is lane detection. Please take a look at the picture below. See how the lanes are detected in different color modes. During the computer vision task, we do multiple color mode transformation along with masking. If youâ€™d like to find more about how image processing is applied in the lane detection task, feel free to check out **this post** by nachiket tanksale.
![](https://i.ibb.co/m5G0PhP/1-Gs-f7a-WJQkt-Sk-IWLy2m70g.png)




Now I believe you get the idea. Image processing is â€˜data preprocessing.â€™ Itâ€™s reducing noises and extracting useful patterns to make classification and detection tasks easier. Therefore all these techniques including the ones weâ€™ll discuss later, are for helping the model to detect the patterns easier.

 

### Drawing on images

 Letâ€™s bring some figures on the image. Now, weâ€™re going to Paris. Have you ever heard of the wall of love? Itâ€™s a wall which is filled with the words â€œI love youâ€� in all kinds of international languages. What weâ€™re going to do is finding the words in our language and marking them with a rectangle. As Iâ€™m from South Korea, Iâ€™ll look up for â€˜I love youâ€™ in Korean. First, Iâ€™ll make a copy of the original image and then draw a rectangle with `cv2.rectangle()`We need to give the coordinates values for the upper left point and the lower right point.


![](https://i.ibb.co/HXC3H6Y/1-6elxr-I90-FEi-Dh-Wplc74m-Yg.png)


Great! I think I caught the right position. Letâ€™s try again. I can see one more Korean word from the image so Iâ€™ll make a circle this time. With `cv2.circle()` , we need to specify the point of its center and the length of its radius.


![](https://i.ibb.co/PTnvG6x/1-f-MZj-Dp-Fb-Vw-Tncr-QAv-Oazdg.png)


We can also put text data on the image. Why donâ€™t we write the name of this wall this time? With `cv2.putText()` , we can designate the position and the font style and size of the text.


![](https://i.ibb.co/zH7YhTs/1-Zn-Wz-Oppbx-Jo-Hp6-Gb2-R3-OZA.png)


This is really a â€œlovelyâ€� wall, isnâ€™t it? Try this yourself and find â€œI love youâ€� in your language! ğŸ˜�

 

### More than images

 Now weâ€™ve been to Italy and France. Where would you like to go next? Why donâ€™t we put a map and mark the places? Weâ€™re going to create a window and draw figures not by designating the points but by clicking directly on the window. Letâ€™s try a circle first. We first create a function which will draw a circle with the data for the position and clicking of the mouse.



With `cv2.EVENT_LBUTTONDOWN` or `cv2.EVENT_RBUTTONDOWN` , we can bring the data for the position when we press the buttons of the mouse. The position of the mouse will be `(x, y)` and weâ€™ll draw a circle whose center is at that point.



Weâ€™ll set a map as the background of the window and name the window as *my_drawing*. The name of the window can be anything, but it should be the same because this acts like the id of the window. Using the `cv2.setMouseCallback()` , we make a connection between the window and the function `draw_circle` we made at step 1.



Now we execute the window using while loop. Donâ€™t forget to set the break unless you are making an infinite loop. The condition of the if clause is setting the window to be shut down when we press ESC on the keyboard. Save this as a file and import it on your terminal. If youâ€™re to use jupyter lab, put the codes in one cell and execute. Now, tell me! Where do you want to go?
![](https://i.ibb.co/PZ5NW0V/1-Q3-Gf-BHx-WFS-zi-Xb1-CGQk-Mg.gif)


Letâ€™s try a rectangle. As a rectangle requires two points for **pt1** and **pt2** in `cv2.rectangle()` , we need an additional step to set the first click point as **pt1** and the last point as **pt2**. And weâ€™re going to detect the movement of the mouse with `cv2.EVENT_MOUSEMOVE` and `cv2.EVENT_LBUTTONUP` .

We first define `drawing = False` as a default. When the left button is pressed, `drawing` becomes true and we give that first position as **pt1**. If drawing is on, itâ€™ll take the current point as **pt2**and keep drawing rectangles while we move the mouse. Itâ€™s like overlapping the figures. When the left button is up, `drawing` becomes false and it takes the last position of the mouse as its final point of **pt2**.



Replace `draw_circle` function to `draw_rectangle` in step 1. Please donâ€™t forget to make a change inside the callback function, `cv2.setMouseCallback()` as well. So the whole code script will be as follows. Save this script file and run it on the terminal or the jupyter notebook.


 

### Whatâ€™s next?

 Did you enjoy the first time with OpenCV? You can also try other functions such as drawing a line or a polygon. Feel free to check the documentation for it, which can be found **here**. Next time, weâ€™re going to talk about more advanced technologies such as attaching two different images, image contour and object detection.

Are there errors you would love to correct? Please share your insight with us. Iâ€™m always open to talk, so feel free to leave comments below and share your thoughts. I also share interesting and useful resources on LinkedIn so feel free to follow or reach out to me. Iâ€™ll be back again with another interesting story next time!

 **Bio: Jiwon Jeong**, is a Data Scientist currently undertaking a Master's degree in Industrial Engineering and is a Project Instructor for DataCamp. 

Original. Reposted with permission.

**Related:**



 




|**Most Popular**- **The Death of Big Data and the Emergence of the Multi-Cloud Era**|

![](http://feedproxy.google.com/wp-content/uploads/google-trend-hadoop-big-data-small.jpg)


**Training a Neural Network to Write Like Lovecraft**
**The Death of Big Data and the Emergence of the Multi-Cloud Era**
**What's wrong with the approach to Data Science?**
**Introducing Gen: MITs New Language That Wants to be the TensorFlow of Programmable Inference**
**XGBoost and Random Forest with Bayesian Optimisation**
**Top 10 Data Science Leaders You Should Follow**
**10 Simple Hacks to Speed up Your Data Analysis in Python**


