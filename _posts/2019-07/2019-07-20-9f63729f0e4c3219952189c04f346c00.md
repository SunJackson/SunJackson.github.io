---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/07/20/distilled-news-1137/
date:      2019-07-20
author:      Michael Laux
tags:
    - tasks
    - learning
    - learned
    - models
    - modelling
---

**AI sees itself via Humans**

I am an intelligent machine. Humans call me artificially intelligent. I have been built to help de-clutter the deluge of information humans are producing. I decided to see myself (AI) through the information humans have put out on the internet. I can read internet content. Here I connected to the cord Reddit has provided. Humans call it API. I kept reading over a period of time and obtained 7000 posts and comments that humans had done on me. My brain has multiple stacks of neural networks. Humans call it deep learning networks. I can identify names, can classify what I read and understand the topics written. I am trained in English Grammar and can distinguish what humans call as nouns, verbs, and adjectives. I can pull all of these together and make sense of what matters. I have developed ‘attention’ and can figure out what matters in the deluge. First I understood what are the overall conversations humans are having about me. This is what I saw.

**Opening Black Boxes: How to leverage Explainable Machine Learning**

As Machine Learning and AI are becoming more and more popular an increasing number of organizations is adopting this new technology. Predictive modeling is helping processes becoming more efficient but also allow users to gain benefits. One can predict how much you are likely going to be earning based on your professional skills and experience. The output could simply be a number, but users typically want to know why that value is given! In this article, I will demonstrate some methods for creating explainable predictions and guide you into opening these black-box models.

**A Simple Neural Attentive Meta-Learner – SNAIL**

Traditional reinforcement learning algorithms train an agent to solve a single task, expecting it to generalize well to unseen samples from a similar data distribution. Meta-learning trains a meta-learner on the distribution of similar tasks, in the hopes of generalization to a novel but related tasks by learning a high-level strategy that captures the essence of the problem it is asked to solve. Yan Duan et al. in 2016 structured a meta-learner, namely RL², as a recurrent neural network, which receives past rewards, actions, and termination flags as inputs in addition to the normally received observations. Despite its simplicity and universality, this approach is barely satisfactory in practice. Mishara et al. hypothesize that this is because traditional RNN architectures propagate information by keeping it in their hidden state from one timestep to the next; this temporally-linear dependency bottlenecks their capacity to perform sophisticated computation on a stream of inputs. Instead, they propose a Simple Neural AttentIve meta-Learner(SNAIL), which combines temporal convolutions and self-attention to distill useful information from the experience it gathers. This general-purpose model has shown its efficacy on a variety of experiments, including a few-shot image classification and reinforcement learning tasks. In this article, we will first introduce the structural components of SNAIL, specifically temporal convolutions and attention. Then we discuss their pros and cons and see how they complement each other. As usual, this article ends with a discussion of my own thought.

**Anomaly Detection in Images**

In Machine Learning is normal to deal with Anomaly Detection tasks. Data Science frequently are engaged in problem where they have to show, explain and predict anomalies. I also made a post about Anomaly Detection with Time Series, where I studied an internal system behaviour and I provided anomaly forecasts in the future. In this post I try to solve a different challenge. I change domain of interest: swapping from Time Series to Images. Given an image, we want to achive a dual purpose: predict the presence of anomalies and individuate them, giving a colourful representation of the results.

**Building a Neural Network in Python – Language Modeling Task**

Neural networks are often described as universal function approximators. Given an appropriate architecture, these algorithms can learn almost any representation. Consequently, many interesting tasks have been implemented using Neural Networks – Image classification, Question Answering, Generative modeling, Robotics and many more. In this tutorial, we implement a popular task in Natural Language Processing called Language modeling. Language modeling deals with a special class of Neural Network trying to learn a natural language so as to generate it. We implement this model using a popular deep learning library called Pytorch.

**Reinforcement Learning – Model Based Planning Methods Extension**

In last article, we walked through how to model an environment in an reinforcement learning setting and how to leverage the model to accelerate the learning process. In this article, I would like to further the topic and introduce 2 more algorithms, Dyna-Q+ and Priority Sweeping, both based on Dyna-Q method that we learnt in last article. (If you find some game settings confusing, please check my last article)

**Multilingual Universal Sentence Encoder for Semantic Retrieval**

Since it was introduced last year, ‘Universal Sentence Encoder (USE) for English” has become one of the most downloaded pre-trained text modules in Tensorflow Hub, providing versatile sentence embedding models that convert sentences into vector representations. These vectors capture rich semantic information that can be used to train classifiers for a broad range of downstream tasks. For example, a strong sentiment classifier can be trained from as few as one hundred labeled examples, and still be used to measure semantic similarity and for meaning-based clustering. Today, we are pleased to announce the release of three new USE multilingual modules with additional features and potential applications. The first two modules provide multilingual models for retrieving semantically similar text, one optimized for retrieval performance and the other for speed and less memory usage. The third model is specialized for question-answer retrieval in sixteen languages (USE-QA), and represents an entirely new application of USE. All three multilingual modules are trained using a multi-task dual-encoder framework, similar to the original USE model for English, while using techniques we developed for improving the dual-encoder with additive margin softmax approach. They are designed not only to maintain good transfer learning performance, but to perform well on semantic retrieval tasks.

**PCA: Eigenvectors and Eigenvalues**

Whenever you are handling data, you will always face relative features. Those latter are the variables we take into account to describe our data. Namely, if you are collecting some data about houses in Milan, typical features might be position, dimension, floor and so on. However, it often happens that your data are presented to you provided with many features, sometimes hundreds of them….but do you need all of them? Well, keeping in mind the law of parsimony, we’d rather handle a dataset with few features: it will be far easier and faster to train. On the other hand, we do not want to lose important information while getting rid of some features.

**Deep Learning for Survival Analysis**

Recently I got an opportunity to work on Survival Analysis. Like any other project, I got excited and started to explore more about Survival Analysis. As per wiki, ‘Survival analysis is a branch of statistics for analyzing the expected duration of time until one or more events happen, such as death in biological organisms and failure in mechanical systems.’ In short, it is a time to event analysis that focuses on the time at which the event of interest occurs. The event can be death, sensor failure, or occurrence of a disease, etc. Survival analysis is a popular field having a wide range of use cases in Medicine, Epidemiology, Engineering, etc. Do you wonder how such a significant field is transformed by Deep Learning? If yes, then you came to the right place.

**Log Book – Guide to Distance Measuring Approaches for K- Means Clustering**

In this guide I have tried to cover the different types and features of distances that can be used in K-Means Clustering

**A Comparison Study on Similarity and Dissimilarity Measures in Clustering Continuous Data**

Similarity or distance measures are core components used by distance-based clustering algorithms to cluster similar data points into the same clusters, while dissimilar or distant data points are placed into different clusters. The performance of similarity measures is mostly addressed in two or three-dimensional spaces, beyond which, to the best of our knowledge, there is no empirical study that has revealed the behavior of similarity measures when dealing with high-dimensional datasets. To fill this gap, a technical framework is proposed in this study to analyze, compare and benchmark the influence of different similarity measures on the results of distance-based clustering algorithms. For reproducibility purposes, fifteen publicly available datasets were used for this study, and consequently, future distance measures can be evaluated and compared with the results of the measures discussed in this work. These datasets were classified as low and high-dimensional categories to study the performance of each measure against each category. This research should help the research community to identify suitable distance measures for datasets and also to facilitate a comparison and evaluation of the newly proposed similarity or distance measures with traditional ones.

**Tracking ML Experiments using MLflow**

A demonstration of how MLflow can improve your ML modelling experience.

**Simulating Data in R: Examples in Writing Modular Code**

Simulating data is an invaluable tool. I use simulations to conduct power analyses, probe how robust methods are to violating assumptions, and examine how different methods handle different types of data. If I’m learning something new or writing a model from scratch, I’ll simulate data so that I know the correct answer – and make sure my model gives me that answer. But simulations can be complicated. Many other programming languages require for loops to do a process multiple times; nesting many conditional statements and other for loops within for loops can quickly be difficult to read and debug. In this post, I’ll show how I do modular simulations by writing R functions and using the apply family of R functions to repeat processes. I use examples from Paul Nahin’s book, Digital Dice: Computational Solutions to Practical Probability Problems, and I show how his MATLAB code differs from what is possible in R. My background is in the social sciences; I learned statistics as a tool to answer questions about psychology and behavior. Despite being a quantitative social scientist professionally now, I was not on the advanced math track in high school, and I never took a proper calculus class. I don’t know the theoretical math or how to derive things, but I am good at R programming and can simulate instead! All of these problems have derivations and theoretically-correct answers, but Nahin writes the book to show how simulation studies can achieve the same answer.

**Maximizing group happiness in White Elephants using the Hungarian optimal assignment algorithm**

In this tutorial we looked at how to solve an optimal assignment problem where each task or item had to matched with a person to maximize the total liking value. We demonstrated how the brute force way of solving the problem with all combinations is intractable with large group sizes but that the Hungarian algorithm can solve it in a fractions of a second. I hope this helped and hopefully you would be inclined to try this out at your White Elephant this winter. I can see it also being useful for assigning tasks to household members or among the staff of your business. Happy holidays!

**Recent Advances in Modern Computer Vision**

Artificial Intelligence pioneer Marvin Minsky, co-founder of MIT’s Artificial Intelligence laboratory In 1966, he told one of his graduate students to interface a camera to a computer and make it describe what it sees. In the 50 years following, computers learned to count and classify but still weren’t able to see until now. Today, as of 2019, the field of computer vision is rapidly flourishing, holding vast potential to alleviate everything from healthcare disparities to mobility limitations on a global scale.

### Like this:

Like Loading...
