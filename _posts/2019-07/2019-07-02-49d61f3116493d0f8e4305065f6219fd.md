---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/07/03/distilled-news-1119/
date:      2019-07-02
author:      Michael Laux
tags:
    - data
    - models
    - learning
    - speech
    - management
---

**Neural Network Optimization**

Covering optimizers, momentum, adaptive learning rates, batch normalization, and more.

**Feature Importance with Neural Network**

One of the best challenge in Machine Learning tends to let model speak them self. Not also is important to develop a strong solution with great predicting power, but also in lot of business applications is interesting to know how the model provides these results: which variables are engage the most, the presence of correlations, the possible causation relationships and so on. These needs made Tree based model a good weapon in this field. They are scalable and permits to compute variable explanation very easy. Every software provide this option and each of us has at least once tried to compute the variable importance report with Random Forest or similar. With Neural Net this kind of benefit is considered as taboo. Neural Network are often seen as black box, from which is very difficult to extract usefull information for other purpose like feature explatations. In this post I try to provide an elegant and clever solution, that with few lines of codes, permits you to squeeze your Machine Learnig Model and extract as much information as possible, in order to provide feature importance, individuate the significant correlations and try to explain causation.

**Kubeflow Components and Pipelines**

I want to keep things simple therefore we cover components, pipelines and experiments. With pipelines and components, you get the basics which are required to build ML workflows. There are many more tools integrated into Kubeflow and I will cover them in the upcoming posts. Kubeflow is originated at Google.

**How To Build A Speech Recognition Bot With Python**

You may have realized something now. The overwhelming success of speech-enabled products like Amazon Alexa has proven that some degree of speech support will be an essential aspect of household technology for the foreseeable future. In other words, speech-enabled products would be a game changer as that offer a level of interactivity and accessibility that few technologies can match.

**How to Apply Self-Supervision to Tabular Data: Introducing dfencoder**

Denoising autoencoders for the everyday data scientist.

**Data Mining for Sustainable Data Management**

In the rapidly expanding technological world of today, when smartphones, tablets, PCs have become an inseparable part of the human life, it is the quintessential philosophy that the power of information and data is realized. Today, as we live in the ‘information age’, the data volumes are exploding; more data has been created in the past two years than in the entire previous history of the human race. The enormous potential that lies behind data analytics and data mining, the future has to imbibe the implementation of data mining techniques for sustainable data management.

**Model Selection, Tuning and Evaluation in K-Nearest Neighbors**

The core of the Data Science lifecycle is model building. Although relatively unsophisticated, a model called K-nearest neighbors, or KNN when acronymified, is a solid way to demonstrate the basics of the model making process …from selection, to hyperparameter optimization and finally evaluation of accuracy and precision (however, take the importance of accuracy with a grain of salt). If Occam’s Razor has taught us anything, it’s that simplicity is not a bad thing, so let’s dive into looking at an algorithm that is often a component in building other models in Machine Learning which are quite sophisticated.

**What is Out of Bag (OOB) score in Random Forest?**

This blog attempts to explain the internal functioning of oob_score when it is set as true in the ‘RandomForestClassifier’ in ‘Scikit learn’ framework. This blog describes the intuition behind the Out of Bag (OOB) score in Random forest, how it is calculated and where it is useful.

**The Wild & Wonderful World Of A/B Testing**

In the dark and distant past, when our design ancestors – the cave painters, the illuminated manuscript doodlers, the church muralists, the stained glass artisans, the poster printers, the annual report elitist, the cyber pixel-pushers – lived in a world where the design profession was regulated to the dark corners of subjectivity, between art and marketing, between personal perception and emotion. Designers were haunted by the painfully unhelpful phrases uttered by clients, such as ‘I’ll know it when I see it’, ‘This doesn’t pop’, or ‘Could you make the logo bigger?’.

**Principled Machine Learning: Practices and Tools for Efficient Collaboration**

Machine learning projects are often harder than they should be. We’re dealing with data and software, and it should be a simple matter of running the code, iterating through some algorithm tweaks, and after a while we have a perfectly trained AI model. But fast forward three months later, the training data might have been changed or deleted, and the understanding of training scripts might be a vague memory of which does what. Have you created a disconnect between the trained model and the process to create the model? How do you share work with colleagues for collaboration or replicating your results? As is true for software projects in general, what’s needed is better management of code versions and project assets. One might need to revisit the state of the project as it was at any stage in the past. We do this (review old commits) in software engineering all the time. Shouldn’t a machine learning project also need to occasionally do the same? It’s even more than that. What about the equivalent of a Pull Request, or other sorts of team management practices routinely used in other fields?

**All you need to know about NLP Text Preprocessing**

Text preprocessing is a severely overlooked topic and a lot of NLP applications fail badly due to use of the wrong kind of text preprocessing.

**Conceptualizing the Knowledge Graph Construction Pipeline**

The advent of the internet has granted access to a large number of content creators to generate information. Owing to this, there is a massive amount of data that is now present on the web. In order to provide useful insights, we need an efficient way to represent all this data. One such efficient knowledge representation method is via knowledge graphs. In brief, a knowledge graph is a large network of interconnected data. Knowledge graphs are constructed from knowledge bases. Knowledge bases gather their information from free text on web pages, databases, and audio and video content.

**The Logic behind the Probabilistic Soft Logic**

Following up on my previous blog post on the ‘High Level Overview of the Probabilistic Soft Logic’, we’ll be looking at the core of PSL.

**A High Level Overview of the Probabilistic Soft logic**

Since early times, data and information have become the pivot of evolution, whether this data be documented or passed down by word. And with the advent of the internet, data generation has escalated, producing numerous amounts of data. This mass generation of data has made it harder to maintain and pass down all the elements of a piece of information without losing its value or content elements. So in order to comprehend and extract valuable information from data, machine learning algorithms have been applied applied for data analysis.

### Like this:

Like Loading...
