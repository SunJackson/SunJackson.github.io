---
layout:     post
catalog: true
title:      Ten more random useful things in R you may not know about
subtitle:      转载自：http://feedproxy.google.com/~r/kdnuggets-data-mining-analytics/~3/0FjDbzeMtbM/ten-more-random-useful-things-r.html
date:      2019-07-31
author:      Asel M
tags:
    - get_chart
    - functions
    - xml
    - dplyr
    - sql
---

**By Keith McNulty, McKinsey & Company**

I was surprised by the positive reaction to my article a couple of months agowhich itemized ten random things in R that people might not know about.

I had a feeling that R has developed as a language to such a degree that many of us are using it now in completely different ways. This means that there are likely to be numerous tricks, packages, functions, etc that each of us use, but that others are completely unaware of, and would find useful if they knew about them. As Mike Kearney also pointed out, none of my list of ten had anything to do with stats, which just shows how far R has come in recent years.

To be honest, I struggled to keep it to ten last time, so here are ten more things about R that help make my work easier and which you might find useful. Do drop a note here or on Twitter if any of these helpful to your current work, or if you have further suggestions for things which others should know about.

 

### 1. dbplyr

 

`dbplyr` is exactly what its name implies. It allows you use `dplyr` with databases. If you work with databases and you’ve never heard of `dbplyr` then you are likely still using SQL strings in your code, which forces you to think SQL when you actually want to think tidy, and can be a real pain when you want to abstract your code to generate functions and the like.

`dbplyr` allows you to create your SQL query using `dplyr`. It does this by establishing a database table that can be manipulated using `dplyr` functions, translating those functions into SQL. For example, if you have a database connection called `con`, and you want to manipulate a table called `CAT_DATA`within `CAT_SCHEMA` you can set this table up as:



Then you can perform the usual manipulations such as `filter`, `mutate`, `group_by`, `summarise` etc on `cat_table` and all of these will be translated into a SQL query in the background. What’s incredibly useful is that the data is not physically downloaded into your R session until you use the `dplyr::collect()`function to finally grab it. This means you can get SQL to do all the work and collect your manipulated data at the end, rather than having to pull the entire database at the beginning.

For more on `dbplyr` you can check my previous article here and the tutorial here.

 

### 2. rvest and xml2

 People say Python is much better for web scraping. That may be true. But for those of us who like working in the tidyverse, the `rvest` and `xml2` packages can make straightforward web scraping pretty easy by working with `magrittr` and allowing us to pipe commands. Given that HTML and XML code on webpages is usually heavily nested, I think its pretty intuitive to structure scraping code using `%>%`.

By initially reading the HTML code of the page of interest, these packages break the nested HTML and XML nodes into lists that you can progressively search and mine for specific nodes or attributes of interest. Using this in combination with Chrome’s inspect capability will allow you to quickly extract the key information you need from the webpage.

As a quick example, I recently wrote a function to scrape the basic Billboard music chart at any point in history as a dataframe from this fairly snazzy pageusing code as simple as this:



More on this example here, more on `rvest` here and more on `xml2` here.

 

### 3. k-means on long data

 k-means is an increasingly popular statistical method to cluster observations in data, often to simplify a large number of datapoints into a smaller number of clusters or archetypes. The `kml` package now allows k-means clustering to take place on longitudinal data, where the ‘datapoints’ are actually data series.

This is super useful where the datapoints you are studying are actually readings over time. This could be clinical observation of weight gain or loss in hospital patients, or compensation trajectories of employees.

`kml` works by first transforming data into an object of the class `ClusterLongData`using the `cld` function. Then it partitions the data using a ‘hill climbing’ algorithm, testing several values of `k` 20 times each. Finally, the `choice()`function allows you to view the results of the algorithm for each `k` graphically and decide what you believe to be an optimal clustering.

 

### 4. The connections window in RStudio

 The connections window in the latest version of RStudio allows you to browse any remote databases without having to move into a separate environment like SQL developer. This convenience now offers the opportunity to fulfil dev projects entirely within the RStudio IDE.

By setting up your connection to a remote database in the connections window, you can browse inside nested schemas, tables, data types, and even view a table directly to see an extract of what the data looks like.
