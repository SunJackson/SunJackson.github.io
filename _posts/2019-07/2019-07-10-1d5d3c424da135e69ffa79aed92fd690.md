---
layout:     post
catalog: true
title:      Guest post by Julien Mairal： A Kernel Point of View on Convolutional Neural Networks, part I
subtitle:      转载自：https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/
date:      2019-07-10
author:      Sebastien Bubeck
tags:
    - kernels
    - learning
    - learned
    - kernel methods
    - networks
---

 

![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/kernel_fig.jpg?resize=646%2C368&ssl=1)


 

I (*n.b., Julien Mairal*) have been interested in drawing links between neural networks and kernel methods for some time, and I am grateful to Sebastien for giving me the opportunity to say a few words about it on his blog. My initial motivation was not to provide another “why deep learning works” theory, but simply to encode into kernel methods a few successful principles from convolutional neural networks (CNNs), such as the ability to model the local stationarity of natural images at multiple scales—we may call that modeling receptive fields—along with feature compositions and invariant representations. There was also something challenging in trying to reconcile end-to-end deep neural networks and non-parametric methods based on kernels that typically decouple data representation from the learning task.

The main goal of this blog post is then to discuss the construction of a particular multilayer kernel for images that encodes the previous principles, derive some invariance and stability properties for CNNs, and also present a simple mechanism to perform feature learning in reproducing kernel Hilbert spaces. In other words, we should not see any intrinsic contradiction between kernels and representation learning.

**Preliminaries on kernel methods**

Given data living in a set ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e44d6dd2d58e906a7f3ec11d7f3cac9c_l3.png?resize=15%2C12&ssl=1)
, a positive definite kernel ![](https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f0d19a1401658006e20eb7aff7c20689_l3.png?resize=124%2C13&ssl=1)
 implicitly defines a Hilbert space ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d8c7ae0e5e08bd1b3f5ef053720bf142_l3.png?resize=15%2C12&ssl=1)
 of functions from ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e44d6dd2d58e906a7f3ec11d7f3cac9c_l3.png?resize=15%2C12&ssl=1)
 to ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b2c3c459eddec9847f841b19a2274a3d_l3.png?resize=13%2C12&ssl=1)
, called reproducing kernel Hilbert space (RKHS), along with a mapping function ![](https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-075eb9a40ac7f19fc1d24932d430cf57_l3.png?resize=84%2C16&ssl=1)
.

A predictive model ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&ssl=1)
 in ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d8c7ae0e5e08bd1b3f5ef053720bf142_l3.png?resize=15%2C12&ssl=1)
 associates to every point ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&ssl=1)
 a label in ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b2c3c459eddec9847f841b19a2274a3d_l3.png?resize=13%2C12&ssl=1)
, and admits a simple form ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-af2242f529038b9f66bdd803a7fcf32d_l3.png?resize=138%2C19&ssl=1)
. Then, Cauchy-Schwarz inequality gives us a first basic stability property

     ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ba1f97e9889116f67e3caf7d27f6dca2_l3.png?resize=418%2C21&ssl=1)


This relation exhibits a discrepancy between neural networks and kernel methods. Whereas neural networks optimize the data representation for a specific task, the term on the right involves the product of two quantities where data representation and learning are decoupled:

![](https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9b7eefc0051c0b86a82ee0265f44a085_l3.png?resize=125%2C19&ssl=1)
 is a distance between two data representations ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-41c6c60616e1acea2bdd02deee51011e_l3.png?resize=83%2C18&ssl=1)
, which are independent of the learning process, and ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c755a8a9349d0895075e9494d1b11fc1_l3.png?resize=38%2C19&ssl=1)
 is a norm on the model ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&ssl=1)
 (typically optimized over data) that acts as a measure of complexity.

Thinking about neural networks in terms of kernel methods then requires defining the underlying representation ![](https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eb419c2adecf84ed9a2d9693bc58d101_l3.png?resize=35%2C18&ssl=1)
, which can only depend on the network architecture, and the model ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&ssl=1)
, which will be parametrized by (learned) network’s weights.

**Building a convolutional kernel for convolutional neural networks**

Following Alberto Bietti’s paper, we now consider the direct construction of a multilayer convolutional kernel for images. Given a two-dimensional image ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-55b536a6647748d6c0c6b58015805c68_l3.png?resize=17%2C11&ssl=1)
, the main idea is to build a sequence of “feature maps” ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4e504020251e8444e8047821206317fa_l3.png?resize=71%2C12&ssl=1)
 that are two-dimensional spatial maps carrying information about image neighborhoods (a.k.a receptive fields) at every location. As we proceed in this sequence, the goal is to model larger neighborhoods with more “invariance”.

Formally, an input image ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-55b536a6647748d6c0c6b58015805c68_l3.png?resize=17%2C11&ssl=1)
 is represented as a square-integrable function in ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b1cdcac953d52ed35e77925a243c3df7_l3.png?resize=76%2C19&ssl=1)
, where ![](https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec0c546b6596f336d8e1d41bb064b951_l3.png?resize=12%2C12&ssl=1)
 is a set of pixel coordinates, and ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c58a47e1230e20fa0f090bbe6e111ba7_l3.png?resize=22%2C15&ssl=1)
 is a Hilbert space. ![](https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec0c546b6596f336d8e1d41bb064b951_l3.png?resize=12%2C12&ssl=1)
 may be a discrete grid or a continuous domain such as ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5abe0f29e8cc710ae26f4f0af5a0859_l3.png?resize=20%2C15&ssl=1)
, and ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c58a47e1230e20fa0f090bbe6e111ba7_l3.png?resize=22%2C15&ssl=1)
 may simply be ![](https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-97886402213f48c46e631e5331a34035_l3.png?resize=20%2C15&ssl=1)
 for RGB images. Then, a feature map ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ad23c5c360c3f33031a5d000d37416f_l3.png?resize=17%2C11&ssl=1)
 in ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-66fdb69a62e8ec8647eac89f54998a71_l3.png?resize=77%2C19&ssl=1)
 is obtained from a previous layer ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&ssl=1)
 as follows:

Formally, the previous construction amounts to applying operators ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4726bbf70431cf284be54bbc6a04ad60_l3.png?resize=18%2C15&ssl=1)
 (patch extraction), ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78f07026bc8c5150a11bf9e00756b7a7_l3.png?resize=24%2C15&ssl=1)
 (kernel mapping), and ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-866de181a59a21d2ca2306a9adbd9bc1_l3.png?resize=20%2C15&ssl=1)
 (smoothing/pooling operator) to ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&ssl=1)
 such that the ![](https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&ssl=1)
-th layer representation can be written as

     ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e8c2d99cc679426d1af08e6d15510211_l3.png?resize=437%2C21&ssl=1)


We may finally define a kernel for images as ![](https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-16be084d5dd2ed3d7a18cdcf70c33fe2_l3.png?resize=231%2C19&ssl=1)
, whose RKHS contains the functions ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-95aa9a4388dd5f5da6292875abe6596a_l3.png?resize=162%2C19&ssl=1)
 for ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&ssl=1)
 in ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-502d385c60e5ecdb1a0f26ee770d30b1_l3.png?resize=77%2C19&ssl=1)
. Note now that we have introduced a concept of image representation ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&ssl=1)
, which only depends on some network architecture (amounts of pooling, patch size), and predictive model ![](https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-fb636251e88ba51d909c76c1110eed5e_l3.png?resize=19%2C16&ssl=1)
 parametrized by ![](https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&ssl=1)
.

From such a construction, we will now derive stability results for classical convolutional neural networks (CNNs) and then derive non-standard CNNs based on kernel approximations that we call convolutional kernel networks (CKNs).

 

Next week, we will see how to perform feature (end-to-end) learning with the previous kernel representation, and also discuss other classical links between neural networks and kernel methods.


 
