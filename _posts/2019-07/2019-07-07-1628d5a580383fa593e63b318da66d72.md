---
layout:     post
catalog: true
title:      Sampling paths from a Gaussian process
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/Wpi4r_casho/
date:      2019-07-07
author:      kjytay
tags:
    - functions
    - kernels
    - lengths
    - sigma
    - kernel_fn
---





***Gaussian processes*** are a widely employed statistical tool because of their flexibility and computational tractability. (For instance, one recent area where Gaussian processes are used is in machine learning for hyperparameter optimization.)

A stochastic process ![](https://s0.wp.com/latex.php?latex=%5C%7B+X_t+%5C%7D_%7Bt+%5Cin+%5Cmathbb%7BI%7D%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5C%7B+X_t+%5C%7D_%7Bt+%5Cin+%5Cmathbb%7BI%7D%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is a Gaussian process if (and only if) any finite subcollection of random variables ![](https://s0.wp.com/latex.php?latex=%28X_%7Bt_1%7D%2C+%5Cdots%2C+X_%7Bt_n%7D%29&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%28X_%7Bt_1%7D%2C+%5Cdots%2C+X_%7Bt_n%7D%29&bg=ffffff&%23038;fg=333333&%23038;s=0)
 has a multivariate Gaussian distribution. Here, ![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BI%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BI%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is the index set for the Gaussian process; most often we have ![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BI%7D+%3D+%5B0%2C+%5Cinfty%29&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BI%7D+%3D+%5B0%2C+%5Cinfty%29&bg=ffffff&%23038;fg=333333&%23038;s=0)
 (to index time) or ![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BI%7D+%3D+%5Cmathbb%7BR%7D%5Ed&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BI%7D+%3D+%5Cmathbb%7BR%7D%5Ed&bg=ffffff&%23038;fg=333333&%23038;s=0)
 (to index space).

The stochastic nature of Gaussian processes also allows it to be thought of as a distribution over functions. One draw from a Gaussian process over corresponds to choosing a function ![](https://s0.wp.com/latex.php?latex=f%3A+%5Cmathbb%7BI%7D+%5Cmapsto+%5Cmathbb%7BR%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=f%3A+%5Cmathbb%7BI%7D+%5Cmapsto+%5Cmathbb%7BR%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)
 according to some probability distribution over these functions.

Gaussian processes are defined by their mean and covariance functions. The covariance (or kernel) function ![](https://s0.wp.com/latex.php?latex=K%3A+%5Cmathbb%7BI%7D+%5Ctimes+%5Cmathbb%7BI%7D+%5Cmapsto+%5Cmathbb%7BR%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=K%3A+%5Cmathbb%7BI%7D+%5Ctimes+%5Cmathbb%7BI%7D+%5Cmapsto+%5Cmathbb%7BR%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is what characterizes the shapes of the functions which are drawn from the Gaussian process. ***In this post, we will demonstrate how the choice of covariance function affects the shape of functions it produces.*** For simplicity, we will assume ![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BI%7D+%3D+%5Cmathbb%7BR%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cmathbb%7BI%7D+%3D+%5Cmathbb%7BR%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)
.

(Click on this link to see all code for this post in one script. For more technical details on the covariance functions, see this previous post.)

**Overall set-up**

Let’s say we have a zero-centered Gaussian process denoted by ![](https://s0.wp.com/latex.php?latex=GP%28m%28%5Ccdot%29%2C+K%28%5Ccdot%2C+%5Ccdot%29%29&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=GP%28m%28%5Ccdot%29%2C+K%28%5Ccdot%2C+%5Ccdot%29%29&bg=ffffff&%23038;fg=333333&%23038;s=0)
, and that ![](https://s0.wp.com/latex.php?latex=f&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=f&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is a function drawn from this Gaussian process. For a vector ![](https://s0.wp.com/latex.php?latex=%28x_1%2C+%5Cdots%2C+x_n%29&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%28x_1%2C+%5Cdots%2C+x_n%29&bg=ffffff&%23038;fg=333333&%23038;s=0)
, the function values ![](https://s0.wp.com/latex.php?latex=%28f%28x_1%29%2C+%5Cdots%2C+f%28x_n%29%29&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%28f%28x_1%29%2C+%5Cdots%2C+f%28x_n%29%29&bg=ffffff&%23038;fg=333333&%23038;s=0)
 must have a multivariate Gaussian distribution with mean ![](https://s0.wp.com/latex.php?latex=%28m%28x_1%29%2C+%5Cdots%2C+m%28x_n%29%29&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%28m%28x_1%29%2C+%5Cdots%2C+m%28x_n%29%29&bg=ffffff&%23038;fg=333333&%23038;s=0)
 and covariance matrix ![](https://s0.wp.com/latex.php?latex=%5CSigma&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5CSigma&bg=ffffff&%23038;fg=333333&%23038;s=0)
 with entries ![](https://s0.wp.com/latex.php?latex=%5CSigma_%7Bij%7D+%3D+K%28x_i%2C+x_j%29&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5CSigma_%7Bij%7D+%3D+K%28x_i%2C+x_j%29&bg=ffffff&%23038;fg=333333&%23038;s=0)
. We make use of this property to draw this function: we select a fine grid of x-coordinates, use `mvrnorm()` from the `MASS` package to draw the function values at these points, then connect them with straight lines.

Assume that we have already written an R function `kernel_fn` for the kernel. The first function below generates a covariance matrix from this kernel, while the second takes `N` draws from this kernel (using the first function as a subroutine):

The `...` argument for the `draw_samples()` function allows us to pass arguments into the kernel function `kernel_fn`.

We will use the following parameters for the rest of the post:

**Squared exponential (SE) kernel**

The squared exponential (SE) kernel, also known as the ***radial basis function (RBF) kernel*** or the ***Gaussian kernel***has the form

![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%5Csigma%5E2+%5Cexp+%5Cleft%5B+-%5Cfrac%7B%5C%7C+x+-+x%27+%5C%7C%5E2%7D%7B2l%5E2%7D+%5Cright%5D%2C+%5Cend%7Baligned%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%5Csigma%5E2+%5Cexp+%5Cleft%5B+-%5Cfrac%7B%5C%7C+x+-+x%27+%5C%7C%5E2%7D%7B2l%5E2%7D+%5Cright%5D%2C+%5Cend%7Baligned%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)


where ![![](https://s0.wp.com/latex.php?latex=%5Csigma%5E2+%5Cgeq+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
 and ![](https://s0.wp.com/latex.php?latex=l+%3E+0&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=l+%3E+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=%5Csigma%5E2&bg=ffffff&%23038;fg=333333&%23038;s=0)
 parameter which determines how variable the function is overall; for simplicity we will assume it to be equal to 1 for the rest of this post.) It is possibly the most commonly used kernel because of its computational tractability. The following code generates 3 draws from the SE kernel with $latex l = 0.2:](https://s0.wp.com/latex.php?latex=%5Csigma%5E2+%5Cgeq+0&bg=ffffff&fg=333333&s=0&is-pending-load=1)


![](https://statisticaloddsandends.files.wordpress.com/2019/07/se_kernel0.png?w=456&is-pending-load=1)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/se_kernel0.png?w=456)


The following code shows how changing the “length-scale” parameter `l` affects the functions drawn. The smaller `l` is, the more wiggly the functions drawn.

![](https://statisticaloddsandends.files.wordpress.com/2019/07/se_kernel.png?w=450&is-pending-load=1#038;h=227&fit=584%2C227)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/se_kernel.png?w=450&h=227&fit=584%2C227)


**Rational quadratic (RQ) kernel**

The rational quadratic (RQ) kernel has the form

![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%5Csigma%5E2+%5Cleft%28+1+%2B+%5Cfrac%7B%5C%7C+x+-+x%27+%5C%7C%5E2%7D%7B2+%5Calpha+l%5E2%7D%5Cright%29%5E%7B-%5Calpha%7D%2C+%5Cend%7Baligned%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%5Csigma%5E2+%5Cleft%28+1+%2B+%5Cfrac%7B%5C%7C+x+-+x%27+%5C%7C%5E2%7D%7B2+%5Calpha+l%5E2%7D%5Cright%29%5E%7B-%5Calpha%7D%2C+%5Cend%7Baligned%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)


where ![![](https://s0.wp.com/latex.php?latex=%5Csigma+%5Cgeq+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
, ![](https://s0.wp.com/latex.php?latex=l+%3E+0&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=l+%3E+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=%5Calpha+%3E+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
 are hyperparameters. Below we create a function for the kernel and demonstrate how `l` affects the functions drawn:](https://s0.wp.com/latex.php?latex=%5Csigma+%5Cgeq+0&bg=ffffff&fg=333333&s=0&is-pending-load=1)

![ are hyperparameters. Below we create a function for the kernel and demonstrate how `l` affects the functions drawn:](https://s0.wp.com/latex.php?latex=%5Calpha+%3E+0&bg=ffffff&%23038;fg=333333&%23038;s=0)

rq_kernel <- function(x, y, alpha = 1, sigma = 1, length = 1) {
 sigma^2 * (1 + (x - y)^2 / (2 * alpha * length^2))^(-alpha)
}

par(mfrow = c(1, 3))
for (a in c(0.01, 0.5, 50)) {
 Y <- draw_samples(x, N, kernel_fn = rq_kernel, alpha = a)
 
 plot(range(x), range(Y), xlab = "x", ylab = "y", type = "n",
 main = paste("RQ kernel, alpha =", a))
 for (n in 1:N) {
 lines(x, Y[, n], col = col_list[n], lwd = 1.5)
 }
}

![](https://statisticaloddsandends.files.wordpress.com/2019/07/rq_kernel.png?w=450&is-pending-load=1#038;h=227&fit=584%2C227)


![](https://statisticaloddsandends.files.wordpress.com/2019/07/rq_kernel.png?w=450&is-pending-load=1#038;h=227&fit=584%2C227)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/rq_kernel.png?w=450&h=227&fit=584%2C227)


**Matérn covariance functions**

The Matérn covariance function has the form

![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%5Csigma%5E2+%5Cfrac%7B2%5E%7B1-%5Cnu%7D%7D%7B%5CGamma+%28%5Cnu%29%7D+%5Cleft%28+%5Cfrac%7B%5Csqrt%7B2%5Cnu%7D+%5C%7Cx-x%27%5C%7C%7D%7Bl%7D%5Cright%29%5E%5Cnu+K_%5Cnu+%5Cleft%28+%5Cfrac%7B%5Csqrt%7B2%5Cnu%7D+%5C%7Cx-x%27%5C%7C%7D%7Bl%7D+%5Cright%29%2C+%5Cend%7Baligned%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%5Csigma%5E2+%5Cfrac%7B2%5E%7B1-%5Cnu%7D%7D%7B%5CGamma+%28%5Cnu%29%7D+%5Cleft%28+%5Cfrac%7B%5Csqrt%7B2%5Cnu%7D+%5C%7Cx-x%27%5C%7C%7D%7Bl%7D%5Cright%29%5E%5Cnu+K_%5Cnu+%5Cleft%28+%5Cfrac%7B%5Csqrt%7B2%5Cnu%7D+%5C%7Cx-x%27%5C%7C%7D%7Bl%7D+%5Cright%29%2C+%5Cend%7Baligned%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)


where ![![](https://s0.wp.com/latex.php?latex=%5CGamma&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is the gamma function and ![](https://s0.wp.com/latex.php?latex=K_%5Cnu&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=K_%5Cnu&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is the modified Bessel function of the second kind. The hyperparameters are ![](https://s0.wp.com/latex.php?latex=%5Csigma+%5Cgeq+0&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Csigma+%5Cgeq+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
, ![](https://s0.wp.com/latex.php?latex=l+%3E+0&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=l+%3E+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=%5Cnu+%5Cgeq+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
. For ![](https://s0.wp.com/latex.php?latex=%5Cnu+%3D+p+%2B+1%2F2&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cnu+%3D+p+%2B+1%2F2&bg=ffffff&%23038;fg=333333&%23038;s=0)
 for some integer ![](https://s0.wp.com/latex.php?latex=p&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=p&bg=ffffff&%23038;fg=333333&%23038;s=0)
, the expression on the RHS becomes a little nicer. In practice the values of ![](https://s0.wp.com/latex.php?latex=%5Cnu+%3D+3%2F2&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cnu+%3D+3%2F2&bg=ffffff&%23038;fg=333333&%23038;s=0)
 and ![](https://s0.wp.com/latex.php?latex=%5Cnu+%3D+5%2F2&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cnu+%3D+5%2F2&bg=ffffff&%23038;fg=333333&%23038;s=0)
 are used much more often than anything else, so that is all we code up here.](https://s0.wp.com/latex.php?latex=%5CGamma&bg=ffffff&fg=333333&s=0&is-pending-load=1)


![](https://statisticaloddsandends.files.wordpress.com/2019/07/mat_kernel.png?w=450&is-pending-load=1#038;h=227&fit=584%2C227)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/mat_kernel.png?w=450&h=227&fit=584%2C227)


The paths from the Matérn-1/2 kernel are often deemed too rough to be used in practice.

**Periodic kernel**

The periodic kernel has the form

![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%5Csigma%5E2+%5Cexp+%5Cleft%5B+-+%5Cfrac%7B2+%5Csin%5E2+%28%5Cpi+%5C%7C+x+-+x%27%5C%7C+%2F+p%29+%7D%7Bl%5E2%7D+%5Cright%5D%2C+%5Cend%7Baligned%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%5Csigma%5E2+%5Cexp+%5Cleft%5B+-+%5Cfrac%7B2+%5Csin%5E2+%28%5Cpi+%5C%7C+x+-+x%27%5C%7C+%2F+p%29+%7D%7Bl%5E2%7D+%5Cright%5D%2C+%5Cend%7Baligned%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)


where ![![](https://s0.wp.com/latex.php?latex=%5Csigma+%5Cgeq+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
, ![](https://s0.wp.com/latex.php?latex=l+%3E+0&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=l+%3E+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=p+%3E+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
![](https://s0.wp.com/latex.php?latex=p&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is the period of the function, as can be seen from the paths below:](https://s0.wp.com/latex.php?latex=%5Csigma+%5Cgeq+0&bg=ffffff&fg=333333&s=0&is-pending-load=1)


![](https://statisticaloddsandends.files.wordpress.com/2019/07/period_kernel.png?w=450&is-pending-load=1#038;h=227&fit=584%2C227)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/period_kernel.png?w=450&h=227&fit=584%2C227)


**Linear/polynomial kernel**

The polynomial kernel has the form

![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%28x%5ET+x%27+%2B+%5Csigma%5E2%29%5Ed%2C+%5Cend%7Baligned%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+K%28x%2C+x%27%29+%3D+%28x%5ET+x%27+%2B+%5Csigma%5E2%29%5Ed%2C+%5Cend%7Baligned%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)


where ![](https://s0.wp.com/latex.php?latex=d+%5Cin+%5Cmathbb%7BN%7D&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=d+%5Cin+%5Cmathbb%7BN%7D&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is the degree of the polynomial and ![](https://s0.wp.com/latex.php?latex=%5Csigma+%5Cgeq+0&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Csigma+%5Cgeq+0&bg=ffffff&%23038;fg=333333&%23038;s=0)
 is a hyperparameter. The first plot shows how the value of ![](https://s0.wp.com/latex.php?latex=%5Csigma&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=%5Csigma&bg=ffffff&%23038;fg=333333&%23038;s=0)
 can affect the linear kernel, while the second plot shows how the dimension affects the shape of the polynomial kernel.

![](https://statisticaloddsandends.files.wordpress.com/2019/07/linear_kernel.png?w=450&is-pending-load=1#038;h=227&fit=584%2C227)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/linear_kernel.png?w=450&h=227&fit=584%2C227)


![](https://statisticaloddsandends.files.wordpress.com/2019/07/poly_kernel.png?w=450&is-pending-load=1#038;h=227&fit=584%2C227)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/poly_kernel.png?w=450&h=227&fit=584%2C227)


**Brownian motion**

Brownian motion, the most studied object in stochastic processes, is a one-dimensional Gaussian process with mean zero and covariance function ![](https://s0.wp.com/latex.php?latex=K%28x%2C+x%27%29+%3D+%5Cmin+%28x%2C+x%27%29&bg=ffffff&fg=333333&s=0&is-pending-load=1)
![](https://s0.wp.com/latex.php?latex=K%28x%2C+x%27%29+%3D+%5Cmin+%28x%2C+x%27%29&bg=ffffff&%23038;fg=333333&%23038;s=0)
. Its paths are extremely rough.

![](https://statisticaloddsandends.files.wordpress.com/2019/07/bm_kernel.png?w=456&is-pending-load=1)
![](https://statisticaloddsandends.files.wordpress.com/2019/07/bm_kernel.png?w=456)


Note that I had to use the `pmin()` function instead of `min()` in the Brownian motion covariance function. This is because the `outer(X, Y, FUN, ...)` function we called in `cov_matrix()`

> 
“…[extends `X` and `Y`] by `rep` to length the products of the lengths of `X` and `Y` before `FUN` is called.” (from `outer()` documentation)


`pmin()` would perform the operation we want, while `min()` would simply return the minimum value present in the two arguments, not what we want.


*Related*







---
