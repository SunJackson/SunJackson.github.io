---
layout:     post
catalog: true
title:      Support for Apache MXNet 1.4 and Model Server in Amazon SageMaker
subtitle:      转载自：https://aws.amazon.com/blogs/machine-learning/support-for-apache-mxnet-1-4-and-model-server-in-amazon-sagemaker/
date:      2019-07-01
author:      Erkan Tas
tags:
    - mxnet
    - models
    - networks
    - enables
    - enabling
---

Apache MXNet is an open-source deep learning software framework used to train and deploy deep neural networks. Data scientists and machine learning (ML) developers love MXNet due to its flexibility and efficiency when building deep learning models. Amazon SageMaker is committed to improving the customer experience for all ML frameworks and libraries, including MXNet. With the latest release of MXNet 1.4, you can use MXNet containers in internet-free mode, and use Model Server for Apache MXNet (MMS) to deploy deep learning models for inference.

Model Server for Apache MXNet (MMS) is an open source toolset that simplifies the task of deploying deep learning models for inference. You can use MMS to serve MXNet and other framework models easily, quickly, and at scale. For more information, see Model Server for Apache MXNet v1.0 release.

The MXNet 1.4 update has several new features, including network isolation, Julia bindings, experimental control flow operators, JVM memory management, graph optimization and quantizations, and usability enhancements. For change log information, see Apache MXNet (incubating) 1.4.0.

Amazon SageMaker training and deployed inference containers are internet-enabled by default. With the new MXNet container, you are able to use containers in internet-free mode, which enables running training jobs inside a secure and isolated environment. If you do not want Amazon SageMaker to provide external network access to your training or inference containers, you can enable network isolation when you create your training job or model.

The MXNet 1.4 update is accompanied by the Python 3.6 support. You can now use Python 3.6 when building and deploying deep neural networks with the MXNet framework. For more information, see What’s New In Python 3.6.

With the latest release, the Keras version for MXNet is now 2.2.4.1. Keras 2.2.4.1 adds bug and usability fixes on top of the API completeness and usability improvements introduced in the Keras 2.2.3 release. For release notes, see the Keras 2.2.4 GitHub repo.

Another update is the 1.4.1 release of ONNX. 1.4.1 comes with several big features, including support for large models, ability to store the data externally, and control flow operators. It also adds a test driver for ONNXIFI enabling C++ tests.

OpenBlas, an optimized BLAS (Basic Linear Algebra Subprograms) library, is no longer available in MXNet 1.4. MXNet now offers MKL pip packages that are much faster when running on Intel hardware.

With MKL BLAS, performance improves with variable range, depending on the computation load of the models. MKL DNN uses a BLAS library internally and supports linking with MKLML or MKL for additional performance. For more information, see Build/Install MXNet with MKL-DNN.

The new enhancements to built-in containers are now available in all AWS Regions where Amazon SageMaker is available. We recommend that you update your Python SDK version to use this release of MXNet and MMS. You can do this by running the following command:

```
pip install --upgrade sagemaker
```

For more information about using pre-configured containers within Amazon SageMaker, see Use Apache MXNet with Amazon SageMaker. To learn more about how to produce Docker images for serving MXNet on Amazon SageMaker, visit the GitHub page for SageMaker MXNet Serving Container.

 

---

### About the Author

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/09/14/erkan-tas-100-1.jpg)
**Erkan Tas is a Sr. Product Manager for Amazon SageMaker**. He is on a mission to make Artificial Intelligence easy, accessible, and scalable. He is also a sailor, overlander, science and nature admirer, Go and Stratocaster player.
