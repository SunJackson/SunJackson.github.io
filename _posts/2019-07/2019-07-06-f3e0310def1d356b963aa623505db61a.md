---
layout:     post
catalog: true
title:      Finding out why
subtitle:      转载自：https://analytixon.com/2019/07/06/finding-out-why-7/
date:      2019-07-06
author:      Michael Laux
tags:
    - causal
    - papers
    - outcomes
    - exposures
    - data
---

***Paper***: ***Approximate Causal Abstraction***

Scientific models describe natural phenomena at different levels of abstraction. Abstract descriptions can provide the basis for interventions on the system and explanation of observed phenomena at a level of granularity that is coarser than the most fundamental account of the system. Beckers and Halpern (2019), building on work of Rubenstein et al. (2017), developed an account of abstraction for causal models that is exact. Here we extend this account to the more realistic case where an abstract causal model offers only an approximation of the underlying system. We show how the resulting account handles the discrepancy that can arise between low- and high-level causal models of the same system, and in the process provide an account of how one causal model approximates another, a topic of independent interest. Finally, we extend the account of approximate abstractions to probabilistic causal models, indicating how and where uncertainty can enter into an approximate abstraction.

***Paper***: ***Interpretable Almost-Matching-Exactly With Instrumental Variables***

Uncertainty in the estimation of the causal effect in observational studies is often due to unmeasured confounding, i.e., the presence of unobserved covariates linking treatments and outcomes. Instrumental Variables (IV) are commonly used to reduce the effects of unmeasured confounding. Existing methods for IV estimation either require strong parametric assumptions, use arbitrary distance metrics, or do not scale well to large datasets. We propose a matching framework for IV in the presence of observed categorical confounders that addresses these weaknesses. Our method first matches units exactly, and then consecutively drops variables to approximately match the remaining units on as many variables as possible. We show that our algorithm constructs better matches than other existing methods on simulated datasets, and we produce interesting results in an application to political canvassing.

***Article***: ***Causal inference with time-varying mediators***

I have a question about your paper ‘Mediation analysis for a survival outcome with time-varying exposures, mediators, and confounders’ that I was hoping that you could help my colleague (Julia Ward) and me with. We are currently using Medicare claims data to evaluate the following general mediation among dialysis patients with atrial fibrillation: Race -> Warfarin prescriptions -> Stroke within 1 year. where Warfarin prescriptions is a time-varying mediator (using part D claims with number supplied as days) and there are time-dependent confounders. Even though the exposure doesn’t vary over time, this is an extension of Van der Laans time dependent mediation method because yours also includes time dependent confounders. However, I would also like to account for death as a competing risk via a sub-hazard. Am I correct that the G-formula cannot do this? If so, are you aware of any methods that could do this? I found the following paper that implements a marginal structural subdistribution hazard models, but this doesn’t do mediation (at least I don’t think so).

***Paper***: ***A Python Library For Empirical Calibration***

Dealing with biased data samples is a common task across many statistical fields. In survey sampling, bias often occurs due to the unrepresentative samples. In causal studies with observational data, the treated vs untreated group assignment is often correlated with covariates, i.e., not random. Empirical calibration is a generic weighting method that presents a unified view on correcting or reducing the data biases for the tasks mentioned above. We provide a Python library EC to compute the empirical calibration weights. The problem is formulated as a convex optimization and solved efficiently in the dual form. Compared to existing software, EC is both more efficient and robust. EC also accommodates different optimization objectives, supports weight clipping, and allows inexact calibration which improves the usability. We demonstrate its usage across various experiments with both simulated and real-world data.

***Paper***: ***Direct Estimation of Difference Between Structural Equation Models in High Dimensions***

Discovering cause-effect relationships between variables from observational data is a fundamental challenge in many scientific disciplines. However, in many situations it is desirable to directly estimate the change in causal relationships across two different conditions, e.g., estimating the change in genetic expression across healthy and diseased subjects can help isolate genetic factors behind the disease. This paper focuses on the problem of directly estimating the structural difference between two causal DAGs, having the same topological ordering, given two sets of samples drawn from the individual DAGs. We present an algorithm that can recover the difference-DAG in $O(d \log p)$ samples, where $d$ is related to the number of edges in the difference-DAG. We also show that any method requires at least $\Omega(d \log p/d)$ samples to learn difference DAGs with at most $d$ parents per node. We validate our theoretical results with synthetic experiments and show that our method out-performs the state-of-the-art.

***Paper***: ***Formulating causal questions and principled statistical answers***

Although review papers on causal inference methods are now available, there is a lack of introductory overviews on what they can render and on the guiding criteria for choosing one particular method. This tutorial gives an overview in situations where an exposure of interest is set at a chosen baseline (`point exposure’) and the target outcome arises at a later time point. We first phrase relevant causal questions and make a case for being specific about the possible exposure levels involved and the populations for which the question is relevant. Using the potential outcomes framework, we describe principled definitions of causal effects and of estimation approaches classified according to whether they invoke the no unmeasured confounding assumption (including outcome regression and propensity score-based methods) or an instrumental variable with added assumptions. We discuss challenges and potential pitfalls and illustrate application using a `simulation learner’, that mimics the effect of various breastfeeding interventions on a child’s later development. This involves a typical simulation component with generated exposure, covariate, and outcome data that mimic those from an observational or randomised intervention study. The simulation learner further generates various (linked) exposure types with a set of possible values per observation unit, from which observed as well as potential outcome data are generated. It thus provides true values of several causal effects. R code for data generation and analysis is available on www.ofcaus.org, where SAS and Stata code for analysis is also provided.

### Like this:

Like Loading...
