---
layout:     post
title:      Faster time series alignment / joins for pandas, beating R's xts package
subtitle:   转载自：http://wesmckinney.com/blog/faster-time-series-alignment-joins-for-pandas-beating-rs-xts-package/
date:       2011-09-24
author:     Wes McKinney
header-img: img/background3.jpg
catalog: true
tags:
    - joining
    - joins
    - code
    - xts
    - timings
---





** Sat 24 September 2011

 

> 
September 29, 2015: This post is so old, I suggest you install latest
versions of everything and try the benchmarks out yourself. -- Wes


In anticipation of integrating NumPy's shiny new `datetime64` dtype into [pandas](http://pandas.sourceforge.net/.), I set about writing some faster alignment and merging functions for ordered time series data indexed by datetime64 timestamps. Many people have pointed me to the widely used R [xts](http://cran.r-project.org/web/packages/xts/index.html) package as a baseline for highly optimized joining functions.

Anyway, long story short, with a little NumPy- and Cython-fu I think I've matched or beaten xts for almost all of its supported join types by up to 40% (left/outer/inner) using the `merge.xts` function.

In a [blog article](http://wesmckinney.com/blog?p=215) earlier today I wrote about some of the performance problems I had to address to do this. The rest of the joining code is pretty straightforward Cython code. Though it'll probably be a few weeks before this new code gets incorporated into `DataFrame.join`. You'll just have to take my word for it that I'm doing an apples-to-apples comparison (or read the source yourself) =)

### Python benchmarks

Here are the Python timings in milliseconds for joining two time series data sets. The column labels are the lengths (in scientific notation, from 100 through 1,000,000). The two timings are with two univariate time series and two collections of 5 time series.

**EDIT (9/24/2011):** after corresponding with the xts author, Jeff Ryan, I reran the benchmarks with the code modified to ensure that garbage collection time isn't being included in the runtime. The results after the change to the benchmark are less disparate than before. I also tweaked the Cython algos to determine the outer/inner join time index and re-ran the benchmarks. In the 1e6 outer join case the new algo trimmed 8 ms off, 4-5ms in the inner join case. Whenever I develop a strong desire to hack up a pile of spaghetti-like Cython code (combining the index union/intersection routines with the take / row-copying code) I can probably shave off another few millis…

**EDIT 9/28:** I put in some work integrating the new merging routines throughout DataFrame and friends in pandas and added a new `Int64Index` class to facilitate fast joining of time series data. Here are the updated benchmarks, which now have pandas a bit slower than xts for outer/inner joins in the univariate case but still significantly faster in the multivariate case:

As you can see in the 1 million row case there is an additional 4-5 ms of overhead across the board which largely has to do with handling types other than floating point. With some effort I could eliminate this overhead but I'm going to leave it for now.

And the source code for the benchmark:

### R/xts benchmarks

And the R benchmark using xts. The results for the smaller datasets are unreliable due to the low precision of `system.time`.

The Python code for the benchmark is all found [here](https://github.com/wesm/pandas/blob/fast-merge/scripts/bench_join.py).

Here is the R code for the benchmark ([GitHub link](https://github.com/wesm/pandas/blob/fast-merge/scripts/bench_join.R)):
