---
layout:     post
catalog: true
title:      Bayesian Statistics： Analysis of Health Data
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/lwoS1thOOZA/
date:      2019-03-11
author:      Michael Grogan
tags:
    - bf_top
    - regressions
    - age
    - variables
    - probabilities
---

1. Regression Models


****

Tags



- Bayesian Analysis
- Linear Regression
- R Programming
- t-test

The premise of Bayesian statistics is that distributions are based on a personal belief about the shape of such a distribution, rather than the classical assumption which does not take such subjectivity into account.

In this regard, Bayesian statistics defines distributions in the following way:

- **Prior:** Beliefs about a distribution prior to observing any data.

- **Likelihood:** Distribution based on the observed data.

- **Posterior:** Distribution that combines observed data with prior beliefs.


Classical statistics relies largely on the t-test to determine significance of a particular variable, and does not take subjective predictions of the data into account. However, the issue with such an approach is that no constraint is placed on the data, and as Richard Morey explains in his blog, an alternative hypothesis becomes “completely unfalsifiable”.

In this regard, the Bayes factor penalizes hypotheses that are not specific enough, allowing for a more concrete assessment of how accurate a specific prediction is.

## Problem and hypothesis

As an example, let us consider the hypothesis that BMI increases with age. Conversely, the null hypothesis argues that there is no evidence for a positive correlation between BMI and age.

In this regard, even if we did find a positive correlation between BMI and age, the hypothesis is virtually unfalsifiable given that the existence of no relationship whatever between these two variables is highly unlikely.

Therefore, as opposed to using a simple t-test, a Bayes Factor analysis needs to have specific predictions to assess the accuracy of the same.

## t-test vs. Bayes Factor t-test

For this problem, the diabetes dataset from the UCI Machine Learning Repository is used. The variables Age and BMI are extracted, the data is ordered by age, and a t-test is calculated across two separate age groups.

With a p-value below 0.05, the t-test shows significance at the 5% level, indicating that the null hypothesis of the mean is equal to 0 is rejected. However, the issue still remains in that the degree of evidence in favor of H1 over H0 cannot be quantified in detail.

In this regard, a Bayes Factor t-test is run across the different scores.

A score of 0.7139 is yielded. Typically, a score of > 1 signifies anecdotal evidence for H0 compared to H1. The exact thresholds are defined by Wagenmakers et. al, 2011, and a copy of the table can be found at the following The 20% Statistician post.

Let’s come back to the issue of the posterior distribution. In the case that we are unable to calculate the posterior distribution, it can be estimated using Markov chain Monte Carlo methods (MCMC).

The chains are estimated and the distributions are plotted:

Here is the graph of the distributions:![](https://i0.wp.com/datascienceplus.com/wp-content/uploads/2019/03/image-1-490x218.png?w=450&ssl=1)
![](https://i0.wp.com/datascienceplus.com/wp-content/uploads/2019/03/image-1-490x218.png?w=450&ssl=1)


## regressionBF

Bayesian analysis can also be used to compare probabilities across several regression models.

As an example, let’s take the following regression model:

Again, we see that certain variables are indicated as statistically significant while others are not. However, the same problem arises in that p-values are not regarded as direct measures of evidence against the null hypothesis under the Bayesian school of thought, and thus more concrete probability measures should be used.

In this regard, a Bayesian regression is run, with a Bayes factor analysis indicating the highest and lowest probability regressions.

From here, we see that the following three combinations of variables in each regression demonstrate the reported highest probability in computing BMI:

- Insulin + BloodPressure + Glucose

- Insulin + Age + BloodPressure + Glucose

- Insulin + BloodPressure + Glucose + Pregnancies


Conversely, these three combinations of variables demonstrated the lowest reported probability:

- Age

- Pregnancies

- Age + Pregnancies


As indicated by **which.max(bf)**, 19 regression models were generated in total.

In order to generate a plot of the probabilities for each combination, the probabilities of the top reported models can be divided against the probabilities of all the generated models:

![](https://i0.wp.com/datascienceplus.com/wp-content/uploads/2019/03/image-2-490x181.png?w=450&ssl=1)
![](https://i0.wp.com/datascienceplus.com/wp-content/uploads/2019/03/image-2-490x181.png?w=450&ssl=1)


Additionally, “top-down” and “bottom-up” analyses can be generated, wherein the former each independent variable is eliminated one at a time, whereas in the latter each independent variable is added one at a time.

![](https://i0.wp.com/datascienceplus.com/wp-content/uploads/2019/03/image-3-490x181.png?w=450&ssl=1)
![](https://i0.wp.com/datascienceplus.com/wp-content/uploads/2019/03/image-3-490x181.png?w=450&ssl=1)


![](https://i0.wp.com/datascienceplus.com/wp-content/uploads/2019/03/image-4-490x181.png?w=450&ssl=1)
![](https://i0.wp.com/datascienceplus.com/wp-content/uploads/2019/03/image-4-490x181.png?w=450&ssl=1)


According to these two graphs, Blood Pressure is indicated as the most influential variable in explaining the indicative probability favoring H1 over H0.

## Conclusion

Ultimately, the area of Bayesian statistics is very large and the examples above cover just the tip of the iceberg.

However, in this particular example we have looked at:

- The comparison between a t-test and the Bayes Factor t-test

- How to estimate posterior distributions using Markov chain Monte Carlo methods (MCMC)

- Use of regressionBF to compare probabilities across regression models


Many thanks for your time.

****

Related Post



- How to do regression analysis for multiple independent or dependent variables
- Robust Regressions: Dealing with Outliers in R
- Multilevel Modelling in R: Analysing Vendor Data
- Logistic Regression with Python using Titanic data
- Failure Pressure Prediction Using Machine Learning



*Related*








---
