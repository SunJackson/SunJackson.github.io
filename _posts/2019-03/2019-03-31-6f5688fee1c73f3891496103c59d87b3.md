---
layout:     post
catalog: true
title:      Monotonic Binning with GBM
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/wpz5kpGLC5Q/
date:      2019-03-31
author:      statcompute
tags:
    - binning algorithms
    - functions
    - regression
    - talbot
    - datasets
---





In addition to monotonic binning algorithms introduced in my previous post (https://statcompute.wordpress.com/2019/03/10/a-summary-of-my-home-brew-binning-algorithms-for-scorecard-development), two more functions based on Generalized Boosted Regression Models have been added to my GitHub repository, gbm_bin() and gbmcv_bin(). 

The function gbm_bin() estimates a GBM model without the cross validation and tends to generate a more granular binning outcome. 

 

The function gbmcv_bin() estimates a GBM model with the cross validation (CV). Therefore, it would generate a more stable but coarse binning outcome. Nonetheless, the computation is more expensive due to CV, especially for large datasets. 


Motivated by the idea of my friend Talbot (https://www.linkedin.com/in/talbot-katz-b76785), I also drafted a function pava_bin() based upon the Pool Adjacent Violators Algorithm (PAVA) and compared it with the iso_bin() function based on the isotonic regression. As shown in the comparison below, there is no difference in the binning outcome. However, the computing cost of pava_bin() function is higher given that PAVA is an iterative algorithm solving for the monotonicity. 




*Related*








---
