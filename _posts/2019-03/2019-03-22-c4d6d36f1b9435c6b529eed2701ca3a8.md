---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/03/22/distilled-news-1006/
date:      2019-03-22
author:      Michael Laux
tags:
    - code
    - curve
    - word
    - testing
    - tests
---

**Automatically Storing Data from Analyzed Data Sets**

This is the fifth article in a series teaching you to how to write programs that automatically analyze scientific data. The first presented the concept and motivation, then laid out the high level steps. The second taught you how to structure data sets to make automated data analysis possible, and automatically identify the conditions of each test. The third article discussed creating a for loop that automatically performs calculations on each test result and saves the results. The fourth post covered what is likely the most important part: Automatically checking the data and analysis for errors. This fifth post will teach you how to store data in a logical folder structure, enabling easy access to the data for regression development and validation.

**On the Curse of Dimensionality**

If there is one tip that I would give to anyone in machine learning, this would be it: never forget the curse of dimensionality. The traditional explanation goes something like this: ‘Well, if you have a lot of input dimensions, then your problem becomes computationally expensive and difficult to solve’. Yes, this is true, but why is it true? Let’s talk about this in more detail.

**ROC Curve Explained in One Picture**

With a ROC curve, you’re trying to find a good model that optimizes the trade off between the False Positive Rate (FPR) and True Positive Rate (TPR). What counts here is how much area is under the curve (Area under the Curve = AuC). The ideal curve in the left image fills in 100%, which means that you’re going to be able to distinguish between negative results and positive results 100% of the time (which is almost impossible in real life). The further you go to the right, the worse the detection. The ROC curve to the far right does a worse job than chance, mixing up the negatives and positives (which means you likely have an error in your setup).

**Word Distance between Word Embeddings with Weight**

In previous story, I introduced Word Mover’s Distance (WMD) which measure the distance between word embeddings. You may notice that there is no weighting mechanism between words. How does weighting help on NLP tasks? Therefore, Huang et al. proposed an improvement and named Supervised Word Mover’s Distance (S-WMD).

**BigQuery for Data Science**

One of the perks of using Google Cloud Platform (GCP) is having BigQuery, Google’s cloud hosted data warehouse solution at your disposal. BigQuery gives GCP users access to the key features of Dremel, Google’s very own internal data warehouse solution. Under the hood Dremel stores data in columnar format and uses a tree architecture to parallelise queries across thousands of machines, with each query scanning the entire table. So, what is so great about that? With BigQuery you can run SQL queries on a table with billions of rows and get the results in seconds! Although thousands of Google machines process the data, each query only takes up a small amount of compute time, so it only costs $5.00 per TB of data processed. Best of all, Google takes care of infrastructure management. Queries which used to take hours or longer on traditional databases can now be processed in a matter of seconds. This enables analysts to answer business questions rapidly, build dashboards on aggregated data, etc.

**What to expect from Reinforcement Learning?**

Geoffrey Hinton once gave the example of ‘The trophy would not fit in the suitcase because it was too [big/small]’, where it clearly depends on our own prior world knowledge to what ‘it’ is referring to. We’re considerably confident that a suitcase is regularly bigger than a trophy so that either a ‘too big trophy’ or a ‘too small suitcase’ is meant.

**Enlightened DataLab Notebooks**

The road to expertise in Cloud Computing is fraught with harrowingly extended afternoons, and countless under completed blog posts. When you want to quickly spin up a virtual machine, and start working in Python from a notebook in the browser, you’re often met with these frustrations. Why can’t I write to my bucket? What is preventing the notebook from working in my browser? Why can’t I see any files when I SSH into the machine? And maybe even ‘What is Docker?’

**How to import multiple .csv files simultaneously in R and create a data frame**

Have you ever struggled to import hundred of small datasets files? Can be very time consuming or maybe impossible. I was in this situation some time ago when I had a folder with approximately three thousand CSV files, and I was interested in creating a single dataset.

**5 Tools To Evaluate Machine Learning Model Fairness and Bias.**

Evaluating machine learning models for bias is becoming an increasingly common focus for different industries and data researchers. Model Fairness is a relatively new subfield in Machine Learning. In the past, the study of discrimination emerged from analyzing human-driven decisions and the rationale behind those decisions. Since we started to rely on predictive ML models to make decisions for different industries such as insurance and banking, we need to implement strategies to ensure the fairness of those models and detect any discriminative behaviour during predictions.

**Outlier Detection with Extended Isolation Forest**

After half a year since my first article on anomaly detection, one of its readers has brought to my attention the fact that there is a recent improvement to the Isolation Forest algorithm, namely Extended Isolation Forest (EIF), which addresses major drawbacks of the original method. In this article I give a quick reminder on the original IF algorithms, describe the potential problem with it and how EIF handles it. At the end I will present a Python example how to use both algorithms and compare their performance.

**Is Robotic Process Automation (RPA) Really AI?**

Based on a McKinsey study we reported that 47% of companies had at least one AI/ML implementation in place. Looking back at the data and the dominance of RPA as the most widely reported instance makes us think that the number is probably significantly lower.

**Determining Sample Size in One Picture**

Determining sample sizes is a challenging undertaking. For simplicity, I’ve limited this picture to the one of the most common testing situation: testing for differences in means. Some assumptions have been made (for example, normality and equal sample sizes). Additionally, the formulas shown are for one-tailed tests. Usually, a small tweak (e.g. replacing Za by Za/2) is all that’s required for two-tailed tests.

**R meta programmation**

Lately, R meta programmation seems to be in vogue. Very huge promises, encompassing code to produce code, variable indirection naming schemes, and many others marvelous features are now available through the tidyverse. Indeed, very huge promises, are generally the right sensor to enter into skepticism and to verify by our-self it worth or not to switch from well-known and limited code approaches, to less-known more promising and more modern code approaches

**The reticulate package solves the hardest problem in data science: people**

The reticulate package integrates Python within R and, when used with RStudio 1.2, brings the two languages together like never before. Much more important than the technical details of how it all works is the impact that it has on on both individuals and teams by enabling data scientists who speak different languages to collaborate seamlessly on a project. A data scientist is first and foremost a problem solver. The ability to frame a problem and decide how it might be solved is what separates someone who merely knows code syntax from someone who is capable of discovering a novel solution to a hard problem. Despite all of the buzz around the field, however, there exists a major skills gap where there is limited talent available.

**What’s in a language**

Alan Turing, an English mathematician and computer scientist posed a simple question in 1950 paper under the name of the ‘The Imitation Game’. Can an interrogator determine the gender of a man and woman correctly simply by having them write down answers to questions the interrogator asks? The catch is while the man is trying to aid the interrogator in identifying the genders correctly, the woman is tasked with deceiving you into thinking she is the man. Turing continued the question to say, instead of a man or woman, what if a machine was one of the two ‘people’ being questioned. Could the interrogator correctly identity who was the human? And if the machine was able to trick the interrogator into answering the question, is the machine thinking just as a person? simply put?-?’Can machines think?’





### Like this:

Like Loading...


*Related*

