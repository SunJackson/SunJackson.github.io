---
layout:     post
catalog: true
title:      Holistically-Nested Edge Detection with OpenCV and Deep Learning
subtitle:      转载自：https://www.pyimagesearch.com/2019/03/04/holistically-nested-edge-detection-with-opencv-and-deep-learning/
date:      2019-03-04
author:      Adrian Rosebrock
tags:
    - images
    - edges
    - holistically
    - lines
    - detection
---

![](https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/holistically-nested-edge-detection/holistically_nested_edge_detection_demo.gif)


In this tutorial, you will learn how to apply Holistically-Nested Edge Detection (HED) with OpenCV and Deep Learning. We’ll apply Holistically-Nested Edge Detection to both images and video streams, followed by comparing the results to OpenCV’s standard Canny edge detector.

**Edge detection enables us to find the boundaries of objects in images**and was one of the first applied use cases of image processing and computer vision.

When it comes to edge detection with OpenCV you’ll most likely utilize the Canny edge detector; however, **there are a few problems with the Canny edge detector, namely:**

1. Setting the lower and upper values to the hysteresis thresholding is a *manual process* which requires experimentation and visual validation.

1. Hysteresis thresholding values that work well for one image may not work well for another (this is *nearly always true* for images captured in varying lighting conditions).

1. The Canny edge detector often requires a number of preprocessing steps (i.e. conversion to grayscale, blurring/smoothing, etc.) in order to obtain a good edge map.


**Holistically-Nested Edge Detection** (HED) attempts to address the limitations of the Canny edge detector through an *end-to-end deep neural network*.

This network accepts an RGB image as an input and then produces an edge map as an output. Furthermore, the edge map produced by HED does a better job preserving object boundaries in the image.

**To learn more about Holistically-Nested Edge Detection with OpenCV, *just keep reading!***

### Holistically-Nested Edge Detection with OpenCV and Deep Learning

In this tutorial we will learn about Holistically-Nested Edge Detection (HED) using OpenCV and Deep Learning.

We’ll start by discussing the Holistically-Nested Edge Detection algorithm.

From there we’ll review our project structure and then utilize HED for edge detection in both *images* and *video*.

Let’s go ahead and get started!

### What is Holistically-Nested Edge Detection?

The algorithm we’ll be using here today is from Xie and Tu’s 2015 paper, *Holistically-Nested Edge Detection*, or simply “HED” for short.

The work of Xie and Tu describes a deep neural network capable of automatically learning rich hierarchical edge maps that are capable of determining the edge/object boundary of objects in images.

This edge detection network is capable of obtaining state-of-the-art results on the Berkely BSDS500 and NYU Depth datasets.

A full review of the network architecture and algorithm outside the scope of this post, so please refer to the official publication for more details.

### Project structure

Go ahead and grab today’s ***“Downloads”*** and unzip the files.

From there, you can inspect the project directory with the following command:



||$ tree --dirsfirst.├── hed_model│   ├── deploy.prototxt│   └── hed_pretrained_bsds.caffemodel├── images│   ├── cat.jpg│   ├── guitar.jpg│   └── janie.jpg├── detect_edges_image.py└── detect_edges_video.py 2 directories, 7 files|

.

│   ├── deploy.prototxt

├── images

│   ├── guitar.jpg

├── detect_edges_image.py

 

Our HED Caffe model is included in the 
hed_model/  directory.

I’ve provided a number of sample 
images/  including one of myself, my dog, and a sample cat image I found on the internet.

Today we’re going to review the 
detect_edges_image.py  and 
detect_edges_video.py  scripts. Both scripts share the same edge detection process, so we’ll be spending most of our time on the HED image script.

### Holistically-Nested Edge Detection in Images

The Python and OpenCV Holistically-Nested Edge Detection example we are reviewing today is very similar to the HED example in OpenCV’s official repo.

**My primary contribution here is to:**

1. Provide some additional documentation (when appropriate)

1. And most importantly, **show you how to use Holistically-Nested Edge Detection in your own projects.**


Let’s go ahead and get started — open up the 
detect_edge_image.py file and insert the following code:



||# import the necessary packagesimport argparseimport cv2import os # construct the argument parser and parse the argumentsap = argparse.ArgumentParser()ap.add_argument("-d", "--edge-detector", type=str, required=True, help="path to OpenCV's deep learning edge detector")ap.add_argument("-i", "--image", type=str, required=True, help="path to input image")args = vars(ap.parse_args())|

import argparse

import os

# construct the argument parser and parse the arguments

ap.add_argument("-d", "--edge-detector", type=str, required=True,

ap.add_argument("-i", "--image", type=str, required=True,

args = vars(ap.parse_args())

Our imports are handled on **Lines 2-4**. We’ll be using `argparse` to parse command line arguments. OpenCV functions and methods are accessed through the 
cv2  import. Our 
os  import will allow us to build file paths regardless of operating system.

This script requires two command line arguments:


--edge-detector : The path to OpenCV’s deep learning edge detector. The path contains two Caffe files that will be used to initialize our model later.

--image : The path to the input image for testing. Like I said previously — I’ve provided a few images in the ***“Downloads”***, but you should try the script on your own images as well.

Let’s define our 
CropLayer  class:



||class CropLayer(object): def __init__(self, params, blobs): # initialize our starting and ending (x, y)-coordinates of # the crop self.startX = 0 self.startY = 0 self.endX = 0 self.endY = 0|

 def __init__(self, params, blobs):

 # the crop

 self.startY = 0

 self.endY = 0

In order to utilize the Holistically-Nested Edge Detection model with OpenCV, we need to define a custom layer cropping class — we appropriately name this class 
CropLayer .

In the constructor of this class, we store the starting and ending *(x, y)*-coordinates of where the crop will start and end, respectively (**Lines 15-21**).

The next step when applying HED with OpenCV is to define the 
getMemoryShapes function, the method responsible for computing the volume size of the 
inputs :



|2324252627282930313233343536373839| def getMemoryShapes(self, inputs): # the crop layer will receive two inputs -- we need to crop # the first input blob to match the shape of the second one, # keeping the batch size and number of channels (inputShape, targetShape) = (inputs[0], inputs[1]) (batchSize, numChannels) = (inputShape[0], inputShape[1]) (H, W) = (targetShape[2], targetShape[3])  # compute the starting and ending crop coordinates self.startX = int((inputShape[3] - targetShape[3]) / 2) self.startY = int((inputShape[2] - targetShape[2]) / 2) self.endX = self.startX + W self.endY = self.startY + H  # return the shape of the volume (we'll perform the actual # crop during the forward pass return [[batchSize, numChannels, H, W]]|

24


26


28


30


32


34


36


38


 # the crop layer will receive two inputs -- we need to crop

 # keeping the batch size and number of channels

 (batchSize, numChannels) = (inputShape[0], inputShape[1])

 

 self.startX = int((inputShape[3] - targetShape[3]) / 2)

 self.endX = self.startX + W

 

 # crop during the forward pass

**Line 27** derives the shape of the input volume as well as the target shape.

**Line 28** extracts the batch size and number of channels from the 
inputs as well.

Finally, **Line 29** extracts the height and width of the target shape, respectively.

Given these variables, we can compute the starting and ending crop *(x, y)*-coordinates on **Lines 32-35**.

We then return the shape of the volume to the calling function on **Line 39**.

The final method we need to define is the 
forward function. This function is responsible for performing the crop during the forward pass (i.e., inference/edge prediction) of the network:



|| def forward(self, inputs): # use the derived (x, y)-coordinates to perform the crop return [inputs[0][:, :, self.startY:self.endY, self.startX:self.endX]]|

 # use the derived (x, y)-coordinates to perform the crop

 self.startX:self.endX]]

**Lines 43 and 44** take advantage of Python and NumPy’s convenient list/array slicing syntax.

Given our 
CropLayer class we can now load our HED model from disk and register 
CropLayer with the 
net:



||# load our serialized edge detector from diskprint("[INFO] loading edge detector...")protoPath = os.path.sep.join([args["edge_detector"], "deploy.prototxt"])modelPath = os.path.sep.join([args["edge_detector"], "hed_pretrained_bsds.caffemodel"])net = cv2.dnn.readNetFromCaffe(protoPath, modelPath) # register our new layer with the modelcv2.dnn_registerLayer("Crop", CropLayer)|

print("[INFO] loading edge detector...")

 "deploy.prototxt"])

 "hed_pretrained_bsds.caffemodel"])

 

cv2.dnn_registerLayer("Crop", CropLayer)

Our prototxt path and model path are built up using the 
--edge-detector  command line argument available via 
args["edge_detector"]  (**Lines 48-51**).

From there, both the 
protoPath  and 
modelPath  are used to load and initialize our Caffe model on **Line 52**.

Let’s go ahead and load our input 
image :



||# load the input image and grab its dimensionsimage = cv2.imread(args["image"])(H, W) = image.shape[:2] # convert the image to grayscale, blur it, and perform Canny# edge detectionprint("[INFO] performing Canny edge detection...")gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)blurred = cv2.GaussianBlur(gray, (5, 5), 0)canny = cv2.Canny(blurred, 30, 150)|

image = cv2.imread(args["image"])

 

# edge detection

gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

canny = cv2.Canny(blurred, 30, 150)

Our original 
image  is loaded and spatial dimensions (width and height) are extracted on **Lines 58 and 59**.

We also compute the Canny edge map (**Lines 64-66**) so we can compare our edge detection results to HED.

Finally, we’re ready to apply HED:



|6869707172737475767778798081828384858687|# construct a blob out of the input image for the Holistically-Nested# Edge Detectorblob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(W, H), mean=(104.00698793, 116.66876762, 122.67891434), swapRB=False, crop=False) # set the blob as the input to the network and perform a forward pass# to compute the edgesprint("[INFO] performing holistically-nested edge detection...")net.setInput(blob)hed = net.forward()hed = cv2.resize(hed[0, 0], (W, H))hed = (255 * hed).astype("uint8") # show the output edge detection results for Canny and# Holistically-Nested Edge Detectioncv2.imshow("Input", image)cv2.imshow("Canny", canny)cv2.imshow("HED", hed)cv2.waitKey(0)|

69


71


73


75


77


79


81


83


85


87


# Edge Detector

 mean=(104.00698793, 116.66876762, 122.67891434),

 

# to compute the edges

net.setInput(blob)

hed = cv2.resize(hed[0, 0], (W, H))

 

# Holistically-Nested Edge Detection

cv2.imshow("Canny", canny)

cv2.waitKey(0)

To apply Holistically-Nested Edge Detection (HED) with OpenCV and deep learning, we:

Construct a 
blob  from our image (**Lines 70-72**).
Pass the blob through the HED net, obtaining the 
hed  output (**Lines 77 and 78**).
- Resize the output to our original image dimensions (**Line 79**).

Scale our image pixels back to the range *[0, 255]* and ensure the type is 
"uint8"  (**Line 80**).

Finally, we we’ll display:

1. The original input image

1. The Canny edge detection image

1. Our Holistically-Nested Edge detection results


### Image and HED Results

To apply Holistically-Nested Edge Detection to your own images with OpenCV, make sure you use the ***“Downloads”*** section of this tutorial to grab the source code, trained HED model, and example image files. From there, open up a terminal and execute the following command:



||$ python detect_edges_image.py --edge-detector hed_model --image images/cat.jpg[INFO] loading edge detector...[INFO] performing Canny edge detection...[INFO] performing holistically-nested edge detection...|

[INFO] loading edge detector...

[INFO] performing holistically-nested edge detection...

![](https://www.pyimagesearch.com/wp-content/uploads/2019/03/holistically_nested_edge_detection_cat.png)
**Figure 2:** Edge detection via the HED approach with OpenCV and deep learning (input image source).

On the *left* we have our input image.

In the *center* we have the Canny edge detector.

And on the *right* is our final output after applying Holistically-Nested Edge Detection.

Notice how the Canny edge detector is not able to preserve the object boundary of the cat, mountains, or the rock the cat is sitting on.

**HED, on the other hand, is able to preserve all of those object boundaries.**

Let’s try another image:



||$ python detect_edges_image.py --edge-detector hed_model --image images/guitar.jpg[INFO] loading edge detector...[INFO] performing Canny edge detection...[INFO] performing holistically-nested edge detection...|

[INFO] loading edge detector...

[INFO] performing holistically-nested edge detection...

![](https://www.pyimagesearch.com/wp-content/uploads/2019/03/holistically_nested_edge_detection_guitar.png)
**Figure 3:** Me playing guitar in my office (*left*). Canny edge detection (*center*). Holistically-Nested Edge Detection (*right*).

In **Figure 3** above we can see an example image of myself playing guitar. With the Canny edge detector there is a lot of “noise” caused by the texture and pattern of the carpet — HED, on the other contrary, has no such noise.

Furthermore, HED does a better job of capturing the object boundaries of my shirt, my jeans (including the hole in my jeans), and my guitar.

Let’s do one final example:



||$ python detect_edges_image.py --edge-detector hed_model --image images/janie.jpg[INFO] loading edge detector...[INFO] performing Canny edge detection...[INFO] performing holistically-nested edge detection...|

[INFO] loading edge detector...

[INFO] performing holistically-nested edge detection...

![](https://www.pyimagesearch.com/wp-content/uploads/2019/03/holistically_nested_edge_detection_janie.png)
**Figure 4:** My beagle, Janie, undergoes Canny and Holistically-Nested Edge Detection (HED) with OpenCV and deep learning.

There are two objects in this image: (1) Janie, the dog, and (2) the chair behind her.

The Canny edge detector (*center*) does a reasonable job highlighting the outline of the chair but isn’t able to properly capture the object boundary of the dog, primarily due to the light/dark and dark/light transitions in her coat.

HED (*right*) is able to capture the entire outline of Janie more easily.

### Holistically-Nested Edge Detection in Video

We’ve applied Holistically-Nested Edge Detection to images with OpenCV — is it possible to do the same for videos?

Let’s find out.

Open up the 
detect_edges_video.py file and insert the following code:



||# import the necessary packagesfrom imutils.video import VideoStreamimport argparseimport imutilsimport timeimport cv2import os # construct the argument parser and parse the argumentsap = argparse.ArgumentParser()ap.add_argument("-d", "--edge-detector", type=str, required=True, help="path to OpenCV's deep learning edge detector")ap.add_argument("-i", "--input", type=str, help="path to optional input video (webcam will be used otherwise)")args = vars(ap.parse_args())|

from imutils.video import VideoStream

import imutils

import cv2

 

ap = argparse.ArgumentParser()

 help="path to OpenCV's deep learning edge detector")

 help="path to optional input video (webcam will be used otherwise)")

Our vide script requires three additional imports:


VideoStream : Reads frames from an input source such as a webcam, video file, or another source.

imutils : My package of convenience functions that I’ve made available on GitHub and PyPi. We’re using my 
resize  function.

time : This module allows us to place a sleep command to allow our video stream to establish and “warm up”.

The two command line arguments on **Lines 10-15** are quite similar:


--edge-detector : The path to OpenCV’s HED edge detector.

--input : An *optional* path to an input video file. If a path isn’t provided then the webcam will be used.

Our 
CropLayer  class is identical to the one we defined previously:



|17181920212223242526272829303132333435363738394041424344454647|class CropLayer(object): def __init__(self, params, blobs): # initialize our starting and ending (x, y)-coordinates of # the crop self.startX = 0 self.startY = 0 self.endX = 0 self.endY = 0  def getMemoryShapes(self, inputs): # the crop layer will receive two inputs -- we need to crop # the first input blob to match the shape of the second one, # keeping the batch size and number of channels (inputShape, targetShape) = (inputs[0], inputs[1]) (batchSize, numChannels) = (inputShape[0], inputShape[1]) (H, W) = (targetShape[2], targetShape[3])  # compute the starting and ending crop coordinates self.startX = int((inputShape[3] - targetShape[3]) / 2) self.startY = int((inputShape[2] - targetShape[2]) / 2) self.endX = self.startX + W self.endY = self.startY + H  # return the shape of the volume (we'll perform the actual # crop during the forward pass return [[batchSize, numChannels, H, W]]  def forward(self, inputs): # use the derived (x, y)-coordinates to perform the crop return [inputs[0][:, :, self.startY:self.endY, self.startX:self.endX]]|

18


20


22


24


26


28


30


32


34


36


38


40


42


44


46


 def __init__(self, params, blobs):

 # the crop

 self.startY = 0

 self.endY = 0

 def getMemoryShapes(self, inputs):

 # the first input blob to match the shape of the second one,

 (inputShape, targetShape) = (inputs[0], inputs[1])

 (H, W) = (targetShape[2], targetShape[3])

 # compute the starting and ending crop coordinates

 self.startY = int((inputShape[2] - targetShape[2]) / 2)

 self.endY = self.startY + H

 # return the shape of the volume (we'll perform the actual

 return [[batchSize, numChannels, H, W]]

 def forward(self, inputs):

 return [inputs[0][:, :, self.startY:self.endY,

After defining our *identical*
CropLayer  class, we’ll go ahead and initialize our video stream and HED model:



|49505152535455565758596061626364656667686970717273|# initialize a boolean used to indicate if either a webcam or input# video is being usedwebcam = not args.get("input", False) # if a video path was not supplied, grab a reference to the webcamif webcam: print("[INFO] starting video stream...") vs = VideoStream(src=0).start() time.sleep(2.0) # otherwise, grab a reference to the video fileelse: print("[INFO] opening video file...") vs = cv2.VideoCapture(args["input"]) # load our serialized edge detector from diskprint("[INFO] loading edge detector...")protoPath = os.path.sep.join([args["edge_detector"], "deploy.prototxt"])modelPath = os.path.sep.join([args["edge_detector"], "hed_pretrained_bsds.caffemodel"])net = cv2.dnn.readNetFromCaffe(protoPath, modelPath) # register our new layer with the modelcv2.dnn_registerLayer("Crop", CropLayer)|

50


52


54


56


58


60


62


64


66


68


70


72


# video is being used

 

if webcam:

 vs = VideoStream(src=0).start()

 

else:

 vs = cv2.VideoCapture(args["input"])

# load our serialized edge detector from disk

protoPath = os.path.sep.join([args["edge_detector"],

modelPath = os.path.sep.join([args["edge_detector"],

net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)

# register our new layer with the model

Whether we elect to use our 
webcam  or a video file, the script will dynamically work for either (**Lines 51-62**).

Our HED model is loaded and the 
CropLayer  is registered on **Lines 65-73**.

Let’s acquire frames in a loop and apply edge detection!



|757677787980818283848586878889|# loop over frames from the video streamwhile True: # grab the next frame and handle if we are reading from either # VideoCapture or VideoStream frame = vs.read() frame = frame if webcam else frame[1]  # if we are viewing a video and we did not grab a frame then we # have reached the end of the video if not webcam and frame is None: break  # resize the frame and grab its dimensions frame = imutils.resize(frame, width=500) (H, W) = frame.shape[:2]|

76


78


80


82


84


86


88


while True:

 # VideoCapture or VideoStream

 frame = frame if webcam else frame[1]

 # if we are viewing a video and we did not grab a frame then we

 if not webcam and frame is None:

 

 frame = imutils.resize(frame, width=500)

We begin looping over frames on **Lines 76-80**. If we reach the end of a video file (which happens when a frame is 
None ), we’ll break from the loop (**Lines 84 and 85**).

**Lines 88 and 89** resize our frame so that it has a width of 500 pixels. We then grab the dimensions of the frame after resizing.

Now let’s process the frame *exactly* as in our previous script:



|919293949596979899100101102103104105106| # convert the frame to grayscale, blur it, and perform Canny # edge detection gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) blurred = cv2.GaussianBlur(gray, (5, 5), 0) canny = cv2.Canny(blurred, 30, 150)  # construct a blob out of the input frame for the Holistically-Nested # Edge Detector, set the blob, and perform a forward pass to # compute the edges blob = cv2.dnn.blobFromImage(frame, scalefactor=1.0, size=(W, H), mean=(104.00698793, 116.66876762, 122.67891434), swapRB=False, crop=False) net.setInput(blob) hed = net.forward() hed = cv2.resize(hed[0, 0], (W, H)) hed = (255 * hed).astype("uint8")|

92


94


96


98


100


102


104


106


 # edge detection

 blurred = cv2.GaussianBlur(gray, (5, 5), 0)

 

 # Edge Detector, set the blob, and perform a forward pass to

 blob = cv2.dnn.blobFromImage(frame, scalefactor=1.0, size=(W, H),

 swapRB=False, crop=False)

 hed = net.forward()

 hed = (255 * hed).astype("uint8")

Canny edge detection (**Lines 93-95**) and HED edge detection (**Lines 100-106**) are computed over the input frame.

From there, we’ll display the edge detection results:



|108109110111112113114115116117118119120121122123124125126127128| # show the output edge detection results for Canny and # Holistically-Nested Edge Detection cv2.imshow("Frame", frame) cv2.imshow("Canny", canny) cv2.imshow("HED", hed) key = cv2.waitKey(1) & 0xFF  # if the `q` key was pressed, break from the loop if key == ord("q"): break # if we are using a webcam, stop the camera video streamif webcam: vs.stop() # otherwise, release the video file pointerelse: vs.release() # close any open windowscv2.destroyAllWindows()|

109


111


113


115


117


119


121


123


125


127


 # Holistically-Nested Edge Detection

 cv2.imshow("Canny", canny)

 key = cv2.waitKey(1) & 0xFF

 # if the `q` key was pressed, break from the loop

 break

# if we are using a webcam, stop the camera video stream

 vs.stop()

# otherwise, release the video file pointer

 vs.release()

# close any open windows

Our three output frames are displayed on **Lines 110-112**: (1) the original, resized frame, (2) the Canny edge detection result, and (3) the HED result.

Keypresses are captured via **Line 113**. If 
"q"  is pressed, we’ll break from the loop and cleanup (**Lines 116-128**).

### Video and HED Results

So, how does Holistically-Nested Edge Detection perform in real-time with OpenCV?

Let’s find out.

Be sure to use the ***“Downloads”*** section of this blog post to download the source code and HED model.

From there, open up a terminal and execute the following command:



||$ python detect_edges_video.py --edge-detector hed_model[INFO] starting video stream...[INFO] loading edge detector...|

[INFO] starting video stream...

![](https://s3-us-west-2.amazonaws.com/static.pyimagesearch.com/holistically-nested-edge-detection/holistically_nested_edge_detection_demo.gif)


In the short GIF demo above you can see a demonstration of the HED model in action.

Notice in particular how the boundary of the lamp in the background is completely lost when using the Canny edge detector; however, when using HED the boundary is preserved.

In terms of performance, I was using my 3Ghz Intel Xeon W when gathering the demo above. We are obtaining close to real-time performance on the CPU using the HED model.

To obtain true real-time performance you would need to utilize a GPU; however, keep in mind that GPU support for OpenCV’s “dnn” module is particularly limited (specifically NVIDIA GPUs are not currently supported).

In the meantime, you may want to consider using the Caffe + Python bindings if you need real-time performance.

## Summary

In this tutorial, you learned how to perform Holistically-Nested Edge Detection (HED) using OpenCV and Deep Learning.

Unlike the Canny edge detector, which requires preprocessing steps, manual tuning of parameters, and often does not perform well on images captured using varying lighting conditions, Holistically-Nested Edge Detection seeks to create an *end-to-end* deep learning edge detector.

As our results show, the output edge maps produced by HED do a better job of preserving object boundaries than the simple Canny edge detector. Holistically-Nested Edge Detection can potentially replace Canny edge detection in applications where the environment and lighting conditions are potentially unknown or simply not controllable.

The downside is that HED is *significantly* more computationally expensive than Canny. The Canny edge detector can run in super real-time on a CPU; however, real-time performance with HED would require a GPU.

I hope you enjoyed today’s post!

**To download the source code to this guide, and be notified when future tutorials are published here on PyImageSearch, *just enter your email address in the form below!***

## Downloads:
