---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/03/19/distilled-news-1002/
date:      2019-03-19
author:      Michael Laux
tags:
    - networks
    - data
    - learning
    - learned
    - sentiment
---

**Adding Custom Fonts to ggplot in R**

ggplot – You can spot one from a mile away, which is great! And when you do it’s a silent fist bump. But sometimes you want more than the standard theme. Fonts can breathe new life into your plots, helping to match the theme of your presentation, poster or report. This is always a second thought for me and need to work out how to do it again, hence the post.

**Basic Binary Sentiment Analysis using NLTK**

In today’s context, it turns out a LOT. Social media has opened the floodgates of customer opinions and it is now free-flowing in mammoth proportions for businesses to analyze. Today, using machine learning companies are able to extract these opinions in the form of text or audio and then analyze the emotions behind them on an unprecedented scale. Sentiment analysis, opinion mining call it what you like, if you have a product/service to sell you need to be on it. ‘ When captured electronically, customer sentiment?-?expressions beyond facts, that convey mood, opinion, and emotion?-?carries immense business value. We’re talking the voice of the customer, and of the prospect, patient, voter, and opinion leader.’ – Starting from user reviews in media to analyzing stock prices, sentiment analysis has become a ubiquitous tool in almost all industries. For example, the graph below shows the stock price movement of eBay with a sentiment index created based on an analysis of tweets that mention eBay.

**How I implemented googleSignIn in R (shiny) and lived**

Known user identity when building shiny apps can sometimes come really handy. While you can implement your own user login, for instance using cookies, you can also use some of the services which authenticate a user for you, such as Google. This way, you don’t have to handle cookies or passwords, just a small part of bureaucracy in your database.

**IT Support Ticket Classification and Deployment using Machine Learning and AWS Lambda**

As a part of our final project for Cognitive computing, we decided to address a real life business challenge for which we chose IT Service Management. Of all the business cases, we were interested with four user cases that might befitting for our project.

**[eBook] Standardizing the Machine Learning Lifecycle**

Successfully building and deploying a machine learning model can be difficult to do once. Enabling other data scientists (or yourself) to reproduce your pipeline, compare the results of different versions, track what’s running where, and redeploy and rollback updated models, is much harder. In this eBook, we’ll explore what makes the machine learning lifecycle so challenging compared to the traditional software-development lifecycle, and share the Databricks approach to addressing these challenges.

**R and Python: Using reticulate to get the best of both worlds**

It’s March 15th and that means it’s World Sleep Day (WSD). Don’t snooze off just yet! We’re about to check out a package that can make using R and Python a dream. It’s called reticulate and we’ll use it to train a Support Vector Machine for a simple classification task.

**Full Stack Visualizations For Complex Solutions – For Data Scientists**

This post is mainly for data scientists who want to develop an interface around their solution quickly. While it is true that you can build some interactive dashboards in Jupyter Notebooks or other places, I personally have encountered their limitations in a couple of my projects. Plus, sometimes it’s just much easier to let people play around with the solution rather than you explaining to them.

**Top R Packages for Data Cleaning**

Data cleaning is one of the most important and time consuming task for data scientists. Here are the top R packages for data cleaning.

**15 Great Articles about Bayesian Methods and Networks**

This resource is part of a series on specific topics related to data science: regression, clustering, neural networks, deep learning, decision trees, ensembles, correlation, Python, R, Tensorflow, SVM, data reduction, feature selection, experimental design, cross-validation, model fitting, and many more.

**New word for Data Science – Signuology**

I propose a new word for data science for sparking new thinking. Signuology is defined as the study of sets of characteristic predictive signals contained within data in the form of combined features of the data that are characteristic of an observation of interest within the data. The terms data mining and data structure imply rigid and discrete characteristics. A signal has more flexibility, borrowing from ideas contained in the superposition principle in physics. One can take the same data and ask a difference question, a different dependent variable, and find a different signal; the data structure will be the same. Data structure as a high level concept appears to limit one’s thinking.

**How do I know if my AI idea is possible?**

One of the questions that I get asked often as an AI consultant is, in some ways, the most simple: Is this possible? People will come to me with some very vague notion of something they want automated or some sort of AI product they want to create. They usually don’t come from a technology background, but they are smart, intelligent, informed people. They have read about AI technology being applied in other, similar domains and they see a similar opportunity in their own domain.

**Checklist for debugging neural networks**

Tangible steps you can take to identify and fix issues with training, generalization, and optimization for machine learning models

**An All-Neural On-Device Speech Recognizer**

In 2012, speech recognition research showed significant accuracy improvements with deep learning, leading to early adoption in products such as Google’s Voice Search. It was the beginning of a revolution in the field: each year, new architectures were developed that further increased quality, from deep neural networks (DNNs) to recurrent neural networks (RNNs), long short-term memory networks (LSTMs), convolutional networks (CNNs), and more. During this time, latency remained a prime focus – an automated assistant feels a lot more helpful when it responds quickly to requests.

**Magma**

Magma is an open-source software platform that gives network operators an open, flexible and extendable mobile core network solution. Magma enables better connectivity by:• Allowing operators to offer cellular service without vendor lock-in with a modern, open source core network• Enabling operators to manage their networks more efficiently with more automation, less downtime, better predictability, and more agility to add new services and applications• Enabling federation between existing MNOs and new infrastructure providers for expanding rural infrastructure• Allowing operators who are constrained with licensed spectrum to add capacity and reach by using Wi-Fi and CBRS

**Lessons learned building natural language processing systems in health care**

We’re in an exciting decade for natural language processing (NLP). Computers will get as good as humans in complex tasks like reading comprehension, language translation, and creative writing. Language understanding benefits from every part of the fast-improving ABC of software: AI (freely available deep learning libraries like PyText and language models like BERT), big data (Hadoop, Spark, and Spark NLP), and cloud (GPU’s on demand and NLP-as-a-service from all the major cloud providers).





### Like this:

Like Loading...


*Related*

