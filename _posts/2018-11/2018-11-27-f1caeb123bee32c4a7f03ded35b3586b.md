---
layout:     post
catalog: true
title:      Whats new on arXiv
subtitle:      转载自：https://analytixon.com/2018/11/27/whats-new-on-arxiv-825/
date:      2018-11-27
author:      Michael Laux
tags:
    - modeling
    - learned
    - networks
    - based
    - machine learning
---

**A Voice Controlled E-Commerce Web Application**

Automatic voice-controlled systems have changed the way humans interact with a computer. Voice or speech recognition systems allow a user to make a hands-free request to the computer, which in turn processes the request and serves the user with appropriate responses. After years of research and developments in machine learning and artificial intelligence, today voice-controlled technologies have become more efficient and are widely applied in many domains to enable and improve human-to-human and human-to-computer interactions. The state-of-the-art e-commerce applications with the help of web technologies offer interactive and user-friendly interfaces. However, there are some instances where people, especially with visual disabilities, are not able to fully experience the serviceability of such applications. A voice-controlled system embedded in a web application can enhance user experience and can provide voice as a means to control the functionality of e-commerce websites. In this paper, we propose a taxonomy of speech recognition systems (SRS) and present a voice-controlled commodity purchase e-commerce application using IBM Watson speech-to-text to demonstrate its usability. The prototype can be extended to other application scenarios such as government service kiosks and enable analytics of the converted text data for scenarios such as medical diagnosis at the clinics.

**How to improve the interpretability of kernel learning**

In recent years, machine learning researchers have focused on methods to construct flexible and interpretable prediction models. However, the interpretability evaluation, the relationship between the generalization performance and the interpretability of the model and the method for improving the interpretability are very important factors to consider. In this paper, the quantitative index of the interpretability is proposed and its rationality is given, and the relationship between the interpretability and the generalization performance is analyzed. For traditional supervised kernel machine learning problem, a universal learning framework is put forward to solve the equilibrium problem between the two performances. The uniqueness of solution of the problem is proved and condition of unique solution is obtained. Probability upper bound of the sum of the two performances is analyzed.

**Towards Emotion Recognition: A Persistent Entropy Application**

Emotion recognition and classification is a very active area of research. In this paper, we present a first approach to emotion classification using persistent entropy and support vector machines. A topology-based model is applied to obtain a single real number from each raw signal. These data are used as input of a support vector machine to classify signals into 8 different emotions (calm, happy, sad, angry, fearful, disgust and surprised).

**NeuroTreeNet: A New Method to Explore Horizontal Expansion Network**

It is widely recognized that the deeper networks or networks with more feature maps have better performance. Existing studies mainly focus on extending the network depth and increasing the feature maps of networks. At the same time, horizontal expansion network (e.g. Inception Model) as an alternative way to improve network performance has not been fully investigated. Accordingly, we proposed NeuroTreeNet (NTN), as a new horizontal extension network through the combination of random forest and Inception Model. Based on the tree structure, in which each branch represents a network and the root node features are shared to child nodes, network parameters are effectively reduced. By combining all features of leaf nodes, even less feature maps achieved better performance. In addition, the relationship between tree structure and the performance of NTN was investigated in depth. Comparing to other networks (e.g. VDSR\_5) with equal magnitude parameters, our model showed preferable performance in super resolution reconstruction task.

**On dynamic ensemble selection and data preprocessing for multi-class imbalance learning**

Class-imbalance refers to classification problems in which many more instances are available for certain classes than for others. Such imbalanced datasets require special attention because traditional classifiers generally favor the majority class which has a large number of instances. Ensemble of classifiers have been reported to yield promising results. However, the majority of ensemble methods applied to imbalanced learning are static ones. Moreover, they only deal with binary imbalanced problems. Hence, this paper presents an empirical analysis of dynamic selection techniques and data preprocessing methods for dealing with multi-class imbalanced problems. We considered five variations of preprocessing methods and fourteen dynamic selection schemes. Our experiments conducted on 26 multi-class imbalanced problems show that the dynamic ensemble improves the AUC and the G-mean as compared to the static ensemble. Moreover, data preprocessing plays an important role in such cases.

**Selected Methods for non-Gaussian Data Analysis**

The basic goal of computer engineering is the analysis of data. Such data are often large data sets distributed according to various distribution models. In this manuscript we focus on the analysis of non-Gaussian distributed data. In the case of univariate data analysis we discuss stochastic processes with auto-correlated increments and univariate distributions derived from specific stochastic processes, i.e. Levy and Tsallis distributions. Deep investigation of multivariate non-Gaussian distributions requires the copula approach. A copula is an component of multivariate distribution that models the mutual interdependence between marginals. There are many copula families characterised by various measures of the dependence between marginals. Importantly, one of those are `tail’ dependencies that model the simultaneous appearance of extreme values in many marginals. Those extreme events may reflect a crisis given financial data, outliers in machine learning, or a traffic congestion. Next we discuss higher order multivariate cumulants that are non-zero if multivariate distribution is non-Gaussian. However, the relation between cumulants and copulas is not straight forward and rather complicated. We discuss the application of those cumulants to extract information about non-Gaussian multivariate distributions, such that information about non-Gaussian copulas. The use of higher order multivariate cumulants in computer science is inspired by financial data analysis, especially by the safe investment portfolio evaluation. There are many other applications of higher order multivariate cumulants in data engineering, especially in: signal processing, non-linear system identification, blind sources separation, and direction finding algorithms of multi-source signals.

**Dancing in the Dark: Private Multi-Party Machine Learning in an Untrusted Setting**

Distributed machine learning (ML) systems today use an unsophisticated threat model: data sources must trust a central ML process. We propose a brokered learning abstraction that allows data sources to contribute towards a globally-shared model with provable privacy guarantees in an untrusted setting. We realize this abstraction by building on federated learning, the state of the art in multi-party ML, to construct TorMentor: an anonymous hidden service that supports private multi-party ML. We define a new threat model by characterizing, developing and evaluating new attacks in the brokered learning setting, along with new defenses for these attacks. We show that TorMentor effectively protects data providers against known ML attacks while providing them with a tunable trade-off between model accuracy and privacy. We evaluate TorMentor with local and geo-distributed deployments on Azure/Tor. In an experiment with 200 clients and 14 MB of data per client, our prototype trained a logistic regression model using stochastic gradient descent in 65s.

**Explicability? Legibility? Predictability? Transparency? Privacy? Security? The Emerging Landscape of Interpretable Agent Behavior**

There has been significant interest of late in generating behavior of agents that is interpretable to the human (observer) in the loop. However, the work in this area has typically lacked coherence on the topic, with proposed solutions for ‘explicable’, ‘legible’, ‘predictable’ and ‘transparent’ planning with overlapping, and sometimes conflicting, semantics all aimed at some notion of understanding what intentions the observer will ascribe to an agent by observing its behavior. This is also true for the recent works on ‘security’ and ‘privacy’ of plans which are also trying to answer the same question, but from the opposite point of view — i.e. when the agent is trying to hide instead of revealing its intentions. This paper attempts to provide a workable taxonomy of relevant concepts in this exciting and emerging field of inquiry.

**TrIMS: Transparent and Isolated Model Sharing for Low Latency Deep LearningInference in Function as a Service Environments**

Deep neural networks (DNNs) have become core computation components within low latency Function as a Service (FaaS) prediction pipelines: including image recognition, object detection, natural language processing, speech synthesis, and personalized recommendation pipelines. Cloud computing, as the de-facto backbone of modern computing infrastructure for both enterprise and consumer applications, has to be able to handle user-defined pipelines of diverse DNN inference workloads while maintaining isolation and latency guarantees, and minimizing resource waste. The current solution for guaranteeing isolation within FaaS is suboptimal — suffering from ‘cold start’ latency. A major cause of such inefficiency is the need to move large amount of model data within and across servers. We propose TrIMS as a novel solution to address these issues. Our proposed solution consists of a persistent model store across the GPU, CPU, local storage, and cloud storage hierarchy, an efficient resource management layer that provides isolation, and a succinct set of application APIs and container technologies for easy and transparent integration with FaaS, Deep Learning (DL) frameworks, and user code. We demonstrate our solution by interfacing TrIMS with the Apache MXNet framework and demonstrate up to 24x speedup in latency for image classification models and up to 210x speedup for large models. We achieve up to 8x system throughput improvement.

**MLModelScope: Evaluate and Measure ML Models within AI Pipelines**

The current landscape of Machine Learning (ML) and Deep Learning (DL) is rife with non-uniform frameworks, models, and system stacks but lacks standard tools to facilitate the evaluation and measurement of model. Due to the absence of such tools, the current practice for evaluating and comparing the benefits of proposed AI innovations (be it hardware or software) on end-to-end AI pipelines is both arduous and error prone — stifling the adoption of the innovations. We propose MLModelScope — a hardware/software agnostic platform to facilitate the evaluation, measurement, and introspection of ML models within AI pipelines. MLModelScope aids application developers in discovering and experimenting with models, data scientists developers in replicating and evaluating for publishing models, and system architects in understanding the performance of AI workloads. We describe the design and implementation of MLModelScope and show how it is able to give users a holistic view into the execution of models within AI pipelines. Using AlexNet as a case study, we demonstrate how MLModelScope aids in identifying deviation in accuracy, helps in pin pointing the source of system bottlenecks, and automates the evaluation and performance aggregation of models across frameworks and systems.

**Characterizing and Avoiding Negative Transfer**

When labeled data is scarce for a specific target task, transfer learning often offers an effective solution by utilizing data from a related source task. However, when transferring knowledge from a less related source, it may inversely hurt the target performance, a phenomenon known as negative transfer. Despite its pervasiveness, negative transfer is usually described in an informal manner, lacking rigorous definition, careful analysis, or systematic treatment. This paper proposes a formal definition of negative transfer and analyzes three important aspects thereof. Stemming from this analysis, a novel technique is proposed to circumvent negative transfer by filtering out unrelated source data. Based on adversarial networks, the technique is highly generic and can be applied to a wide range of transfer learning algorithms. The proposed approach is evaluated on six state-of-the-art deep transfer methods via experiments on four benchmark datasets with varying levels of difficulty. Empirically, the proposed method consistently improves the performance of all baseline methods and largely avoids negative transfer, even when the source data is degenerate.

**Strategy of the Negative Sampling for Training Retrieval-Based Dialogue Systems**

The article describes the new approach for quality improvement of automated dialogue systems for customer support service. Analysis produced in the paper demonstrates the dependency of the quality of the retrieval-based dialogue system quality on the choice of negative responses. The proposed approach implies choosing the negative samples according to the distribution of responses in the train set. In this implementation the negative samples are randomly chosen from the original response distribution and from the ‘artificial’ distribution of negative responses, such as uniform distribution or the distribution obtained by transformation of the original one. The results obtained for the implemented systems and reported in this paper confirm the significant improvement of automated dialogue systems quality in case of using the negative responses from transformed distribution.

**Recurrently Controlled Recurrent Networks**

Recurrent neural networks (RNNs) such as long short-term memory and gated recurrent units are pivotal building blocks across a broad spectrum of sequence modeling problems. This paper proposes a recurrently controlled recurrent network (RCRN) for expressive and powerful sequence encoding. More concretely, the key idea behind our approach is to learn the recurrent gating functions using recurrent networks. Our architecture is split into two components – a controller cell and a listener cell whereby the recurrent controller actively influences the compositionality of the listener cell. We conduct extensive experiments on a myriad of tasks in the NLP domain such as sentiment analysis (SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment classification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading comprehension (NarrativeQA). Across all 26 datasets, our results demonstrate that RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs, suggesting that our controller architecture might be a suitable replacement for the widely adopted stacked architecture.

**Exploiting Test Time Evidence to Improve Predictions of Deep Neural Networks**

Many prediction tasks, especially in computer vision, are often inherently ambiguous. For example, the output of semantic segmentation may depend on the scale one is looking at, and image saliency or video summarization is often user or context dependent. Arguably, in such scenarios, exploiting instance specific evidence, such as scale or user context, can help resolve the underlying ambiguity leading to the improved predictions. While existing literature has considered incorporating such evidence in classical models such as probabilistic graphical models (PGMs), there is limited (or no) prior work looking at this problem in the context of deep neural network (DNN) models. In this paper, we present a generic multi task learning (MTL) based framework which handles the evidence as the output of one or more secondary tasks, while modeling the original problem as the primary task of interest. Our training phase is identical to the one used by standard MTL architectures. During prediction, we back-propagate the loss on secondary task(s) such that network weights are re-adjusted to match the evidence. An early stopping or two norm based regularizer ensures weights do not deviate significantly from the ones learned originally. Implementation in two specific scenarios (a) predicting semantic segmentation given the image level tags (b) predicting instance level segmentation given the text description of the image, clearly demonstrates the effectiveness of our proposed approach.

**Novelty and Coverage in context-based information filtering**

We present a collection of algorithms to filter a stream of documents in such a way that the filtered documents will cover as well as possible the interest of a person, keeping in mind that, at any given time, the offered documents should not only be relevant, but should also be diversified, in the sense not only of avoiding nearly identical documents, but also of covering as well as possible all the interests of the person. We use a modification of the WEBSOM algorithm, with limited architectural adaptation, to create a user model (which we call the ‘user context’ or simply the ‘context’) based on a network of units laid out in the word space and trained using a collection of documents representative of the context. We introduce the concepts of novelty and coverage. Novelty is related to, but not identical to, the homonymous information retrieval concept: a document is novel it it belongs to a semantic area of interest to a person for which no documents have been seen in the recent past. A group of documents has coverage to the extent to which it is a good representation of all the interests of a person. In order to increase coverage, we introduce an ‘interest’ (or ‘urgency’) factor for each unit of the user model, modulated by the scores of the incoming documents: the interest of a unit is decreased drastically when a document arrives that belongs to its semantic area and slowly recovers its initial value if no documents from that semantic area are displayed. Our tests show that these algorithms can effectively increase the coverage of the documents that are shown to the user without overly affecting precision.

**OCLEP+: One-class Anomaly and Intrusion Detection Using Minimal Length of Emerging Patterns**

This paper presents a method called One-class Classification using Length statistics of Emerging Patterns Plus (OCLEP+).

**Average-Case Information Complexity of Learning**
![](https://s0.wp.com/latex.php?latex=d&bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=d%3D1&bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=%5Cinfty&bg=ffffff&fg=000&s=0)

![](https://s0.wp.com/latex.php?latex=O%28d%29&bg=ffffff&fg=000&s=0)


**Intersectionality: Multiple Group Fairness in Expectation Constraints**

Group fairness is an important concern for machine learning researchers, developers, and regulators. However, the strictness to which models must be constrained to be considered fair is still under debate. The focus of this work is on constraining the expected outcome of subpopulations in kernel regression and, in particular, decision tree regression, with application to random forests, boosted trees and other ensemble models. While individual constraints were previously addressed, this work addresses concerns about incorporating multiple constraints simultaneously. The proposed solution does not affect the order of computational or memory complexity of the decision trees and is easily integrated into models post training.

**Graph Learning-Convolutional Networks**

Recently, graph Convolutional Neural Networks (graph CNNs) have been widely used for graph data representation and semi-supervised learning tasks. However, existing graph CNNs generally use a fixed graph which may be not optimal for semi-supervised learning tasks. In this paper, we propose a novel Graph Learning-Convolutional Network (GLCN) for graph data representation and semi-supervised learning. The aim of GLCN is to learn an optimal graph structure that best serves graph CNNs for semi-supervised learning by integrating both graph learning and graph convolution together in a unified network architecture. The main advantage is that in GLCN, both given labels and the estimated labels are incorporated and thus can provide useful ‘weakly’ supervised information to refine (or learn) the graph construction and also to facilitate the graph convolution operation in GLCN for unknown label estimation. Experimental results on seven benchmarks demonstrate that GLCN significantly outperforms state-of-the-art traditional fixed structure based graph CNNs.

• From Random Times to Fractional Kinetics• Homogeneity-Based Transmissive Process to Model True and False News in Social Networks• Random Attractors for Stochastic Navier-Stokes equation on a 2D rotating sphere with stable Lévy noise• An Isoperimetric Result on High-Dimensional Spheres• CNN based dense underwater 3D scene reconstruction by transfer learning using bubble database• Physics-aware Deep Generative Models for Creating Synthetic Microstructures• Speech recognition with quaternion neural networks• Group induced graphical lasso allows for discovery of molecular pathways-pathways interactions• Structure-Based Networks for Drug Validation• Energy-Based In-Domain Control of a Piezo-Actuated Euler-Bernoulli Beam• A Variable Rate Fronthaul Scheme for Cloud Radio Access Networks (C-RAN)• Online inverse reinforcement learning for nonlinear systems• Defining rough sets using tolerances compatible with an equivalence• A geometric way to build strong mixed-integer programming formulations• Minimax adaptive wavelet estimator for the anisotropic functional deconvolution model with unknown kernel• Optimal Hybrid Beamforming for Multiuser Massive MIMO Systems With Individual SINR Constraints• Bytes are All You Need: End-to-End Multilingual Speech Recognition and Synthesis with Bytes• Rethinking Binary Neural Network for Accurate Image Classification and Semantic Segmentation• Analysis of topological derivative as a tool for qualitative identification• Multi-Task Generative Adversarial Network for Handling Imbalanced Clinical Data• Representation Results for Law Invariant Recursive Dynamic Deviation Measures and Risk Sharing• Machine learning enables long time scale molecular photodynamics simulations• Creating a contemporary corpus of similes in Serbian by using natural language processing• GASTAP: A Gas Analyzer for Smart Contracts• Inference of the three-dimensional chromatin structure and its temporal behavior• Dynamic Ecological System Measures• TimbreTron: A WaveNet(CycleGAN(CQT(Audio))) Pipeline for Musical Timbre Transfer• GuacaMol: Benchmarking Models for De Novo Molecular Design• Energy-Efficient Data Collection and Wireless Power Transfer Using A MIMO Full-Duplex UAV• MR-GAN: Manifold Regularized Generative Adversarial Networks• Two Models of Latent Consensus in Multi-Agent Systems• Two Cognitive Transitions Underlying the Capacity for Cultural Evolution• Nonlinear Regression without i.i.d. Assumption• Linear versus spin: representation theory of the symmetric groups• On Filter Size in Graph Convolutional Networks• A Novel Learning-based Global Path Planning Algorithm for Planetary Rovers• Quantifying Privacy in Nuclear Warhead Authentication Protocols• The nonlinear distribution of employment across municipalities• Core-Selecting Mechanisms in Electricity Markets• On polyhedral approximations of the positive semidefinite cone• A New Cervical Cytology Dataset for Nucleus Detection and Image Classification (Cervix93) and Methods for Cervical Nucleus Detection• Generalised Entropies and Metric-Invariant Optimal Countermeasures for Information Leakage under Symmetric Constraints• Unsupervised brain lesion segmentation from MRI using a convolutional autoencoder• Hierarchical visuomotor control of humanoids• Enhancing Engagement in Token-Curated Registries via an Inflationary Mechanism• Detailed Investigation of Deep Features with Sparse Representation and Dimensionality Reduction in CBIR: A Comparative Study• An infinite-dimensional helix invariant under spherical projections• Multilevel-Coded Pulse-Position Modulation for Covert Communications over Binary-Input Discrete Memoryless Channels• Learning to attend in a brain-inspired deep neural network• MIMO Antenna Elements Effect on Chassis Modes• Robustness via curvature regularization, and vice versa• Representer Point Selection for Explaining Deep Neural Networks• Costless: Optimizing Cost of Serverless Computing through Function Fusion and Placement• 3D Deep Learning with voxelized atomic configurations for modeling atomistic potentials in complex solid-solution alloys• Interpretable Convolutional Filters with SincNet• Data Driven Linearized AC Power Flow Model with Regression Analysis• Generate, Segment and Replace: Towards Generic Manipulation Segmentation• A Regularized Spatial Market Segmentation Method with Dirichlet Process Gaussian Mixture Prior• A Multi-variable Stacked Long-Short Term Memory Network for Wind Speed Forecasting• Connecting the Dots Between MLE and RL for Sequence Generation• Divergence Prior and Vessel-tree Reconstruction• Amortized Bayesian inference for clustering models• Automating Motion Correction in Multishot MRI Using Generative Adversarial Networks• Estimation of Inter-Sentiment Correlations Employing Deep Neural Network Models• Physics-Informed CoKriging: A Gaussian-Process-Regression-Based Multifidelity Method for Data-Model Convergence• Learning to Activate Relay Nodes: Deep Reinforcement Learning Approach• Mean Local Group Average Precision (mLGAP): A New Performance Metric for Hashing-based Retrieval• The geometry of big queues• DEFactor: Differentiable Edge Factorization-based Probabilistic Graph Generation• Wilson loops in Ising lattice gauge theory• A^2Net: Adjacent Aggregation Networks for Image Raindrop Removal• Alternating Loss Correction for Preterm-Birth Prediction from EHR Data with Noisy Labels• What and Where: A Context-based Recommendation System for Object Insertion• Senti-Attend: Image Captioning using Sentiment and Attention• Spatio-Temporal Road Scene Reconstruction using Superpixel MRF• Discriminative Feature Learning for Unsupervised Video Summarization• Three-Dimensionally Embedded Graph Convolutional Network (3DGCN) for Molecule Interpretation• Self-Supervised Video Representation Learning with Space-Time Cubic Puzzles• On Independent Cliques and Linear Complementarity Problems• Bayesian QuickNAT: Model Uncertainty in Deep Whole-Brain Segmentation for Structure-wise Quality Control• Polar Decoding on Sparse Graphs with Deep Learning• New ideas in Last-Success-Problems• Streamlining Variational Inference for Constraint Satisfaction Problems• Object Detection based Deep Unsupervised Hashing• A multiple comparison procedure for dose-finding trials with subpopulations• Evolutionary-Neural Hybrid Agents for Architecture Search• Attention, Please! Adversarial Defense via Attention Rectification and Preservation• Simulation of Matrix Product State on a Quantum Computer• Efficient Video Understanding via Layered Multi Frame-Rate Analysis• Permutational powers of a graph• Heterogenous Coefficients, Discrete Instruments, and Identification of Treatment Effects• Uncorrelatedness sets of discrete uniform distributions via Vandermonde-type determinants• Keep Drawing It: Iterative language-based image generation and editing• Robust RGB-D Face Recognition Using Attribute-Aware Loss• The Problem of Pawns• A note on the Bilinear Bogolyubov Theorem: Transverse and bilinear sets• FANet: Quality-Aware Feature Aggregation Network for RGB-T Tracking• Subband Beamforming in Coherent Hybrid Massive MIMO Using Eigenbeams• On Periodic Functions as Regularizers for Quantization of Neural Networks• MEMOIR: Multi-class Extreme Classification with Inexact Margin• Hardware Conditioned Policies for Multi-Robot Transfer Learning• General Bernstein-like inequality for additive functionals of Markov chains• Complement-Free Couples Must Communicate: A Hardness Result for Two-Player Combinatorial Auctions• Hydra: A Peer to Peer Distributed Training & Data Collection Framework• Sensitivity Analysis of Continuous-Time Linear Control Systems subject to Control and Measurement Noise: An Information-Theoretic Approach• A Simplified Approach to Analyze Complementary Sensitivity Trade-offs in Continuous-Time and Discrete-Time Systems• Forward Stability of ResNet and Its Variants• Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications• Matching Disparate Image Pairs Using Shape-Aware ConvNets• Conditional Recurrent Flow: Conditional Generation of Longitudinal Samples with Applications to Neuroimaging• TGE-viz : Transition Graph Embedding for Visualization of Plan Traces and Domains• Biscotti: A Ledger for Private and Secure Peer-to-Peer Machine Learning• RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks• Steady-state Non-Line-of-Sight Imaging• Joint modeling of evacuation departure and travel times in hurricanes• RADMPC: A Fast Decentralized Approach for Chance-Constrained Multi-Vehicle Path-Planning• Generating Realistic Training Images Based on Tonality-Alignment Generative Adversarial Networks for Hand Pose Estimation• An efficient nonnegativity preserving algorithm for multilinear systems with nonsingular M-tensors• A Method for Analysis of Patient Speech in Dialogue for Dementia Detection• An Unified Intelligence-Communication Model for Multi-Agent System Part-I: Overview• The most probable neural circuit exhibits low-dimensional sustained activity• Spatiotemporal Arbitrage of Large-Scale Portable Energy Storage for Grid Congestion Relief• Clustering of Transcriptomic Data for the Identification of Cancer Subtypes• PCGAN: Partition-Controlled Human Image Generation• A multi-dimensional extension of the Lightweight Temporal Compression method• Channel Capacity for MIMO Spectrally Precoded OFDM with Block Reflectors• Guided Feature Selection for Deep Visual Odometry• Loop Closure Detection with RGB-D Feature Pyramid Siamese Networks• Geometric Invariants for Sparse Unknown View Tomography• On very restricted arithmetic progressions in symmetric sets in finite field model• Privacy-Preserving Action Recognition for Smart Hospitals using Low-Resolution Depth Images• Online Newton Step Algorithm with Estimated Gradient• Glottal Closure Instants Detection From Pathological Acoustic Speech Signal Using Deep Learning• Deep RNN Framework for Visual Sequential Applications• Practical optimal registration of terrestrial LiDAR scan pairs• Generalized $R^2$ Measures for a Mixture of Bivariate Linear Dependences• On-chip learning for domain wall synapse based Fully Connected Neural Network• Learning Sound Events From Webly Labeled Data• Heat kernel for non-local operators with variable order• Joint State Estimation and Communication over a State-Dependent Gaussian Multiple Access Channel• Temporal Bilinear Networks for Video Action Recognition• Sequential Variational Autoencoders for Collaborative Filtering• Robust Super-Level Set Estimation using Gaussian Processes• Birational geometry of symplectic quotient singularities• On the König-Hall-Egerváry theorem for multidimensional matrices and multipartite hypergraphs• Is Data Clustering in Adversarial Settings Secure?• Poisoning Behavioral Malware Clustering• Learning Conditional Random Fields with Augmented Observations for Partially Observed Action Recognition• The dry history of liquid computers• Externalities in Socially-Based Resource Sharing Network• Virtual Sensor for Vehicle Sideslip Angle Based on Tire Model Adaptation• Low-resolution Face Recognition in the Wild via Selective Knowledge Distillation• Enabling Efficient Updates in KV Storage via Hashing: Design and Performance Evaluation• Non-local RoI for Cross-Object Perception• A pooling based scene text proposal technique for scene text reading in the wild• Visual Attention on the Sun: What Do Existing Models Actually Predict?• Nonlinear Dynamics of Binocular Rivalry: A Comparative Study• Bi-Free Extreme Values• Complexity of computing an arbitrary lifted cover inequality• The Unimodality of the Crank on Overpartitions• Describe and Attend to Track: Learning Natural Language guided Structural Representation and Visual Attention for Object Tracking• An elementary approach to the quasipolynomiality of the Kronecker coefficients• Dissimilarity Coefficient based Weakly Supervised Object Detection• Background Subtraction with Real-time Semantic Segmentation• Multi-view Point Cloud Registration with Adaptive Convergence Threshold and its Application on 3D Model Retrieval





### Like this:

Like Loading...


*Related*

