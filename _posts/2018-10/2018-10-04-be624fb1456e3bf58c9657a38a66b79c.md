---
layout:     post
catalog: true
title:      Whats new on arXiv
subtitle:      转载自：https://advanceddataanalytics.net/2018/10/04/whats-new-on-arxiv-780/
date:      2018-10-04
author:      Michael Laux
tags:
    - networks
    - networked
    - based
    - modeling
    - models
---

**A Direct Proof of the Reflection Principle for Brownian Motion**

We present a self-contained proof of the reflection principle for Brownian Motion.

**Link Prediction Adversarial Attack**

Deep neural network has shown remarkable performance in solving computer vision and some graph evolved tasks, such as node classification and link prediction. However, the vulnerability of deep model has also been revealed by carefully designed adversarial examples generated by various adversarial attack methods. With the wider application of deep model in complex network analysis, in this paper we define and formulate the link prediction adversarial attack problem and put forward a novel iterative gradient attack (IGA) based on the gradient information in trained graph auto-encoder (GAE). To our best knowledge, it is the first time link prediction adversarial attack problem is defined and attack method is brought up. Not surprisingly, GAE was easily fooled by adversarial network with only a few links perturbed on the clean network. By conducting comprehensive experiments on different real-world data sets, we can conclude that most deep model based and other state-of-art link prediction algorithms cannot escape the adversarial attack just like GAE. We can benefit the attack as an efficient privacy protection tool from link prediction unknown violation, on the other hand, link prediction attack can be a robustness evaluation metric for current link prediction algorithm in attack defensibility.

**Three remarkable properties of the Normal distribution**

In this paper, we present three remarkable properties of the normal distribution: first that if two independent variables’s sum is normally distributed, then each random variable follows a normal distribution (which is referred to as one of the Levy Cramer theorems), second a variation of the Levy Cramer theorem that states that if two independent symmetric random variables with finite variance have their sum and their difference independent, then each random variable follows a standard normal distribution, and third that the normal distribution is characterized by the fact that it is the only distribution for which the sample mean and variance are independent (which is a central property for deriving the Student distribution and referred as the Geary theorem. The novelty of this paper is to provide new, quicker or self contained proofs of theses theorems.

**Hierarchical community detection by recursive bi-partitioning**
![](https://s0.wp.com/latex.php?latex=K&bg=ffffff&fg=000&s=0)


**Timely Lossless Source Coding for Randomly Arriving Symbols**

We consider a real-time streaming source coding system in which an encoder observes a sequence of randomly arriving symbols from an i.i.d. source, and feeds binary codewords to a FIFO buffer that outputs one bit per time unit to a decoder. Each source symbol represents a status update by the source, and the timeliness of the system is quantified by the age of information (AoI), defined as the time difference between the present time and the generation time of the most up-to-date symbol at the output of the decoder. When the FIFO buffer is allowed to be empty, we propose an optimal prefix-free lossless coding scheme that minimizes the average peak age based on the analysis of discrete-time Geo/G/1 queue. For more practical scenarios in which a special codeword is reserved for indicating an empty buffer, we propose an encoding scheme that assigns a codeword to the empty buffer state based on an estimate of the buffer idle time.

**Posterior Prototyping: Bridging the Gap between Bayesian Record Linkage and Regression**

Record linkage (entity resolution or de-deduplication) is the process of merging noisy databases to remove duplicate entities. While record linkage removes duplicate entities from the data, many researchers are interested in performing inference, prediction or post-linkage analysis on the linked data, which we call the downstream task. Depending on the downstream task, one may wish to find the most representative record before performing the post-linkage analysis. Motivated by the downstream task, we propose first performing record linkage using a Bayesian model and then choosing representative records through prototyping. Given the information about the representative records, we then explore two downstream tasks – linear regression and binary classification via logistic regression. In addition, we explore how error propagation occurs in both of these settings. We provide thorough empirical studies for our proposed methodology, and conclude with a discussion of practical insights into our work.

**Automated learning with a probabilistic programming language: Birch**

This work offers a broad perspective on probabilistic modeling and inference in light of recent advances in probabilistic programming, in which models are formally expressed in Turing-complete programming languages. We consider a typical workflow and how probabilistic programming languages can help to automate this workflow, especially in the matching of models with inference methods. We focus on two properties of a model that are critical in this matching: its structure—the conditional dependencies between random variables—and its form—the precise mathematical definition of those dependencies. While the structure and form of a probabilistic model are often fixed a priori, it is a curiosity of probabilistic programming that they need not be, and may instead vary according to random choices made during program execution. We introduce a formal description of models expressed as programs, and discuss some of the ways in which probabilistic programming languages can reveal the structure and form of these, in order to tailor inference methods. We demonstrate the ideas with a new probabilistic programming language called Birch, with a multiple object tracking example.

**Co-Arg: Cogent Argumentation with Crowd Elicitation**

This paper presents Co-Arg, a new type of cognitive assistant to an intelligence analyst that enables the synergistic integration of analyst imagination and expertise, computer knowledge and critical reasoning, and crowd wisdom, to draw defensible and persuasive conclusions from masses of evidence of all types, in a world that is changing all the time. Co-Arg’s goal is to improve the quality of the analytic results and enhance their understandability for both experts and novices. The performed analysis is based on a sound and transparent argumentation that links evidence to conclusions in a way that shows very clearly how the conclusions have been reached, what evidence was used and how, what is not known, and what assumptions have been made. The analytic results are presented in a report describes the analytic conclusion and its probability, the main favoring and disfavoring arguments, the justification of the key judgments and assumptions, and the missing information that might increase the accuracy of the solution.

**A Generalized Neyman-Pearson Criterion for Optimal Domain Adaptation**

In the problem domain adaptation for binary classification, the learner is presented with labeled examples from a source domain, and must correctly classify unlabeled examples from a target domain, which may differ from the source. Previous work on this problem has assumed that the performance measure of interest is the expected value of some loss function. We introduce a new Neyman-Pearson-like criterion and argue that, for this optimality criterion, stronger domain adaptation results are possible than what has previously been established. In particular, we study a class of domain adaptation problems that generalizes both the covariate shift assumption and a model for feature-dependent label noise, and establish optimal classification on the target domain despite not having access to labelled data from this domain.

**GI-OHMS: Graphical Inference to Detect Overlapping Communities**

Discovery of communities in complex networks is a topic of considerable recent interest within the complex systems community. Due to the dynamic and rapidly evolving nature of large-scale networks, like online social networks, the notion of stronger local and global interactions among the nodes in communities has become harder to capture. In this paper, we present a novel graphical inference method – GI-OHMS (Graphical Inference in Observed-Hidden variable Merged Seeded network) to solve the problem of overlapping community detection. The novelty of our approach is in transforming the complex and dense network of interest into an observed-hidden merged seeded(OHMS) network, which preserves the important community properties of the network. We further utilize a graphical inference method (Bayesian Markov Random Field) to extract communities. The superiority of our approach lies in two main observations: 1) The extracted OHMS network excludes many weaker connections, thus leading to a higher accuracy of inference 2) The graphical inference step operates on a smaller network, thus having much lower execution time. We demonstrate that our method outperforms the accuracy of other baseline algorithms like OSLOM, DEMON, and LEMON. To further improve execution time, we have a multi-threaded implementation and demonstrate significant speed-up compared to state-of-the-art algorithms.

**A Deep Learning Architecture for De-identification of Patient Notes: Implementation and Evaluation**

De-identification is the process of removing 18 protected health information (PHI) from clinical notes in order for the text to be considered not individually identifiable. Recent advances in natural language processing (NLP) has allowed for the use of deep learning techniques for the task of de-identification. In this paper, we present a deep learning architecture that builds on the latest NLP advances by incorporating deep contextualized word embeddings and variational drop out Bi-LSTMs. We test this architecture on two gold standard datasets and show that the architecture achieves state-of-the-art performance on both data sets while also converging faster than other systems without the use of dictionaries or other knowledge sources.

**Deep Fundamental Matrix Estimation without Correspondences**

Estimating fundamental matrices is a classic problem in computer vision. Traditional methods rely heavily on the correctness of estimated key-point correspondences, which can be noisy and unreliable. As a result, it is difficult for these methods to handle image pairs with large occlusion or significantly different camera poses. In this paper, we propose novel neural network architectures to estimate fundamental matrices in an end-to-end manner without relying on point correspondences. New modules and layers are introduced in order to preserve mathematical properties of the fundamental matrix as a homogeneous rank-2 matrix with seven degrees of freedom. We analyze performance of the proposed models using various metrics on the KITTI dataset, and show that they achieve competitive performance with traditional methods without the need for extracting correspondences.

**Optimization Algorithm Inspired Deep Neural Network Structure Design**

Deep neural networks have been one of the dominant machine learning approaches in recent years. Several new network structures are proposed and have better performance than the traditional feedforward neural network structure. Representative ones include the skip connection structure in ResNet and the dense connection structure in DenseNet. However, it still lacks a unified guidance for the neural network structure design. In this paper, we propose the hypothesis that the neural network structure design can be inspired by optimization algorithms and a faster optimization algorithm may lead to a better neural network structure. Specifically, we prove that the propagation in the feedforward neural network with the same linear transformation in different layers is equivalent to minimizing some function using the gradient descent algorithm. Based on this observation, we replace the gradient descent algorithm with the heavy ball algorithm and Nesterov’s accelerated gradient descent algorithm, which are faster and inspire us to design new and better network structures. ResNet and DenseNet can be considered as two special cases of our framework. Numerical experiments on CIFAR-10, CIFAR-100 and ImageNet verify the advantage of our optimization algorithm inspired structures over ResNet and DenseNet.

**Granger causality on horizontal sum of Boolean algebras**
![](https://s0.wp.com/latex.php?latex=%5Csigma&bg=ffffff&fg=000&s=0)


**A Comparative Study of Neural Network Models for Sentence Classification**

This paper presents an extensive comparative study of four neural network models, including feed-forward networks, convolutional networks, recurrent networks and long short-term memory networks, on two sentence classification datasets of English and Vietnamese text. We show that on the English dataset, the convolutional network models without any feature engineering outperform some competitive sentence classifiers with rich hand-crafted linguistic features. We demonstrate that the GloVe word embeddings are consistently better than both Skip-gram word embeddings and word count vectors. We also show the superiority of convolutional neural network models on a Vietnamese newspaper sentence dataset over strong baseline models. Our experimental results suggest some good practices for applying neural network models in sentence classification.

**selectBoost: a general algorithm to enhance the performance of variable selection methods in correlated datasets**

Motivation: With the growth of big data, variable selection has become one of the major challenges in statistics. Although many methods have been proposed in the literature their performance in terms of recall and precision are limited in a context where the number of variables by far exceeds the number of observations or in a high correlated setting. Results: In this article, we propose a general algorithm which improves the precision of any existing variable selection method. This algorithm is based on highly intensive simulations and takes into account the correlation structure of the data. Our algorithm can either produce a confidence index for variable selection or it can be used in an experimental design planning perspective. We demonstrate the performance of our algorithm on both simulated and real data.

**A Puff of Steem: Security Analysis of Decentralized Content Curation**

Decentralized content curation is the process through which uploaded posts are ranked and filtered based exclusively on users’ feedback. Platforms such as the blockchain-based Steemit employ this type of curation while providing monetary incentives to promote the visibility of high quality posts according to the perception of the participants. Despite the wide adoption of the platform very little is known regarding its performance and resilience characteristics. In this work, we provide a formal model for decentralized content curation that identifies salient complexity and game-theoretic measures of performance and resilience to selfish participants. Armed with our model, we provide a first analysis of Steemit identifying the conditions under which the system can be expected to correctly converge to curation while we demonstrate its susceptibility to selfish participant behaviour. We validate our theoretical results with system simulations in various scenarios.

**Can everyday AI be ethical. Fairness of Machine Learning Algorithms**

Combining big data and machine learning algorithms, the power of automatic decision tools induces as much hope as fear. Many recently enacted European legislation (GDPR) and French laws attempt to regulate the use of these tools. Leaving aside the well-identified problems of data confidentiality and impediments to competition, we focus on the risks of discrimination, the problems of transparency and the quality of algorithmic decisions. The detailed perspective of the legal texts, faced with the complexity and opacity of the learning algorithms, reveals the need for important technological disruptions for the detection or reduction of the discrimination risk, and for addressing the right to obtain an explanation of the auto- matic decision. Since trust of the developers and above all of the users (citizens, litigants, customers) is essential, algorithms exploiting personal data must be deployed in a strict ethical framework. In conclusion, to answer this need, we list some ways of controls to be developed: institutional control, ethical charter, external audit attached to the issue of a label.

**McTorch, a manifold optimization library for deep learning**

**Shrinkwrap: Differentially-Private Query Processing in Private Data Federations**

A private data federation is a set of autonomous databases that share a unified query interface offering in-situ evaluation of SQL queries over the union of the sensitive data of its members. Owing to privacy concerns, these systems do not have a trusted data collector that can see all their data and their member databases cannot learn about individual records of other engines. Federations currently achieve this goal by evaluating queries obliviously using secure multiparty computation. This hides the intermediate result cardinality of each query operator by exhaustively padding it. With cascades of such operators, this padding accumulates to a blow-up in the output size of each operator and a proportional loss in query performance. Hence, existing private data federations do not scale well to complex SQL queries over large datasets. We introduce Shrinkwrap, a private data federation that offers data owners a differentially private view of the data held by others to improve their performance over oblivious query processing. Shrinkwrap uses computational differential privacy to minimize the padding of intermediate query results, achieving up to 35X performance improvement over oblivious query processing. When the query needs differentially private output, Shrinkwrap provides a trade-off between result accuracy and query evaluation performance.

**Weighted Sigmoid Gate Unit for an Activation Function of Deep Neural Network**

An activation function has crucial role in a deep neural network. A simple rectified linear unit (ReLU) are widely used for the activation function. In this paper, a weighted sigmoid gate unit (WiG) is proposed as the activation function. The proposed WiG consists of a multiplication of inputs and the weighted sigmoid gate. It is shown that the WiG includes the ReLU and same activation functions as a special case. Many activation functions have been proposed to overcome the performance of the ReLU. In the literature, the performance is mainly evaluated with an object recognition task. The proposed WiG is evaluated with the object recognition task and the image restoration task. Then, the expeirmental comparisons demonstrate the proposed WiG overcomes the existing activation functions including the ReLU.

• Auction Theory Extensions for Real Life Applications• Functional Dynamics by Intention Recognition in Iterated Games• PhoneMD: Learning to Diagnose Parkinson’s Disease from Smartphone Data• Synthesis of Majority Expressions through Primitive Function Manipulation• Using Machine Learning to Discern Eruption in Noisy Environments: A Case Study using CO2-driven Cold-Water Geyser in Chimayo, New Mexico• Closed-Form Directivity Expression for Arbitrary Volumetric Antenna Arrays• Reinforcement Learning for Model-Free Power Management of Networked Microgrids• Hives Determined by Pairs in the Affine Grassmannian over Discrete Valuation Rings• Predicting Factuality of Reporting and Bias of News Media Sources• Determining r-Robustness of Arbitrary Digraphs Using Zero-One Linear Integer Programming• Global stability of the Rate Control Protocol (RCP) and some implications for protocol design• Efficient Fastest-Path Computations in Road Maps• PromID: human promoter prediction by deep learning• Rough set based lattice structure for knowledge representation in medical expert systems: low back pain management case study• Scientific image rendering for space scenes with the SurRender software• Mixing patterns and individual differences in networks• Efficient Estimation of Equilibria of Large Congestion Games with Heterogeneous Players• A Novel Algebraic Geometry Compiling Framework for Adiabatic Quantum Computations• Impact of 3D UWB Antenna Radiation Pattern on Air-to-Ground Drone Connectivity Jianlin Chen,• Eco-Routing of Plug-In Hybrid Electric Vehicles in Transportation Networks• Representation Flow for Action Recognition• Unsupervised Machine Learning of Open Source Russian Twitter Data Reveals Global Scope and Operational Characteristics• Structured Multi-Label Biomedical Text Tagging via Attentive Neural Tree Decoding• Modeling and Performance of Microwave and Millimeter-Wave Layered Waveguide Filters• Adaptive, Personalized Diversity for Visual Discovery• Optimally Segmenting Inputs for NMT Shows Preference for Character-Level Processing• Diversifying Music Recommendations• DeepCMB: Lensing Reconstruction of the Cosmic Microwave Background with Deep Neural Networks• Submodular Optimization in the MapReduce Model• Correlation-induced localization• Opinion Formation Threshold Estimates from Different Combinations of Social Media Data-Types• An Analysis of Approaches Taken in the ACM RecSys Challenge 2018 for Automatic Music Playlist Continuation• Distinguishing numbers of finite $4$-valent vertex-transitive graphs• Semidefinite Relaxation-Based PAPR-Aware Precoding for Massive MIMO-OFDM Systems• Harnessing Correlations in Distributed Erasure Coded Key-Value Stores• Distributive Lattices have the Intersection Property• Three-Cornered Hat and Groslambert Covariance: A first attempt to assess the uncertainty domains• Band Assignment in Dual Band Systems: A Learning-based Approach• Finite $3$-connected homogeneous graphs• Odds for the Brazilian 2018 president elections: An application of Bayesian statistics in contingency tables• The Effect of Data Marshalling on Computation Offloading Decisions• Contracting to a Longest Path in H-Free Graphs• Image as Data: Automated Visual Content Analysis for Political Science• A note on the largest bipartite subgraph in point-hyperplane incidence graphs• Nonlinear large deviation bounds with applications to traces of Wigner matrices and cycles counts in Erdös-Renyi graphs• Performance Evaluation of SIFT Descriptor against Common Image Deformations on Iban Plaited Mat Motifs• Assessing Performance of Aerobic Routines using Background Subtraction and Intersected Image Region• Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable Objects, and Fluids• Lattice-based Robust Distributed Source Coding• A General Weighted Average Representation of the Ordinary and Two-Stage Least Squares Estimands• Moment-Sum-Of-Squares Approach For Fast Risk Estimation In Uncertain Environments• Which graphs occur as $γ$-graphs?• A Dynamical Systems Approach to Modeling and Analysis of Transactive Energy Coordination• Machine learning for accelerating effective property prediction for poroelasticity problem in stochastic media• Inner Approximation of Minkowski Sums: A Union-Based Approach and Applications to Aggregated Energy Resources• Interpreting Layered Neural Networks via Hierarchical Modular Representation• On delocalization of eigenvectors of random non-Hermitian matrices• Detecting Bot Activity in the Ethereum Blockchain Network• Transient and persistent particle subdiffusion in a disordered chain coupled to bosons• DE/PSO-aided Hybrid Linear Detectors for MIMO-OFDM Systems under Correlated Arrays• Convergence of Persistence Diagrams for Topological Crackle• Primitive Fitting Using Deep Boundary Aware Geometric Segmentation• Simulating the weak death of the neutron in a femtoscale universe with near-Exascale computing• Newton Polytopes and Relative Entropy Optimization• Cascaded Pyramid Network for 3D Human Pose Estimation Challenge• Towards WARSHIP: Combining Components of Brain-Inspired Computing of RSH for Image Super Resolution• Extreme Augmentation : Can deep learning based medical image segmentation be trained using a single manually delineated scan?• Theory of Generative Deep Learning : Probe Landscape of Empirical Error via Norm Based Capacity Control• Weak Convergence (IIA) – Functional and Random Aspects of the Univariate Extreme Value Theory• Algebraic number fields and the LLL algorithm• PIRM Challenge on Perceptual Image Enhancement on Smartphones: Report• Estimating the error distribution function in nonparametric regression• Characterising poroelastic materials in the ultrasonic range – A Bayesian approach• A Robot Localization Framework Using CNNs for Object Detection and Pose Estimation• On SDEs driven by fractional Brownian motions with irregular drifts• First-order phase transitions in the Kuramoto model with compact bimodal frequency distributions• An easy-to-use empirical likelihood ABC method• Approximating Approximate Pattern Matching• Enhanced image approximation using shifted rank-1 reconstruction• Learning sparse optimal rule fit by safe screening• New entanglement-assisted MDS quantum codes from constacyclic codes• Simultaneous Parameter Estimation and Variable Selection via the LN-CASS Prior• Distributed transactional reads: the strong, the quick, the fresh \& the impossible• Location of zeros for the partition function of the Ising model on bounded degree graphs• Nonparametric statistical inference for drift vector fields of multi-dimensional diffusions• Classification of maximum hittings by large families• Multilevel Monte Carlo Acceleration of Seismic Wave Propagation under Uncertainty• Sum decomposition of divergence into three divergences• Nonparametric High-dimensional K-sample Comparison• Fault Tolerant and Fully Dynamic DFS in Undirected Graphs: Simple Yet Efficient• BSDE Representation and Randomized Dynamic Programming Principle for Stochastic Control Problems of Infinite-Dimensional Jump-Diffusions• Submodular Stochastic Probing with Prices• Judiciously 3-partitioning 3-uniform hypergraphs• 2018 Low-Power Image Recognition Challenge• A deep learning pipeline for product recognition in store shelves• An Experimental Evaluation of the Generalized Sinusoidal Frequency Modulated Waveform for Active Sonar Systems• A characterization of the Edge of Criticality in Binary Echo State Networks• A Gradient based Decentralized Volt/Var Optimization Scheme for Distribution Systems with Smart Inverters• Simulation of elliptic and hypo-elliptic conditional diffusions• Algorithms for Destructive Shift Bribery• Collective Effects and Performance of Algorithmic Electric Vehicle Charging Strategies• SAVOIAS: A Diverse, Multi-Category Visual Complexity Dataset• A Bayesian model for sparse graphs with flexible degree distribution and overlapping community structure• Stochastic Methods for the Neutron Transport Equation I: Linear Semigroup asymptotics• Weighted dynamic finger in binary search trees• Reinventing Data Stores for Video Analytics• Two-stage stochastic approximation for dynamic rebalancing of shared mobility systems• Disambiguating Music Artists at Scale with Audio Metric Learning• A Neural Transition-based Model for Nested Mention Recognition• On tangential transversality• On strong tangential transversality• Neural Segmental Hypergraphs for Overlapping Mention Recognition• Pattern groups and a poset based Hopf monoid• An Effective Single-Image Super-Resolution Model Using Squeeze-and-Excitation Networks• Reverse Greedy is Bad for k-Center• Human-Centered Autonomous Vehicle Systems: Principles of Effective Shared Autonomy• Mining Contrasting Quasi-Clique Patterns• On S-Finite Measures and Kernels• Cloud4IoT: a heterogeneous, distributed and autonomic cloud platform for the IoT• Galerkin Approximation of Dynamical Quantities using Trajectory Data• Task-Oriented Hand Motion Retargeting for Dexterous Manipulation Imitation• SuperDepth: Self-Supervised, Super-Resolved Monocular Depth Estimation• Early Detection of Parkinson’s Disease through Patient Questionnaire and Predictive Modelling





### Like this:

Like Loading...


*Related*

