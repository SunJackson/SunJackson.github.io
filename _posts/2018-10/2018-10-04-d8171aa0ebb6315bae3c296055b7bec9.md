---
layout:     post
catalog: true
title:      If you did not already know
subtitle:      转载自：https://advanceddataanalytics.net/2018/10/04/if-you-did-not-already-know-502/
date:      2018-10-04
author:      Michael Laux
tags:
    - digital
    - inference
    - inferring
    - nbp
    - children
---

**Digital Native (DN)** ![](https://aboutdataanalytics.files.wordpress.com/2015/01/google.png?w=529)
The term Digital Native was coined and popularized by education consultant, Marc Prensky in his 2001 article entitled Digital Natives, Digital Immigrants, in which he relates the contemporaneous decline in American education to educators’ failure to understand the needs of modern students. His article posited that ‘the arrival and rapid dissemination of digital technology in the last decade of the 20th century’ had fundamentally changed the way students think and process information, making it impossible for them to excel academically using the outdated teaching methods of the day. In other words, children raised in the post-digital, media saturated world, require a media-rich learning environment to hold their attention. Contextually, his ideas were introduced after a decade of worry over increased diagnosis of children with ADD and ADHD, which itself turned out to be largely overblown. Prensky did not strictly define the Digital Native in his 2001 article, but it was later, somewhat arbitrarily, applied to children born after 1980, due to the fact that computer bulletin board systems, and Usenet were already in use at the time. The idea became popular among educators and parents, whose children fell within Prensky’s definition of a Digital Native, and has since been embraced as an effective marketing tool. … 

**Graphical Causal Models** ![](https://aboutdataanalytics.files.wordpress.com/2015/01/google.png?w=529)
A species of the broader genus of graphical models, especially intended to help with problems of causal inference. … 

**Pull Message Passing for Nonparametric Belief Propagation (PMPNBP)** ![](https://aboutdataanalytics.files.wordpress.com/2015/01/google.png?w=529)
We present a ‘pull’ approach to approximate products of Gaussian mixtures within message updates for Nonparametric Belief Propagation (NBP) inference. Existing NBP methods often represent messages between continuous-valued latent variables as Gaussian mixture models. To avoid computational intractability in loopy graphs, NBP necessitates an approximation of the product of such mixtures. Sampling-based product approximations have shown effectiveness for NBP inference. However, such approximations used within the traditional ‘push’ message update procedures quickly become computationally prohibitive for multi-modal distributions over high-dimensional variables. In contrast, we propose a ‘pull’ method, as the Pull Message Passing for Nonparametric Belief propagation (PMPNBP) algorithm, and demonstrate its viability for efficient inference. We report results using an experiment from an existing NBP method, PAMPAS, for inferring the pose of an articulated structure in clutter. Results from this illustrative problem found PMPNBP has a greater ability to efficiently scale the number of components in its mixtures and, consequently, improve inference accuracy. … 





### Like this:

Like Loading...


*Related*

