---
layout:     post
catalog: true
title:      If you did not already know
subtitle:      转载自：https://advanceddataanalytics.net/2018/10/25/if-you-did-not-already-know-523/
date:      2018-10-24
author:      Michael Laux
tags:
    - interventions
    - regression
    - distance
    - differences
    - differs
---

**Sounding Board** ![](https://aboutdataanalytics.files.wordpress.com/2015/01/google.png?w=529)
We present Sounding Board, a social chatbot that won the 2017 Amazon Alexa Prize. The system architecture consists of several components including spoken language processing, dialogue management, language generation, and content management, with emphasis on user-centric and content-driven design. We also share insights gained from large-scale online logs based on 160,000 conversations with real-world users. … 

**Structural Intervention Distance (SID)** ![](https://aboutdataanalytics.files.wordpress.com/2015/01/google.png?w=529)
Causal inference relies on the structure of a graph, often a directed acyclic graph (DAG). Different graphs may result in different causal inference statements and different intervention distributions. To quantify such differences, we propose a (pre-) distance between DAGs, the structural intervention distance (SID). The SID is based on a graphical criterion only and quantifies the closeness between two DAGs in terms of their corresponding causal inference statements. It is therefore well-suited for evaluating graphs that are used for computing interventions. Instead of DAGs it is also possible to compare CPDAGs, completed partially directed acyclic graphs that represent Markov equivalence classes. Since it differs significantly from the popular Structural Hamming Distance (SHD), the SID constitutes a valuable additional measure. … 

**Locally Estimated Scatterplot Smoothing (LOESS)** ![](https://aboutdataanalytics.files.wordpress.com/2015/01/google.png?w=529)
LOESS and LOWESS (locally weighted scatterplot smoothing) are two strongly related non-parametric regression methods that combine multiple regression models in a k-nearest-neighbor-based meta-model. “LOESS” is a later generalization of LOWESS; although it is not a true initialism, it may be understood as standing for “LOcal regrESSion”. … 





### Like this:

Like Loading...


*Related*

