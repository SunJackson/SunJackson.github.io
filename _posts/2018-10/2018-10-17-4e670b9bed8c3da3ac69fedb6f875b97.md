---
layout:     post
catalog: true
title:      Slides from my talk at the R-Ladies Meetup about Interpretable Deep Learning with R, Keras and LIME
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/T9MIY4Ec524/
date:      2018-10-17
author:      Dr. Shirin Glander
tags:
    - models
    - neural
    - lime
    - interpretable
    - images
---





During my stay in London for the m3 conference, I also gave a talk at the R-Ladies London Meetup on Tuesday, October 16th, about one of my favorite topics: Interpretable Deep Learning with R, Keras and LIME.

> 
Keras is a high-level open-source deep learning framework that by default works on top of TensorFlow. Keras is minimalistic, efficient and highly flexible because it works with a modular layer system to define, compile and fit neural networks. It has been written in Python but can also be used from within R. Because the underlying backend can be changed from TensorFlow to Theano and CNTK (with more options being developed right now) it is designed to be framework-independent. Models can be trained on CPU or GPU, locally or in the cloud. Shirin will show an example of how to build an image classifier with Keras. We’ll be using a convolutional neural net to classify fruits in images. But that’s not all! We not only want to judge our black-box model based on accuracy and loss measures – we want to get a better understanding of how the model works. We will use an algorithm called LIME (local interpretable model-agnostic explanations) to find out what part of the different test images contributed most strongly to the classification that was made by our model. Shirin will introduce LIME and explain how it works. And finally, she will show how to apply LIME to the image classifier we built before, as well as to a pre-trained Imagenet model.







*Related*








---
