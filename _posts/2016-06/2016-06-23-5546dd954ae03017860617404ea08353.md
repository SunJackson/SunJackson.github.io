---
layout:     post
title:      The Real Story Behind Today's Referendum
subtitle:   转载自：http://inverseprobability.com/2016/06/23/the-real-story-behind-todays-referendum
date:       2016-06-23
author:     未知
header-img: img/background2.jpg
catalog: true
tags:
    - political
    - topics
    - politics needs
    - social
    - reading
---

![](http://inverseprobability.com/eu-63985_1280.jpg)


Today tens of millions of people in the UK will head to the polls and vote “leave” or “remain” in the country’s referendum on the EU. But perhaps the real story behind this event, is not the result nor the nature of the political argument, but how we as individuals engaged in political debate.

Recently, there was a [scandal of possible bias](https://www.theguardian.com/technology/2016/may/24/facebook-changes-trending-topics-anti-conservative-bias) in Facebook’s curation of their ‘trending topics’ feed. The perception was that ‘conservative topics’ were less likely to appear than ‘liberal topics’. Suspicions were further raised when it was revealed that some ‘hand curation’ of trending topics was applied to those selected by Facebook’s algorithms.

We are all conscious of bias in traditional news outlets, The Daily Telegraph leans to the right, The Guardian to the left. But bias in Facebook was apparently seen as something far more threatening due to the extent that so many people rely on the social network to curate our news.

That discussion missed the point. The real concern is not the trending topics, it is our individually tailored about the ‘news feed’. News feed in Facebook is the ordered lists of posts that appear front and central on the site. The ones where you get updates from your friends and see the links they’ve shared. News feed’s algorithms are personalised to you, [they respond to what you like](https://www.facebook.com/help/166738576721085). They deliver material you’re interested in. They can do this by looking at your past behaviour and showing more prominently posts you are more likely to interact with: whether you watch the video, follow the link, share the post, make a comment. All these interactions feed the algorithm.

Back in the 1960s [Mick Jagger is famous for saying](https://www.youtube.com/watch?v=7S94ohyErSw) “You can’t always get what you want, but if you try some times, you might just find, you might just find, you get what you need … eeeed.” Mick probably wasn’t referring to the intellectual freedom of that decade, but to other freedoms that generation explored. However, it is certainly true that in the 1960s no one was reading a newspaper that was precisely tailored to themselves, tailored to give a reflection of their views derived by close examination of previous reading habits and interactions with a range of different media. Back then you didn’t get ‘what you want’, but what we probably needed, and now, is an exposure to the wider range of opinions that exist across the population.

For many of us, the traditional newspaper no longer exists. Not only that, we don’t even do the quick scan of the front pages as we pick up our preferred read from the newsagent. Today we can get exactly what we want, we get exactly what is delivered by a close examination of our personal preferences.

Our social media is biased towards us. This has been called the ‘[filter bubble](https://en.wikipedia.org/wiki/Filter_bubble)’. It’s not a new phenomenon, the Chipping Norton set probably focuses mainly on issues that affect Chipping Norton. In Sheffield where I live, the injustices of the 1980s miners’ strike are still felt keenly today despite the site of its most famous battle, Orgreave, being long removed and replaced with an EU funded Advanced Manufacturing Research Centre. My research area is machine learning, but the academic community around me broadly expresses the same center left political views and identifies as atheist.

By tailoring towards our tastes social media is more engaging than traditional outlets. We like nothing better than finding our preconceptions confirmed. Our news feed is a syrupy concoction of apparently spicy opinion that has actually been carefully tuned to our individual taste. It reflects exactly the same set of ideas that we so greedily consumed yesterday, last week, last month and last year. That is the art of the algorithm, the secret sauce that keeps us coming back.

If a rogue article does slip through the net, a lump of garlic in the ice cream, our reaction is never to empathize or compromise. We troll, we flame, we shame. When was the last time you saw someone change their mind on social media?

The end effect is to offend and entrench, when what we *need* is to upend and enlighten. Deep down Facebook knows what we want. We want our prejudices to be confirmed when we need them to be challenged. For many of us, the real story of today’s referendum is the extent to which it has played out on our social media profiles. The extent to which algorithms have determined our way of thinking, not through an artificial human bias, but by leaving us unchallenged and unexposed. Politics needs compromise, understanding, collaboration and intelligent debate. Whatever today’s outcome, leave or remain, we need to understand how to exploit social media to ensure we explore each others opinions and better understand each others’ motivations.
