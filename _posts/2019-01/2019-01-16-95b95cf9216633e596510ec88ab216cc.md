---
layout:     post
catalog: true
title:      If you did not already know
subtitle:      转载自：https://analytixon.com/2019/01/16/if-you-did-not-already-know-610/
date:      2019-01-16
author:      Michael Laux
tags:
    - controls
    - principle
    - text
    - learning
    - learned
---

**Pontryagin Maximum Principle** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
Pontryagin’s maximum (or minimum) principle is used in optimal control theory to find the best possible control for taking a dynamical system from one state to another, especially in the presence of constraints for the state or input controls. It was formulated in 1956 by the Russian mathematician Lev Pontryagin and his students. It has as a special case the Euler-Lagrange equation of the calculus of variations. The principle states, informally, that the control Hamiltonian must take an extreme value over controls in the set of all permissible controls. Whether the extreme value is maximum or minimum depends both on the problem and on the sign convention used for defining the Hamiltonian. The normal convention, which is the one used in Hamiltonian, leads to a maximum hence maximum principle but the sign convention used in this article makes the extreme value a minimum. … 

**Conceptual Expansion** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
Problems with few examples of a new class of objects prove challenging to most classifiers. One solution to is to reuse existing data through transfer methods such as one-shot learning or domain adaption. However these approaches require an explicit hand-authored or learned definition of how reuse can occur. We present an approach called conceptual expansion that learns how to reuse existing machine-learned knowledge when classifying new cases. We evaluate our approach by adding new classes of objects to the CIFAR-10 dataset and varying the number of available examples of these new classes. … 

**Tree-Structured Multi-Linear Principle Component Analysis (TMPCA)** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
A novel text data dimension reduction technique, called the tree-structured multi-linear principle component analysis (TMPCA), is proposed in this work. Being different from traditional text dimension reduction methods that deal with the word-level representation, the TMPCA technique reduces the dimension of input sequences and sentences to simplify the following text classification tasks. It is shown mathematically and experimentally that the TMPCA tool demands much lower complexity (and, hence, less computing power) than the ordinary principle component analysis (PCA). Furthermore, it is demon- strated by experimental results that the support vector machine (SVM) method applied to the TMPCA-processed data achieves commensurable or better performance than the state-of-the-art recurrent neural network (RNN) approach. … 





### Like this:

Like Loading...


*Related*

