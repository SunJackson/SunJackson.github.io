---
layout:     post
catalog: true
title:      My presentations on ‘Elements of Neural Networks & Deep Learning’ -Parts 4,5
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/SNVg6uSRk3g/
date:      2019-01-15
author:      Tinniam V Ganesh
tags:
    - deep
    - layer
    - presentations
    - multi
    - function
---





This is the next set of presentations on â€œElements of Neural Networks and Deep Learningâ€�. In the 4th presentation I discuss and derive the generalized equations for a multi-unit, multi-layer Deep Learning network. The 5th presentation derives the equations for a Deep Learning network when performing multi-class classification along with the derivations for cross-entropy loss. The corresponding implementations are available in vectorized R, Python and Octave are available in my book â€˜Deep Learning from first principles:Second edition- In vectorized Python, R and Octaveâ€˜

1. **Elements of Neural Network and Deep Learning â€“ Part 4**This presentation is a continuation of my 3rd presentation in which I derived the equations for a simple 3 layer Neural Network with 1 hidden layer. In this video presentation, I discuss step-by-step the derivations for a L-Layer, multi-unit Deep Learning Network, with any activation function g(z)



The implementations of L-Layer, multi-unit Deep Learning Network in vectorized R, Python and Octave are available in my post Deep Learning from first principles in Python, R and Octave â€“ Part 3

2.**Elements of Neural Network and Deep Learning â€“ Part 5**This presentation discusses multi-class classification using the Softmax function. The detailed derivation for the Jacobian of the Softmax is discussed, and subsequently the derivative of cross-entropy loss is also discussed in detail. Finally the final set of equations for a Neural Network with multi-class classification is derived.



The corresponding implementations in vectorized R, Python and Octave are available in the following postsa. Deep Learning from first principles in Python, R and Octave â€“ Part 4b. Deep Learning from first principles in Python, R and Octave â€“ Part 5

To be continued. Watch this space!

![](https://gigadom.files.wordpress.com/2017/01/Untitled.png?w=456)
![](https://gigadom.files.wordpress.com/2017/01/Untitled.png?w=456)
Checkout my book â€˜Deep Learning from first principles: Second Edition â€“ In vectorized Python, R and Octaveâ€™. My book starts with the implementation of a simple 2-layer Neural Network and works its way to a generic L-Layer Deep Learning Network, with all the bells and whistles. The derivations have been discussed in detail. The code has been extensively commented and included in its entirety in the Appendix sections. My book is available on Amazon as paperback ($18.99) and in kindle version($9.99/Rs449).

Also see1. My book â€˜Practical Machine Learning in R and Python: Third editionâ€™ on Amazon2. Big Data-2: Move into the big league:Graduate from R to SparkR3. Introducing QCSimulator: A 5-qubit quantum computing simulator in R4. My TEDx talk on the â€œInternet of Things5. Rock Nâ€™ Roll with Bluemix, Cloudant & NodeExpress6. GooglyPlus: yorkr analyzes IPL players, teams, matches with plots and tables7. Literacy in India â€“ A deepR dive8. Fun simulation of a Chain in Android

To see all posts click Index of Posts


*Related*








---
