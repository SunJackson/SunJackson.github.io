---
layout:     post
catalog: true
title:      hrbrthemes 0.6.0 on CRAN + Other In-Development Package News
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/sXqxKxneBus/
date:      2019-01-21
author:      hrbrmstr
tags:
    - lakes
    - packages grouped
    - library
    - title
    - ice_on
---





Version 0.6.0 of the `hrbrthemes`![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
 package should be hitting a CRAN mirror near you soon. Apart from some general documentation and code cleanup this release includes the dark theme folks have been seeing in blog posts and tweets over the past few months. Itâ€™s called `theme_ft_rc()` since it is an homage to the wonderful new chart theme developed by the @ft_data crew over at the Financial Times (you can see examples from their work here).

While there was nothing stopping folks from using the GitHub version, the CRAN release makes it more widely available. There are still intermittent issues with fonts for some folks which Iâ€™ll be working on for the next release.

Since youâ€™ve already seen lots of examples of these charts I wonâ€™t just make a gratuitous example using the theme. I *will*, however, make some charts based on a new data package dubbed `iceout`![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
. The `iceout` package was originally conceived by Ben Tupper from the Bigelow Laboratory for Ocean Sciences. I keep an eye on fellow Mainer repositories and I did not realize (but should have known) that researches keep track of when inland bodies of water freeze and thaw. The package name is derived from the term used for the thaw measurements (â€œice-outâ€� or â€œice-offâ€�).

Before becoming obsessed with this data and getting the package to the current state it is in, the original codebase worked off of a USGS Lake Ice-Out Data for New England dataset that focused solely on New England and only went up to 2005. Some digging discovered that

- Maineâ€™s Department of Agriculture and Forestry maintains online records since 2003; and,

- Minnesotaâ€™s Department of Natural Resources maintains a comprehensive database of records going back to the 1800â€™s.


*But* I hit the jackpot after discovering the U.S. National Snow & Ice Data Centerâ€™s Global Lake and River Ice Phenology dataset which:

â€¦ contains freeze and breakup dates and other ice cover descriptive data for 865 lakes and rivers. Of the 542 water bodies that have records longer than 19 years, 370 are in North America and 172 are in Eurasia; 249 have records longer than 50 years; and 66 longer than 100 years. A few have data prior to 1845. These data, from water bodies distributed around the Northern Hemisphere, allow analysis of broad spatial patterns as well as long-term temporal patterns.

So, I converted the original package to a data package containing all four of those datasets plus some interactive functions for pulling â€œliveâ€� data and a set of â€œbuildersâ€� to regenerate the databases. Letâ€™s take a quick look at whatâ€™s in the NSIDC data and the global coverage area:

```
library(iceout) # github/hrbrmstr/iceout
library(hrbrthemes) 
library(ggplot2)
library(dplyr)

data("nsidc_iceout")

glimpse(nsidc_iceout)
## Observations: 35,918
## Variables: 37
## $ lakecode "ARAI1", "ARAI1", "ARAI1", "ARAI1", "ARAI1", "ARAI1", "ARAI1â€¦
## $ lakename "Lake Suwa", "Lake Suwa", "Lake Suwa", "Lake Suwa", "Lake Suâ€¦
## $ lakeorriver "L", "L", "L", "L", "L", "L", "L", "L", "L", "L", "L", "L", â€¦
## $ season "1443-44", "1444-45", "1445-46", "1446-47", "1447-48", "1448â€¦
## $ iceon_year 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, â€¦
## $ iceon_month 12, 11, 12, 12, 11, 12, 12, 12, 12, 11, 12, 12, 12, 12, 12, â€¦
## $ iceon_day 8, 23, 1, 2, 30, 8, 13, 8, 23, 28, 3, 5, 1, 5, 6, 20, 10, 15â€¦
## $ iceoff_year NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦
## $ iceoff_month NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦
## $ iceoff_day NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦
## $ duration NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦
## $ latitude 36.15, 36.15, 36.15, 36.15, 36.15, 36.15, 36.15, 36.15, 36.1â€¦
## $ longitude 138.08, 138.08, 138.08, 138.08, 138.08, 138.08, 138.08, 138.â€¦
## $ country "Japan", "Japan", "Japan", "Japan", "Japan", "Japan", "Japanâ€¦
## $ froze TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, â€¦
## $ obs_comments "calendar correction for ice_on: -30 days of original data; â€¦
## $ area_drained 531, 531, 531, 531, 531, 531, 531, 531, 531, 531, 531, 531, â€¦
## $ bow_comments NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦
## $ conductivity_us NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦
## $ elevation 759, 759, 759, 759, 759, 759, 759, 759, 759, 759, 759, 759, â€¦
## $ filename "ARAI", "ARAI", "ARAI", "ARAI", "ARAI", "ARAI", "ARAI", "ARAâ€¦
## $ initials "ARAI", "ARAI", "ARAI", "ARAI", "ARAI", "ARAI", "ARAI", "ARAâ€¦
## $ inlet_streams "-", "-", "-", "-", "-", "-", "-", "-", "-", "-", "-", "-", â€¦
## $ landuse_code "UAFO", "UAFO", "UAFO", "UAFO", "UAFO", "UAFO", "UAFO", "UAFâ€¦
## $ largest_city_population 52000, 52000, 52000, 52000, 52000, 52000, 52000, 52000, 5200â€¦
## $ max_depth 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, 7.6, â€¦
## $ mean_depth 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, 4.7, â€¦
## $ median_depth NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦
## $ power_plant_discharge NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦
## $ secchi_depth NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦
## $ shoreline 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, â€¦
## $ surface_area 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, 12.9, â€¦
## $ state "Nagano Prefecture", "Nagano Prefecture", "Nagano Prefectureâ€¦
## $ iceon_date 1443-12-08, 1444-11-23, 1445-12-01, 1446-12-02, 1447-11-30,â€¦
## $ iceon_doy 342, 328, 335, 336, 334, 343, 347, 342, 357, 333, 337, 339, â€¦
## $ iceout_date NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,â€¦
## $ iceout_doy NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, â€¦

maps::map("world", ".", exact = FALSE, plot = FALSE, fill = TRUE) %>%
 fortify() -> wrld

ggplot() + 
 ggalt::geom_cartogram(
 data = wrld, map = wrld, aes(long, lat, map_id=region), 
 fill="#3B454A", color = "white", size = 0.125
 ) +
 geom_point(
 data = distinct(nsidc_iceout, lakeorriver, longitude, latitude),
 aes(longitude, latitude, fill = lakeorriver), 
 size = 1.5, color = "#2b2b2b", stroke = 0.125, shape = 21
 ) +
 scale_fill_manual(
 name = NULL, values = c("L"="#fdbf6f", "R"="#1f78b4"), labels=c("L" = "Lake", "R" = "River")
 ) +
 ggalt::coord_proj("+proj=wintri", ylim = range(nsidc_iceout$latitude, na.rm = TRUE)) +
 labs(title = "NSIDC Dataset Coverage") +
 theme_ft_rc(grid="") +
 theme(legend.position = c(0.375, 0.1)) +
 theme(axis.text = element_blank(), axis.title = element_blank())

```

![](https://i2.wp.com/rud.is/b/wp-content/uploads/2019/01/nc-idc-coverage.png?resize=780%2C296&ssl=1)
![](https://i2.wp.com/rud.is/b/wp-content/uploads/2019/01/nc-idc-coverage.png?resize=780%2C296&ssl=1)


W00t! Lots of data (though not all of the extra features are populated for all readings/areas)!

I think the reason the ice-out data garnered my obsession was how it can be used as another indicator that we are indeed in the midst of a climate transformation. Letâ€™s look at the historical ice-out information for Maine inland bodies of water:

```
filter(nsidc_iceout, country == "United States", state == "ME") %>% 
 mutate(iceout_date = as.Date(format(iceout_date, "2020-%m-%d"))) %>% # we want the Y axis formatted as month-day so we choose a leap year to ensure we get leap dates (if any)
 ggplot(aes(iceoff_year, iceout_date)) +
 geom_point(aes(color = lakename), size = 0.5, alpha=1/4) +
 geom_smooth(aes(color = lakename), se=FALSE, method = "loess", size=0.25) +
 scale_y_date(date_labels = "%b-%d") +
 labs(
 x = NULL, y = "Ice-out Month/Day", color = NULL,
 title = "Historical Ice-out Data/Trends for Maine Inland Bodies of Water"
 ) +
 theme_ft_rc(grid="XY")

```

![](https://i1.wp.com/rud.is/b/wp-content/uploads/2019/01/me-inland.png?resize=780%2C561&ssl=1)
![](https://i1.wp.com/rud.is/b/wp-content/uploads/2019/01/me-inland.png?resize=780%2C561&ssl=1)


You can follow that code-pattern to look at other states. Itâ€™s also fun to look at the ice-out date distributions by latitude grouping:

```
filter(nsidc_iceout, !is.na(latitude) & !is.na(longitude) & !is.na(iceout_date)) %>% 
 filter(country == "United States") %>% 
 mutate(iceout_date = as.Date(format(iceout_date, "2020-%m-%d"))) %>% 
 mutate(lat_grp = cut(latitude, scales::pretty_breaks(5)(latitude), ordered_result = TRUE)) %>% 
 arrange(desc(iceoff_year)) %>% 
 ggplot() +
 ggbeeswarm::geom_quasirandom(
 aes(lat_grp, iceout_date, fill = iceoff_year), groupOnX = TRUE, 
 shape = 21, size =1, color = "white", stroke = 0.125, alpha=1/2
 ) +
 scale_y_date(date_labels = "%b-%d") +
 viridis::scale_fill_viridis(name = "Year", option = "magma") +
 labs(
 x = "Latitude Grouping", y = "Ice-out Month/Day",
 title = "U.S. Ice-out Historical Day/Month Distributions by Latitude Grouping"
 ) +
 theme_ft_rc(grid="Y")

```

![](https://i2.wp.com/rud.is/b/wp-content/uploads/2019/01/lat-grp.png?resize=780%2C655&ssl=1)
![](https://i2.wp.com/rud.is/b/wp-content/uploads/2019/01/lat-grp.png?resize=780%2C655&ssl=1)


If you want to focus on individual lakes thereâ€™s a Shiny app for that (well one for the U.S. anyway).

After loading the package, just enter `explore_us()` at an R console and youâ€™ll see something like this:

![](https://i0.wp.com/rud.is/b/wp-content/uploads/2019/01/explore-us-shiny-02.png?resize=780%2C678&ssl=1)
![](https://i0.wp.com/rud.is/b/wp-content/uploads/2019/01/explore-us-shiny-02.png?resize=780%2C678&ssl=1)


The leaflet view will zoom to each new lake selected and the graph will be updated as well.

### Other Package News

The `sergeant`![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
 package is reaching a stable point in the 0.8.0 branch (mostly due to David Severskiâ€™s tireless help finding bugs ![](https://i2.wp.com/s.w.org/images/core/emoji/11/72x72/1f601.png?w=456&ssl=1)
![](https://i2.wp.com/s.w.org/images/core/emoji/11/72x72/1f601.png?w=456&ssl=1)
) and should be headed to CRAN soon. Get your issues or PRs in if you want them CRANdied.

Iâ€™ve *finally* updated the Java library dependencies in `pdfboxjars`![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
 so `pdfbox`![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
 will no longer cause GitHub to tell you or I that it is insecure.

Thereâ€™s a new package dubbed `reapr`![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
 that is aimed somewhere at the intersection of `curl` + `httr` + `rvest`. Fundamentally, it provides some coder-uplift when scraping data. The README has examples but hereâ€™s what you get on an initial scrape of this blogâ€™s index page:

```
reapr::reap_url("http://rud.is/b")
## Title: rud.is | "In God we trust. All others must bring data"
## Original URL: http://rud.is/b
## Final URL: https://rud.is/b/
## Crawl-Date: 2019-01-17 19:51:09
## Status: 200
## Content-Type: text/html; charset=UTF-8
## Size: 50 kB
## IP Address: 104.236.112.222
## Tags: body[1], center[1], form[1], h2[1], head[1], hgroup[1], html[1],
## label[1], noscript[1], section[1], title[1],
## aside[2], nav[2], ul[2], style[5], img[6],
## input[6], article[8], time[8], footer[9], h1[9],
## header[9], p[10], li[19], meta[20], div[31],
## script[40], span[49], link[53], a[94]
## # Comments: 17
## Total Request Time: 2.093s

```

The `reap_url()` function:

- Uses `httr::GET()` to make web connections and retrieve content which enables it to behave more like an actual (non-javascript-enabled) browser. You can pass anything `httr::GET()` can handle to `...` (e.g. `httr::user_agent()`) to have as much granular control over the interaction as possible. 

Returns a richer set of data. After the `httr::response` object is obtained many tasks are performed including:

- timestamping of the URL crawl

- extraction of the asked-for URL and the final URL (in the caseof redirects)

- extraction of the IP address of the target server

- extraction of both plaintext and parsed (`xml_document`) HTML

- extraction of the plaintext webpage `` (if any)

- generation of a dynamic list tags in the document which can befed directly to HTML/XML search/retrieval function (which mayspeed up node discovery)

- extraction of the text of all comments in the HTML document

- inclusion of the full `httr::response` object with the returnedobject

- extraction of the time it took to make the complete request


Iâ€™m still wrestling with the API so definitely file issues with suggestions (wherever youâ€™re most comfortable socially coding).

Speaking of IP addresses (bullet 3 above), I finally got some time to study the `gdns`![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
 C library (a modern DNS API library) and created the `clandnstine`![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
 package. The package name jeu de mots is due to the fact that the intent is to have it solely support DNS over TLS requests since regular DNS is plaintext, enables ISP spying/injection and generally fraught with peril. All forms of DNS lookups are supported. The catch is that you have to point it at a DNS over TLS-capable resolver. The package defaults to Quad9 (9.9.9.9) because I trust them more than Google or Cloudflare (btw: thatâ€™s not saying much as I trust used car salesfolks more than all three of them). Keep an eye (or RSS reader) peeled on $WORK blog over the coming weeks as Iâ€™ll have some analysis and data on a few hundred DNS over TLS endpoints you can use thanks to a new study developed by cow-orkers Jon Hart and Shan Skidar.

There also a toy package `forecequotes`![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
![](https://i0.wp.com/s.w.org/images/core/emoji/11/72x72/1f517.png?w=456&ssl=1)
 that is more â€œhave fun with the `cli` & `crayon` packagesâ€� than anything else. But if you like Star Wars, random quote APIs and want to integrate richer command line interface output into your work, then definitely give it a peek.

Finally, I havenâ€™t used Râ€™s direct C interface in a while (since Rcpp is addictive and handy) and wanted to keep those skills fresh, so I made a wrapper to an old (in internet years) IP address trie C library. The underlying library is much slower than what we use in `iptools` but it works, does a bit more than its `iptoos` counterpart and covers data marshaling, external pointer handling, and attribute/class setting so it may be a half-decent reference package for using the R<->C bridge.

### FIN

If you know of more/better ice-out data please drop an issue in the Bigelow Labsâ€™ `iceout` repo and Iâ€™ll get it integrated. And, if you do your own ice-out exploration definitely blog about it, tell R Weekly and drop a note in the comments.

Here are links to all the mentioned packages grouped by social coding platform (so you can interact/collaborate wherever you feel most comfortable working):

**sr.ht**

**GitLab**

**GitHub**


*Related*








---
