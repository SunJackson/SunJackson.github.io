---
layout:     post
title:      theano and the curse of GpuFromHost
subtitle:   转载自：http://matpalm.com/blog/2015/02/22/the_curse_of_gpufromhost
date:       2018-07-19
author:     未知
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - theano
    - profiling
    - numpy
    - variables
    - debugging
    - operations
    - operate
    - examples
    - code
    - runs
    - models
    - simple model
    - matrix
    - graph
    - looping
    - tx
    - gpu
    - intro
    - symbolic
    - awesome
    - version
    - actual
    - cpu
---

### brutually short intro to theano

i've been reviving some old [theano](http://deeplearning.net/software/theano) code recently and in 
case you haven't seen it theano is a pretty awesome python library that reads a lot like 
[numpy](http://www.numpy.org/) but provides two particularly interesting features.

[symbolic differentiation](http://deeplearning.net/software/theano/tutorial/gradients.html); not 
something i'll talk about here, but super useful if you're tinkering with new models and you're using a gradient 
descent method for learning (and these days, who's not..)
the ability to run transparently 
on a gpu; well, almost transparently, this'll be the main focus of this post...

### multiplying matrices

let's work through a very simple model that's kinda like a system of linear equations. 
we'll compare 1) numpy (our timing baseline) vs 2) theano on a cpu vs 3) theano on a gpu.
keep in mind this model is contrived and doesn't really represent anything useful, it's more to demonstrate 
some matrix operations.

#### in numpy

first consider the following numpy code 
([speed_test_numpy.py](https://gist.github.com/matpalm/7b519c93ca6fb732dd17#file-speed_test_numpy-py))
which does a simple y=mx+b like calculation a number
of times in a tight loop. this looping isn't just for benchmarking, lots of learning algorithms operate on a tight
loop.

this code on a 6 core 3.8Ghz AMD runs in a bit over 2min

#### in theano

now consider the same thing in theano 
([speed_test_theano.py](https://gist.github.com/matpalm/7b519c93ca6fb732dd17#file-speed_test_theano-py))

hopefully it's clear enough what is happening here at a high level but just briefly the tm, tx, tb and ty variables represent
a symbolic representation of what we want to do and the theano.function call compiles this into actual executable code.
there is lots of [gentle intro material](http://deeplearning.net/software/theano/tutorial/adding.html#baby-steps-algebra) that introduces this notation on the theano site.

when run on the cpu it takes about the same time as the numpy version

but when "magically" run on the gpu it's quite a bit faster.

awesome! a x40 speed up! so we're done right? not quite, we can do better.

### profiling

let's drill into what's actually happening; we can do this in two ways, 
[debugging the compiled graph](http://deeplearning.net/software/theano/tutorial/printing_drawing.html#debug-printing) and 
[theano profiling.](http://deeplearning.net/software/theano/tutorial/profiling.html)

debugging allows us to see what a function has been compiled to. for the cpu case it's just a
single [blas gemm (general matrix mulitplication)](http://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms#Level_3) call. that's
exactly what'd we want, so great!

profiling allows to see where time is spent. 100% in this single op, no surprise.

looking at the gpu version though things are a little different...

we can see a GpuGemm operation, the gpu equivalent of Gemm, but now there's a bunch of GpuFromHost & HostFromGpu operations too? what are these? 

i'll tell you what they are, they are the bane of your existence! these represent transferring data to/from the gpu which is slow and, if we're not
careful, can add up to a non trivial amount. if we review the profiling output we can see that, though we're faster
than the non gpu version, we're spending >70% of the time just moving data.

(though remember this example is contrived, we'd expect to be doing more in our overall computation that just a single general matrix mulitply)

ouch!

### shared variables

the crux of this problem is that we actually have two types of variables in this model; the parameterisation of the model (m & b) and 
those related to examples (x & y). so, though it's realistic to do a speed test with a tight loop over the same function many times,
what is *not* realistic is that we are passing the model parameters to/from the gpu
each and every input example. this is a complete waste; it's much more sensible to send them over to the gpu once at the
start of the loop and retreive them once at the end. this is an important and very common pattern.

how do we fix this? it's actually pretty simple; 
[shared variables](http://deeplearning.net/software/theano/tutorial/examples.html#using-shared-variables). yay!

consider the following; [speed_test_theano_shared.py](https://gist.github.com/matpalm/7b519c93ca6fb732dd17#file-speed_test_theano_shared-py)

reviewing the debug we can see this removes a stack of the GpuFromHost calls.

and we're down to < 2s

what's even crazier is we can go further by moving the x and y matrices onto the gpu too. it turns out this isn't *too*
far fetched since if x and y were representing training examples we'd be iterating over them anyways (and if we could fit them
all onto the gpu that'd be great )

the debug graph is like the cpu graph now, just one gemm call.

and runs in under a second. x150 the numpy version. nice! :)
