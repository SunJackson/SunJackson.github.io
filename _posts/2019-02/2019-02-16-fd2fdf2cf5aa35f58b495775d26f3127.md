---
layout:     post
catalog: true
title:      Document worth reading： “On the Transferability of Representations in Neural Networks Between Datasets and Tasks”
subtitle:      转载自：https://analytixon.com/2019/02/16/document-worth-reading-on-the-transferability-of-representations-in-neural-networks-between-datasets-and-tasks/
date:      2019-02-16
author:      Michael Laux
tags:
    - networks composed
    - neural
    - deep
    - interesting empirical
---

Deep networks, composed of multiple layers of hierarchical distributed representations, tend to learn low-level features in initial layers and transition to high-level features towards final layers. Paradigms such as transfer learning, multi-task learning, and continual learning leverage this notion of generic hierarchical distributed representations to share knowledge across datasets and tasks. Herein, we study the layer-wise transferability of representations in deep networks across a few datasets and tasks and note some interesting empirical observations. On the Transferability of Representations in Neural Networks Between Datasets and Tasks





### Like this:

Like Loading...


*Related*

