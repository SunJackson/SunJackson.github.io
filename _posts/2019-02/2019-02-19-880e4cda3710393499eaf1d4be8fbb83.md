---
layout:     post
catalog: true
title:      Import AI 134： Learning old tricks on new robots; Facebook improves translation with noise; Google wants people to train fake-audio detectors
subtitle:      转载自：https://jack-clark.net/2019/02/19/import-ai-134-learning-old-tricks-on-new-robots-facebook-improves-translation-with-noise-google-wants-people-to-train-fake-audio-detectors/
date:      2019-02-19
author:      Jack Clark
tags:
    - training
    - trained
    - robots
    - robotics
    - structures
---




### Import AI 134: Learning old tricks on new robots; Facebook improves translation with noise; Google wants people to train fake-audio detectors

#### by Jack Clark

**Why robots are the future of ocean maintenance:***…Robot boats, robot copters, and robot underwater gliders…*Researchers with Oslo Metropolitan University and Norwegian University of Science and Technology are trying to reduce the cost of automated sub-sea data collection and surveillance operations through the use of robots, and have published a paper outlining one of the key components needed to build this system – a cheap, lightweight way to get small sub-surface gliders to be able to return to the surface.

**  Weight rules everything around me:** The technical innovations here involve simplifying the design to reduce the number of components needed to build a pressure-tolerant MUG, which in turn reduces the weight of the systems, making it easier for them to be deployed and recovered via drones.
“Further development will add the ability to adjust pitch and yaw, improve power efficiency, add GPS and environmental sensors, as well as UAV deployment/recovery strategies”, they write.

**  Why this esoteric non-AI-heavy paper matters: **This paper is mostly interesting for the not-too-distant future it portends; one where robot boats patrol the oceans, releasing underwater gliders to gather information about the environment, and serving as a homebase for drones that can collect the gliders and transmit them back to the robot boat, and serve as a kind of airborne antenna to relay radio signals between the boats and the gliders. Now, just imagine what you’ll be able to do with these systems once we get cheaper, more powerful computers and better autonomous control&analysis AI systems that can be deployed onto them – the future is a world full of robots, sensing and responding to minute fluctuations in the environment.

**   Read more:** Towards autonomous ocean observing systems using Miniature Underwater Gliders with UAV deployment and recovery capabilities (Arxiv).
+++

…What do you need to know about AI? From hardware innovation to advancements in machine learning to developments in ethics and regulation, join leading experts with the insight you need to see where AI is going–and how to get there first.…**Register soon.** **Early price ends March 1st**, and space is limited. Save up to $800 on most passes with code IMPORTAI20.

+++


**  How they do it:** To solve this, DeepMind uses an extension of its Scheduled Auxiliary Control (SAC-X) algorithm, which lets them train across multiple tasks with multiple rewards. Their secret to solving the tasks robustly on physical robots is to use additional data at training time, where the goal is “simultaneously learn control policies from both feature-based representation and raw vision inputs in the real-world – resulting in controllers that can afterwards be deployed on a real robot using two off-the-shelf cameras”.


**  Why it matters:** Getting anything to work reliably on a real robot is a journey of pain, frustration, pain, tedium, and – yes! – more pain. It’s encouraging to see SAC-X work in this domain, and it suggests that we’re figuring out better ways to learn things on real-world platforms.


+++


**  Noise methods:** The technique uses four noise methods: deletions, insertions, substitutions, and swaps. Deletions are where the researchers delete a character in a sentence; insertions are where they insert a character into a random position; substitutions are where they replace a character with another random character, and swaps are where two adjacent characters change position.


  **Where doesn’t noise help: **This technique doesn’t help when trying to perform translations on text derived from social media – this is because social media errors tend to stem from content on having a radically different writing and tonal style to what is traditionally seen in training sets, rather than spelling errors.


**  Why this matters:** This is another example of the ways in which computers can be arbitraged for data: instead of needing to go and gather datasets with real-world faults, the addition of synthetic noise means you can instead algorithmically extend existing datasets through the augmentation of noisy data. The larger implication here is that computational resources are becoming an ever-more-significant factor in AI development.**Read more:** Training on Synthetic Noise IMproves Robustness to Natural Noise in Machine Translation (Arxiv).


**In the future, neural networks will be bred, not created:*****…****General-purpose population training for those who can afford it…*Population Based Training (PBT) is a recent invention by DeepMind that makes it possible to optimize the weights and hyperparameters of a set of neural networks by periodically copying the weights of the best performers and mutating their parameters. This is part of the broader trend of the *industrialization of artificial intelligence*, as researchers seek to create automated procedures for doing what was otherwise previously done by patient graduate students (eg, fiddling with weights of different networks, logging runs, pausing and re-starting models, etc).


**  Results: **“We conducted a case study of our system in WaveNet human speech synthesis and demonstrated that our PBT system produces superior accuracy and performance compared to other popular hyperparameter tuning methods,” they write. “Moreover, the PBT system is able to directly train a model using the discovered dynamic set of hyperparameters while traditional methods can only tune static parameters. In addition, we show that the proposed PBT framework is feasible for large scale deep neural network training”.


+++


**   Why it matters:** It seems valuable to have technology actors discuss the potential second-order effects of technologies they work on. It’s less clear to me that the approach of training increasingly more exquisite discriminators against increasingly capable generators has an end-state that is stable, but I’m curious to see what evidence competitions like this help generate regarding this.


+++


**Structural risks from AI:**The discussion of AI risk tends to divide downsides into accident risk, and misuse risk. This obscures an important source of potential harms that fits into neither category, which the authors call structural risk.


**  AI and structure: **There are many examples of ways in which AI could influence structures in a harmful way. AI could undermine stability between nuclear powers, by compromising second-strike capabilities and increasing the risk of pre-emptive escalation. Worries about AI’s impact on economic competition, the labour market, and civil liberties also fit into this category. Structures can themselves increase AI-related risks. Without mechanisms for international coordination, countries may be pushed towards sacrificing safety for performance in military AI.


Drawing in more expertise from the social sciences is a one way to address this, as these disciplines are more experienced in taking structural perspectives on complex issues. A greater focus on establishing norms and institutions for AI is also important, given the necessity of coordination between actors in solving structural problems.


**Trump signs executive order on AI:**President Trump has signed an executive order, outlining proposals for a new ‘AI Initiative’ across government.

**  Objectives: **The memo gives six objectives for government agencies: to promote investment in R&D improve access to government data; reduce barriers to innovation; develop appropriate technical standards; train the workforce; and to create a plan for protecting US advantage in critical technologies.


**  Why it matters: **The US government has been slow to formulate a strategy on AI, and this is an important step. As it stands, however, it is little more than a statement of intent; it remains to be seen whether this will translate into action. Without significant funding, this initiative is unlikely to amount to much. The memo also lacks detail on the ethical challenges of AI, such as ensuring benefits are equitably distributed, and risks are minimized.


+++**OpenAI Bits&Pieces:**

**GPT-2:**We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization — all without task-specific training.**Also in this release: **Discussion of the policy implications of releasing increasingly larger AI models. This release triggered a fairly significant and robust discussion about GPT2, increasingly powerful models, appropriate methods for engaging the media and ML communities about topics like publication norms.


   **Read more: **Better Language Models and Their Implications (OpenAI).


*AGI Romance**+++ ❤ +++*


This story is the same as ever, but the context is different: The boy and the girl are working on a machine, a living thing, a half-life between something made by people and something that births itself.


You know we’re just mechanics, she would say.More like makeup artists, he would say.Maybe somewhere in-between, she would say, looking at him with her green eyes, the blue of the monitor reflected in them.


You know I had a dream last night where I was a machine, she would say.You’re asleep right now, he would say. Wake up!Tease, she would say. You’ll teach it bad jokes.I think it’ll teach us more, he would say, filing a code review request.Where did you learn to write code like this, she would say. Did you go to art school?


You know I think it might know something, she would say one day.What do you mean, he would say.You know I think it knows we like each other, she would say.How can you tell, he would say.When I smile at you it smiles at me, she would say. I feel a connection.You know I think it is predicting what we’ll do, he would say.


And that would be the end: after that there is nothing but infinity. They will disappear into their own history together, and then another story will happen again, in improbable circumstances, and love will emerge again: perhaps the only constant among living things is the desire to predict the proximity of one to another and to close that distance.


### Like this:

Like Loading...


*Related*




![](https://pixel.wp.com/b.gif?v=noscript)

