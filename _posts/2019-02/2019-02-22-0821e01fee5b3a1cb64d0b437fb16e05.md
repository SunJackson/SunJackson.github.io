---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/02/22/distilled-news-984/
date:      2019-02-22
author:      Michael Laux
tags:
    - networks
    - learning
    - classification
    - probability
    - agents
---

**Image clustering using Transfer learning**

Clustering is an interesting field of Unsupervised Machine learning where we classify datasets into set of similar groups. It is part of ‘Unsupervised learning’ meaning, where there is no prior training happening and the dataset will be unlabeled. Clustering can be done using different techniques like K-means clustering, Mean Shift clustering, DB Scan clustering, Hierarchical clustering etc. The key assumption behind all the clustering algorithms is that nearby points in the feature space, possess similar qualities and they can be clustered together. In this article, we will be doing a clustering on images. Images are also same as datapoints in regular ML and can considered as similar issue. But the Big question is, Define Similarity of Images !!!!!

**Visualizing Brooklyn Nine-Nine with R!**

Brooklyn Nine-Nine has become one of my favorite sitcoms in recent years, probably taking over from Parks and Recreation and Community. So in this blog post, I’m going to web scrape some very simple TV statistics, clean it up with the tidyverse, and visualize it with ggplot2…

**Boosting and AdaBoost clearly explained**

**Probability Cheat Sheet – Harvard University**

**Backpropagation for people who are afraid of math**

Backpropagation is one of the most important concepts in machine learning. There are many online resources that explain the intuition behind this algorithm (IMO the best of these is the backpropagation lecture in the Stanford cs231n video lectures. Another very good source, is this), but getting from the intuition to practice, can be (put gently) quite challenging. After spending more hours then i’d like to admit, trying to get all the sizes of my layers and weights to fit, constantly forgetting what’s what, and what’s connected where, I sat down and drew some diagrams that illustrates the entire process. Consider it a visual pseudocode.

**A Hitchhiker’s Guide to Mixture Density Networks**

Assessing the uncertainty of predictions is elementary for business decisions. Mixture density networks help you to better understand the uncertainty you are facing in the real world.

**NLP and Sarcasm: What’s the Deal?**

As humans, you and I can look at these two chats and determine that in the first the person appears to be sincere while in the other comes off sarcastic and cold simply due to the way it was punctuated. This may seem fairly obvious. Yet for chatbots and natural language processing algorithms, these two responses tend to appear identical. When taken in the literal sense, there’s no reason to assume that both people had the same reaction. Removing our understanding of social cues hinders our ability to discern the true intention of the message.

**How to Build A Data Set For Your Machine Learning Project**

Are you about thinking AI for your organization? You have identified a use case with a proven ROI? Perfect! but not so fast… do you have a data set? Well, most companies are struggling to build an AI-ready data set or perhaps simply ignore this issue, I thought that this article might help you a little bit.

**An Introduction on Time Series Forecasting with Simple Neura Networks and LSTM**

An Introduction on Time Series Forecasting with Simple Neural Networks and LSTM How to develop Artificial Neural Networks and LSTM recurrent neural networks for time series prediction in Python with the Keras deep learning network The purpose of this article is to explain Artificial Neural Network (ANN) and Long Short-Term Memory Recurrent Neural Network (LSTM RNN) and enable you to use them in real life and build the simplest ANN and LSTM recurrent neural network for the time series data.

**Decision Trees – An Intuitive Introduction**

An extensive introduction including a look at decision tree classification, data distribution, decision tree regression, decision tree learning, information gain, and more.

**KubernetesExecutor for Airflow**

Airflow has a new executor that spawns worker pods natively on Kubernetes. There’s a Helm chart available in this git repository, along with some examples to help you get started with the KubernetesExecutor.

**How to Install OpenAI Gym in a Windows Environment**

A step by step guide for getting OpenAI Gym up and running

**A Beginner’s Guide to Convolutional Neural Networks (CNNs)**

A convolution is how the input is modified by a filter. In convolutional networks, multiple filters are taken to slice through the image and map them one by one and learn different portions of an input image. Imagine a small filter sliding left to right across the image from top to bottom and that moving filter is looking for, say, a dark edge. Each time a match is found, it is mapped out onto an output image.

**Bioinformatics: Where code meets biology**

A brief introduction to the future of healthcare

**Ontology Development 101: A Guide to Creating Your First Ontology**

In recent years the development of ontologies – explicit formal specifications of the terms in the domain and relations among them (Gruber 1993) – has been moving from the realm of Artificial-Intelligence laboratories to the desktops of domain experts. Ontologies have become common on the World-Wide Web. The ontologies on the Web range from large taxonomies categorizing Web sites (such as on Yahoo!) to categorizations of products for sale and their features (such as on Amazon.com). The WWW Consortium (W3C) is developing the Resource Description Framework (Brickley and Guha 1999), a language for encoding knowledge on Web pages to make it understandable to electronic agents searching for information. The Defense Advanced Research Projects Agency (DARPA), in conjunction with the W3C, is developing DARPA Agent Markup Language (DAML) by extending RDF with more expressive constructs aimed at facilitating agent interaction on the Web (Hendler and McGuinness 2000). Many disciplines now develop standardized ontologies that domain experts can use to share and annotate information in their fields. Medicine, for example, has produced large, standardized, structured vocabularies such as snomed (Price and Spackman 2000) and the semantic network of the Unified Medical Language System (Humphreys and Lindberg 1993). Broad general-purpose ontologies are emerging as well. For example, the United Nations Development Program and Dun & Bradstreet combined their efforts to develop the UNSPSC ontology which provides terminology for products and services (www.unspsc.org). An ontology defines a common vocabulary for researchers who need to share information in a domain. It includes machine-interpretable definitions of basic concepts in the domain and relations among them.Why would someone want to develop an ontology? Some of the reasons are:• To share common understanding of the structure of information among people or software agents• To enable reuse of domain knowledge• To make domain assumptions explicit• To separate domain knowledge from the operational knowledge• To analyze domain knowledge

**One-versus-All multi-class classification**

In practice many classification problems have more than two classes we wish to distinguish, e.g., face recognition, hand gesture recognition, general object detection, speech recognition, and more. However because it has only two sides, a single linear separator is fundamentally insufficient as a mechanism for differentiating between more than two classes of data. Nonetheless we can use our understanding of two-class classification to overcome this shortcoming when dealing with C>2 C>2 classes by learning C C linear classifiers (one per class), each distinguishing one class from the rest of the data. The heart of the matter is how we should combine these individual classifiers to create a reasonable multi-class decision boundary. In this Section we develop this basic scheme – called One-versus-All multi-class classification – step-by-step by studying how such an idea should unfold on a toy dataset. With due diligence and a little common sense we can intuitively derive universal ideas regarding multiclass classification that are the basis for most popular multi-class classification schemes, including One-versus-All (OvA) classification.





### Like this:

Like Loading...


*Related*

