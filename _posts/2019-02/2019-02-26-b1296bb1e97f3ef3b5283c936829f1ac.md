---
layout:     post
catalog: true
title:      5 Best JavaScript Web Scraping Libraries and Tools
subtitle:      转载自：https://www.codementor.io/hirenpatel545/5-best-javascript-web-scraping-libraries-and-tools-sicow2rx9
date:      2019-02-26
author:      Hiren Patel
tags:
    - cheerio
    - javascript
    - requests
    - running browsers
    - features support
---

##  Introduction

As it’s obvious, Internet is getting overloaded with information and data. With the growth of data on the web, web scraping is also likely to become more and more important for businesses for mining the Internet for actionable insights. While there are various tools available for web scraping, a growing number of people spend their valuable time exploring web scraping libraries and tools for JavaScript.

You might wonder why JavaScript? Why does JavaScript matter so much?

Well, JavaScript is the most popular and widely used programming language world over. Since it offers numerous important functionalities, there is a growing use of JavaScript in the way websites are designed.

When it comes to extracting data from these websites, it will require a browser through using which you can parse the HTML and run page scripts and then inject your data extraction code that will run in the browser context.

In order to carry out your web scraping work, there are countless JavaScript packages. However, you need to familiarize yourself with only a few in order to choose the right one. Therefore, we have compiled a list of the best JavaScript libraries that you can explore.

These libraries take care of the most important aspects that concern your needs.

Here is a list of web scraping frameworks and libraries we will go through in this article.

> 
**1. Request****2. Cheerio****3. Osmosis****4. Puppeteer****5. Agenty**


##  1. Request (Aka HTTP Client) :

- Request is a pretty straightforward yet efficient HTTP client that enables you to make quick and easy HTTP calls.

- It supports HTTPS and follows redirects by default.

- It’s so easy to use that you could jump right in without spending time in studying the documentation.

- For example, if you want to pull down the contents of a page, it’s as easy as :


```
 const request = require('request');

 request('http://stackabuse.com', function(err, res, body) { 
 console.log(body);
 });

```

####  Features:

- support all HTTP Methods (GET,POST,DELETE,etc.)

- support forms uploads

- supports both streaming and callback interfaces

- HTTP Authentication

- Proxy Support

- Support TLS/SSL Protocol& Many more…


####  Resources:

##  2. Cheerio (Aka Parser) :

- Cheerio provides fast, flexible and lean implementation of core jQuery designed specifically for the server.

- Cheerio parses markup and provides an API for traversing/manipulating the resulting data structure.


####  Features:

- **Familiar syntax:** Cheerio implements a subset of core jQuery. It removes all the DOM inconsistencies and browser cruft from the jQuery library, revealing its truly gorgeous API.

- **Lightening Quick:** Cheerio works with a very simple, consistent DOM model. As a result parsing, manipulating, and rendering are incredibly efficient. Preliminary end-to-end benchmarks suggest that cheerio is about 8x faster than JSDOM.

- **Stunningly flexible:** Cheerio can parse nearly any HTML or XML document.


####  Resources:

##  3. Osmosis (Aka Parser) :

- Osmosis is HTML/XML parser and web scraper.

- It is written in node.js which packed with css3/xpath selector and lightweight http wrapper

- No large dependencies like Cheerio


####  Features:

- Supports CSS 3.0 and XPath 1.0 selector hybrids

- Load and search AJAX content

- Logs URLs, redirects, and errors

- Cookie jar and custom cookies/headers/user agent

- Login/form submission, session cookies, and basic auth

- Single proxy or multiple proxies and handles proxy failure

- Retries and redirect limits& Many more..


####  Resources:

##  4. Puppeteer (Aka Headless Chrome Browser for Automation) :

- Puppeteer is a Node.js library which offers a simple but efficient API that enables you to control Google’s Chrome or Chromium browser.

- It also enables you to run Chromium in headless mode (useful for running browsers in servers) and can send and receive requests without the need of a user interface.

- The great thing is that it works in the background, performing actions as instructed by the API.


####  Features:

- Click elements such as buttons, links, and images

- Automate form submissions

- Navigate pages

- Take a timeline trace to find out where the issues are in a website

- Carry out automated testing for user interfaces and various front-end apps, directly in a browser

- Take screenshots

- Convert web pages to pdf files


####  Resources:

##  5. Agenty (Aka The Complete Web Scraping Framework) :

- Apify SDK  is  an open-source Node.js library for scraping and web crawling.

- Apify SDK is a unique tool that simplifies the development of web crawlers, scrapers, data extractors and web automation jobs.

- It offers tools to manage and automatically scale a pool of headless Chrome / Puppeteer instances, to maintain queues of URLs to crawl, store crawling results to a local file system or into the cloud, rotate proxies and much more.

- It can be used either stand-alone in your own applications or in actors running on the Apify Cloud.


####  Features:

- Perform a deep crawl of an entire website using a persistent queue of URLs.

- Run your scraping code on a list of 100k URLs in a CSV file, without losing any data when your code crashes.

- Rotate proxies to hide your browser origin.

- Schedule the code to run periodically and send notification on errors.

- Disable browser fingerprinting protections used by websites.


####  Resources:

##  Conclusion

Web scraping is set to grow as the time progresses. As web scraping applications abound, JavaScript libraries will grow in demand.

While there are salient JavaScript libraries, it could be puzzling to choose the right one. However, it would eventually boil down to your own respective requirements.

Instead of choosing a fancy tool that may not be of much use, you should focus on finding out a tool that suits your requirements best.

In consonance with your requirements, you can choose any of these tools mentioned above and leverage the powers of web scraping to accelerate the growth of your business!!!
