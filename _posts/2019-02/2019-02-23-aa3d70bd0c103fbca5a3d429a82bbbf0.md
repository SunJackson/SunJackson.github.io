---
layout:     post
catalog: true
title:      If you did not already know
subtitle:      转载自：https://analytixon.com/2019/02/23/if-you-did-not-already-know-649/
date:      2019-02-23
author:      Michael Laux
tags:
    - inference
    - networks
    - performance
    - multimodal
    - sgx
---

**Privado** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
Recently, cloud providers have extended support for trusted hardware primitives such as Intel SGX. Simultaneously, the field of deep learning is seeing enormous innovation and increase in adoption. In this paper, we therefore ask the question: ‘Can third-party cloud services use SGX to provide practical, yet secure DNN Inference-as-a-service? ‘ Our work addresses the three main challenges that SGX-based DNN inferencing faces, namely, security, ease-of-use, and performance. We first demonstrate that side-channel based attacks on DNN models are indeed possible. We show that, by observing access patterns, we can recover inputs to the DNN model. This motivates the need for Privado, a system we have designed for secure inference-as-a-service. Privado is input-oblivious: it transforms any deep learning framework written in C/C++ to be free of input-dependent access patterns. Privado is fully-automated and has a low TCB: with zero developer effort, given an ONNX description, it generates compact C code for the model which can run within SGX-enclaves. Privado has low performance overhead: we have used Privado with Torch, and have shown its overhead to be 20.77\% on average on 10 contemporary networks. … 

**Stochastic Answer Network (SAN)** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
We propose a stochastic answer network (SAN) to explore multi-step inference strategies in Natural Language Inference. Rather than directly predicting the results given the inputs, the model maintains a state and iteratively refines its predictions. Our experiments show that SAN achieves the state-of-the-art results on three benchmarks: Stanford Natural Language Inference (SNLI) dataset, MultiGenre Natural Language Inference (MultiNLI) dataset and Quora Question Pairs dataset.![](https://aboutdataanalytics.files.wordpress.com/2015/04/link.png?w=529)
 Stochastic Answer Networks for SQuAD 2.0 … 

**Dense Multimodal Fusion (DMF)** ![](https://analytixon.files.wordpress.com/2015/01/google.png?w=529)
Multiple modalities can provide more valuable information than single one by describing the same contents in various ways. Hence, it is highly expected to learn effective joint representation by fusing the features of different modalities. However, previous methods mainly focus on fusing the shallow features or high-level representations generated by unimodal deep networks, which only capture part of the hierarchical correlations across modalities. In this paper, we propose to densely integrate the representations by greedily stacking multiple shared layers between different modality-specific networks, which is named as Dense Multimodal Fusion (DMF). The joint representations in different shared layers can capture the correlations in different levels, and the connection between shared layers also provides an efficient way to learn the dependence among hierarchical correlations. These two properties jointly contribute to the multiple learning paths in DMF, which results in faster convergence, lower training loss, and better performance. We evaluate our model on three typical multimodal learning tasks, including audiovisual speech recognition, cross-modal retrieval, and multimodal classification. The noticeable performance in the experiments demonstrates that our model can learn more effective joint representation. … 





### Like this:

Like Loading...


*Related*

