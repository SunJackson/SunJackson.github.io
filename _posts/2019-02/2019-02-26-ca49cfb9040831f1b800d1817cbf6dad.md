---
layout:     post
catalog: true
title:      Customers who bought…
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/Lnhh_1jEkO4/
date:      2019-02-26
author:      Learning Machines
tags:
    - diapers
    - beer
    - items
    - customers
    - butter
---










![](https://i0.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/shopping-1889066_1920-e1550439059196-300x256.jpg?resize=300%2C256)
![](https://i0.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/shopping-1889066_1920-e1550439059196-300x256.jpg?resize=300%2C256)
One of the classic examples in data science (called data mining at the time) is the beer and diapers example: when a big supermarket chain started analyzing their sales data they encountered not only trivial patterns, like toothbrushes and toothpaste being bought together, but also quite strange combinations like beer and diapers. Now, the trivial ones are reassuring that the method works but what about the more extravagant ones? Does it mean that young parents are alcoholics? Or that instead of breastfeeding they give their babies beer? Obviously, they had to get to the bottom of this.

As it turned out in many cases they following happened: stressed out mummy sends young daddy to the supermarket because they had run out of diapers. Young daddy seizes the opportunity to not only buy the much needed diapers but also to stock up on some beer! So what the supermarket did was to place the beer directly on the way from the aisle with the diapers – the result was a significant boost in beer sales (for all the young daddies who might have forgotten what they *really* wanted when buying diapers…).

So, to reproduce this example in a simplified way have a look at the following code:

What we are looking for is some kind of dependance pattern within the shopping baskets, in this case we use the good old *correlation* function. Traditionally other (dependance) measures are used, namely *support*, *confidence* and *lift*. We will come to that later on in this post.

Wikipedia offers the following fitting description of association rule learning:

> 
Association rule learning is a rule-based machine learning method for discovering interesting relations between variables in large databases. It is intended to identify rules discovered in databases using some measures of interestingness.
For example, the rule ![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-9eb6b1d05f49e721abf0a2706810ebb4_l3.png?resize=239%2C18)
![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-9eb6b1d05f49e721abf0a2706810ebb4_l3.png?resize=239%2C18)
 found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat.
Such information can be used as the basis for decisions about marketing activities such as, e.g. promotional pricing or product placements.
In addition to the above example from market basket analysis association rules are employed today in many application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics.


So, this is also the basis of popular functions on ecommerce sites (“customers who bought this item also bought…”) or movie streaming platforms (“customers who watched this film also watched…”).

A very good package for real-world datasets is the arules package (on CRAN). Have a look at the following code:

The algorithm used here is the so called Apriori algorithm. It ameliorates the problem with real-world datasets that when you want to test all combinations of all possible items you very soon run into performance problems – even with very fast computers – because there are just too many possibilities to be tested.

The Apriori algorithm aggressively prunes the possibilities to be tested by making use of the fact that if you are only interested in rules that are supported by a certain number of instances you can start with testing the support of individual items – which is easy to do – and work your way up to more complicated rules. 

The trick is that you don’t test more complicated rules with items which don’t have enough support on the individual level: this is because if you don’t have enough instances on the individual level you don’t even have to look at more complicated combinations with those items included (which would be even more scarce). What sounds like an obvious point brings about huge time savings for real-world datasets which couldn’t be analyzed without this trick.

As mentioned above important concepts to assess the quality (or interestingness) of association rules are support, confidence and lift:

**Support** of ![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-2c213ac3b0b07c81ac253ff512e7861f_l3.png?resize=77%2C18)
![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-2c213ac3b0b07c81ac253ff512e7861f_l3.png?resize=77%2C18)
: percentage of X for all cases
**Confidence** of ![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-5d536cf2f986684b0c7e1f05d2801daa_l3.png?resize=181%2C18)
![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-5d536cf2f986684b0c7e1f05d2801daa_l3.png?resize=181%2C18)
: percentage of Y for all X
**Lift** of ![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-5d536cf2f986684b0c7e1f05d2801daa_l3.png?resize=181%2C18)
![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-5d536cf2f986684b0c7e1f05d2801daa_l3.png?resize=181%2C18)
: ratio of the observed support of X and Y to what would be expected if X and Y were independent

To understand these concepts better we are going to rebuild the examples given in the Wikipedia article in R. Have a look at the parts “Definition” and “Useful Concepts” of the article and after that at the following code, which should be self-explanatory:

You should conduct your own experiments by playing around with different item combinations so that you really understand the mechanics of those important concepts.

If all of those analyses are being done for perfecting your customer experience or just outright manipulation to lure you into buying stuff you don’t really need is obviously a matter of perspective…


*Related*








---
