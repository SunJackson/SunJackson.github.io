---
layout:     post
catalog: true
title:      Import AI 135： Evolving neural networks with LEAF; training ImageNet in 1.5 minutes, and the era of bio-synthetic headlines
subtitle:      转载自：https://jack-clark.net/2019/02/25/import-ai-135-evolving-neural-networks-with-leaf-training-imagenet-in-1-5-minutes-and-the-era-of-bio-synthetic-headlines/
date:      2019-02-25
author:      Jack Clark
tags:
    - researchers
    - peoples
    - systems like
    - technology
    - technological
---




### Import AI 135: Evolving neural networks with LEAF; training ImageNet in 1.5 minutes, and the era of bio-synthetic headlines

#### by Jack Clark

**Researchers take a LEAF out of Google’s book with evolutionary ML system:**…*In the future, some companies will have researchers, and some will spend huge $$$ on compute for architecture search…*Researchers with startup Cognizant Technology Solutions have developed their own approach to architecture search, using insights from one of the paper authors Risto Miikkulainen, inventor of the NEAT and HyperNEAT approaches.

   They outline a technology called LEAF (Learning Evolutionary AI Framework) which uses an algorithm called CoDeepNEAT (an extension of NEAT) to let it evolve the architecture and hyperparameters. “Multiobjective CoDeepNEAT can be used to maximize the performance and minimize the complexity of the evolved networks simultaneously,” the authors write. It also has some middleware software to let it spreads jobs over Amazon AWS, Microsoft Azure, or the Google Cloud.


**  Why this matters:** Systems like LEAF show the relationship between compute spending and ultimate performance of trained models, and suggests that some AI developers could consider under-investing in research staff and instead investing in techniques where they can arbitrage compute against researcher-time, delegating the task of network design and fine-tuning to machines instead of people.**\  Read more:** Evolutionary Neural AutoML for Deep Learning (Arxiv).


   RAIL licenses are designed to account for the omni-use nature of AI technology, which means that “the same AI tool that can be used for faster and more accurate cancer diagnoses can also be used in powerful surveillance system”, they write. “This lack of control is especially salient when a developer is working on open-source ML or AI software packages, which are foundational to a wide variety of the most beneficial ML and AI applications.”

**   How RAIl works:** The RAIL licenses work by restricting AI and ML software from being used in a specific list of harmful applications, e.g. in surveillance and crime prediction, while allowing for other applications.


**   Why this matters:** The emergence of licensing schemes like this speaks to the anxieties that some people feel about how AI technology is being used or applied today. If licenses like these get adopted and are followed by users of the technology, then it gives developers a non-commercial way to (slightly) control how their technology is used. Unfortunately, approaches like RAIL will not work against malicious actors, who are likely to ignore any restrictions in a particular software license when carrying out their nefarious activities.**   Read more:** Responsible AI Licenses (RAIL site).


**   Decisions, decisions, decisions: NAIL has these four main decision modules:****     Examiner: **Tries to identify new objects seen in the fiction to add to NAIL’s knowledge graph.**      Hoarder: **Tries to “take all” objects seen at a point in time.**      Interactor:** Tries to figure out what actions to take and how to take them.**     Navigator:** Attempts to apply one of twelve actions (eg, ‘enter’, or ‘South’) to move the player.


**   All about the Knowledge: **While NAIL explores the world, it builds a knowledge graph to help it learn about its gameworld. It organizes this knowledge graph autonomously and extends it over time. Additionally, having a big structured store of information makes debugging easier: “by comparing the knowledge graph to the published map for well documented games like Zork, it was possible to track down bugs in NAIL’s decision modules”.


**This week during the Industrialization of AI = train ImageNet in 1.5 minutes:***…New research from Chinese image recognition giant SenseTime shows how to train big ImageNet clusters…*How can we model the advancement of AI systems? One way is to model technical metrics, like the performance of given algorithms against various reinforcement learning benchmarks, or supervised image classification, or what have you. Another is to try to measure the advancement in the infrastructure that supports Ai – think of this as the difference between measuring the performance traits of a new engine, versus measuring the time it takes for a factory to take that engine and integrate it into a car.


   **The numbers:****  1.5 minutes:** Time it takes to complete 95-epoch training of ImageNet using ‘AlexNet’ across 512 GPUs, exceeding current state-of-the-art systems.**   7.3 minutes: **Time it takes to train ImageNet to 95-epochs using a 50-layered Residual Network – this is a little below the state-of-the-art.


**Why this matters:** Metrics like this give us a sense of how sophisticated AI infrastructure is becoming, and emphasize that organizations which invest in such infrastructure will be able to run more experiments in less time than those that haven’t, which has long-term implications for the competitive structure of markets.**  Read more:** Optimizing Network Performance for Distributed DNN Training on GPU Clusters: ImageNet/AlexNet Training in 1.5 Minutes (Arxiv).


**   The eight hopes and fears of AI:** The researchers characterize four hopes and four fears relating to AI. Often the reverse of a particular hope is a fear, and vice versa. They describe these feelings as:**      – Immortality: Inhumanity** – We’ll live forever, but we might lose our humanity.**      – Ease: Obsolescence** – Everything gets simpler, but we might become pointless.**      – Gratification: Alienation** – AI could respond to our needs, but so effectively that we choose AI over people.**      – Dominance: Uprising** – We might get better robot militaries, but these robot militaries might eventually kill us.


**   Who gets to develop AI? **In the survey, 61.8% of respondents “disagreed that they were able to influence how AI develops in the future” – this disempowerment seems problematic. There was broad agreement amongst those surveyed that the technology would develop regardless of other things.


***AI Policy with ******Matthew van der Merwe******:****…Matthew van der Merwe has kindly offered to write some sections about AI & Policy for Import AI. I’m (lightly) editing them. All credit to Matthew, all blame to me, etc. Feedback: **jack@jack-clark.net**…*


**    What’s missing from the discussion: **There are major gaps in existing work: a lack of shared understanding of key concepts; insufficient use of evidence on technologies and public opinion; and insufficient attention to the tensions between principles and values.


**   Why this matters: **AI ethics is a young field, and still lacks many of the basic features of a mature discipline, e.g. shared understandings of terms and methodology. Building these foundations should be a near-term priority, and will improve the quality of discussion, and rate of progress.**   Read more:** Ethical and societal implications of algorithms, data, and artificial intelligence: a roadmap for research (Nuffield).
**Governance of AI Fellowship, University of Oxford:**The Center for the Governance of AI (GovAI) is accepting applicants for three-month research fellowships. They are looking for candidates from a wide range of disciplines, who are interested in pursuing a career in AI governance. GovAI is based at the Future of Humanity Institute, in Oxford, and is one of the leading hubs for AI governance research.**   Read more:** Governance of AI Fellowship (FHI).**   Read more:** AI Governance: A Research Agenda (FHI).

**Tech Tales:**

*Titles from the essay collection: The Great Transition: Human Society During The Bio-Synthetic Fusion Era*


Hand Back the Microphone! Human Slam Poetry’s Unpredictable Rise


Stag Race Development Dynamics and the AI Safety Incidents in Beijing and Kyoto


Dreamy Crooners and Husky Hackers: An Investigation Into Machine-Driven Pop


Red Scare? The Unreported Tensions That Drove US-China Competitive Dynamics


**Things that inspired this story: **Indexes and archives as historical artefacts in their own right; the idea that the information compression inherent to essay titles contains a bigger signal than people think.
Like this:Like Loading...


*Related*




![](https://pixel.wp.com/b.gif?v=noscript)

