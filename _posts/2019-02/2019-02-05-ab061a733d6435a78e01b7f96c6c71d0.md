---
layout:     post
catalog: true
title:      Learning Data Science： Modelling Basics
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/_7gMzWb1BoA/
date:      2019-02-05
author:      Learning Machines
tags:
    - age
    - income
    - models
    - predictions
    - predicting
---










![](https://i2.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/catwalk-1013864_1920-e1549357363379-203x300.jpg?resize=203%2C300)
![](https://i2.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/catwalk-1013864_1920-e1549357363379-203x300.jpg?resize=203%2C300)
Data Science is all about building good models, so let us start by building a very simple model: we want to predict monthly income from age (in a later post we will see that age is indeed a good predictor for income).

For illustrative purposes we just make up some numbers for age and income, load both into a data frame, plot it and calculate its correlation matrix:

![](https://i0.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/mb1.png?w=450)
![](https://i0.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/mb1.png?w=450)


Just by looking at the plot we can see that the points seem to be linearly dependent. The correlation matrix corroborates this with a correlation of nearly ![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-9779796b1f3b96e67133dbdcbdb63339_l3.png?resize=32%2C15)
![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-9779796b1f3b96e67133dbdcbdb63339_l3.png?resize=32%2C15)
. To build a linear regression model we use the `lm` function (for linear model). To specify the model we use the standard R formula interface: on the left hand side comes the dependent variable, i.e. the variable that we want to predict (`income`) and on the right hand side comes the independent variable, i.e. the variable that we want to use to predict income, viz. `age` – in between both variables we put a tilde (`~`). After that we plot the model as a line and look at some model diagnostics:

![](https://i2.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/mb2.png?w=450)
![](https://i2.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/mb2.png?w=450)


The general line equation is ![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-5c4fc188b07e2781547574f198dc5098_l3.png?resize=88%2C17)
![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-5c4fc188b07e2781547574f198dc5098_l3.png?resize=88%2C17)
, where ![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-fdc40b8ad1cdad0aab9d632215459d28_l3.png?resize=15%2C8)
![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-fdc40b8ad1cdad0aab9d632215459d28_l3.png?resize=15%2C8)
 is the slope (in this case ![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-5c064af84889ae29b5dba6c38eabd066_l3.png?resize=41%2C14)
![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-5c064af84889ae29b5dba6c38eabd066_l3.png?resize=41%2C14)
) and ![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-ad69adf868bc701e561aa555db995f1f_l3.png?resize=8%2C13)
![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-ad69adf868bc701e561aa555db995f1f_l3.png?resize=8%2C13)
 the intercept (here ![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-255fb90b75b19831261c00f2bfeef0aa_l3.png?resize=67%2C14)
![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-255fb90b75b19831261c00f2bfeef0aa_l3.png?resize=67%2C14)
). The p-values in the last column show us that both parameters are significant, so with a high probability not due to randomness. If we now want to predict the income of a 20-year old we just have to calculate ![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-eb2dfd6132964ba4533818e9c42dc9be_l3.png?resize=235%2C15)
![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-eb2dfd6132964ba4533818e9c42dc9be_l3.png?resize=235%2C15)
.

To do the same calculation in R we can conveniently use the `predict` function which does this calculation for us automatically. We can also use vectors as input and get several predictions at once. Important is that we use the independent variable with its name as a data frame, otherwise R will throw an error.

So far so good, but wouldn’t it be nice to actually have a model that is even more accurate, a model where the line actually goes through all the data points so that all the available information is being used. Let us do that with a so called polynomial regression (in red):

![](https://i0.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/mb3.png?w=450)
![](https://i0.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/mb3.png?w=450)


What do you think? Is this a better model? Well, there is no good reason why income should go up the younger or older you are, and there is no good reason why there should be a bump between ![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-339d53c03f379138e262405cffbbcbb5_l3.png?resize=18%2C13)
![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-339d53c03f379138e262405cffbbcbb5_l3.png?resize=18%2C13)
 and ![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-082bf7c74d0fe5dcfa4b9840a99c6d6a_l3.png?resize=17%2C13)
![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-082bf7c74d0fe5dcfa4b9840a99c6d6a_l3.png?resize=17%2C13)
. In other words, this model takes the noise as legitimate input which actually makes it worse! To have a good model you always need some rigidity to generalize the data.

This illustration is a good example of one of the big problems of machine learning: overfitting the data! The other extreme would be underfitting, which is included in the following plot as a blue line:

![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/mb4.png?w=450)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/02/mb4.png?w=450)


We just took the mean value of income and claimed that no matter the age everybody would earn about ![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-3e2d8676a3927f1eb8ce528ea4b437ca_l3.png?resize=36%2C12)
![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-3e2d8676a3927f1eb8ce528ea4b437ca_l3.png?resize=36%2C12)
. This also obviously doesn’t make the cut. In practice and in all data science projects you always have to look for a model that hits the sweet spot between over- and underfitting. This is as much an art as a science, although there are certain best practices like dividing the data into a training and a test set, cross validation etc. 

Another important point it that all models have their area of applicability. In physics for example quantum physics works well for the very small but not very good for the very big, it is the other way round for relativity theory. In this case we didn’t have data for people of very young or very old age, so it is in general very dangerous to make prediction for those people, i.e. for values *outside* of the original observation range (also called extrapolation – in contrast to interpolation = predictions *within* the original range). In case of the linear model we got an income of about ![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-dc6d8f2fb8c17d7953eaa36009ce540b_l3.png?resize=35%2C13)
![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-dc6d8f2fb8c17d7953eaa36009ce540b_l3.png?resize=35%2C13)
 for newborns (the intercept)! And the income gets higher the older people get, also something that doesn’t make sense. This behaviour was a lot worse for the non-linear model.

So, here you can see that it is one thing to just let R run and spit something out and quite another one to find a good model and interpret it correctly – even for such a simple problem as this one. In a later post we will use real-world data to predict income brackets with OneR, decision trees and random forests, so stay tuned!


*Related*








---
