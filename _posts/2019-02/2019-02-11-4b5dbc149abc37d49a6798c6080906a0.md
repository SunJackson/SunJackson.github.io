---
layout:     post
catalog: true
title:      Fashion MNIST with Keras and Deep Learning
subtitle:      转载自：https://www.pyimagesearch.com/2019/02/11/fashion-mnist-with-keras-and-deep-learning/
date:      2019-02-11
author:      Adrian Rosebrock
tags:
    - models
    - imports
    - importing
    - imported
    - lines
---

![](https://www.pyimagesearch.com/wp-content/uploads/2019/02/fashion_mnist_header.png)
In this tutorial you will learn how to train a simple Convolutional Neural Network (CNN) with Keras on the Fashion MNIST dataset, enabling you to classify fashion images and categories.

The Fashion MNIST dataset is meant to be a (slightly more challenging) drop-in replacement for the (less challenging) MNIST dataset.

**Similar to the MNIST digit dataset, the Fashion MNIST dataset includes:**

- 60,000 training examples

- 10,000 testing examples

- 10 classes

- 28×28 grayscale/single channel images


**The ten fashion class labels include:**

1. T-shirt/top

1. Trouser/pants

1. Pullover shirt

1. Dress

1. Coat

1. Sandal

1. Shirt

1. Sneaker

1. Bag

1. Ankle boot


Throughout this tutorial, you will learn how to train a simple Convolutional Neural Network (CNN) with Keras on the Fashion MNIST dataset, giving you not only hands-on experience working with the Keras library but also your first taste of clothing/fashion classification.

**To learn how to train a Keras CNN on the Fashion MNIST dataset, *just keep reading!***

## Fashion MNIST with Keras and Deep Learning

In the first part of this tutorial, we will review the Fashion MNIST dataset, including how to download it to your system.

From there we’ll define a simple CNN network using the Keras deep learning library.

Finally, we’ll train our CNN model on the Fashion MNIST dataset, evaluate it, and review the results.

Let’s go ahead and get started!

### The Fashion MNIST dataset
![](https://www.pyimagesearch.com/wp-content/uploads/2019/02/fashion_mnist_dataset_sample.png)


**Figure 1:** The Fashion MNIST dataset was created by e-commerce company, Zalando, as a drop-in replacement for MNIST Digits. It is a great dataset to practice with when using Keras for deep learning. (image source)

The Fashion MNIST dataset was created by e-commerce company, Zalando.

As they note on their official GitHub repo for the Fashion MNIST dataset, **there are a few problems with the standard MNIST digit recognition dataset:**

1. It’s *far too easy* for standard machine learning algorithms to obtain 97%+ accuracy.

1. It’s *even easier* for deep learning models to achieve 99%+ accuracy.

1. The dataset is *overused*.

1. MNIST *cannot represent* modern computer vision tasks.


Zalando, therefore, created the Fashion MNIST dataset as a drop-in replacement for MNIST.

The Fashion MNIST dataset is identical to the MNIST dataset in terms of training set size, testing set size, number of class labels, and image dimensions:

- 60,000 training examples

- 10,000 testing examples

- 10 classes

- 28×28 grayscale images


**If you’ve ever trained a network on the MNIST digit dataset then you can essentially change one or two lines of code and train the same network on the Fashion MNIST dataset!**

### How to install Keras

If you’re reading this tutorial, I’ll be assuming you have Keras installed. If not, be sure to follow *Installing Keras for deep learning*.

You’ll also need OpenCV and imutils installed. Pip is suitable and you can follow my *pip install opencv* tutorial to get started.

The last tools you’ll need are scikit-learn and matplotlib:



||$ pip install scikit-learn$ pip install matplotlib|

$ pip install matplotlib


Obtaining the Fashion MNIST dataset

There are two ways to obtain the Fashion MNIST dataset.

If you are using the Keras deep learning library, the Fashion MNIST dataset is actually built directly into the `datasets` module of Keras:



||from keras.datasets import fashion_mnist((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()|

((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()

Otherwise, if you are using another deep learning library you can download it directory from the the official Fashion MNIST GitHub repo.

A big thanks to Margaret Maynard-Reid for putting together the *awesome illustration* in **Figure 2**.

### Project structure

To follow along, be sure to grab the ***“Downloads”*** for today’s blog post.

Once you’ve unzipped the files, your directory structure will look like this:



||$ tree --dirsfirst.├── pyimagesearch│   ├── __init__.py│   └── minivggnet.py├── fashion_mnist.py└── plot.png 1 directory, 4 files|

.

│   ├── __init__.py

├── fashion_mnist.py

 

Our project today is rather straightforward — we’re reviewing two Python files:


pyimagesearch/minivggnet.py : Contains a simple CNN based on VGGNet.

fashion_mnist.py : Our training script for Fashion MNIST classification with Keras and deep learning. This script will load the data (remember, it is built into Keras), and train our MiniVGGNet model. A classification report and montage will be generated upon training completion.

### Defining a simple Convolutional Neural Network (CNN)

Today we’ll be defining a very simple Convolutional Neural Network to train on the Fashion MNIST dataset.

We’ll call this CNN “MiniVGGNet” since:

- The model is inspired by its bigger brother, VGGNet

The model has VGGNet characteristics, including:

- Only using *3×3* CONV filters

- Stacking multiple CONV layers before applying a max-pooling operation


We’ve used the MiniVGGNet model before a handful of times on the PyImageSearch blog but we’ll briefly review it here today as a matter of completeness.

Open up a new file, name it 
minivggnet.py, and insert the following code:



|12345678910111213141516171819202122232425|# import the necessary packagesfrom keras.models import Sequentialfrom keras.layers.normalization import BatchNormalizationfrom keras.layers.convolutional import Conv2Dfrom keras.layers.convolutional import MaxPooling2Dfrom keras.layers.core import Activationfrom keras.layers.core import Flattenfrom keras.layers.core import Dropoutfrom keras.layers.core import Densefrom keras import backend as K class MiniVGGNet: @staticmethod def build(width, height, depth, classes): # initialize the model along with the input shape to be # "channels last" and the channels dimension itself model = Sequential() inputShape = (height, width, depth) chanDim = -1  # if we are using "channels first", update the input shape # and channels dimension if K.image_data_format() == "channels_first": inputShape = (depth, height, width) chanDim = 1|

2


4


6


8


10


12


14


16


18


20


22


24


from keras.models import Sequential

from keras.layers.convolutional import Conv2D

from keras.layers.core import Activation

from keras.layers.core import Dropout

from keras import backend as K

class MiniVGGNet:

 def build(width, height, depth, classes):

 # "channels last" and the channels dimension itself

 inputShape = (height, width, depth)

 

 # and channels dimension

 inputShape = (depth, height, width)

Our Keras imports are listed on **Lines 2-10**. Our Convolutional Neural Network model is relatively simple, but we will be taking advantage of batch normalization and dropout which are two methods I nearly always recommend. For further reading please take a look at *Deep Learning for Computer Vision with Python.*

Our 
MiniVGGNet  class and its 
build  method are defined on **Lines 12-14**. The 
build  function accepts four parameters:


width : Image width in pixels.

height : Image height in pixels.

depth : Number of channels. Typically for color this value is 
3  and for grayscale it is 
1  (the Fashion MNIST dataset is grayscale).

classes : The number of types of fashion articles we can recognize. The number of classes affects the final fully-connected output layer. For the Fashion MNIST dataset there are a total of 
10  classes.

Our 
model  is initialized on **Line 17** using the 
Sequential  API.

From there, our 
inputShape  is defined (**Line 18**). We’re going to use 
"channels_last"  ordering since our backend is TensorFlow, but in case you’re using a different backend, **Lines 23-25** will accommodate.

Now let’s add our layers to the CNN:



|27282930313233343536373839404142434445464748495051525354555657585960| # first CONV => RELU => CONV => RELU => POOL layer set model.add(Conv2D(32, (3, 3), padding="same", input_shape=inputShape)) model.add(Activation("relu")) model.add(BatchNormalization(axis=chanDim)) model.add(Conv2D(32, (3, 3), padding="same")) model.add(Activation("relu")) model.add(BatchNormalization(axis=chanDim)) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25))  # second CONV => RELU => CONV => RELU => POOL layer set model.add(Conv2D(64, (3, 3), padding="same")) model.add(Activation("relu")) model.add(BatchNormalization(axis=chanDim)) model.add(Conv2D(64, (3, 3), padding="same")) model.add(Activation("relu")) model.add(BatchNormalization(axis=chanDim)) model.add(MaxPooling2D(pool_size=(2, 2))) model.add(Dropout(0.25))  # first (and only) set of FC => RELU layers model.add(Flatten()) model.add(Dense(512)) model.add(Activation("relu")) model.add(BatchNormalization()) model.add(Dropout(0.5))  # softmax classifier model.add(Dense(classes)) model.add(Activation("softmax"))  # return the constructed network architecture return model|

28


30


32


34


36


38


40


42


44


46


48


50


52


54


56


58


60


 model.add(Conv2D(32, (3, 3), padding="same",

 model.add(Activation("relu"))

 model.add(Conv2D(32, (3, 3), padding="same"))

 model.add(BatchNormalization(axis=chanDim))

 model.add(Dropout(0.25))

 # second CONV => RELU => CONV => RELU => POOL layer set

 model.add(Activation("relu"))

 model.add(Conv2D(64, (3, 3), padding="same"))

 model.add(BatchNormalization(axis=chanDim))

 model.add(Dropout(0.25))

 # first (and only) set of FC => RELU layers

 model.add(Dense(512))

 model.add(BatchNormalization())

 

 model.add(Dense(classes))

 

 return model

Our 
model  has two sets of 
(CONV => RELU => BN) * 2 => POOL  layers (**Lines 28-46**). These layer sets also include batch normalization and dropout.

Convolutional layers, including their parameters, are described in detail in this previous post.

Pooling layers help to progressively reduce the spatial dimensions of the input volume.

Batch normalization, as the name suggests, seeks to normalize the activations of a given input volume before passing it into the next layer. It has been shown to be effective at reducing the number of epochs required to train a CNN at the expense of an increase in per-epoch time.

Dropout is a form of regularization that aims to prevent overfitting. Random connections are dropped to ensure that no single node in the network is responsible for activating when presented with a given pattern.

What follows is a fully-connected layer and softmax classifier (**Lines 49-57**). The softmax classifier is used to obtain output classification probabilities.

The 
model  is then returned on **Line 60.**

For further reading about building models with Keras, please refer to my Keras Tutorial and *Deep Learning for Computer Vision with Python.*

### Implementing the Fashion MNIST training script with Keras

Now that MiniVGGNet is implemented we can move on to the driver script which:

1. Loads the Fashion MNIST dataset.

1. Trains MiniVGGNet on Fashion MNIST + generates a training history plot.

1. Evaluates the resulting model and outputs a classification report.

1. Creates a montage visualization allowing us to see our results visually.


Create a new file named 
fashion_mnist.py, open it up, and insert the following code:



|123456789101112131415161718192021|# set the matplotlib backend so figures can be saved in the backgroundimport matplotlibmatplotlib.use("Agg") # import the necessary packagesfrom pyimagesearch.minivggnet import MiniVGGNetfrom sklearn.metrics import classification_reportfrom keras.optimizers import SGDfrom keras.datasets import fashion_mnistfrom keras.utils import np_utilsfrom keras import backend as Kfrom imutils import build_montagesimport matplotlib.pyplot as pltimport numpy as npimport cv2 # initialize the number of epochs to train for, base learning rate,# and batch sizeNUM_EPOCHS = 25INIT_LR = 1e-2BS = 32|

2


4


6


8


10


12


14


16


18


20


import matplotlib

 

from pyimagesearch.minivggnet import MiniVGGNet

from keras.optimizers import SGD

from keras.utils import np_utils

from imutils import build_montages

import numpy as np

 

# and batch size

INIT_LR = 1e-2

We begin by importing necessary packages, modules, and functions on **Lines 2-15:**

The 
"Agg"  backend is used for Matplotlib so that we can save our training plot to disk (**Line 3**).
Our 
MiniVGGNet  CNN (defined in 
minivggnet.py  in the previous section) is imported on **Line 6**.
We’ll use scikit-learn’s 
classification_report  to print final classification statistics/accuracies (**Line 7**).
Our Keras imports, including our 
fashion_mnist  dataset, are grabbed on **Lines 8-11**.
The 
build_montages  function from imutils will be used for visualization (**Line 12**).
Finally, 
matplotlib , 
numpy  and OpenCV (
cv2 ) are also imported (**Lines 13-15**).

Three hyperparameters are set on **Lines 19-21**, including our:

1. Learning rate

1. Batch size

1. Number of epochs we’ll train for


Let’s go ahead and load the Fashion MNIST dataset and reshape it if necessary:



|2324252627282930313233343536373839|# grab the Fashion MNIST dataset (if this is your first time running# this the dataset will be automatically downloaded)print("[INFO] loading Fashion MNIST...")((trainX, trainY), (testX, testY)) = fashion_mnist.load_data() # if we are using "channels first" ordering, then reshape the design# matrix such that the matrix is:# num_samples x depth x rows x columnsif K.image_data_format() == "channels_first": trainX = trainX.reshape((trainX.shape[0], 1, 28, 28)) testX = testX.reshape((testX.shape[0], 1, 28, 28)) # otherwise, we are using "channels last" ordering, so the design# matrix shape should be: num_samples x rows x columns x depthelse: trainX = trainX.reshape((trainX.shape[0], 28, 28, 1)) testX = testX.reshape((testX.shape[0], 28, 28, 1))|

24


26


28


30


32


34


36


38


# this the dataset will be automatically downloaded)

((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()

# if we are using "channels first" ordering, then reshape the design

# num_samples x depth x rows x columns

 trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))

 

# matrix shape should be: num_samples x rows x columns x depth

 trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))

The Fashion MNIST dataset we’re using is loaded from disk on **Line 26**. If this is the first time you’ve used the Fashion MNIST dataset then Keras will automatically download and cache Fashion MNIST for you.

Additionally, Fashion MNIST is already organized into training/testing splits, so today *we aren’t using* scikit-learn’s 
train_test_split  function that you’d normally see here.

From there we go ahead and re-order our data based on 
"channels_first"  or 
"channels_last"  image data formats (**Lines 31-39**). The ordering largely depends upon your backend. I’m using TensorFlow as the backend to Keras, which I presume you are using as well.

Let’s go ahead and preprocess + prepare our data:



||# scale data to the range of [0, 1]trainX = trainX.astype("float32") / 255.0testX = testX.astype("float32") / 255.0 # one-hot encode the training and testing labelstrainY = np_utils.to_categorical(trainY, 10)testY = np_utils.to_categorical(testY, 10) # initialize the label nameslabelNames = ["top", "trouser", "pullover", "dress", "coat", "sandal", "shirt", "sneaker", "bag", "ankle boot"]|

trainX = trainX.astype("float32") / 255.0

 

trainY = np_utils.to_categorical(trainY, 10)

 

labelNames = ["top", "trouser", "pullover", "dress", "coat",

Here our pixel intensities are scaled to the range *[0, 1]* (**Lines 42 and 43**). We then one-hot encode the labels (**Lines 46 and 47**).

Here is an example of one-hot encoding based on the 
labelNames  on **Lines 50 and 51:**

“T-shirt/top”: 
[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]
“bag”: 
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]

Let’s go ahead and fit our 
model :



||# initialize the optimizer and modelprint("[INFO] compiling model...")opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)model = MiniVGGNet.build(width=28, height=28, depth=1, classes=10)model.compile(loss="categorical_crossentropy", optimizer=opt, metrics=["accuracy"]) # train the networkprint("[INFO] training model...")H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=BS, epochs=NUM_EPOCHS)|

print("[INFO] compiling model...")

model = MiniVGGNet.build(width=28, height=28, depth=1, classes=10)

 metrics=["accuracy"])

# train the network

H = model.fit(trainX, trainY,

 batch_size=BS, epochs=NUM_EPOCHS)

On **Lines 55-58** our 
model  is initialized and compiled with the Stochastic Gradient Descent (
SGD ) optimizer and learning rate decay.

From there the 
model  is trained via the call to 
model.fit  on **Lines 62-64.**

After training for 
NUM_EPOCHS , we’ll go ahead and evaluate our network + generate a training plot:



|666768697071727374757677787980818283848586|# make predictions on the test setpreds = model.predict(testX) # show a nicely formatted classification reportprint("[INFO] evaluating network...")print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1), target_names=labelNames)) # plot the training loss and accuracyN = NUM_EPOCHSplt.style.use("ggplot")plt.figure()plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")plt.plot(np.arange(0, N), H.history["acc"], label="train_acc")plt.plot(np.arange(0, N), H.history["val_acc"], label="val_acc")plt.title("Training Loss and Accuracy on Dataset")plt.xlabel("Epoch #")plt.ylabel("Loss/Accuracy")plt.legend(loc="lower left")plt.savefig("plot.png")|

67


69


71


73


75


77


79


81


83


85


preds = model.predict(testX)

# show a nicely formatted classification report

print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),

 

N = NUM_EPOCHS

plt.figure()

plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")

plt.plot(np.arange(0, N), H.history["val_acc"], label="val_acc")

plt.xlabel("Epoch #")

plt.legend(loc="lower left")

To evaluate our network, we’ve made predictions on the testing set (**Line 67**) and then printed a 
classification_report  in our terminal (**Lines 71 and 72**).

Training history is plotted and output to disk (**Lines 75-86**).

As if what we’ve done so far hasn’t been fun enough, **we’re now going to visualize our results!**



|888990919293949596979899100101102103104105|# initialize our list of output imagesimages = [] # randomly select a few testing fashion itemsfor i in np.random.choice(np.arange(0, len(testY)), size=(16,)): # classify the clothing probs = model.predict(testX[np.newaxis, i]) prediction = probs.argmax(axis=1) label = labelNames[prediction[0]] # extract the image from the testData if using "channels_first" # ordering if K.image_data_format() == "channels_first": image = (testX[i][0] * 255).astype("uint8") # otherwise we are using "channels_last" ordering else: image = (testX[i] * 255).astype("uint8")|

89


91


93


95


97


99


101


103


105


images = []

# randomly select a few testing fashion items

 # classify the clothing

 prediction = probs.argmax(axis=1)

 

 # ordering

 image = (testX[i][0] * 255).astype("uint8")

 # otherwise we are using "channels_last" ordering

 image = (testX[i] * 255).astype("uint8")

To do so, we:

Sample a set of the testing images via 
random sampling , looping over them individually (**Line 92**).
Make a prediction on each of the 
random  testing images and determine the 
label  name (**Lines 94-96**).
Based on channel ordering, grab the 
image  itself (**Lines 100-105**).

Now let’s add a colored label to each image and arrange them in a montage:



|107108109110111112113114115116117118119120121122123124125126127128129130| # initialize the text label color as green (correct) color = (0, 255, 0)  # otherwise, the class label prediction is incorrect if prediction[0] != np.argmax(testY[i]): color = (0, 0, 255) # merge the channels into one image and resize the image from # 28x28 to 96x96 so we can better see it and then draw the # predicted label on the image image = cv2.merge([image] * 3) image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR) cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)  # add the image to our list of output images images.append(image) # construct the montage for the imagesmontage = build_montages(images, (96, 96), (4, 4))[0] # show the output montagecv2.imshow("Fashion MNIST", montage)cv2.waitKey(0)|

108


110


112


114


116


118


120


122


124


126


128


130


 color = (0, 255, 0)

 # otherwise, the class label prediction is incorrect

 color = (0, 0, 255)

 # merge the channels into one image and resize the image from

 # predicted label on the image

 image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)

 (0, 255, 0), 2)

 # add the image to our list of output images

 

montage = build_montages(images, (96, 96), (4, 4))[0]

# show the output montage

cv2.waitKey(0)

Here we:

Initialize our label  
color  as green for “correct” and red for “incorrect” classification (**Lines 108-112**).
Create a 3-channel image by merging the grayscale 
image  three times (**Line 117**).
Enlarge the 
image  (**Line 118**) and draw a 
label  on it (**Lines 119-120**).
Add each 
image  to the 
images  list (**Line 123**)

Once the 
images  have all been annotated via the steps in the 
for  loop, our OpenCV montage is built via **Line 126**.

Finally, the visualization is displayed until a keypress is detected (**Lines 129 and 130**).

### Fashion MNIST results

We are now ready to train our Keras CNN on the Fashion MNIST dataset!

Make sure you have used the ***“Downloads”*** section of this blog post to download the source code and project structure.

From there, open up a terminal, navigate to where you downloaded the code, and execute the following command:



|123456789101112131415161718192021222324252627282930313233343536|$ python fashion_mnist.pyUsing TensorFlow backend.[INFO] loading Fashion MNIST...[INFO] compiling model...[INFO] training model...Train on 60000 samples, validate on 10000 samplesEpoch 1/2560000/60000 [==============================] - 28s 460us/step - loss: 0.5227 - acc: 0.8241 - val_loss: 0.3165 - val_acc: 0.8837Epoch 2/2560000/60000 [==============================] - 26s 429us/step - loss: 0.3327 - acc: 0.8821 - val_loss: 0.2523 - val_acc: 0.9083Epoch 3/2560000/60000 [==============================] - 26s 429us/step - loss: 0.2870 - acc: 0.8955 - val_loss: 0.2464 - val_acc: 0.9107...Epoch 23/2560000/60000 [==============================] - 26s 430us/step - loss: 0.1691 - acc: 0.9378 - val_loss: 0.1791 - val_acc: 0.9358Epoch 24/2560000/60000 [==============================] - 26s 430us/step - loss: 0.1693 - acc: 0.9374 - val_loss: 0.1819 - val_acc: 0.9349Epoch 25/2560000/60000 [==============================] - 26s 430us/step - loss: 0.1679 - acc: 0.9391 - val_loss: 0.1802 - val_acc: 0.9352[INFO] evaluating network...              precision    recall  f1-score   support          top       0.88      0.89      0.89      1000     trouser       1.00      0.99      0.99      1000    pullover       0.90      0.92      0.91      1000       dress       0.92      0.94      0.93      1000        coat       0.92      0.89      0.90      1000      sandal       0.99      0.99      0.99      1000       shirt       0.81      0.80      0.81      1000     sneaker       0.96      0.98      0.97      1000         bag       0.99      0.99      0.99      1000  ankle boot       0.98      0.97      0.97      1000    micro avg       0.94      0.94      0.94     10000   macro avg       0.94      0.94      0.94     10000weighted avg       0.94      0.94      0.94     10000|

2


4


6


8


10


12


14


16


18


20


22


24


26


28


30


32


34


36


Using TensorFlow backend.

[INFO] compiling model...

Train on 60000 samples, validate on 10000 samples

60000/60000 [==============================] - 28s 460us/step - loss: 0.5227 - acc: 0.8241 - val_loss: 0.3165 - val_acc: 0.8837

60000/60000 [==============================] - 26s 429us/step - loss: 0.3327 - acc: 0.8821 - val_loss: 0.2523 - val_acc: 0.9083

60000/60000 [==============================] - 26s 429us/step - loss: 0.2870 - acc: 0.8955 - val_loss: 0.2464 - val_acc: 0.9107

Epoch 23/25

Epoch 24/25

Epoch 25/25

[INFO] evaluating network...

 

     trouser       1.00      0.99      0.99      1000

       dress       0.92      0.94      0.93      1000

      sandal       0.99      0.99      0.99      1000

     sneaker       0.96      0.98      0.97      1000

  ankle boot       0.98      0.97      0.97      1000

   micro avg       0.94      0.94      0.94     10000

weighted avg       0.94      0.94      0.94     10000

![](https://www.pyimagesearch.com/wp-content/uploads/2019/02/plot.png)
**Figure 3:** Our Keras + deep learning Fashion MNIST training plot contains the accuracy/loss curves for training and validation.

Here you can see that our network obtained **94% accuracy** on the testing set.

The model classified the “trouser” class 100% correctly but seemed to struggle quite a bit with the “shirt” class (~81% accurate).

According to our plot in **Figure 3**, there appears to be very little overfitting.

A deeper architecture with data augmentation would likely lead to higher accuracy.

Below I have included a sample of fashion classifications:
![](https://www.pyimagesearch.com/wp-content/uploads/2019/02/fashion_mnist_results.jpg)


**Figure 4:** The results of training a Keras deep learning model (based on VGGNet, but smaller in size/complexity) using the Fashion MNIST dataset.

As you can see our network is performing quite well at fashion recognition.

### Will this model work for fashion images outside the Fashion MNIST dataset?

At this point, you are properly wondering if the model we just trained on the Fashion MNIST dataset would be directly applicable to images *outside* the Fashion MNIST dataset?

The short answer is *“No, unfortunately not.”*

The longer answer requires a bit of explanation.

To start, keep in mind that the Fashion MNIST dataset is meant to be a drop-in replacement for the MNIST dataset, implying that *our images have already been processed*.

Each image has been:

- Converted to *grayscale*.

- *Segmented*, such that all background pixels are black and all foreground pixels are some gray, non-black pixel intensity.

- *Resized* to 28×28 pixels.


For real-world fashion and clothing images, you would have to preprocess your data in the *same manner* as the Fashion MNIST dataset.

And furthermore, even if you *could* preprocess your dataset in the exact same manner, the model still might not be transferable to real-world images.

Instead, you should train a CNN on example images that will mimic the images the CNN “sees” when deployed to a real-world situation.

To do that you will likely need to utilize multi-label classification and multi-output networks.

For more details on both of these techniques be sure to refer to the following tutorials:

1. *Multi-label classification with Keras*

1. *Keras: Multiple outputs and multiple losses*


## Summary

In this tutorial, you learned how to train a simple CNN on the Fashion MNIST dataset using Keras.The Fashion MNIST dataset is meant to be a drop-in replacement for the standard MNIST digit recognition dataset, including:

- 60,000 training examples

- 10,000 testing examples

- 10 classes

- 28×28 grayscale images


While the Fashion MNIST dataset is slightly more challenging than the MNIST digit recognition dataset, unfortunately, it cannot be used directly in real-world fashion classification tasks, unless you preprocess your images in the exact same manner as Fashion MNIST (segmentation, thresholding, grayscale conversion, resizing, etc.).

In most real-world fashion applications mimicking the Fashion MNIST pre-processing steps will be near impossible.

You can and should use Fashion MNIST as a drop-in replacement for the MNIST digit dataset; however, **if you are interested in actually recognizing fashion items in real-world images you should refer to the following two tutorials:**

1. *Multi-label classification with Keras*

1. *Keras: Multiple outputs and multiple losses*


Both of the tutorials linked to above will guide you in building a more robust fashion classification system.

I hope you enjoyed today’s post!

**To download the source code to this post, and be notified when future tutorials are published here on PyImageSearch, *just enter your email address in the form below!***

## Downloads:
