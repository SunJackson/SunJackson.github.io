---
layout:     post
title:      Weekly Review： 11/04/2017
subtitle:   转载自：https://codesachin.wordpress.com/2017/11/06/weekly-review-11042017/
date:       2017-11-06
author:     srjoglekar246
header-img: img/background3.jpg
catalog: true
tags:
    - networks
    - visual
    - ai
    - nexar
    - challenging
---

A busy week. I finished my Aerial Robotics course! The next in the [Specialization](https://www.coursera.org/specializations/robotics) is Computational Motion Planning, which I am more excited about – mainly because the curriculum goes more towards my areas of expertise. Aerial Robotics was challenging primarily because I was doing a lot of physics/calculus which I had not attempted since a long time.

Onto the articles for this week:

**[Colab is now public!](https://qz.com/1113999/nerds-rejoice-google-just-released-its-internal-tool-to-collaborate-on-ai)**

Google made *Colaboratory*, a previously-internal tool public. ‘Colab’ is a document-collaboration tool, with the added benefits of being able to run script-sized pieces of code. This is especially useful if you want to prototype small proofs-of-concept, which can then be shared with documentation and demo-able output. I had previously used it within Google to tinker with TensorFlow, and write small scripts for database queries.

**[Visual Guide to Evolution Strategies](http://blog.otoro.net/2017/10/29/visual-evolution-strategies)**

The above link is a great introduction to Evolutionary Strategies such as [GAs](https://en.wikipedia.org/wiki/Genetic_algorithm) and [CMA-ES](https://en.wikipedia.org/wiki/CMA-ES). They show a visual representation of how each of these algorithms converges on the optima from the first iteration to the last on simple problems. Its pretty interesting to see how each algorithm ‘broadens’ or ‘focuses’ the domain of its candidate solutions as iterations go by.

**[Baidu’s Deep Voice](https://blog.athelas.com/paper-1-baidus-deep-voice-675a323705df)**

In a 2-part series ([Part 1](https://blog.athelas.com/paper-1-baidus-deep-voice-675a323705df) & [Part 2](https://blog.athelas.com/baidu-deep-voice-explained-part-2-training-810e87d20047)), the author discusses the architecture of Baidu’s Text-to-Speech system (Deep Voice). Take a look if you have never read about/worked on such systems and want to have a general idea of how they are trained and deployed.

**[Capsule Networks](https://www.wired.com/story/googles-ai-wizard-unveils-a-new-twist-on-neural-networks)**

Geoff Hinton and his team at Google recently discussed the idea of Capsule networks, which try and remedy the rigidity in usual CNNs – by defining groups of specialized neurons called ‘capsules’ whose contribution to higher-level neurons is decided by the similarity of output. [Heres](https://hackernoon.com/what-is-a-capsnet-or-capsule-network-2bfbe48769cc) a small intro on Capsule Networks, or the [original paper](https://arxiv.org/abs/1710.09829) if you wanna delve deeper.

**[Nexar Challenge Results](https://blog.getnexar.com/how-a-22-year-old-from-shanghai-won-a-global-deep-learning-challenge-76f2299446a1?gi=326763e2e356)**

[Nexar](https://www.getnexar.com/) released the results of its Deep-Learning challenge on Image segmentation – the problem of ‘boxing’ and ‘tagging’ objects in pictures with multiple entities present. This is especially useful in their own AI-dashboard apps, which need to be quite accurate to prevent possible collisions in deployment.

As further reading, you could also check out [this article](https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4) on the history of CNNs in Image Segmentation, another one on [Region-of-Interest Pooling](https://blog.deepsense.ai/region-of-interest-pooling-explained) in CNNs, and [Deformable Neural Networks](https://www.slideshare.net/TerryTaewoongUm/deformable-convolutional-network-2017). (All of these concepts are mentioned in the main Nexar article)





### Like this:

Like Loading...
