---
layout:     post
title:      Machine learning APIs： which performs best?
subtitle:   转载自：http://www.louisdorard.com/blog/machine-learning-apis-comparison
date:       2015-05-04
author:     Louis Dorard
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - services offer free accounts
    - features
    - dx
    - output
    - instances
---

All 4 services offer free accounts which I used for this comparison (note: PredicSis is still in private beta but you can [request an account here](http://launch.predicsis.com/)). In this post, I will only compare the performance of these two methods and I won't consider other aspects such as pricing, features, DX, UX, etc.

In order to evaluate the models produced by the APIs, we need to separate our dataset downloaded from Kaggle in two: a training set which we use to create a model, and an evaluation set. We apply the model to the inputs of the evalution set and we get a prediction for each input. We can evaluate the accuracy of the model by comparing the predicted output with the true output (which was held out).

The dataset we start with contains 150,000 instances and weighs 7.2 MB. I randomly selected 90% of the dataset for training and in the remaining 10% I randomly selected 5,000 inputs for evaluation.

For each API, there are three things to measure: the time taken by each method and the accuracy of predictions made by the model. For accuracy, I used the same performance measure as that of the Kaggle challenge, which is called [AUC](http://www.kaggle.com/wiki/AreaUnderCurve). I won’t explain what it is here, but what you have to know about AUC is that a) performance values are between 0 and 1, b) a random classifier would have an AUC of around 0.5, c) a perfect classifier would have an AUC of 1. As a consequence, the higher the AUC, the better the model. 
