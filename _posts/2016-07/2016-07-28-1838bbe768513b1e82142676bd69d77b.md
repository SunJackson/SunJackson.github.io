---
layout:     post
title:      Talk： Building Machines that Imagine and Reason
subtitle:   转载自：http://blog.shakirm.com/2016/07/talk-building-machines-that-imagine-and-reason/
date:       2016-07-28
author:     shakirm
header-img: img/background2.jpg
catalog: true
tags:
    - learning
    - generative models
    - deep
    - estimation
    - estimators variational
---

I am excited to be one the speakers at this year's [Deep Learning Summer School](https://sites.google.com/site/deeplearningsummerschool2016/schedule) in Montreal on the 6th August 2016.

Slides can be found here:

![](http://blog.shakirm.com/wp-content/uploads/2016/07/DLSummerSchool_Aug2016.001-1024x768.png)


Deep generative models provide a solution to the problem of unsupervised learning, in which a machine learning system is required to discover the structure hidden within unlabelled data streams. Because they are generative, such models can form a rich imagery the world in which they are used: an imagination that can harnessed to explore variations in data, to reason about the structure and behaviour of the world, and ultimately, for decision-making. This tutorial looks at how we can build machine learning systems with a capacity for imagination using deep generative models, the types of probabilistic reasoning that they make possible, and the ways in which they can be used for decision making and acting.

Deep generative models have widespread applications including those in density estimation, image denoising and in-painting, data compression, scene understanding, representation learning, 3D scene construction, semi-supervised classification, and hierarchical control, amongst many others. After exploring these applications, we'll sketch a landscape of generative models, drawing-out three groups of models: fully-observed models, transformation models, and latent variable models. Different models require different principles for inference and we'll explore the different options available. Different combinations of model and inference give rise to different algorithms, including auto-regressive distribution estimators, variational auto-encoders, and generative adversarial networks. Although we will emphasise deep generative models, and the latent-variable class in particular, the intention of the tutorial will be to explore the general principles, tools and tricks that can be used throughout machine learning. These reusable topics include Bayesian deep learning, variational approximations, memoryless and amortised inference, and stochastic gradient estimation. We'll end by highlighting the topics that were not discussed, and imagine the future of generative models.


*Related*

