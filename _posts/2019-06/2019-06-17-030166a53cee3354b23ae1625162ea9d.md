---
layout:     post
catalog: true
title:      Import AI 151： US Army trains StarCraft II AI; teaching drones to dodge thrown objects; and fighting climate change with machine learning
subtitle:      转载自：https://jack-clark.net/2019/06/17/import-ai-151-us-army-trains-starcraft-ii-ai-teaching-drones-to-dodge-thrown-objects-and-fighting-climate-change-with-machine-learning/
date:      2019-06-17
author:      Jack Clark
tags:
    - researchers
    - ais
    - models
    - modeling
    - generates
---

**Drones that dodge, evade, and avoid objects – they’re closer than you think:***…Drones are an omni-use platform, and they’re about to get really smart…*The University of Maryland and the University of Zurich have taught drones how to dodge rapidly moving objects, taking a further step towards building semi-autonomous, adaptive small-scale aircraft. The research shows that drones equipped with a few basic sensors and some clever AI software can learn to dodge (and chase) a variety of objects. “To our knowledge, this is the first deep learning based solution to the problem of dynamic obstacle avoidance using event cameras on a quadrotor”, they write.

**How it works:** The approach has three key components, which are each specialized modules that use neural networks or optical flow approaches. These systems and their corresponding functions are as follows: 

- *EVDeBlurNet – *deblur and denoise the event image sequences before any computation takes place

- *EVHomographyNet – *approximate background motion 

- *EVSegFlowNet – *segment moving objects and compute their image motion


   These three systems let the drones clean up its input images so it can compute over them, then work out where it is, then look at the objects around itself and react.

**How well does it work? **The researchers approach is promising but not ready for any kind of real-world deployment, due to insufficient accuracy. However, the system displays promising breadth when it comes to dealing with a variety of objects to dodge. For assessment, the researchers run 30 tests with each object and report the result. In tests, the researchers find that the drone can easily dodge thrown balls and model cars (86% success), can dodge *and *chase another drone (83%), can dodge two objects thrown at it in quick success (76%), struggles a bit with an oddly shaped model plane (73%), and achieves a success rate of 70% in a low-light experiment.

**Why this matters:** Drones are getting smaller and smarter, and research like this shows how pretty soon we’re likely going to be able to build DIY drones that have what I’d term ‘dumb spatial intelligence’, that is, we can start to train these systems to do things like dodge moving objects, navigate around obstacles, deal with occluded environments, and learn to follow or fly towards specific people or objects. The implications for this are significant, unlocking numerous commercial applications, while also changing the landscape of asymmetric warfare in profound ways, the consequences of which shall likely highlight the difficulty of controlling AI capability use and diffusion.**Read more:**EVDodge: Embodied AI For High-Speed Dodging On A Quadrotor Using Event Cameras (Arxiv).

**#####################################################**

**“Build marines!” – US Army trains teaches RL agents to respond to voice commands:***…StarCraft II research highlights military interest in complex, real-time strategy games…*US Army Research Laboratory researchers have developed a reinforcement learning agent that can carry out actions in response to pre-defined human commands. For this experiment, they test in the domain of StarCraft II, a complex real-time strategy game. The goal of this is to work out smarter ways in which humans can control semi-autonomous AI systems in the future. “Our mutual-embedding model provides a promising mechanism for creating a generalized sequential reward that capitalizes on a human’s capacity to utilize higher order knowledge to achieve long-term goals,” they write. “By providing a means for a human to guide a learning agent via natural language, generalizable sequential policies may be learned without the overhead of creating hand-crafted sub-tasks or checkpoints that would depend critically on expert knowledge about RL reward functions”.

**How it works:** The researchers use a relatively simple technique of “training a mutual-embedding model using a multi-input deep-neural network that projects a sequence of natural language commands into the same high-dimensional representation space as corresponding goal states”. In a prototype experiment, they see how well they can use voice commands to succeed at the ‘BuildMarines’ challenge, a mini-game within the StarCraft 2 environment.

**Why this matters:** Developing more natural interfaces between humans and AI systems is a long-standing goal of AI research, and it’s interesting to see how military organizations think about this problem. I wouldn’t be surprised to see more military organizations explore using StarCraft 2 as a basic testing ground for advanced AI systems, given its overlap with natural military interests of logistics, supply chains, and the marshaling and deployment of forces.**  Read more:** Grounding Natural Language Commands to StarCraft II Game States for Narration-Guided Reinforcement Learning (Arxiv).

**#####################################################**

**UN researchers generate fake UN speeches:***…Machine-driven diplomacy…*Researchers affiliated with the United Nations’ ‘Global Pulse’ and the University of  Durham, have used AI systems to generate remarks in the style of political leaders speaking at the UN General Assembly. For this experiment, they train on the English language transcripts of 7,507 speeches given by political leaders at the UN General Assembly (UNGA) between 1970 and 2015.

**Training tools and costs:** The core of this system as an AWD-LSTM model pre-trained on Wikitext-103, then fine-tuned against the corpus of UN data. Training cost as little as $7.80 total when using AWS spot instances, and took about 13 hours using NVIDIA k80 GPUs.

**Dataset bias: **The experiment serves as a proof-of-concept that also highlights some of the ways in which dataset bias can influence language models – while it was relatively easy for the authors to prompt the language model to generate UN-style speeches, they found it was more difficult to generate ‘inflammatory’ speeches as there are fewer of these in the UN dataset.

**How well does it work: **Qualitatively, the model is able to periodically generate samples that can read like convincing extracts from real speeches. For instance, a model prompted with “The Secretary-General strongly condemns the deadly terrorist attacks that took place in Mogadishu” generates the outputs “We fully support the action undertaken by the United Nations and the international community in that regard, as well as to the United Nations and the African Union, to ensure that the children of this country are left alone in the process of rebuilding their societies.”

**Implications:** Language models like these have a few implications, the researchers write. These include the likelihood of broad diffusion of the technology (for example, though OpenAI chose not to fully release its GPT-2 model, others might); it being generally easier to generate disinformation; it being easy to automatically generate hate speech; and it becoming easier to train models to impersonate people.

**Recommendations:** So, what do we do? The authors recommend we map the human rights impacts of these technologies, develop tools for systematically and continuously monitoring AI-generated content, set up strategies for countermeasures, and build alliances between various AI actors to develop a “coherent and proactive global strategy”.

**Why this matters: **Research like this highlights the concern some people feel about increasingly powerful models, and emphasizes the significant implications of them for society, as well as the need for us to think creatively about interventions to deal with the most easy-to-anticipate malicious uses of such systems.**  Read more: **Automated Speech Generation from UN General Assembly Statements: Mapping Risks in AI Generated Texts (Arxiv).

**#####################################################**

**What happens when you can buy AI-infused cyberattacks on the dark web?***…Alphabet-subsidiary Jigsaw says it paid for a Russian troll campaign last year…*$250. That’s how much it cost Alphabet-subsidiary to pay someone to run a troll campaign against a website it had created named “Down With Stalin”, according to an article in Wired. They paid used a service called ‘SEOTweet’ to carry out a social media disinformation campaign, which let to 730 Russian-language tweets from 25 accounts, as well as 100 posts to forums and blog comment sections.

**Controversy: **Some people think it’s kind of shady that an Alphabet-subsidiary would pay a third-party to mount an actual cyberattack. The experiment could be seen, for instance, as Alphabet and Google trying to meddle in Russian politics, one researcher said.**  Read more:** Alphabet-owned Jigsaw Bought a Russian Troll Campaign As An Experiment (Arxiv).

**#####################################################**

**AI luminaries team up to fight climate change:***…Climate change + machine learning = perhaps we can stabilize the planet…*Can machine learning help fix climate change? An interdisciplinary group of researchers from universities like the University of Pennsylvania and Carnegie Mellon University, and companies like DeepMind and Microsoft Research, think the use of machine learning can help society tackle one of its greatest existential threats. The researchers identify ten rough categories of machine learning (computer vision; NLP; time-series analysis; unsupervised learning; RL & control; causal inference; uncertainty quantifications; transfer learning; interpretable ML, and ‘other’), then set them against various ‘climate change solution domains’ like CO2 Removal, Transportation, Solar Geoengineering, and more.  The paper tags its various approaches with the following possible labels: High Leverage (which means ML may be especially helpful here); Long-term (which indicates things that will have a primary impact after 2040); and ‘High Risk’ which indicates things that have risks or potential side effects. The paper is as much a call for massive interdisciplinary collaboration, as it is a survey.

**High Leverage tools for a climate change future: **Some of the areas where machine learning can help and which the authors deem ‘High Leverage’ when it comes to mitigating climate change include: developing better materials for energy storage or consumption; helping to develop nuclear fusion; reducing emissions from fossil fuel power generation; creating sample-efficient ML to work in ‘low-data settings’; modeling demand for power; smarter freight routing; further development of electric vehicles; improving low-carbon options; creating smarter and more efficient buildings; gathering infrastructure data; improving the efficiency of supply chains; developing better materials and construction; improving the efficiency of HVAC systems; remotely sensing emissions; precision agriculture; estimating carbon stored in forests; tools to track deforestation; helping to sequester CO2; forecasting extreme events; monitoring ecosystems and species populations; increasing food security; developing better systems to disaster relief; “engineering a planetary control system”; and using ML to model consumers and understand how to nudge them to more climate-friendly actions; and better predicting the financial effects of climate change.****

**Why this matters**… should be fairly self-evident! We must preserve spaceship Earth – all the other reachable planets are shit in comparison.**   Read more:** Tackling Climate Change with Machine Learning (Arxiv). 

**#####################################################**

**Want to see how good your system is at surveilling people in crowded spaces? Enter the MOTChallenge:***…CVPR19 benchmark aims to push the limits on AIs for spotting people in crowded scenes…***An interdisciplinary group of researchers from ETH Zurich, the Technical University of Munich (TUM), and the Australian Institute for Machine Learning at the University of Adelaide have released the 2019 Multiple Object Tracking challenge, called the *MOTChallenge. *This challenges AI systems to label and spot pedestrians in crowded spaces.The new benchmarks have arrived:** The new CVPR19 benchmark consists of eight novel sequences from three “very crowded” scenes, where densities of pedestrians can climb as high as 246 per frame – almost as hard as playing *Where’s Waldo? *The datasets have been annotated with a particular emphasis on people, so pedestrians are labelled if they’re moving and given a separate label if they’re not in an upright position (aka, sitting down). “The idea is to use these annotations in the evaluation such that an algorithm is neither penalized nor rewarded for tracking, *e.g.*, a sitting or not moving person”.

**Evaluation metrics:** Entrants to the competition will be evaluated using the ‘CLEAR’ metrics, as well as some of the quality measures introduced in an earlier CVPR paper: “Tracking of multiple, partially occluded humans based on static body part detection”.

**Why this matters: **AI research thrives on challenges, with harder evaluation criteria typically combing with larger datasets to motivate researchers to invent new systems capable of enhanced performance. Additionally, systems developed for competitions like this will have a significant role in the rollout of AI-infused surveillance technologies, so monitoring competitions such as this can give us a better sense of that.**   Read more:** CVPR19 Tracking and Detection Challenge: How crowded can it get? (Arxiv).**   Get the data, current ranking and submission guidelines** from the official website (MOTChallenge.net).

**#####################################################**

**OpenAI Bits & Pieces:**

**OpenAI testifies for House Intelligence Committee on AI, synthetic media, & deepfakes:**Last week, I testified in Washington about the relationship between AI, synthetic media, and deepfakes. For this testimony I sought to communicate the immense utility of AI systems, while advocating for a variety of interventions to increase the overall resilience of society to increasingly cheap & multi-modal fake media.

   I also collected inputs for my testimony via a public Google Form I posted on Twitter, yielding around 25 responses – this worked really well, and felt like a nice way to be able to integrate broad feedback from the AI community into important policy conversations. 

**   Watch the hearing here:** Open Hearing on Deepfakes and Artificial Intelligence (YouTube).**   Read written testimony** from OpenAI and the other panellists here (House Permanent Select Committee on Intelligence website).
