---
layout:     post
catalog: true
title:      Causation doesn’t imply Correlation either
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/Dw74y2SEMdA/
date:      2019-06-25
author:      Learning Machines
tags:
    - plot
    - quadrants
    - linear
    - correlation
    - hiding
---

First I want to provide you with some intuition on what *correlation* is really all about! For many people (and many of my students for sure) the implications of the following formula for the *correlation coefficient* ![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-01bcf7e9e043561da78fecf715c8a46e_l3.png?resize=8%2C8&is-pending-load=1)
![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-01bcf7e9e043561da78fecf715c8a46e_l3.png?resize=8%2C8)
 of two variables ![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-7e5fbfa0bbbd9f3051cd156a0f1b5e31_l3.png?resize=10%2C8&is-pending-load=1)
![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-7e5fbfa0bbbd9f3051cd156a0f1b5e31_l3.png?resize=10%2C8)
 and ![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-38461fc041e953482219abf5d4cce1cb_l3.png?resize=9%2C12&is-pending-load=1)
![](https://i0.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-38461fc041e953482219abf5d4cce1cb_l3.png?resize=9%2C12)
 are not immediately clear:

     ![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-bb9a6bdc99da8b6d1c89fb0306e682ff_l3.png?resize=236%2C53&is-pending-load=1)
![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-bb9a6bdc99da8b6d1c89fb0306e682ff_l3.png?resize=236%2C53)


In fact the most interesting part is this: ![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-8b8ebe47fe9f576c1d99d3ba1d9650fe_l3.png?resize=121%2C18&is-pending-load=1)
![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-8b8ebe47fe9f576c1d99d3ba1d9650fe_l3.png?resize=121%2C18)
. We see a product of two differences. The differences consist of the data points minus the respective *means* (average values): in effect this leads to the origin being moved to the means of both variables (as if you moved the crosshair right into the centre of all data points).

There are now four possible *quadrants* for every data point: top or bottom, left or right. Top right means that both differences are positive, so the result will be positive too. The same is true for the bottom left quadrant because minus times minus equals plus (it often boils down to simple school maths)! The other two quadrants give negative results because minus times plus and plus times minus equals minus.

After that we sum over all products and normalize them by dividing by the respective *standard deviations* (how much the data are spread out), so that we will only get values between ![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-37abf2e602a43ae0ff9f12b1536fa74c_l3.png?resize=21%2C13&is-pending-load=1)
![](https://i2.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-37abf2e602a43ae0ff9f12b1536fa74c_l3.png?resize=21%2C13)
 and ![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-69a7c7fb1023d315f416440bca10d849_l3.png?resize=7%2C13&is-pending-load=1)
![](https://i1.wp.com/blog.ephorie.de/wp-content/ql-cache/quicklatex.com-69a7c7fb1023d315f416440bca10d849_l3.png?resize=7%2C13)
.

Let us see this in action with an example. First we define a helper function for visualizing this intuition:

Now for the actual example (in fact the same example we had in this post: Learning Data Science: Modelling Basics):

![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor5-840x600.png?w=450&is-pending-load=1)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor5-840x600.png?w=450)


![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor6-840x600.png?w=450&is-pending-load=1)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor6-840x600.png?w=450)


The correlation is very high because most of the data points are in the positive (green) quadrants and the data is close to its *regression line* (linear regression and correlation are closely related mathematically).

Now, let us get to the actual topic of this post: *Causation doesn’t imply Correlation either*. What could be “more causal” than a parabolic shot? When you shoot a projectile without air resistance the trajectory will form a perfect *parabola*! This *is* in fact rocket science!

Let us simulate such a shot and calculate the correlation between time and altitude, two variables that are perfectly causally dependent:

![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor3-1-840x600.png?w=450&is-pending-load=1)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor3-1-840x600.png?w=450)


![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor7-840x600.png?w=450&is-pending-load=1)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor7-840x600.png?w=450)


The correlation is exactly zero, zip, nada! And it is clear why: the data points in the positive and in the negative quadrants cancel each other out completely because of the perfect symmetry!

This leads us to the following very important insight:

> 
Correlation is a measure of linear dependance (and linear dependance only!).


Even a strong causal relationship can be overlooked by correlation because of its *non-linear nature* (as in this case with the *quadratic *relationship). The following example conveys the same idea in a somewhat more humorous manner – it is the by now infamous *datasaurus*:

![](https://i0.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor4-840x600.png?w=450&is-pending-load=1)
![](https://i0.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor4-840x600.png?w=450)


![](https://i2.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor8-840x600.png?w=450&is-pending-load=1)
![](https://i2.wp.com/blog.ephorie.de/wp-content/uploads/2019/05/spurcor8-840x600.png?w=450)


As with the above example we can clearly see why the correlation is so low, although there is a whole dinosaur hiding in your data…

The learning is that you should never just blindly trust statistical measures on their own, always visualize your data when possible: there might be some real beauties hiding inside your data, waiting to be discovered…


*Related*







---
