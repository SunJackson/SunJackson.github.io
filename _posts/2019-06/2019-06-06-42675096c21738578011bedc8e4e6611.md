---
layout:     post
catalog: true
title:      Turning unstructured text into insights with Bewgle powered by AWS
subtitle:      转载自：https://aws.amazon.com/blogs/machine-learning/turning-unstructured-text-into-insights-with-bewgle-powered-by-aws/
date:      2019-06-06
author:      Marisa Messina
tags:
    - bewgle
    - customers
    - data
    - teams
    - increase customer
---

Bewgle is an SAP.iO, Techstars-funded company that uses AWS services to surface insights from user-generated text and audio streams. Bewgle generates insights to help product managers to increase customer satisfaction and engagement with their various products—beauty, electronics, or anything in between.  By listening to the voices of their customers with the help of Bewgle powered by AWS, these product managers are able to drive increased sales for their products.

An average human can read only about 250 words per minute. To synthesize 1000 customer reviews would therefore take upwards of 8 hours. Analyzing the information from all those reviews—plus other text like forum posts and blog posts, as well as unstructured content like survey verbatims and audio streams—quickly becomes untenable.

This is exactly the kind of problem where AI can excel, specifically, the subset of machine learning (ML) called natural language processing (NLP). At the heart of Bewgle’s solution is an AI platform developed completely on AWS that analyzes millions of pieces of content, then extracts key topics and the sentiment behind them. What would otherwise take years can now be done in minutes with Amazon Machine Learning and the AWS tech stack as a whole.

Indeed, the Bewgle solution makes use of a breadth of AWS services. Bewgle’s data processing pipeline relies on AWS Lambda and Amazon DynamoDB, which form the core of the ML tasks involved:

- Storing data for analysis at scale.

- Cleaning up data.

- Firing various processing functions dynamically to generate the analysis.


The team developed an innovative serverless ML workflow to scale the system and orchestrate various workflows in a loosely coupled way. This gave them tremendous agility and flexibility in evaluating and choosing various approaches independently, facilitating speedy innovation.

A typical workflow for Bewgle starts with Amazon SageMaker Ground Truth, which they use to collect and tag data at scale and on demand. The team lauds the high accuracy of the data tagging that Amazon SageMaker Ground Truth delivers. Bewgle co-founder Shantanu Shah explains, “It [Amazon SageMaker Ground Truth] enables efficiency for Bewgle as we no longer have to look for and manage human taggers, and it’s affordable too.”

Once the data tagging is complete, the Bewgle team turns to Amazon SageMaker to reason over it.  They appreciate using the familiar Jupyter Notebook interface to work with the data; they quickly and easily build and test multiple models.  The automatic hyperparameter tuning within Amazon SageMaker greatly speeds and facilitates what would otherwise be a significant effort for the Bewgle team and makes it possible to achieve a high level of accuracy and confidence.

The next step is model deployment, and Amazon SageMaker once again is the solution.  Deploying with Amazon SageMaker is helpful because, in Shah’s words, “Traffic bursts are not an issue as the scalability and redundancy are automatically taken care of.”   He adds, “Overall, [Amazon] SageMaker helps in every step of model building, tuning and serving and saves countless hours of effort for Bewgle.”

This end to end workflow is depicted in the below diagram.

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2019/06/06/bewgle.gif)


To make the insights available to customers, they built an API using AWS Elastic Beanstalk. The API allows customers to consume the data in any format. A UI layer built on top of the API also allows the customers to view the data as a digest and a dashboard.  With this implementation, listening to user insights at scale becomes easy.  Bewgle users from R&D teams can be smarter in designing new products; product design teams can consider many factors that might otherwise be overlooked; and business development teams can analyze and compare competitor data when determining new features.

Customer support teams are another key user group for Bewgle. Traditional approaches to customer support center mostly or strictly on answering queries related to structured data that they already have (e.g., templatized emails).  Because verbatims (such as comments left by hotel guests) are unstructured data, they cannot contribute to answering customer support queries. Bewgle believes that converting this unstructured text data into structured data is a key to continuously enhancing customer service. Bewgle’s NLP algorithms continuously learn as the data increases, and their output is structured data that is usable by customer service teams. As a tangible example, consider a customer who notes in a feedback form for a product that they could not open the container to access it. The customer service team is able to take that insight and realize that the glue had hardened on a certain batch, making them impossible to open. As such, the company can avoid creating more disgruntled customers (and potentially losing revenue as a result) by removing that batch from the customer-ready pile.

The team is composed of ex-Googlers who founded Bewgle to solve the information overload problem.  The Bewgle crew finds that the AWS AI and ML services enable their workflow to include “less headache” and more impact. The ease of use, documentation, and broad popularity of the AWS tech stack makes it appealing, and the reason for Bewgle’s choice to use AWS as its primary AI/ML platform.

In particular, Shah notes, “Amazon SageMaker allows us to add tremendous flexibility. [Now] we can rapidly iterate on our models as a result and this directly impacts the strength of our company.”

As the awareness of unstructured data analysis, NLP, and AI techniques has grown, Bewgle has seen rapid growth in its business over the last year. Going forward, the team plans to further scale the technology to other verticals and expand to other geographies.

---

### About the Author

![](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2019/04/29/mari-messina-100-2.jpg)
Marisa Messina is on the AWS AI marketing team, where her job includes identifying the most innovative AWS-using customers and showcasing their inspiring stories. Prior to AWS, she worked on consumer-facing hardware and then university-facing cloud offerings at Microsoft. Outside of work, she enjoys exploring the Pacific Northwest hiking trails, cooking without recipes, and dancing in the rain.



 
