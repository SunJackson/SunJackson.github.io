---
layout:     post
catalog: true
title:      If you did not already know
subtitle:      转载自：https://advanceddataanalytics.net/2018/08/12/if-you-did-not-already-know-450/
date:      2018-08-11
author:      Michael Laux
tags:
    - convolutional
    - models
    - vaes
    - amortized
    - amortization
---

**Jubatus** ![](https://aboutdataanalytics.files.wordpress.com/2015/01/google.png?w=529)
Jubatus is a distributed processing framework and streaming machine learning library. Jubatus includes these functionalities:· Online Machine Learning Library: Classification, Regression, Recommendation (Nearest Neighbor Search), Graph Mining, Anomaly Detection, Clustering· Feature Vector Converter (fv_converter): Data Preprocess and Feature Extraction· Framework for Distributed Online Machine Learning with Fault Tolerance … 

**EffNet** ![](https://aboutdataanalytics.files.wordpress.com/2015/01/google.png?w=529)
With the ever increasing application of Convolutional Neural Networks to costumer products the need emerges for models which can efficiently run on embedded, mobile hardware. Slimmer models have therefore become a hot research topic with multiple different approaches which vary from binary networks to revised convolution layers. We offer our contribution to the latter and propose a novel convolution block which significantly reduces the computational burden while surpassing the current state-of-the-art. Our model, dubbed EffNet, is optimised for models which are slim to begin with and is created to tackle issues in existing models such as MobileNet and ShuffleNet. … 

**Amortized Inference Regularization (AIR)** ![](https://aboutdataanalytics.files.wordpress.com/2015/01/google.png?w=529)
The variational autoencoder (VAE) is a popular model for density estimation and representation learning. Canonically, the variational principle suggests to prefer an expressive inference model so that the variational approximation is accurate. However, it is often overlooked that an overly-expressive inference model can be detrimental to the test set performance of both the amortized posterior approximator and, more importantly, the generative density estimator. In this paper, we leverage the fact that VAEs rely on amortized inference and propose techniques for amortized inference regularization (AIR) that control the smoothness of the inference model. We demonstrate that, by applying AIR, it is possible to improve VAE generalization on both inference and generative performance. Our paper challenges the belief that amortized inference is simply a mechanism for approximating maximum likelihood training and illustrates that regularization of the amortization family provides a new direction for understanding and improving generalization in VAEs. … 





### Like this:

Like Loading...


*Related*

