---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2018/12/06/distilled-news-926/
date:      2018-12-06
author:      Michael Laux
tags:
    - data
    - models
    - modeling
    - detections
    - learns
---

**Portfolio optimization in R using a Genetic Algorithm**

Portfolio optimization is one of the most interesting fields of study of financial mathematics. Since the birth of Modern Portfolio Theory (MPT) by Harry Markowitz, many scientists have studied a lot of analytical and numerical methods to build the best investment portfolio according to a defined set of assets. In this article, I’ll show a method to optimize a portfolio by using a numerical technique based on genetic algorithms. The power of genetic algorithms makes it possible to find the optimal portfolio even when the objective function isn’t smooth or differentiable.

**From Good to Great Data Science, Part 1: Correlations and Confidence**

As a data scientist you’ll spend a lot of time answering questions with data. I currently work as a data scientist in the healthcare industry, providing metrics and building models for hospitals and healthcare related organizations. In my practice most of my time is spent doing two things:• Translating qualitative business questions into rigorous solutions that can be generated with data• Implementing these solutions programmaticallyI’m going to walk you through two questions that I’ve actually been asked on the job:1. Should my hospital focus more on improving its mortality rate?2. Which pharmacists are handing out too many opioids?What they both have in common is that there’s a right way and a wrong way to do them. Further, it’s very easy to answer these questions the wrong way and have your mistakes go unnoticed. As you’ll see, the difference between great and average answers to these questions is a having a little bit of a mathematical background.

**YOLO: Real Time Object Detection**

We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is far less likely to predict false detections where nothing exists. Finally, YOLO learns very general representations of objects. It outperforms all other detection methods, including DPM and R-CNN, by a wide margin when generalizing from natural images to artwork on both the Picasso Dataset and the People-Art Dataset.

**A Practical Guide to Object Detection using the Popular YOLO Framework – Part III (with Python codes)**

How easy would our life be if we simply took an already designed framework, executed it, and got the desired result? Minimum effort, maximum reward. Isn’t that what we strive for in any profession? I feel incredibly lucky to be part of our machine learning community where even the top tech behemoths embrace open source technology. Of course it’s important to understand and grasp concepts before implementing them, but it’s always helpful when the ground work has been laid for you by top industry data scientists and researchers. This is especially true for deep learning domains like computer vision. Not everyone has the computational resources to build a DL model from scratch. That’s where predefined frameworks and pretained models come in handy. And in this article, we will look at one such framework for object detection – YOLO. It’s a supremely fast and accurate framework, as we’ll see soon.

**Change detection in dynamic attributed networks**

A network provides powerful means of representing complex relationships between entities by abstracting entities as vertices, and relationships as edges connecting vertices in a graph. Beyond the presence or absence of relationships, a network may contain additional information that can be attributed to the entities and their relationships. Attaching these additional attribute data to the corresponding vertices and edges yields an attributed graph. Moreover, in the majority of real-world applications, such as online social networks, financial networks and transactional networks, relationships between entities evolve over time. Change detection in dynamic attributed networks is an important problem in many areas, such as fraud detection, cyber intrusion detection, and health care monitoring. It is a challenging problem because it involves a time sequence of attributed graphs, each of which is usually very large and can contain many attributes attached to the vertices and edges, resulting in a complex, high-dimensional mathematical object. In this survey we provide an overview of some of the existing change detection methods that utilize attribute information. We categorize these methods based on the levels of structure in the graph that are exploited to detect changes. These levels are vertices, edges, subgraphs, communities, and the overall graph. We focus attention on the strengths and weaknesses of these methods, including their performance and scalability. Furthermore, we discuss some publicly available dynamic network datasets and give a brief overview of models to generate dynamic attributed networks. Finally, we discuss the limitations of existing approaches identifying key areas for future research.

**Machine Intelligence for Statistical Inference and Human Interpretation of Data**

One of the criticisms of machine learning and artificial intelligence approaches to the study of data is that both are ‘black box’ technologies, which can provide useful automated answers but which do not provide human interpretable output, and for which it is often not possible to understand how they are doing what they are doing. Ayasdi’s approach to this problem draws upon our core technology, Topological Data Analysis (TDA) and is able to supply powerful, detailed explanations outputs. In this post, however, we will extend our work beyond the current TDA ‘comparison’ methodology. The current methodology uses the topological networks built from the data points (rows) in a data set. In this new work, Ayasdi will also incorporate the features (columns), demonstrating an improved and readily interpreted result. Let’s first describe how the explain methodology works.

**Data Enrichment: More data is often the easiest way**

When it comes to Data Science, the most recurring topic is modeling. Quite a few articles out there talk about data preparation and only a bunch about how to communicate your results properly. However, there are hardly any dealing with the topic that we are going to cover today: data enrichment. In our experience with helping companies to start using their data efficiently, in most (especially bigger) organisations the single lowest hanging fruit to go after is a context. Many times the organisations attempt to solve a particular problem with data and fail.

**Shareable Data Science with Kyso**

In this tutorial, you’ll learn how to create publishable and reproducible data science studies on Kyso’s platform, using interactive plotly visualizations

**TF-Ranking: A Scalable TensorFlow Library for Learning-to-Rank**

Ranking, the process of ordering a list of items in a way that maximizes the utility of the entire list, is applicable in a wide range of domains, from search engines and recommender systems to machine translation, dialogue systems and even computational biology. In applications like these (and many others), researchers often utilize a set of supervised machine learning techniques called learning-to-rank. In many cases, these learning-to-rank techniques are applied to datasets that are prohibitively large – scenarios where the scalability of TensorFlow could be an advantage. However, there is currently no out-of-the-box support for applying learning-to-rank techniques in TensorFlow. To the best of our knowledge, there are also no other open source libraries that specialize in applying learning-to-rank techniques at scale. Today, we are excited to share TF-Ranking, a scalable TensorFlow-based library for learning-to-rank. As described in our recent paper, TF-Ranking provides a unified framework that includes a suite of state-of-the-art learning-to-rank algorithms, and supports pairwise or listwise loss functions, multi-item scoring, ranking metric optimization, and unbiased learning-to-rank.

**Four Techniques for Outlier Detection**

There are many techniques to detect and optionally remove outliers from a dataset. In this blog post, we show an implementation in KNIME Analytics Platform of four of the most frequently used – traditional and novel – techniques for outlier detection.

**How to build a data science project from scratch**

There are many online courses about data science and machine learning that will guide you through a theory and provide you with some code examples and an analysis of very clean data. However, in order to start practising data science, it is better if you challenge a real-life problem. Digging into the data in order to find deeper insights. Carrying out feature engineering using additional sources of data and building stand-alone machine learning pipelines. This blogpost will guide you through the main steps of building a data science project from scratch. It is based on a real-life problem – what are the main drivers of rental prices in Berlin? It will provide an analysis of this situation. It will also highlight the common mistake beginners tend to make when it comes to machine learning.

**Creating Tables Using R and Pure HTML**

A problem with R is that its tables are not good enough to share with non-R users, both in terms of visual attractiveness and ease of reading – particularly when the table is large. Quite a few different packages, tools, and workflows have been developed to address this problem, from formattable through to R Markdown and Displayr, to name a few. Over the past few months I have found myself increasingly using R to write tables in pure HTML. Why? Because pure HTML gives the greatest level of control. In this post I am going to work through a simple but easily generalizable example, which can both be used within R and RStudio, as well as when building interactive dashboards.

**Bayesian nonparametrics in NIMBLE: Density estimation**

NIMBLE is a hierarchical modeling package that uses nearly the same language for model specification as the popular MCMC packages WinBUGS, OpenBUGS and JAGS, while making the modeling language extensible – you can add distributions and functions – and also allowing customization of the algorithms used to estimate the parameters of the model. Recently, we added support for Markov chain Monte Carlo (MCMC) inference for Bayesian nonparametric (BNP) mixture models to NIMBLE. In particular, starting with version 0.6-11, NIMBLE provides functionality for fitting models involving Dirichlet process priors using either the Chinese Restaurant Process (CRP) or a truncated stick-breaking (SB) representation of the Dirichlet process prior. In this post we illustrate NIMBLE’s BNP capabilities by showing how to use nonparametric mixture models with different kernels for density estimation. In a later post, we will take a parametric generalized linear mixed model and show how to switch to a nonparametric representation of the random effects that avoids the assumption of normally-distributed random effects.

**Review: RoR – ResNet of ResNet / Multilevel ResNet (Image Classification)**

In this story, RoR (Residual Networks of Residual Networks) is shortly reviewed. After the success of ResNet which become an state-of-the-art deep learning approaches and won numerous recognition competitions, there were numerous researches working on how to generalize or improve the ResNet, such as Pre-Activation ResNet, ResNet in ResNet (RiR), ResNet with Stochastic Depth (SD), Wide Residual Network (WRN). RoR is another paper to improve the ResNet, they introduce a concept that a group of ResNet blocks can also have one shortcut connection. This makes a network become multi-level hierarchical ResNet. This is a paper firstly appeared in 2016 after ResNet, accepted in 2017 and finally published in 2018 TCSVT recently, which have got tens of citations already. (SH Tsang @ medium)





### Like this:

Like Loading...


*Related*

