---
layout:     post
catalog: true
title:      Whats new on arXiv
subtitle:      转载自：https://analytixon.com/2018/12/07/whats-new-on-arxiv-835/
date:      2018-12-07
author:      Michael Laux
tags:
    - learning
    - learns
    - learned
    - modeling
    - modeled
---

**Predicting future stock market structure by combining social and financial network information**

We demonstrate that future market correlation structure can be predicted with high out-of-sample accuracy using a multiplex network approach that combines information from social media and financial data. Market structure is measured by quantifying the co-movement of asset prices returns, while social structure is measured as the co-movement of social media opinion on those same assets. Predictions are obtained with a simple model that uses link persistence and link formation by triadic closure across both financial and social media layers. Results demonstrate that the proposed model can predict future market structure with up to a 40\% out-of-sample performance improvement compared to a benchmark model that assumes a time-invariant financial correlation structure. Social media information leads to improved models for all settings tested, particularly in the long-term prediction of financial market structure. Surprisingly, financial market structure exhibited higher predictability than social opinion structure.

**AI Matrix – Synthetic Benchmarks for DNN**

Deep neural network (DNN) architectures, such as convolutional neural networks (CNN), involve heavy computation and require hardware, such as CPU, GPU, and AI accelerators, to provide the massive computing power. With the many varieties of AI hardware prevailing on the market, it is often hard to decide which one is the best to use. Thus, benchmarking AI hardware effectively becomes important and is of great help to select and optimize AI hardware. Unfortunately, there are few AI benchmarks available in both academia and industry. Examples are BenchNN[1], DeepBench[2], and Dawn Bench[3], which are usually a collection of typical real DNN applications. While these benchmarks provide performance comparison across different AI hardware, they suffer from a number of drawbacks. First, they cannot adapt to the emerging changes of DNN algorithms and are fixed once selected. Second, they contain tens to hundreds of applications and take very long time to finish running. Third, they are mainly selected from open sources, which are restricted by copyright and are not representable to proprietary applications. In this work, a synthetic benchmarks framework is firstly proposed to address the above drawbacks of AI benchmarks. Instead of pre-selecting a set of open-sourced benchmarks and running all of them, the synthetic approach generates only a one or few benchmarks that best represent a broad range of applications using profiled workload characteristics data of these applications. Thus, it can adapt to emerging changes of new DNN algorithms by re-profiling new applications and updating itself, greatly reduce benchmark count and running time, and strongly represent DNN applications of interests. The generated benchmarks are called AI Matrix, serving as a performance benchmarks matching the statistical workload characteristics of a combination of applications of interests.

**Extensions of the Dynamic Programming Framework: Battery Scheduling, Demand Charges, and Renewable Integration**

In this paper, we consider dynamic programming problems with non-separable objective functions. We show that for any problem in this class, there exists an augmented-state dynamic programming problem which satisfies the principle of optimality and the solutions to which yield solutions to the original forward separable problem. We further generalize this approach to stochastic dynamic programming problems by extending the definition of the principle of optimality to problems driven by random variables. We then apply the resulting algorithms to the problem of optimal battery scheduling with demand charges using a data-based stochastic model for electricity usage and solar generation by the consumer.

**The Graph-based Broad Behavior-Aware Recommendation System for Interactive News**

In this paper, we propose a heuristic recommendation system for interactive news, called the graph-based broad behavior-aware network (G-BBAN). Different from most of existing work, our network considers six behaviors that may potentially be conducted by users, including unclick, click, like, follow, comment, and share. Further, we introduce the core and coritivity concept from graph theory into the system to measure the concentration degree of interests of each user, which we show can help to improve the performance even further if it’s considered. There are three critical steps in our recommendation system. First, we build a structured user-dependent interaction behavior graph for multi-level and multi-category data as a preprocessing step. This graph constructs the data sources and knowledge information which will be used in G-BBAN through representation learning. Second, for each user node on the graph, we calculate its core and coritivity and then add the pair as a new feature associated to this user. According to the definition of core and coritivity, this user-dependent feature provides useful insights into the concentration degree of his/her interests and affects the trade-off between accuracy and diversity of the personalized recommendation. Last, we represent item (news) information by entity semantics and environment semantics; design a multi-channel convolutional neural network called G-CNN to learn the semantic information and an attention-based LSTM to learn user’s behavior representation; combine with previous concentration feature and input into another two fully connected layers to finish the classification task. The whole network consists of the final G-BBAN. Through comparing with baselines and several variates of itself, our proposed method shows the superior performance in extensive experiments.

**Anomaly Detection Models for IoT Time Series Data**

Insitu sensors and Wireless Sensor Networks (WSNs) have become more and more popular in the last decade, due to their potential to be used in various applications of many different fields. As of today, WSNs are pretty much used by any monitoring system: from those that are health care related, to those that are used for environmental forecasting or surveillance purposes. All applications that make use of insitu sensors, strongly rely on their correct operation, which however, is quite difficult to guarantee. These sensors in fact, are typically cheap and prone to malfunction. Additionally, for many tasks (e.g. environmental forecasting), sensors are also deployed under potentially harsh weather condition, making their breakage even more likely. The high probability of erroneous readings or data corruption during transmission, brings up the problem of ensuring quality of the data collected by sensors. Since WSNs have to operate continuously and therefore generate very large volumes of data every day, the quality control process has to be automated, scalable and fast enough to be applicable to streaming data. The most common approach to ensure the quality of sensors data, consists in automated detection of erroneous readings or anomalous behaviours of sensors. In the literature, this strategy is known as anomaly detection and can be pursued in many different ways.

**Modeling natural language emergence with integral transform theory and reinforcement learning**

Zipf’s law predicts a power-law relationship between word rank and frequency in language communication systems and has been widely reported in a variety of natural language processing applications. However, the emergence of natural language is often modeled as a function of bias between speaker and listener interests, which lacks a direct way of relating information-theoretic bias to Zipfian rank. A function of bias also serves as an unintuitive interpretation of the communicative effort exchanged between a speaker and a listener. We counter these shortcomings by proposing a novel integral transform and kernel for mapping communicative bias functions to corresponding word frequency-rank representations at any arbitrary phase transition point, resulting in a direct way to link communicative effort (modeled by speaker/listener bias) to specific vocabulary used (represented by word rank). We demonstrate the practical utility of our integral transform by showing how a change from bias to rank results in greater accuracy and performance at an image classification task for assigning word labels to images randomly subsampled from CIFAR10. We model this task as a reinforcement learning game between a speaker and listener and compare the relative impact of bias and Zipfian word rank on communicative performance (and accuracy) between the two agents.

**Modulated Policy Hierarchies**

Solving tasks with sparse rewards is a main challenge in reinforcement learning. While hierarchical controllers are an intuitive approach to this problem, current methods often require manual reward shaping, alternating training phases, or manually defined sub tasks. We introduce modulated policy hierarchies (MPH), that can learn end-to-end to solve tasks from sparse rewards. To achieve this, we study different modulation signals and exploration for hierarchical controllers. Specifically, we find that communicating via bit-vectors is more efficient than selecting one out of multiple skills, as it enables mixing between them. To facilitate exploration, MPH uses its different time scales for temporally extended intrinsic motivation at each level of the hierarchy. We evaluate MPH on the robotics tasks of pushing and sparse block stacking, where it outperforms recent baselines.

**Learning from a tiny dataset of manual annotations: a teacher/student approach for surgical phase recognition**

Vision algorithms capable of interpreting scenes from a real-time video stream are necessary for computer-assisted surgery systems to achieve context-aware behavior. In laparoscopic procedures one particular algorithm needed for such systems is the identification of surgical phases, for which the current state of the art is a model based on a CNN-LSTM. A number of previous works using models of this kind have trained them in a fully supervised manner, requiring a fully annotated dataset. Instead, our work confronts the problem of learning surgical phase recognition in scenarios presenting scarce amounts of annotated data (under 25% of all available video recordings). We propose a teacher/student type of approach, where a strong predictor called the teacher, trained beforehand on a small dataset of ground truth-annotated videos, generates synthetic annotations for a larger dataset, which another model – the student – learns from. In our case, the teacher features a novel CNN-biLSTM-CRF architecture, designed for offline inference only. The student, on the other hand, is a CNN-LSTM capable of making real-time predictions. Results for various amounts of manually annotated videos demonstrate the superiority of the new CNN-biLSTM-CRF predictor as well as improved performance from the CNN-LSTM trained using synthetic labels generated for unannotated videos. For both offline and online surgical phase recognition with very few annotated recordings available, this new teacher/student strategy provides a valuable performance improvement by efficiently leveraging the unannotated data.

**GDPP: Learning Diverse Generations Using Determinantal Point Process**

Generative models have proven to be an outstanding tool for representing high-dimensional probability distributions and generating realistic looking images. A fundamental characteristic of generative models is their ability to produce multi-modal outputs. However, while training, they are often susceptible to mode collapse, which means that the model is limited in mapping the input noise to only a few modes of the true data distribution. In this paper, we draw inspiration from Determinantal Point Process (DPP) to devise a generative model that alleviates mode collapse while producing higher quality samples. DPP is an elegant probabilistic measure used to model negative correlations within a subset and hence quantify its diversity. We use DPP kernel to model the diversity in real data as well as in synthetic data. Then, we devise a generation penalty term that encourages the generator to synthesize data with a similar diversity to real data. In contrast to previous state-of-the-art generative models that tend to use additional trainable parameters or complex training paradigms, our method does not change the original training scheme. Embedded in an adversarial training and variational autoencoder, our Generative Determinantal Point Process approach shows a consistent resistance to mode-collapse on a wide-variety of synthetic data and natural image datasets including MNIST, CIFAR10, and CelebA, while outperforming state-of-the-art methods for data-efficiency, convergence-time, and generation quality. Our code is publicly available.

**TF-Ranking: Scalable TensorFlow Library for Learning-to-Rank**

TensorFlow Ranking is the first open source library for solving large-scale ranking problems in a deep learning framework. It is highly configurable and provides easy-to-use APIs to support different scoring mechanisms, loss functions and evaluation metrics in the learning-to-rank setting. Our library is developed on top of TensorFlow and can thus fully leverage the advantages of this platform. For example, it is highly scalable, both in training and in inference, and can be used to learn ranking models over massive amounts of user activity data. We empirically demonstrate the effectiveness of our library in learning ranking functions for large-scale search and recommendation applications in Gmail and Google Drive.

**Scalable Graph Learning for Anti-Money Laundering: A First Look**

Organized crime inflicts human suffering on a genocidal scale: the Mexican drug cartels have murdered 150,000 people since 2006, upwards of 700,000 people per year are ‘exported’ in a human trafficking industry enslaving an estimated 40 million people. These nefarious industries rely on sophisticated money laundering schemes to operate. Despite tremendous resources dedicated to anti-money laundering (AML) only a tiny fraction of illicit activity is prevented. The research community can help. In this brief paper, we map the structural and behavioral dynamics driving the technical challenge. We review AML methods, current and emergent. We provide a first look at scalable graph convolutional neural networks for forensic analysis of financial data, which is massive, dense, and dynamic. We report preliminary experimental results using a large synthetic graph (1M nodes, 9M edges) generated by a data simulator we created called AMLSim. We consider opportunities for high performance efficiency, in terms of computation and memory, and we share results from a simple graph compression experiment. Our results support our working hypothesis that graph deep learning for AML bears great promise in the fight against criminal financial activity.

**Graph Node-Feature Convolution for Representation Learning**

Graph convolutional network (GCN) is an emerging neural network approach. It learns new representation of a node by aggregating feature vectors of all neighbors in the aggregation process without considering whether the neighbors or features are useful or not. Recent methods have improved solutions by sampling a fixed size set of neighbors, or assigning different weights to different neighbors in the aggregation process, but features within a feature vector are still treated equally in the aggregation process. In this paper, we introduce a new convolution operation on regular size feature maps constructed from features of a fixed node bandwidth via sampling to get the first-level node representation, which is then passed to a standard GCN to learn the second-level node representation. Experiments show that our method outperforms competing methods in semi-supervised node classification tasks. Furthermore, our method opens new doors for exploring new GCN architectures, particularly deeper GCN models.

**BlockPuzzle – A Challenge in Physical Reasoning and Generalization for Robot Learning**

In this work we propose a novel task framework under which a variety of physical reasoning puzzles can be constructed using very simple rules. Under sparse reward settings, most of these tasks can be very challenging for a reinforcement learning agent to learn. We build several simple environments with this task framework in Mujoco and OpenAI gym and attempt to solve them. We are able to solve the environments by designing curricula to guide the agent in learning and using imitation learning methods to transfer knowledge from a simpler environment. This is only a first step for the task framework, and further research on how to solve the harder tasks and transfer knowledge between tasks is needed.

**Deep Factors with Gaussian Processes for Forecasting**

A large collection of time series poses significant challenges for classical and neural forecasting approaches. Classical time series models fail to fit data well and to scale to large problems, but succeed at providing uncertainty estimates. The converse is true for deep neural networks. In this paper, we propose a hybrid model that incorporates the benefits of both approaches. Our new method is data-driven and scalable via a latent, global, deep component. It also handles uncertainty through a local classical Gaussian Process model. Our experiments demonstrate that our method obtains higher accuracy than state-of-the-art methods.

**A Big Data Architecture for Log Data Storage and Analysis**

We propose an architecture for analysing database connection logs across different instances of databases within an intranet comprising over 10,000 users and associated devices. Our system uses Flume agents to send notifications to a Hadoop Distributed File System for long-term storage and ElasticSearch and Kibana for short-term visualisation, effectively creating a data lake for the extraction of log data. We adopt machine learning models with an ensemble of approaches to filter and process the indicators within the data and aim to predict anomalies or outliers using feature vectors built from this log data.

**Explore-Exploit: A Framework for Interactive and Online Learning**

Interactive user interfaces need to continuously evolve based on the interactions that a user has (or does not have) with the system. This may require constant exploration of various options that the system may have for the user and obtaining signals of user preferences on those. However, such an exploration, especially when the set of available options itself can change frequently, can lead to sub-optimal user experiences. We present Explore-Exploit: a framework designed to collect and utilize user feedback in an interactive and online setting that minimizes regressions in end-user experience. This framework provides a suite of online learning operators for various tasks such as personalization ranking, candidate selection and active learning. We demonstrate how to integrate this framework with run-time services to leverage online and interactive machine learning out-of-the-box. We also present results demonstrating the efficiencies that can be achieved using the Explore-Exploit framework.

**Snapshot Distillation: Teacher-Student Optimization in One Generation**

Optimizing a deep neural network is a fundamental task in computer vision, yet direct training methods often suffer from over-fitting. Teacher-student optimization aims at providing complementary cues from a model trained previously, but these approaches are often considerably slow due to the pipeline of training a few generations in sequence, i.e., time complexity is increased by several times. This paper presents snapshot distillation (SD), the first framework which enables teacher-student optimization in one generation. The idea of SD is very simple: instead of borrowing supervision signals from previous generations, we extract such information from earlier epochs in the same generation, meanwhile make sure that the difference between teacher and student is sufficiently large so as to prevent under-fitting. To achieve this goal, we implement SD in a cyclic learning rate policy, in which the last snapshot of each cycle is used as the teacher for all iterations in the next cycle, and the teacher signal is smoothed to provide richer information. In standard image classification benchmarks such as CIFAR100 and ILSVRC2012, SD achieves consistent accuracy gain without heavy computational overheads. We also verify that models pre-trained with SD transfers well to object detection and semantic segmentation in the PascalVOC dataset.

**NOTE-RCNN: NOise Tolerant Ensemble RCNN for Semi-Supervised Object Detection**

The labeling cost of large number of bounding boxes is one of the main challenges for training modern object detectors. To reduce the dependence on expensive bounding box annotations, we propose a new semi-supervised object detection formulation, in which a few seed box level annotations and a large scale of image level annotations are used to train the detector. We adopt a training-mining framework, which is widely used in weakly supervised object detection tasks. However, the mining process inherently introduces various kinds of labelling noises: false negatives, false positives and inaccurate boundaries, which can be harmful for training the standard object detectors (e.g. Faster RCNN). We propose a novel NOise Tolerant Ensemble RCNN (NOTE-RCNN) object detector to handle such noisy labels. Comparing to standard Faster RCNN, it contains three highlights: an ensemble of two classification heads and a distillation head to avoid overfitting on noisy labels and improve the mining precision, masking the negative sample loss in box predictor to avoid the harm of false negative labels, and training box regression head only on seed annotations to eliminate the harm from inaccurate boundaries of mined bounding boxes. We evaluate the methods on ILSVRC 2013 and MSCOCO 2017 dataset; we observe that the detection accuracy consistently improves as we iterate between mining and training steps, and state-of-the-art performance is achieved.

**How to Profile Privacy-Conscious Users in Recommender Systems**

Matrix factorization is a popular method to build a recommender system. In such a system, existing users and items are associated to a low-dimension vector called a profile. The profiles of a user and of an item can be combined (via inner product) to predict the rating that the user would get on the item. One important issue of such a system is the so-called cold-start problem: how to allow a user to learn her profile, so that she can then get accurate recommendations? While a profile can be computed if the user is willing to rate well-chosen items and/or provide supplemental attributes or demographics (such as gender), revealing this additional information is known to allow the analyst of the recommender system to infer many more personal sensitive information. We design a protocol to allow privacy-conscious users to benefit from matrix-factorization-based recommender systems while preserving their privacy. More precisely, our protocol enables a user to learn her profile, and from that to predict ratings without the user revealing any personal information. The protocol is secure in the standard model against semi-honest adversaries.

**QADiver: Interactive Framework for Diagnosing QA Models**

Question answering (QA) extracting answers from text to the given question in natural language, has been actively studied and existing models have shown a promise of outperforming human performance when trained and evaluated with SQuAD dataset. However, such performance may not be replicated in the actual setting, for which we need to diagnose the cause, which is non-trivial due to the complexity of model. We thus propose a web-based UI that provides how each model contributes to QA performances, by integrating visualization and analysis tools for model explanation. We expect this framework can help QA model researchers to refine and improve their models.

**Deep Learning Application in Security and Privacy — Theory and Practice: A Position Paper**

Technology is shaping our lives in a multitude of ways. This is fuelled by a technology infrastructure, both legacy and state of the art, composed of a heterogeneous group of hardware, software, services and organisations. Such infrastructure faces a diverse range of challenges to its operations that include security, privacy, resilience, and quality of services. Among these, cybersecurity and privacy are taking the centre-stage, especially since the General Data Protection Regulation (GDPR) came into effect. Traditional security and privacy techniques are overstretched and adversarial actors have evolved to design exploitation techniques that circumvent protection. With the ever-increasing complexity of technology infrastructure, security and privacy-preservation specialists have started to look for adaptable and flexible protection methods that can evolve (potentially autonomously) as the adversarial actor changes its techniques. For this, Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL) were put forward as saviours. In this paper, we look at the promises of AI, ML, and DL stated in academic and industrial literature and evaluate how realistic they are. We also put forward potential challenges a DL based security and privacy protection technique has to overcome. Finally, we conclude the paper with a discussion on what steps the DL and the security and privacy-preservation community have to take to ensure that DL is not just going to be hype, but an opportunity to build a secure, reliable, and trusted technology infrastructure on which we can rely on for so much in our lives.

**One for All: Neural Joint Modeling of Entities and Events**

The previous work for event extraction has mainly focused on the predictions for event triggers and argument roles, treating entity mentions as being provided by human annotators. This is unrealistic as entity mentions are usually predicted by some existing toolkits whose errors might be propagated to the event trigger and argument role recognition. Few of the recent work has addressed this problem by jointly predicting entity mentions, event triggers and arguments. However, such work is limited to using discrete engineering features to represent contextual information for the individual tasks and their interactions. In this work, we propose a novel model to jointly perform predictions for entity mentions, event triggers and arguments based on the shared hidden representations from deep learning. The experiments demonstrate the benefits of the proposed method, leading to the state-of-the-art performance for event extraction.

**Lifelong Learning for Image Captioning by Asking Natural Language Questions**

In order to bring artificial agents into our lives, we will need to go beyond supervised learning on closed datasets to having the ability to continuously expand knowledge. Inspired by a student learning in a classroom, we present an agent that can continuously learn by posing natural language questions to humans. Our agent is composed of three interacting modules, one that performs captioning, another that generates questions and a decision maker that learns when to ask questions by implicitly reasoning about the uncertainty of the agent and expertise of the teacher. As compared to current active learning methods which query images for full captions, our agent is able to ask pointed questions to improve the generated captions. The agent trains on the improved captions, expanding its knowledge. We show that our approach achieves better performance using less human supervision than the baselines on the challenging MSCOCO dataset.

**Towards Gaussian Bayesian Network Fusion**

Data sets are growing in complexity thanks to the increasing facilities we have nowadays to both generate and store data. This poses many challenges to machine learning that are leading to the proposal of new methods and paradigms, in order to be able to deal with what is nowadays referred to as Big Data. In this paper we propose a method for the aggregation of different Bayesian network structures that have been learned from separate data sets, as a first step towards mining data sets that need to be partitioned in an horizontal way, i.e. with respect to the instances, in order to be processed. Considerations that should be taken into account when dealing with this situation are discussed. Scalable learning of Bayesian networks is slowly emerging, and our method constitutes one of the first insights into Gaussian Bayesian network aggregation from different sources. Tested on synthetic data it obtains good results that surpass those from individual learning. Future research will be focused on expanding the method and testing more diverse data sets.

• Joint Mapping and Calibration via Differentiable Sensor Fusion• Automatic salt deposits segmentation: A deep learning approach• Integral Geometric Dual Distributions of Multilinear Models• Sharma-Mittal Quantum Discord• Machine Learning for Yield Curve Feature Extraction: Application to Illiquid Corporate Bonds• Relation Networks for Optic Disc and Fovea Localization in Retinal Images• TorchProteinLibrary: A computationally efficient, differentiable representation of protein structure• Automatic lesion boundary detection in dermoscopy• Automatic Seismic Salt Interpretation with Deep Convolutional Neural Networks• A Consolidated Approach to Convolutional Neural Networks and the Kolmogorov Complexity• Incorporating Deep Features in the Analysis of Tissue Microarray Images• Construction and reduction of the Pareto set in asymmetric travelling salesman problem with two criteria• Generic Singularities of the 3D-Contact sub-Riemannian Conjugate Locus• Minimax Optimal Additive Functional Estimation with Discrete Distribution• Cluster-Based Learning from Weakly Labeled Bags in Digital Pathology• The Indus Script and Economics. A Role for Indus Seals and Tablets in Rationing and Administration of Labor• Dynamic Ecological System Analysis• Constrained Control of Depth of Hypnosis During Induction Phase• A Mixed Integer Linear Programming Model for Multi-Satellite Scheduling• Determining the essentially different partitions of all Japanese convex tangrams• Segmenting Dynamic Network Data• Simulated Tempering Langevin Monte Carlo II: An Improved Proof using Soft Markov Chain Decomposition• Correspondence Analysis of Government Expenditure Patterns• Testing Changes in Communities for the Stochastic Block Model• Deep Signal Recovery with One-Bit Quantization• A Hybrid Beamforming Receiver with Two-Stage Analog Combining and Low-Resolution ADCs• On sampling of scattering phase functions• Generating Material Maps to Map Informal Settlements• Coupled Multirate Infinitesimal GARK Schemes for Stiff Systems with Multiple Time Scales• Mapping Informal Settlements in Developing Countries with Multi-resolution, Multi-spectral Data• The $g$-good neighbour diagnosability of hierarchical cubic networks• FTR-18: Collecting rumours on football transfer news• Image-based model parameter optimisation using Model-Assisted Generative Adversarial Networks• Fast and Reliable Initial Access with Random Beamforming for mmWave Networks• Finding Zeros of Hölder Metrically Subregular Mappings via Globally Convergent Levenberg-Marquardt Methods• Improving Traffic Safety Through Video Analysis in Jakarta, Indonesia• TextureNet: Consistent Local Parametrizations for Learning from High-Resolution Signals on Meshes• Sub-national levels and trends in contraceptive prevalence, unmet need, and demand for family planning in Nigeria with survey uncertainty• Cascade-Net: a New Deep Learning Architecture for OFDM Detection• Decision Forests Induce Characteristic Kernels• Unsupervised learning with GLRM feature selection reveals novel traumatic brain injury phenotypes• Realization of tensor-product and of tensor-Factorization of rational functions• Optimal Transport on the Probability Simplex with Logarithmic Cost• Adversarial Defense by Stratified Convolutional Sparse Coding• Using Monte Carlo Tree Search as a Demonstrator within Asynchronous Deep RL• Learning Interpretable Rules for Multi-label Classification• Forward Modeling for Partial Observation Strategy Games – A StarCraft Defogger• Bayesian Sequential Design Based on Dual Objectives for Accelerated Life Tests• Corresponding Projections for Orphan Screening• Binary Decision Diagrams for Bin Packing with Minimum Color Fragmentation• Automatic Logarithm and Associated Measures• A Linear Formulation for Power System State Estimation including RTU and PMU Measurements• Stochastic Gradient MCMC with Repulsive Forces• Energy-efficient Resource Allocation for Wirelessly Powered Backscatter Communications• Optimal Combining and Performance Analysis for Two-Way EH Relay Systems with TDBC Protocol• Heterogeneous Power-Splitting Based Two-Way DF Relaying with Non-Linear Energy Harvesting• MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment• Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search• Using Column Generation to Solve Extensions to the Markowitz Model• Intraday forecasts of a volatility index: Functional time series methods with dynamic updating• Understanding Unequal Gender Classification Accuracy from Face Images• Kernel based method for the $k$-sample problem• DVC: An End-to-end Deep Video Compression Framework• From Third Person to First Person: Dataset and Baselines for Synthesis and Retrieval• True Contextuality in a Psychophysical Experiment• Multi-View Egocentric Video Summarization• Secure physical layer network coding versus secure network coding• Recovering missing CFD data for high-order discretizations using deep neural networks and dynamics learning• Simple Confidence Intervals for MCMC Without CLTs• Markov chain Monte Carlo Methods For Lattice Gaussian Sampling: Lattice Reduction and Decoding Optimization• Deep Inception Generative Network for Cognitive Image Inpainting• On a Sufficient Condition for Planar Graphs of Maximum Degree 6 to be Totally 7-Colorable• Semi-Online Bipartite Matching• Theory of Cognitive Relativity: A Promising Paradigm for True AI• Automated segmentaiton and classification of arterioles and venules using Cascading Dilated Convolutional Neural Networks• Number of Connected Components in a Graph: Estimation via Counting Patterns• Fuzzing: Art, Science, and Engineering• A Dynamic Network and Representation LearningApproach for Quantifying Economic Growth fromSatellite Imagery• Operator Splitting Performance Estimation: Tight contraction factors and optimal parameter selection• SwishNet: A Fast Convolutional Neural Network for Speech, Music and Noise Classification and Segmentation• Discrete Attacks and Submodular Optimization with Applications to Text Classification• Learning RoI Transformer for Detecting Oriented Objects in Aerial Images• M-Channel Critically Sampled Spectral Graph Filter Banks With Symmetric Structure• Approximating Categorical Similarity in Sponsored Search Relevance• Irregular Channel Polarization and Its Applications to Static Adversarial Wiretap Channel• Integrated Stabilization Policy over a Software Defined Network• Vision-Based Gait Analysis for Senior Care• Farey boat II. $\mathbb{Q}$-deformations: $q$-deformed rationals and $q$-continued fractions• Rank Projection Trees for Multilevel Neural Network Interpretation• A Nonstationary Designer Space-Time Kernel• Stochastic Training of Residual Networks: a Differential Equation Viewpoint• A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues• Robust Optimal Energy and Reserve Management of Multiple-Microgrids via Cooperative Bidding• Effects of Loss Functions And Target Representations on Adversarial Robustness• NTX: An Energy-efficient Streaming Accelerator for Floating-point Generalized Reduction Workloads in 22nm FD-SOI• Strategy-Proof Spectrum Allocation among Multiple Operators• Racial Faces in-the-Wild: Reducing Racial Bias by Deep Unsupervised Domain Adaptation• Optimality conditions for an exhausterable function on an exhausterable set• Online Estimation of Power System Inertia Using Dynamic Regressor Extension and Mixing• Towards Traversing the Continuous Spectrum of Image Retrieval• Scheduling multiple agile Earth observation satellites with multiple observations• A Probabilistic Model of Cardiac Physiology and Electrocardiograms• Measuring the Stability of EHR- and EKG-based Predictive Models• Four identities related to third order mock theta functions• A calibrated sensitivity analysis for matched observational studies with application to the effect of second-hand smoke exposure on blood lead levels in U.S. children• Discovering hierarchies using Imitation Learning from hierarchy aware policies• BOLIB: Bilevel Optimization LIBrary of test problems• Internal Distribution Matching for Natural Image Retargeting• Improving robustness of classifiers by training against live traffic• Building robust classifiers through generation of confident out of distribution examples• Universal Streaming of Subset Norms• A PMU-based Multivariate Model for Classifying Power System Events• On Compressing U-net Using Knowledge Distillation• A Family-based Graphical Approach for Testing Hierarchically Ordered Families of Hypotheses• The Unifed Distribution• On-line Human Gait Stability Prediction using LSTMs for the fusion of Deep-based Pose Estimation and LRF-based Augmented Gait State Estimation in an Intelligent Robotic Rollator• A Deep Learning Approach for Multi-View Engagement Estimation of Children in a Child-Robot Joint Attention task• AnyThreat: An Opportunistic Knowledge Discovery Approach to Insider Threat Detection• A New Approach for Large Scale Multiple Testing with Application to FDR Control for Graphically Structured Hypotheses• The semi-Markov beta-Stacy process: a Bayesian non-parametric prior for semi-Markov processes• Distributed mining of time–faded heavy hitters• Toward an analog of Kruskal’s theorem on tensor decomposition• Discovering Molecular Functional Groups Using Graph Convolutional Neural Networks• Numerical observation of a glassy phase in the three-dimensional Coulomb glass• Dynamic Measurement Scheduling for Adverse Event Forecasting using Deep RL• Quantifying the uncertainty of variance partitioning estimates of ecological datasets• Learning Speaker Representations with Mutual Information• Cross-Modulation Networks for Few-Shot Learning• Positive semidefinite approximations to the cone of copositive kernels





### Like this:

Like Loading...


*Related*

