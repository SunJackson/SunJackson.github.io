---
layout:     post
catalog: true
title:      Clustering the Bible
subtitle:      转载自：http://feedproxy.google.com/~r/RBloggers/~3/qDhqhgk7mr4/
date:      2018-12-27
author:      Learning Machines
tags:
    - gospels
    - texts
    - και
    - stylo
    - john
---










During this time of year there is obviously a lot of talk about the Bible. As most people know the New Testament comprises four different Gospels written by anonymous authors 40 to 70 years after Jesus’ supposed crucifiction. Unfortunately we have lost all of the originals but only retained copies of copies of copies (and so on) which date back hundreds of years after they were written in all kinds of different versions (renowned Biblical scholar Professor Bart Ehrmann states that there are more versions of the New Testament than there are words in the New Testament). Just as a fun fact: there are many more Gospels but only those four were included in the official Bible.

So in general it is interesting to learn a little bit more about this stuff, especially because, for better or worse, it is at the core of Western civilization. One interesting question is how do the four Gospels relate to each other. To find that out you could either study ancient Greek and Christian theology for many years and decades – or you could use the `stylo` package and do a cluster analysis within seconds. Obviously we go for the latter…

For that matter we download one version of the four Gospels from Project Gutenberg in the original ancient Greek and put it into a separate directory called ‘corpus’ (which is the name of the default directory of the package). The famous beginning of the Gospel of John (“In the beginning was the Word, and the Word was with God, and the Word was God…”) reads as follows in Ancient Greek:

> 
 Στην αρχή ‘ταν ο λόγος κι’ ο λόγος είτανε με τοΘεό και Θεός είταν ο λόγος. Είταν εκείνος στην αρχήμε το Θεό. Όλα τα πάντα μέσο του έγιναν, και χωρίςτου τίποτα δεν έγινε που γίνηκε. Μέσα του είτανε ζωήκι’ η ζωή ‘τανε το φως των ανθρώπων, και το φωςμέσα στο σκοτάδι φέγγει και το σκοτάδι δεν το κυρίεψε.


For your convenience I provide you with the curated texts here: John, Luke, Mark, Matthew.

After that we can already call the main function of the package:

![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2018/12/NT-clustering-1024x731.png?w=450)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2018/12/NT-clustering-1024x731.png?w=450)


As you can see the Gospels of Matthew and Luke are more similar than Mark (the oldest Gospel), John (the last Gospel that made it into the Bible) is farthest away. This is indeed what Biblical scholars have found out by diligently studying the New Testament: Mark, Luke and Matthew are called “Synoptic Gospels” because they are so similar, John kind of stands on its own. The shared pieces of the Synoptic Gospels can be seen here (picture from Wikipedia, Synoptic Gospels):

![](https://i2.wp.com/blog.ephorie.de/wp-content/uploads/2018/12/372px-Relationship_between_synoptic_gospels-en.svg_.png?resize=372%2C479)
![](https://i2.wp.com/blog.ephorie.de/wp-content/uploads/2018/12/372px-Relationship_between_synoptic_gospels-en.svg_.png?resize=372%2C479)


As you can see, Biblical scholars have found out that Luke and Matthew share about 60 to 70 percent of the text (through the so called double tradition), whereas Mark shares about 40 percent of the text (through the triple tradition). For comparison, John only shares about 10 percent with the synoptic Gospels. Now, this is exactly what our cluster analysis form above shows – what an impressive feat!

By the way, there is an even simpler way to interact with the `stylo` package: through the GUI. Just call `stylo()` and the following window will open where you can play around with different arguments:

![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2018/12/400px-DH-Handbuch_Textanalyse_StyloGUI.png?resize=400%2C164)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2018/12/400px-DH-Handbuch_Textanalyse_StyloGUI.png?resize=400%2C164)


It has never been easier to do sophisticated textual analyses, even in ancient languages one cannot understand! You might ask: how did R do that?

Well, behind the scenes R basically creates frequency tables for the words used in the different documents. It then tries to cluster the documents based on a similarity (or distance) measure. Intuitively that means that the more often authors use the same words the closer their texts are. As you can see R doesn’t really have to understand the words or the language used. It just maps statistical measures which seems to be quite effective (not only) in this case. The statistical measures often give some kind of characteristic signature of an author or a source. In a way this is the quantified version of fuzzy concepts like ‘writing style’ yet R can do it much more quickly even for long texts than any human ever could!

Happy New Year… stay tuned for much more to come in![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2018/12/good-year-3168078_1280-300x209.png?resize=300%2C209)
![](https://i1.wp.com/blog.ephorie.de/wp-content/uploads/2018/12/good-year-3168078_1280-300x209.png?resize=300%2C209)



*Related*








---
