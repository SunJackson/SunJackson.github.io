---
layout:     post
catalog: true
title:      Document worth reading： “Generalization in Machine Learning via Analytical Learning Theory”
subtitle:      转载自：https://analytixon.com/2018/12/28/document-worth-reading-generalization-in-machine-learning-via-analytical-learning-theory/
date:      2018-12-28
author:      Michael Laux
tags:
    - paper introduces
    - abilities
    - raw inputs
    - hold true
    - rademacher
---

This paper introduces a novel measure-theoretic learning theory to analyze generalization behaviors of practical interest. The proposed learning theory has the following abilities: 1) to utilize the qualities of each learned representation on the path from raw inputs to outputs in representation learning, 2) to guarantee good generalization errors possibly with arbitrarily rich hypothesis spaces (e.g., arbitrarily large capacity and Rademacher complexity) and non-stable/non-robust learning algorithms, and 3) to clearly distinguish each individual problem instance from each other. Our generalization bounds are relative to a representation of the data, and hold true even if the representation is learned. We discuss several consequences of our results on deep learning, one-shot learning and curriculum learning. Unlike statistical learning theory, the proposed learning theory analyzes each problem instance individually via measure theory, rather than a set of problem instances via statistics. Because of the differences in the assumptions and the objectives, the proposed learning theory is meant to be complementary to previous learning theory and is not designed to compete with it. Generalization in Machine Learning via Analytical Learning Theory





### Like this:

Like Loading...


*Related*

