---
layout:     post
catalog: true
title:      Whats new on arXiv
subtitle:      转载自：https://analytixon.com/2018/12/03/whats-new-on-arxiv-833/
date:      2018-12-03
author:      Michael Laux
tags:
    - models
    - modeling
    - modeled
    - learning
    - learned
---

**Analyzing Federated Learning through an Adversarial Lens**

Federated learning distributes model training among a multitude of agents, who, guided by privacy concerns, perform training using their local data but share only model parameter updates, for iterative aggregation at the server. In this work, we explore the threat of model poisoning attacks on federated learning initiated by a single, non-colluding malicious agent where the adversarial objective is to cause the model to misclassify a set of chosen inputs with high confidence. We explore a number of strategies to carry out this attack, starting with simple boosting of the malicious agent’s update to overcome the effects of other agents’ updates. To increase attack stealth, we propose an alternating minimization strategy, which alternately optimizes for the training loss and the adversarial objective. We follow up by using parameter estimation for the benign agents’ updates to improve on attack success. Finally, we use a suite of interpretability techniques to generate visual explanations of model decisions for both benign and malicious models and show that the explanations are nearly visually indistinguishable. Our results indicate that even a highly constrained adversary can carry out model poisoning attacks while simultaneously maintaining stealth, thus highlighting the vulnerability of the federated learning setting and the need to develop effective defense strategies.

**BioSimulator.jl: Stochastic simulation in Julia**
![](https://s0.wp.com/latex.php?latex=%5Ctau&bg=ffffff&fg=000&s=0)


**Sequential Embedding Induced Text Clustering, a Non-parametric Bayesian Approach**

Current state-of-the-art nonparametric Bayesian text clustering methods model documents through multinomial distribution on bags of words. Although these methods can effectively utilize the word burstiness representation of documents and achieve decent performance, they do not explore the sequential information of text and relationships among synonyms. In this paper, the documents are modeled as the joint of bags of words, sequential features and word embeddings. We proposed Sequential Embedding induced Dirichlet Process Mixture Model (SiDPMM) to effectively exploit this joint document representation in text clustering. The sequential features are extracted by the encoder-decoder component. Word embeddings produced by the continuous-bag-of-words (CBOW) model are introduced to handle synonyms. Experimental results demonstrate the benefits of our model in two major aspects: 1) improved performance across multiple diverse text datasets in terms of the normalized mutual information (NMI); 2) more accurate inference of ground truth cluster numbers with regularization effect on tiny outlier clusters.

**How to Organize your Deep Reinforcement Learning Agents: The Importance of Communication Topology**

In this empirical paper, we investigate how learning agents can be arranged in more efficient communication topologies for improved learning. This is an important problem because a common technique to improve speed and robustness of learning in deep reinforcement learning and many other machine learning algorithms is to run multiple learning agents in parallel. The standard communication architecture typically involves all agents intermittently communicating with each other (fully connected topology) or with a centralized server (star topology). Unfortunately, optimizing the topology of communication over the space of all possible graphs is a hard problem, so we borrow results from the networked optimization and collective intelligence literatures which suggest that certain families of network topologies can lead to strong improvements over fully-connected networks. We start by introducing alternative network topologies to DRL benchmark tasks under the Evolution Strategies paradigm which we call Network Evolution Strategies. We explore the relative performance of the four main graph families and observe that one such family (Erdos-Renyi random graphs) empirically outperforms all other families, including the de facto fully-connected communication topologies. Additionally, the use of alternative network topologies has a multiplicative performance effect: we observe that when 1000 learning agents are arranged in a carefully designed communication topology, they can compete with 3000 agents arranged in the de facto fully-connected topology. Overall, our work suggests that distributed machine learning algorithms would learn more efficiently if the communication topology between learning agents was optimized.

**Deep Multi-Agent Reinforcement Learning with Relevance Graphs**

Over recent years, deep reinforcement learning has shown strong successes in complex single-agent tasks, and more recently this approach has also been applied to multi-agent domains. In this paper, we propose a novel approach, called MAGnet, to multi-agent reinforcement learning (MARL) that utilizes a relevance graph representation of the environment obtained by a self-attention mechanism, and a message-generation technique inspired by the NerveNet architecture. We applied our MAGnet approach to the Pommerman game and the results show that it significantly outperforms state-of-the-art MARL solutions, including DQN, MADDPG, and MCTS.

**An Introduction to Deep Reinforcement Learning**

Deep reinforcement learning is the combination of reinforcement learning (RL) and deep learning. This field of research has been able to solve a wide range of complex decision-making tasks that were previously out of reach for a machine. Thus, deep RL opens up many new applications in domains such as healthcare, robotics, smart grids, finance, and many more. This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques. Particular focus is on the aspects related to generalization and how deep RL can be used for practical applications. We assume the reader is familiar with basic machine learning concepts.

**Deep Multimodal Learning: An Effective Method for Video Classification**

Videos have become ubiquitous on the Internet. And video analysis can provide lots of information for detecting and recognizing objects as well as help people understand human actions and interactions with the real world. However, facing data as huge as TB level, effective methods should be applied. Recurrent neural network (RNN) architecture has wildly been used on many sequential learning problems such as Language Model, Time-Series Analysis, etc. In this paper, we propose some variations of RNN such as stacked bidirectional LSTM/GRU network with attention mechanism to categorize large-scale video data. We also explore different multimodal fusion methods. Our model combines both visual and audio information on both video and frame level and received great result. Ensemble methods are also applied. Because of its multimodal characteristics, we decide to call this method Deep Multimodal Learning(DML). Our DML-based model was trained on Google Cloud and our own server and was tested in a well-known video classification competition on Kaggle held by Google.

**Clear the Fog: Combat Value Assessment in Incomplete Information Games with Convolutional Encoder-Decoders**

StarCraft, one of the most popular real-time strategy games, is a compelling environment for artificial intelligence research for both micro-level unit control and macro-level strategic decision making. In this study, we address an eminent problem concerning macro-level decision making, known as the ‘fog-of-war’, which rises naturally from the fact that information regarding the opponent’s state is always provided in the incomplete form. For intelligent agents to play like human players, it is obvious that making accurate predictions of the opponent’s status under incomplete information will increase its chance of winning. To reflect this fact, we propose a convolutional encoder-decoder architecture that predicts potential counts and locations of the opponent’s units based on only partially visible and noisy information. To evaluate the performance of our proposed method, we train an additional classifier on the encoder-decoder output to predict the game outcome (win or lose). Finally, we designed an agent incorporating the proposed method and conducted simulation games against rule-based agents to demonstrate both effectiveness and practicality. All experiments were conducted on actual game replay data acquired from professional players.

**OHIE: Blockchain Scaling Made Simple**

Blockchain protocols, originating from Bitcoin, have established a new model of trust through decentralization. However, the low transaction throughput of the first generation of blockchain consensus protocols has been a serious concern. Many new protocols have been proposed recently that scale the throughput of the blockchain with available bandwidth. However, these scalable consensus protocols are becoming increasingly complex, making it more and more difficult to verify their end safety and liveness guarantees. This encumbers adoption since blockchain protocols are difficult to upgrade, once deployed. We propose a new consensus protocol for permissionless blockchains, called OHIE, with an explicit goal of aiming for simplicity. OHIE composes as many parallel instances of Bitcoin’s original (and simple) backbone protocol as needed to achieve near-optimal throughput (i.e., utilizing within a constant factor of the available bandwidth). OHIE tolerates a Byzantine adversary with fraction f < 1/2 of the computation power. We formally prove safety and liveness properties of OHIE. Our proof invokes previously established properties of Bitcoin’s backbone protocol as a black-box, given the modular design of OHIE. In our experimental evaluation with up to 50,000 nodes, OHIE achieves near-optimal throughput, and provides better decentralization of at least about 20x over prior works.

**LoAdaBoost:Loss-Based AdaBoost Federated Machine Learning on medical Data**

Medical data are valuable for improvement of health care, policy making and many other purposes. Vast amount of medical data are stored in different locations ,on many different devices and in different data silos. Sharing medical data among different sources is a big challenge due to regulatory , operational and security reasons. One potential solution is federated machine learning ,which a method that sends machine learning algorithms simultaneously to all data sources ,train models in each source and aggregates the learned models. This strategy allows utilization of valuable data without moving them. In this article, we proposed an adaptive boosting method that increases the efficiency of federated machine learning. Using intensive care unit data from hospital, we showed that LoAdaBoost federated learning outperformed baseline method and increased communication efficiency at negligible additional cost.

**ADSaS: Comprehensive Real-time Anomaly Detection System**

Since with massive data growth, the need for autonomous and generic anomaly detection system is increased. However, developing one stand-alone generic anomaly detection system that is accurate and fast is still a challenge. In this paper, we propose conventional time-series analysis approaches, the Seasonal Autoregressive Integrated Moving Average (SARIMA) model and Seasonal Trend decomposition using Loess (STL), to detect complex and various anomalies. Usually, SARIMA and STL are used only for stationary and periodic time-series, but by combining, we show they can detect anomalies with high accuracy for data that is even noisy and non-periodic. We compared the algorithm to Long Short Term Memory (LSTM), a deep-learning-based algorithm used for anomaly detection system. We used a total of seven real-world datasets and four artificial datasets with different time-series properties to verify the performance of the proposed algorithm.

• Customer Lifetime Value in Video Games Using Deep Learning and Parametric Models• An Internet of Things Oriented Approach for Water Utility Monitoring and Control• Naive Dictionary On Musical Corpora: From Knowledge Representation To Pattern Recognition• Device-to-Device Communication Facilitating Full-Duplex Cooperative Relaying Using Non-Orthogonal Multiple Access• A Distributed Augmented Reality System for Medical Training and Simulation• Molecular Sets (MOSES): A Benchmarking Platform for Molecular Generation Models• From Context to Concept: Exploring Semantic Relationships in Music with Word2Vec• Convergence Analysis of a Cooperative Diffusion Gauss-Newton Strategy• Structure-preserving constrained optimal trajectory planning of a wheeled inverted pendulum• Using ATLAS@Home to exploit extra CPU from busy grid sites• The polytope of legal sequences• Floquet time crystals in clock models• Ameso Optimization: a Relaxation of Discrete Midpoint Convexity• AdaFrame: Adaptive Frame Selection for Fast Video Recognition• Data-driven metasurface discovery• Flow Shape Design for Microfluidic Devices Using Deep Reinforcement Learning• A convex set theoretic approach to optimal hypothesis testing with application to distributed detection• On the Performance of Reed-Muller Codes with respect to Random Errors and Erasures• Optimal Transmission Using a Self-sustained Relay in a Full-Duplex MIMO System• Unifying Decision-Making: a Review on Evolutionary Theories on Rationality and Cognitive Biases• Smoothed Analysis of Multi-Item Auctions with Correlated Values• Fast and Flexible Indoor Scene Synthesis via Deep Convolutional Generative Models• Uncertainty propagation in neural networks for sparse coding• Consistency of Forecasts for the U.S. House of Representatives• Hand Gesture Recognition based on Radar Micro-Doppler Signature Envelopes• Survival and coexistence for a spatial population model with forest fire epidemics• Amplification by Shuffling: From Local to Central Differential Privacy via Anonymity• Unlabeled Compression Schemes Exceeding the VC-dimension• Existence and uniqueness of mild solution to fractional stochastic heat equation• Learning to Separate Multiple Illuminants in a Single Image• A random generator of Young tableaux based on the Schützenberger’s jeu de taquin and its applications• Leveraging Deep Stein’s Unbiased Risk Estimator for Unsupervised X-ray Denoising• Playing Soccer without Colors in the SPL: A Convolutional Neural Network Approach• On Implicit Filter Level Sparsity in Convolutional Neural Networks• 3D Semi-Supervised Learning with Uncertainty-Aware Multi-View Co-Training• Regression and Classification by Zonal Kriging• Leveraging Clinical Time-Series Data for Prediction: A Cautionary Tale• Covariance-Based Multiple-Impulse Rendezvous Design• Algorithms and Hardness for Diameter in Dynamic Graphs• Lobe, Edge, and Arc Transitivity of Graphs of Connectivity 1• Learning Finite State Representations of Recurrent Policy Networks• The Relevance of Bayesian Layer Positioning to Model Uncertainty in Deep Bayesian Active Learning• A Neuron-Network-Based Optimal Control of Ultra-Capacitors with System Uncertainties• A Rprop-Neural-Network-Based PV Maximum Power Point Tracking Algorithm with Short-Circuit Current Limitation• Blue-Noise Sampling on Graphs• Berry-Esseen type estimate and return sequence for parabolic iteration in the upper half-plane• Lightweight and Efficient Image Super-Resolution with Block State-based Recursive Network• The inverse Voronoi problem in graphs• Development of a Multi-Agent System for Optimal Sizing of a Commercial Complex Microgrid• Fast Algorithms for Knapsack via Convolution and Prediction• On least squares problems with certain Vandermonde–Khatri–Rao structure with applications to DMD• Eigenvalue Corrected Noisy Natural Gradient• Parallelizing greedy for submodular set function maximization in matroids and beyond• Are All Training Examples Created Equal? An Empirical Study• Decoupling between thermodynamics and dynamics during rejuvenation in colloidal glasses• Knotting statistics for polygons in lattice tubes• A Pseudospectral Approach to High Index DAE Optimal Control Problems• Rethinking clinical prediction: Why machine learning must consider year of care and feature aggregation• Restricted Boltzmann Machine with Multivalued Hidden Variables: a model suppressing over-fitting• Time Aggregation and Model Interpretation for Deep Multivariate Longitudinal Patient Outcome Forecasting Systems in Chronic Ambulatory Care• Active Learning in Recommendation Systems with Multi-level User Preferences• Two-sample Test of Community Memberships of Weighted Stochastic Block Models• Parsing R-CNN for Instance-Level Human Analysis• X*: Anytime Multiagent Planning With Bounded Search• Adversarial Examples as an Input-Fault Tolerance Problem• Local inversion-free estimation of spatial Gaussian processes• Millimeter Wave Systems for Wireless Cellular Communications• Foot Pressure from Video: A Deep Learning Approach to Predict Dynamics from Kinematics• DeepFlux for Skeletons in the Wild• An Energy-Efficient Transaction Model for the Blockchain-enabled Internet of Vehicles (IoV)• Virtual Class Enhanced Discriminative Embedding Learning• An Interpretable Model with Globally Consistent Explanations for Credit Risk• Modality-based Factorization for Multimodal Fusion• MISO NOMA Downlink Beamforming Optimization with Per-Antenna Power Constraints• Sampling Schemes for Accurate Reconstruction and Computation of Performance Parameters of Antenna Radiation Pattern• Towards Robust Lung Segmentation in Chest Radiographs with Deep Learning• Inferring Concept Prerequisite Relations from Online Educational Resources





### Like this:

Like Loading...


*Related*

