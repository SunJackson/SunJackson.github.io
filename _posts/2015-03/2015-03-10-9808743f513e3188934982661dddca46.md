---
layout:     post
title:      Getting Started with Apache Spark and Neo4j Using Docker Compose
subtitle:   转载自：http://www.kennybastani.com/2015/03/spark-neo4j-tutorial-docker.html
date:       2015-03-10
author:     noreply@blogger.com (Kenny Bastani)
header-img: img/background3.jpg
catalog: true
tags:
    - spark
    - graphs
    - installing
    - installed
    - movies
---

One tool solves for scaling the size, complexity, and retrieval of data, while the other is solving for the complexity of processing the enormity of data by distributed computation at scale. Both of these products are achieving this without sacrificing ease of use.

Inspired by this, I've been working to make the integration in [Neo4j Mazerunner](https://registry.hub.docker.com/u/kbastani/neo4j-graph-analytics) easier to install and deploy. I believe I've taken a step forward in this and I'm excited to announce it in this blog post.

## Announcing Spark Neo4j for Docker

I'll start by saying that I'm not announcing yet another new open source project. [Spark Neo4j](https://registry.hub.docker.com/u/kbastani/spark-neo4j) is a Docker image that uses the new [Compose](https://docs.docker.com/compose) tool to make it easier to deploy and eventually scale both Neo4j and Spark into their own clusters using [Docker Swarm](https://docs.docker.com/swarm).

Docker Compose is something I've been waiting awhile for. It's one pillar of Docker's answer to cluster computing using containers. This previously not so easy thing to do on Docker is now completely doable. In a simple way. That's really exciting.

Now let's get on to this business of processing graphs.

## Installing Spark Neo4j

The tutorial below is meant for Mac users. If you're on Linux, I've got you covered: [Spark Neo4j Linux install guide](https://github.com/kbastani/spark-neo4j/wiki/Linux-Install-Guide). 

This tutorial will walk you through:
- Setting up Spark Neo4j cluster using Docker
- Streaming log output from Spark and Neo4j
- Using Spark GraphX to calculate PageRank and Closeness Centrality on a celebrity graph
- Querying the results in Neo4j to find the most influential actor in Hollywood

### Requirements

Get Docker: [https://docs.docker.com/installation/](https://docs.docker.com/installation)

After you've installed Docker on Mac OSX with boot2docker, you'll need to make sure that the `DOCKER_HOST` environment variable points to the URL of the Docker daemon.

```
CTRL-C will exit the log view and bring you back to your current shell.
You can alter the above command to stream log output from all service containers simultaneously by removing `graphdb` from the last line.

Open the Neo4j browser
Now that you've confirmed Neo4j is running as a container in your Docker host, let's open up Neo4j's browser and test running PageRank on actors in a movie dataset.
Run the following command to open a browser window that navigates to Neo4j's URL.
$ open $(echo \"$(echo $DOCKER_HOST)\"|
 \sed 's/tcp:\/\//http:\/\//g'|
 \sed 's/[0-9]\{4,\}/7474/g'|
 \sed 's/\"//g')

This command finds the `$DOCKER_HOST` environment variable to generate the URL of Neo4j's browser. On Linux, this would be [http://localhost:7474](http://localhost:7474/.).

Import the movie graph
In the Neo4j console type `:play movies` and press enter. Follow the directions to import the movie sample dataset.

We'll use this dataset to test the Spark integration by running PageRank on the "Celebrity Graph" of actors.

Now that the movie dataset has been imported, let's create new relationships between actors who appeared together in the same movie. Copy and paste the following command into the Neo4j console and press `CTRL+Enter` to execute.
MATCH (p1:Person)-[:ACTED_IN]->(m:Movie),
 (p2:Person)-[:ACTED_IN]->(m)
CREATE (p1)-[:KNOWS]->(p2)

```

> 
You'll need to repeat this process if you open a new shell. Spark Neo4j requires the following environment variables: `DOCKER_HOST`, `DOCKER_CERT_PATH`, and `DOCKER_TLS_VERIFY`.


#### Stream log output from the cluster

> 
`CTRL-C` will exit the log view and bring you back to your current shell.
You can alter the above command to stream log output from all service containers simultaneously by removing `graphdb` from the last line.


#### Import the movie graph

> 
We'll use this dataset to test the Spark integration by running PageRank on the "Celebrity Graph" of actors.


> 
PageRank measures the probability of finding a node on the graph by randomly following links from one node to another node. It's a measure of a node's importance.


Now that we've generated our "Celebrity Graph" by inferring the `:KNOWS` relationship between co-actors, we can run PageRank on all nodes connected by this new relationship.

In the Neo4j console, copy and paste the following command:

```
:GET /service/mazerunner/analysis/pagerank/KNOWS

```

and press enter.

If everything ran correctly, we should have a result of:

```
{
 "result": "success"
}

```

> 
This means that the graph was exported to Spark for processing. 


#### Monitor Spark's log output

We can monitor the log output from Spark by returning to the terminal we used during setup from earlier. From that shell, run the following command:

```
:GET /service/mazerunner/analysis/closeness_centrality/KNOWS

```

> 
If your log output from the terminal is visible, you'll see a flurry of activity from Spark as it calculates this new metric. Don't blink, you might miss it.


#### Querying the metrics from Neo4j

You can now query on the newly calculated metrics from Neo4j. In the Neo4j browser, run the following command:

The results show which of the celebrities have the most influence in Hollywood.

> 
Go forth and process graphs.

