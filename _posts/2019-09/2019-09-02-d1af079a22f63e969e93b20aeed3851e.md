---
layout:     post
catalog: true
title:      Distilled News
subtitle:      转载自：https://analytixon.com/2019/09/03/distilled-news-1184/
date:      2019-09-02
author:      Michael Laux
tags:
    - learning
    - usually learn modeling
    - models
    - science
    - labeling
---

**AI Learning to land a Rocket(Lunar Lander) | Reinforcement Learning**

A brief introduction to Reinforcement Learning and solving the ‘Lunar Lander’ Environment in OpenAI gym by training a Deep Q-Network(DQN) agent.

**New Poll: Data Science Skills**

New KDnuggets poll asks 1) What Data Science/Machine Learning-related skills you currently have, and 2) Which skills you want to add or improve? If you are human, please vote and we will analyze and publish the results.

**Everything a Data Scientist Should Know About Data Management – But Was Afraid to Ask**

To be a real ‘full-stack’ data scientist, or what many bloggers and employers call a ‘unicorn,’ you’ve to master every step of the data science process – all the way from storing your data, to putting your finished product (typically a predictive model) in production. But the bulk of data science training focuses on machine/deep learning techniques; data management knowledge is often treated as an afterthought. Data science students usually learn modeling skills with processed and cleaned data in text files stored on their laptop, ignoring how the data sausage is made. Students often don’t realize that in industry settings, getting the raw data from various sources to be ready for modeling is usually 80% of the work. And because enterprise projects usually involve a massive amount of data that their local machine is not equipped to handle, the entire modeling process often takes place in the cloud, with most of the applications and databases hosted on servers in data centers elsewhere. Even after the student landed a job as a data scientist, data management often becomes something that a separate data engineering team takes care of. As a result, too many data scientists know too little about data storage and infrastructure, often to the detriment of their ability to make the right decisions at their jobs. The goal for this article is to provide a roadmap of what a data scientist in 2019 should know about data management – from types of databases, where and how data is stored and processed, to the current commercial options – so the aspiring ‘unicorns’ could dive deeper on their own, or at least learn enough to sound like one at interviews and cocktail parties.

**Scikit-Learn & More for Synthetic Dataset Generation for Machine Learning**

Synthetic Dataset Generation Using Scikit Learn & More It is becoming increasingly clear that the big tech giants such as Google, Facebook, and Microsoft are extremely generous with their latest machine learning algorithms and packages (they give those away freely) because the entry barrier to the world of algorithms is pretty low right now. The open source community and tools (such as Scikit Learn) have come a long way and plenty of open source initiatives are propelling the vehicles of data science, digital analytics, and machine learning. Standing in 2018 we can safely say that, algorithms, programming frameworks, and machine learning packages (or even tutorials and courses how to learn these techniques) are not the scarce resource but high-quality data is. This often becomes a thorny issue on the side of the practitioners in data science (DS) and machine learning (ML) when it comes to tweaking and fine-tuning those algorithms. It will also be wise to point out, at the very beginning, that the current article pertains to the scarcity of data for algorithmic investigation, pedagogical learning, and model prototyping, and not for scaling and running a commercial operation. It is not a discussion about how to get quality data for the cool travel or fashion app you are working on. That kind of consumer, social, or behavioral data collection presents its own issues. However, even something as simple as having access to quality datasets for testing out the limitations and vagaries of a particular algorithmic method, often turns out, not so simple.

**The Death of Centralized AI and the Rise of Open AI**

Centralized AI is giving way to more democratic AI systems, which are becoming more and more accessible to data scientists, both through code and through open ecosystems.

**Types of Bias in Machine Learning**

The sample data used for training has to be as close a representation of the real scenario as possible. There are many factors that can bias a sample from the beginning and those reasons differ from each domain (i.e. business, security, medical, education etc.)1. Sample Bias2. Prejudice Bias3. Confirmation Bias4. Group attribution Bias

**Probability Learning III: Maximum Likelihood**

After the two previous posts about Bayes’ Theorem, I got a lot of requests asking for a deeper explanation on the maths behind the regression and classification uses of the theorem. The next series post are the answer to those requests. However, I think that the maths behind Bayes will be better understood if we first cover the theory and maths underlying another fundamental method of probabilistic machine learning: Maximum Likelihood. This post will be dedicated to explaining it. The previous articles can be found here and here. I suggest reading them before tackling the next ones to follow along with the beautiful story-line that we are creating together.

**What is Explainable AI and Why is it Needed?**

Imagine an advanced fighter aircraft is patrolling a hostile conflict area and a bogie suddenly appears on radar accelerating aggressively at them. The pilot, with the assistance of an Artificial Intelligence co-pilot, has a fraction of a second to decide what action to take – ignore, avoid, flee, bluff, or attack. The costs associated with False Positive and False Negative are substantial – a wrong decision that could potentially provoke a war or lead to the death of the pilot. What is one to do…and why?

**Deep Learning Next Step: Transformers and Attention Mechanism**

With the pervasive importance of NLP in so many of today’s applications of deep learning, find out how advanced translation techniques can be further enhanced by transformers and attention mechanisms.

**Labeling with Active Learning**

We are in the age of data. In recent years, many companies have already started collecting large amounts of data about their business. On the other hand, many companies are just starting now. If you are working in one of these companies, you might be wondering what can be done with all that data. What about using the data to train a supervised machine learning (ML) algorithm? The ML algorithm could perform the same classification task a human would, just so much faster! It could reduce cost and inefficiencies. It could work on your blended data, like images, text documents, and just simple numbers. It could do all those things and even get you that edge over the competition. However, before you can train any decent supervised model, you need ground truth data. Usually, supervised ML models are trained on old data records that are already somehow labeled. The trained models are then applied to run label predictions on new data. And this is the ugly truth: Before proceeding with any model training, any classification problem definition, or any further enthusiasm in gathering data, you need a sufficiently large set of correctly labeled data records to describe your problem. And data labeling – especially in a sufficiently large amount – is … expensive.

**New Model for Word Embeddings which are Resilient to Misspellings (MOE)**

Traditional word embeddings are good at solving lots of natural language processing (NLP) downstream problems such as documentation classification and named-entity recognition (NER). However, one of the drawbacks is a lack of capability on handling out-of-vocabulary (OOV). Facebook introduces Misspelling Oblivious (word) Embeddings (MOE) which overcomes this limitation. MOE extends fastText architecture to achieve it. Therefore, this story goes through the fastText training method and architecture before talking about MOE.

**Comparing the Feature Extraction Algorithms for Images**

There are many algorithms out there dedicated to feature extraction of images. Many of them work similarly to a spirograph, or a Roomba. The little bot goes around the room bumping into walls until it, hopefully, covers every speck off the entire floor. Similarly, an algorithm will travel around an image picking up interesting bits and pieces of information from that image. This process is called feature detection.

**Emoji Analytics**

Emoji is becoming a global language understandable by anyone who expresses… emotion. With the pervasiveness of these little Unicode blocks, we can perform analytics on their use throughout social media to gain insight into sentiments around the world.

**Install Tensorflow 1.13 on Ubuntu 18.04 with GPU support**

Why not install 2.0 version? Tensorflow 2.0 in alpha now – stable release is planned in Q2 this year. If you want try this now, check the official guide from Tensorflow Team here. As usually, I have added the installation process of the latest kernel which has a long term release (in this case 4.19). You can check information about the kernel here. This part is optional and requires you to sign an unsigned kernel – which can be dangerous – so feel free to skip this part. So, let’s begin!

### Like this:

Like Loading...
