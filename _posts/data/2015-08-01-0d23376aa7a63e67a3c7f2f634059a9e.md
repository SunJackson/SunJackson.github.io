---
layout:     post
title:      Spark DataFrames
subtitle:   转载自：http://learningwithdata.com/spark-dataframes.html
date:       2015-08-01
author:     Tyler Folkman
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - spark
    - tool
    - reduce
    - learning
    - libraries
    - library
    - api
    - scala
    - languages
    - source version
    - database like
---

[Spark](https://spark.apache.org/) is a really awesome tool to easily do distributed computations in order to process large-scale data. To be honest, most people probably don't need spark for their own side projects - most of these data will fit in memory or work well in a traditional database like PostgreSQL. That being said, there is a good chance you might need Spark if you are doing data science type work for your job. A lot of companies have a tremendous amount of data and Spark is a great tool to help effectively process these large data.

In case you are not familiar with the map reduce structure, here is a very [brief introduction](http://hci.stanford.edu/courses/cs448g/a2/files/map_reduce_tutorial.pdf). Spark is based on this map reduce paradigm, but has made some nice improvements to the open source version Hadoop. A few of these improvements include the ability to cache data to memory, a simpler API supported in multiple languages (scala, python, and java I believe), and some really nice libraries - including a machine learning and SQL library. In my opinion, these additions really make Spark a powerful tool with a realtively easy learning curve.

My goal today is to show you how to get started with Spark and get introduced to Spark data frames.
