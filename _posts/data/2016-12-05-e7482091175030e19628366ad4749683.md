---
layout:     post
title:      Using Keras' Pretrained Neural Networks for Visual Similarity Recommendations
subtitle:   转载自：http://blog.ethanrosenthal.com/2016/12/05/recasketch-keras/
date:       2016-12-05
author:     Ethan Rosenthal
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - features
    - recommendation models
    - thumbnail images
    - similarity
    - similarities
    - sketchfab
    - deep
    - keras
    - recommender
    - thumbnails
    - promising
    - fancy
    - people
    - trained
    - christopher
    - applications
---

To close out our series on building recommendation models using [Sketchfab data](http://blog.ethanrosenthal.com/2016/10/09/likes-out-guerilla-dataset), I will venture far from the [previous](http://blog.ethanrosenthal.com/2016/10/19/implicit-mf-part-1) [posts'](http://blog.ethanrosenthal.com/2016/11/07/implicit-mf-part-2) factorization-based methods and instead explore an unsupervised, deep learning-based model. You'll find that the implementation is fairly simple with remarkably promising results which is almost a smack in the face to all of that effort put in earlier.

We are going to build a model-to-model recommender using thumbnail images of 3D [Sketchfab](https://sketchfab.com/.) models as our input and the *visual similarity* between models as our recommendation score. I was inspired to do this after reading Christopher Bonnett's [post](http://cbonnett.github.io/Insight.html) on product classification, so we will follow a similar approach.

Since our goal is to measure visual similarity, we will need to generate features from our images and then calculate some similarity measure between different images using said features. Back in the day, maybe one would employ fancy wavelets or SIFT keypoints or something for creating features, but this is the Era of Deep Learning and manual feature extraction is for old people.

Staying on-trend, we will use a pretrained neural network (NN) to extract features. The NN was originally trained to classify images among 1000 labels (e.g. "dog", "train", etc...). We'll chop off the last 3 fully-connected layers of the network which do the final mapping between deep features and class labels and use the fourth-to-last layer as a long feature vector describing our images.

Thankfully, all of this is extremely simple to do with the pretrained models in [Keras](https://keras.io/). Keras allows one to easily build deep learning models on top of either Tensorflow or Theano. Keras also now comes with pretrained models that can be loaded and used. For more information about the available models, visit the [Applications](https://keras.io/applications) section of the documentation. For our purposes, we'll use the [VGG16](https://keras.io/applications#vgg16) model because that's what other people seemed to use and I don't know enough to have a compelling reason to stray from the norm.

Our task is now as follows:

1. Load and process images

1. Feed images through NN.

1. Calculate image similarities.

1. Recommend models!


The first step, which we won't go through here, was to download all of the image thumbnails. There seems to be a standard thumbnail for each Sketchfab model accessible via their API, so I added a function to the [rec-a-sketch](https://github.com/EthanRosenthal/rec-a-sketch) [crawl.py](https://github.com/EthanRosenthal/rec-a-sketch/blob/master/crawl.py) script to automate downloading of all the thumbnails.

Let's load in our libraries and take a look at one of these images.
