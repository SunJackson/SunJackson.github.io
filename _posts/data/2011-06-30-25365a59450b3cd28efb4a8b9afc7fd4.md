---
layout:     post
title:      LLE comes in different flavours
subtitle:   转载自：http://fa.bianp.net/blog/2011/lle-comes-in-different-flavours/
date:       2011-06-30
author:     Fabian Pedregosa
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - http
    - lle
    - manifold
    - mode
    - arpack
    - vanderplas
    - implementation
    - implemented
---

I haven't worked in the manifold module since [last time](http://fseoane.net/blog/2011/manifold-learning-in-scikit-learn), yet thanks
to [Jake VanderPlas](http://www.astro.washington.edu/users/vanderplas) there are some cool features I can talk about.
First of, the ARPACK backend is finally working and gives factor one
speedup over the [lobcpg + PyAMG approach](http://fseoane.net/blog/2011/locally-linear-embedding-and-sparse-eigensolvers). The key is to use ARPACK's
shift-invert mode instead of the regular mode, a subtle change that
drove me crazy for weeks and that Jake spotted by comparing it to his
[C++ LLE implementation](https://github.com/jakevdp/pyLLE). More importantly, some variants of Locally
Linear Embedding (LLE) have been added to the module: [Modified LLE](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.70.382),
[Hessian LLE](http://www-stat.stanford.edu/~donoho/Reports/2003/HessianEigenmaps.pdf) and [LTSA](http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.3693). These seem to generate better solutions than
the classical LLE with timings that are not far apart. All the LLE
variants currently implemented can be seen in [this example](http://scikit-learn.sourceforge.net/dev/auto_examples/manifold/plot_compare_methods.html), where
they are applied to an S-shaped dataset.
![](http://fseoane.net/blog/wp-content/uploads/2011/06/manifold_methods.png)

![](http://fseoane.net/blog/wp-content/uploads/2011/06/manifold_methods.png)

