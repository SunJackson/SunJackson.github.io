---
layout:     post
title:      AlphaGo Zero Is Not A Sign of Imminent Human-Level AI
subtitle:   转载自：http://www.andreykurenkov.com/writing/is-alphago-zero-overrated/
date:       2018-03-30
author:     contact@andreykurenkov.com
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - ai
    - learns
    - learned
    - learning
    - humans
    - humanity
    - http
    - games
    - playing
    - played
    - deep
    - narrowness
    - researchers
    - neural
    - alphago
    - impressive
    - hard problems
    - definite
    - board
    - hype
    - purely
    - based
    - computational
    - computers
    - strategies
    - level
    - enable future
    - agi
---

## Why AlphaGo Zero Is Great

Let’s start with the coverage about DeepMind’s recent successor to AlphaGo, AlphaGo Zero:

Point being: AlphaGo Zero (which we’ll go ahead and shorten to AG0) is arguably the most impressive and definitely the most praised recent AI accomplishment. Roughly speaking, AG0 is just a [Deep](http://theai.wiki/Deep%20Learning) [Neural Network](http://theai.wiki/Neural%20Network) that takes the current state of a Go board as input, and outputs a Go move. Not only is this much simpler than the original AlphaGo, but it is also trained purely through self-play (pitting different AlphaGo Zero neural nets against each other; the original AlphaGo was ‘warmed up’ by training to mimic human expert Go players). It’s not exactly right that it learns ‘with no human help’, since the very rules of Go are hand-coded by humans rather than learned by AlphaGo, but the basic idea that it learns through self-play rather without any mimicry of human Go players is correct. I’ll let the key researcher behind it expand on that:

So, surely DeepMind’s demonstration that an AI algorithm can achieve superhuman Go and Chess play purely through self-play is a testament to the usefulness of such techniques for solving the hard problems of AI? Well, to some extent yes — it has taken the field decades to get here, since the [branching factor](http://theai.wiki/Branching%20Factor) of Go does indeed make it a challenging board game. This is also the first a time the same Deep Learning algorithm was used to crack both Chess and Go, and was not specifically tailored for it such as was the case with [Deep Blue](https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)) (the much heralded machine of IBM that was the first to beat humanity’s best at Chess) and the original AlphaGo. Therefore, AG0 is certainly monumental and exciting work (and great PR).
![](http://www.andreykurenkov.com/content/editorials/images/is-alphago-zero-overrated/history.png)


## Why AlphaGo Zero Is Not That Great

With those positive things having been said, some perspective: AG0 is not really a testament to the usefulness of such techniques for solving the hard problems of AI. You see, Go is only hard within the context of the simplest category of AI problems. That is, it is in the category of problems with every property that makes a learning task easy: it is [deterministic, discrete, static, fully observable, fully-known, single-agent, episodic](https://en.wikibooks.org/wiki/Artificial_Intelligence/AI_Agents_and_their_Environments), cheap and easy to simulate, easy to score… Literally the only challenging aspect of Go is its huge branching factor. Predictions that [AGI (Artificial General Intelligence)](http://theai.wiki/AGI) is imminent based only on AlphaGo’s success can be safely dismissed — [the real world is vastly more complex than a simple game like Go](https://medium.com/@karpathy/alphago-in-context-c47718cb95a5). Even fairly similar problems that have most but not all of the properties that make a learning task easy, [such as the strategic video game DotA II](http://www.andreykurenkov.com/content/news/openai-dota-ii), are far beyond our grasp right now.
![](http://www.andreykurenkov.com/content/editorials/images/is-alphago-zero-overrated/venn.svg)


Another important thing to understand beyond the categorical simplicity of Go is its narrowness. AG0 is a definite example of [Weak AI](http://theai.wiki/Weak%20AI), also known as narrow AI. Weak AI agents are characterized by only being able to perform one ‘narrow’ task, such as playing a 19 by 19 game of Go. Though AG0 has the impressive ability to learn to play 3 different board games, it does so separately per game . And, it can only learn a vary narrow range of games: basically just 2-player grid based board games without any necessary memorization of prior positions or moves.

So, while AG0 works and its achievement is impressive, it is fundamentally similar to Deep Blue in being an expensive system engineered over many years with millions of dollars of investment purely for the task of playing a game — nothing else. Though Deep Blue was great PR for IBM, all that work and investment is not usually seen as having contributed much to the progress of broader AI research, having been ultra-specific to solving the problem of playing Chess. Just as with the algorithms that power AG0, human-tweaked heuristics and sheer computational brute force can definitely be used to solve some challenging problems — but they ultimately did not get us far beyond Chess, not even to Go. We should ask ourselves: can the techniques behind AG0 get us far beyond Go?

Probably, yes; the algorithms behind AG0 (Deep Learning and self-play) are inherently more general than human-defined heuristics and brute computation. Still, it is important to understand and remember the parallels between Deep Blue and AG0: **at the end of the day, both Deep Blue and AG0 are narrow AI programs that were built (at least in part) as PR boons for large companies by huge teams at the costs of millions of dollars; they deal with problems which are difficult for humans, but which are also relatively simple for computers.**
![](http://www.andreykurenkov.com/content/editorials/images/is-alphago-zero-overrated/ibm.png)


I write this not to be controversial or take away from DeepMind’s fantastic work, but rather to fight against all the unwarranted hype AG0’s success has generated and encourage more conversation about the limitations of deep learning and self-play. More people need to [step up](https://arxiv.org/abs/1801.05667) and [say this kind of stuff](https://www.alexirpan.com/2018/02/14/rl-hard.html) for the general public as well as the AI research community to not be led astray by hype and PR.
![](http://www.andreykurenkov.com/content/editorials/images/is-alphago-zero-overrated/hype.png)


And all that aside, it should still be asked: might there be a better for AI agents to learn to play Go? The very name AlphaGo Zero is in reference to the idea that the model learns to play Go [“from scratch”](https://deepmind.com/blog/alphago-zero-learning-scratch), without any further human input or explanation. But is learning ‘from scratch’ really such a good thing? Imagine you knew nothing about Go and decided to start learning it. You would definitely read the rules, some high level strategies, recall how you played similar games in the past, get some advice… right? And it indeed at least partially because of the learning ‘from scratch’ **limitation** of AlphaGo Zero that it is not truly impressive compared to human learning: like Deep Blue, it still relies on seeing orders of magnitude more Go games and planning for orders of magnitude more scenarios in any given game than any human ever does.
![](http://www.andreykurenkov.com/content/editorials/images/is-alphago-zero-overrated/go_gif.gif)


## TLDR

So, let’s sum up: though AlphaGo and AG0’s achievements are historic and impressive, they also represent little if any progress in tackling the truly hard problems of AI (not to mention AGI). Still, as with any field all AI researchers stand on the shoulders of their predecessors; though these techniques may not foreshadow the coming of AGI, they are definitely part of the Deep Learning Revolution the field is still in the midst of and the ideas that they are based on will doubtlessly enable future progress. As with Deep Learning as a whole, it is important to appreciate these fantastic accomplishments for the field of AI without losing perspective about their limitations.
