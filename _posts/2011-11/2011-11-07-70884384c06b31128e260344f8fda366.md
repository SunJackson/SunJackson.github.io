---
layout:     post
title:      Filtering out duplicate pandas.DataFrame rows
subtitle:   转载自：http://wesmckinney.com/blog/filtering-out-duplicate-dataframe-rows/
date:       2011-11-07
author:     Wes McKinney
header-img: img/background2.jpg
catalog: true
tags:
    - method
    - python
    - dataframe
    - groupby
    - function
---





** Mon 07 November 2011

 

[Sean Taylor](http://twitter.com/#!/seanjtaylor) recently alerted me to the fact that there wasn't an easy way to filter out duplicate rows in a pandas DataFrame. R has the [duplicated](http://stat.ethz.ch/R-manual/R-devel/library/base/html/duplicated.html) function which serves this purpose quite nicely. The R method's implementation is kind of kludgy in my opinion (from "The data frame method works by pasting together a character representation of the rows"), but in any case I set about writing a Python version from first principles.

So a `drop_duplicates` method should be able to either consider a subset of the columns or all of the columns for determining which are "duplicates". It occurred to me that a reasonably fast and efficient way to do this was to use [GroupBy](http://pandas.sourceforge.net/groupby.html). You have to know a bit about the internals, but it's fairly straightforward otherwise:

For a faster and more direct implementation in Cython, I decided to use a list of tuples and a dict to keep track of whether a row has been "seen" or not:

Aside: the `uint8` and casting to `np.bool_` thing is there because the buffer interface doesn't work quite right with boolean arrays in Python 2.5. So as soon as I drop Python 2.5 compatibility (probably around the end of the year), I'll go through and fix that stuff up. As a second aside, using a dict with dummy keys was coming out a bit faster than using a set in Cython, for reasons unknown to me.

So, on the Python side, the new DataFrame function just takes the boolean vector returned by that Cython function and uses it to select out the rows:

Not passing any particular column or columns is the same as passing all of them.

I was impressed by the performance:

For reference, it's roughly twice as fast as the equivalent R code (though I'm still using R 2.11.1 -- time to upgrade to 2.14!), but perhaps not too shocking as the R function is converting each row into a string first.
