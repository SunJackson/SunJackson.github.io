---
layout:     post
title:      It's embarassing, really
subtitle:   转载自：http://fastml.com/its-embarassing-really/
date:       2018-07-19
author:     未知
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - https
    - datasets
    - awards
    - awarded
    - kaggle
    - images
    - bitcoin
    - prices
    - robotics
    - grasped
    - originality
    - historical
    - likes
    - recommendations
    - positively
    - recommender
    - goodbooks
    - team chose
    - prizes originally
    - gradient
    - learning
    - arm
    - ethereum
    - winners
    - favicons
---

In August, we published the first version of [goodbooks-10k](https://github.com/zygmuntz/goodbooks-10k), a new dataset for book recommendations. By pure chance, that coincided with a proclamation of Kaggle Datasets Awards. Oh, how we hoped to get one!










The [prize announcement](https://www.kaggle.com/general/39068) filled us with great sadness, as the Kaggle team chose datasets we would never suspect of having a chance. To be clear, there’s nothing wrong with them. You just could wonder if there weren’t any better choices among over 350 alternatives.

Kaggle can give their money to whomever they desire, so let’s familiarize ourselves with the criteria they declared:

![](http://fastml.com/images/kaggle-dataset-awards/criteria.png)


Quality, impact, and reach.

### The actual winners

The [dataset that grasped](https://www.kaggle.com/ugocupcic/grasping-dataset) the jury’s attention the most comes from a simulation of a robot holding a ball. This is certainly a groundbreaking work, as far as simulated robot arm kinematics are concerned [[1](http://www.cs.toronto.edu/~delve/data/pumadyn/desc.html)] [[2](http://www.cs.toronto.edu/~delve/data/kin/desc.html)] [[3](http://fastml.com/very-fast-denoising-autoencoder-with-a-robot-arm#data)]. Moreover, according to the justification, the dataset *combines two exciting fields of research: robotics and deep learning.* It does so in 20 numerical columns. Any child will tell you that any data with such characteristic positively calls for deep learning. Gradient boosting just wouldn’t work here.

Markers of engagement? Yuuuge: three likes (after the announcement) and 24 downloads. How’s that for impact.

![](http://fastml.com/images/kaggle-dataset-awards/grasp.jpg)


The second dataset is [Cryptocurrency Historical Prices](https://www.kaggle.com/sudalairajkumar/cryptocurrencypricehistory), because the best we can hope for here is a dataset updated by hand once a week (for now, anyway). Not that there are any sources with current data available for instant download in a variety of formats, for Bitcoin [[1](https://www.quandl.com/collections/markets/bitcoin-data)] [[2](https://blockchain.info/charts/market-price)] [[3](http://api.bitcoincharts.com/v1/csv)], Ethereum [[1](https://poloniex.com/exchange#btc_eth)] [[2](https://etherscan.io/chart/etherprice)] [[3](https://etherchain.org/api/statistics/price)], and any other God-forsaken cryptocurrency the Chinese entrepreneurs are warming the air with their ASICs for. And clearly, nothing of that nature have ever existed on Kaggle before [[1](https://www.kaggle.com/mczielinski/bitcoin-historical-data)] [[2](https://www.kaggle.com/team-ai/bitcoin-price-prediction)] [[3](https://www.kaggle.com/jessevent/all-crypto-currencies)] [[4](https://www.kaggle.com/kingburrito666/ethereum-historical-data)].

To be fair, though, this one got relatively many upvotes and downloads, as opposed to number one and three. At least some people liked it.

The third choice is perhaps the most curious for us. It’s a [collection of favicons](https://www.kaggle.com/colinmorris/favicons), tiny images that browsers use to represent websites in tabs, in the URL bar, and in bookmarks. 778 MB of favicons. What THAT has to do with data science? If this question leaves you scratching your head, well, apparently *there are lots of opportunities to explore image processing and computer vision techniques in Kernels with this dataset*. Yep, absolutely. The era of research on 32x32 images is just around the corner.

As you would expect, the community is in feeding frenzy over this one, as indicated by 6 likes total.

![](http://fastml.com/images/kaggle-dataset-awards/winners.png)


### There’s more

Twisting a knife in the wound, the scoring team also chose runners up: two riveting - well, not really - tweet archives concerning US domestic issues, and one offshore dataset which managed to spark even less interest: about people who haven’t turned up at job interviews in India, if you must know.

In contrast, these seemed to us like potential competitors to [goodbooks-10k](https://www.kaggle.com/zygmunt/goodbooks-10k), considering originality, downloads and likes: [[1](https://www.kaggle.com/goldenoakresearch/us-household-income-stats-geo-locations)] [[2](https://www.kaggle.com/snapcrack/all-the-news)] [[3](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)]. Not to mention SURECOMMENDER’s antics [[1](https://www.kaggle.com/loveall/cervical-cancer-risk-classification)] [[2](https://kaggle2.blob.core.windows.net/forum-message-attachments/219049/7248/20170907_012156.jpg)], which have been quite enjoyable to watch.

To further add insult to injury: *goodbooks-10k* didn’t even merit a mention, but the next day a notebook and recommender built on the dataset were chosen to receive a [weekly kernel award](https://www.kaggle.com/general/37924#219332). Go figure.

Let’s conclude with some good news: the datasets prizes, originally advertised as one-time event, will be awarded monthly from now on, through the end of the year! After this exciting first round we are definitely keen to partake, as we are sure many smart people are.
