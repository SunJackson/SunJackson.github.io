---
layout:     post
title:      Translating SQL to Pandas, Part 1
subtitle:   转载自：http://www.gregreda.com/2013/01/23/translating-sql-to-pandas-part1/
date:       2013-01-23
author:     Greg Reda
header-img: img/background1.jpg
catalog: true
tags:
    - pandas
    - towed
    - table
    - functionality
    - functions
---

*I wrote a three part pandas tutorial for SQL users that you can find [here](http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures)*.

*UPDATE: If you're interested in learning pandas from a SQL perspective and would prefer to watch a video, you can find video of my 2014 PyData NYC talk [here](http://reda.io/sql2pandas).*

For some reason, I've always found SQL to a much more intuitive tool for exploring a tabular dataset than I have other languages (namely R and Python).

If you know SQL well, you can do a whole lot with it, and since data is often in a relational database anyway, it usually makes sense to stick with it. I find that my workflow often includes writing a lot of queries in SQL (using [Sequel Pro](http://www.sequelpro.com/)) to get the data the way I want it, reading it into R (with [RStudio](http://www.rstudio.com/)), and then maybe a bit more exploration, modeling, and visualization (with [ggplot2](http://ggplot2.org/)).

Not too long ago though, I came across [Wes McKinney](http://blog.wesmckinney.com/)'s [pandas](http://pandas.pydata.org/.) package and my interest was immediately piqued. Pandas adds a bunch of functionality to Python, but most importantly, it allows for a DataFrame data structure - much like a database table or R's data frame.

Given the great things I've been reading about pandas lately, I wanted to make a conscious effort to play around with it. Instead of my typical workflow being a couple disjointed steps with SQL + R + (sometimes) Python, my thought is that it might make sense to have pandas work its way in and take over the R work. While I probably won't be able to completely give up R (too much ggplot2 love over here), I get bored if I'm not learning something new, so pandas it is.

I intend to document the process a bit - hopefully a couple posts illustrating the differences between SQL and pandas (and maybe some R too).

Throughout the rest of this post, we're going to be working with data from the [City of Chicago's open data](https://data.cityofchicago.org/.) - specifically the [Towed Vechicles data](https://data.cityofchicago.org/Transportation/Towed-Vehicles/ygr5-vcbg).

#### Loading the data

##### Using SQLite

To be able to use SQL with this dataset, we'd first have to create the table. Using [SQLite](http://www.sqlite.org/) syntax, we'd run the following:

Because SQLite [uses a very generic type system](http://www.sqlite.org/datatype3.html), we don't get the strict data types that we would in most other databases (such as MySQL and PostgreSQL); therefore, all of our data is going to be stored as text. In other databases, we'd store tow_date as a date or datetime field.

Before we read the data into SQLite, we need to tell the database to that the fields are separated by a comma. Then we can use the import command to read the file into our table.

Note that the downloaded CSV contains two header rows, so we'll need to delete those from our table since we don't need them.

We should have 5,068 records in our table now (note: the City of Chicago regularly updates this dataset, so you might get a different number).

##### Using Python + pandas

Let do the same with [pandas](http://pandas.pydata.org/.) now.

The read_csv function in pandas actually allowed us to skip the two header columns and translate the tow_date field to a datetime field.

Let's check our count just to make sure.

#### Selecting data

##### SQL

Selection data with SQL is fairly intuitive - just SELECT the columns you want FROM the particular table you're interested in. You can also take advantage of the LIMIT clause to only see a subset of your data.

Additionally, you can throw a WHERE or ORDER BY (or both) into your queries for proper filtering and ordering of the data returned:

##### Python + pandas

Let's do some of the same, but this time let's use pandas:

Because pandas is built on top of [NumPy](http://www.numpy.org/), we're able to use [boolean indexing](http://pandas.pydata.org/pandas-docs/dev/indexing.html#boolean-indexing). Since we're going to replicate similar statements to the ones we did in SQL, we know we're going to need towed cars from TX made by KIA.

##### Conclusion, Part 1

This was obviously a very basic start, but there are a lot of good things about pandas - it's certainly concise and readable. Plus, since it works well with the various science + math packages ([SciPy](http://www.scipy.org/.), [NumPy](http://www.numpy.org/), [Matplotlib](http://matplotlib.org/), [statsmodels](http://statsmodels.sourceforge.net/), etc.), there's the potential to work almost entirely in one language for analysis tasks.

I plan on covering aggregate functions, pivots, and maybe some matplotlib in my next post.
