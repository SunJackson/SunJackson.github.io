---
layout:     post
title:      High performance database joins with pandas DataFrame, more benchmarks
subtitle:   转载自：http://wesmckinney.com/blog/high-performance-database-joins-with-pandas-dataframe-more-benchmarks/
date:       2012-01-05
author:     Wes McKinney
header-img: img/background1.jpg
catalog: true
tags:
    - tables
    - merge
    - joins
    - pandas
    - left join
---





** Thu 05 January 2012

 

I posted a [brief article](http://wesmckinney.com/blog?p=395) with some preliminary benchmarks for the new merge/join infrastructure that I've built in pandas. I compared the performance with `base::merge` in R which, as various [folks](http://twitter.com/#!/hadleywickham) in the R community have pointed out, is fairly slow. There are a few other more intelligently-implemented functions available in CRAN, in particular `plyr::join` in [plyr](http://plyr.had.co.nz/) and the merge implemented for `data.table` objects in the [data.table](http://cran.r-project.org/web/packages/data.table/index.html) package.

Lastly, [Sean Taylor](http://twitter.com/#!/seanjtaylor) contributed a [benchmark for SQLite3](http://twitter.com/#!/seanjtaylor/status/154248028113477632), by accounts the most widely deployed SQL engine.

So anyway, here are the two benchmarks I'm interested in to get a sense of the large-ish data runtime of these algorithms:


Many-to-one joins. In these benchmarks I have a 80,000 row table with 10 copies of 8,000 key pairs and an 8,000 row table with a single copy of another 8,000 key pairs, only 6,000 of which are found in the larger table. The result of a left join between these tables should have 80,000 rows, an inner join 60,000, and an outer join 82,000.


Many-to-many joins. To keep things simple I use the same tables as above except the right able is the table above stacked on itself. You can do the combinatorics here, but the outer join between these two tables has 144,000 rows.
**Note:** that `plyr::join` does not implement (or least I've been told to avoid) many-to-many joins so I only run the many-to-one benchmarks for that.


I've normalized the results by the minimum runtime (which is pandas in all cases):

**UPDATE (1/6/2012):** [Jared Lander](https://twitter.com/#!/jaredlander) pointed out that `data.table` is capable of much faster left and right joins by using the syntax `left[right]` instead of `merge(left, right, all.y=True)`. I updated the benchmarks below and added the right join results which shows `data.table` performing very admirably.





|pandas vs R merge benchmarks





|**Many-to-one**


|




|
|pandas
|data.table
|plyr
|base::merge





**inner**
| 1
| 5.905
| 6.35
| 13.29



|**outer**
| 1
| 10.05
| 9.209
| 20.25



|**left**
| 1
| 2.849
| 5.918
| 14.93



|**right**
| 1
| 2.05
| 2.923
| 16.91







|**Many-to-many**



|


|
|pandas
|data.table
|plyr
|base::merge





**inner**
| 1
| 5.194
| 5.223
| 18.87



|**outer**
| 1
| 10
| 6.903
| 33.75



|**left**
| 1
| 2.528
| 4.688
| 24.46



|**right**
| 1
| 1.681
| 2.05
| 25.24









SQLite3 Benchmarks

A bit of care needs to be taken with SQLite3 benchmarks because the time to fetch the table from the database cursor (even though this is an *in-memory* SQLite database) is **very** significant. The performance as you can imagine is also quite different with and without indexes.

Here is the basic code to insert the data into SQLite:

With no indexes, here is a comparison of **just** the SQL execution time vs. the total pandas execution time for the many-to-one case described above:





|
|sqlite3
|pandas





|inner
| 0.02328
| 0.01799



|outer
| 0.02324
| 0.01943



|left
| 0.02324
| 0.01923



